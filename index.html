<!DOCTYPE html>
<html>
<head>
<title>Paper collected by Wang</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<style type="text/css">


/* BODY
=============================================================================*/

body {
  font-family: Helvetica, arial, freesans, clean, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  color: #333;
  background-color: #fff;
  padding: 20px;
  max-width: 960px;
  margin: 0 auto;
}

span#pid {
  color:red;
  
}
span#filename{
  font-style: oblique;
}

span#title{
  font-family: Times New Roman, freesans, clean, sans-serif;
  font-style: italic;
  font-size: 20px;
  border:1px solid #B50;
}
span#abs{
  font-family: Times New Roman, freesans, clean, sans-serif;
  font-style: oblique;
  font-size: 18px;
}
</style>
</head>
<body>

</p></br></br><div id='section'>Paperid: <span id='pid'>1, <a href='https://arxiv.org/pdf/2510.11133.pdf' target='_blank'>https://arxiv.org/pdf/2510.11133.pdf</a></span>   <span><a href='https://github.com/NancyQuris/TACT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yingnan Liu, Rui Qiao, Mong Li Lee, Wynne Hsu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.11133">Test-Time Adaptation by Causal Trimming</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation aims to improve model robustness under distribution shifts by adapting models with access to unlabeled target samples. A primary cause of performance degradation under such shifts is the model's reliance on features that lack a direct causal relationship with the prediction target. We introduce Test-time Adaptation by Causal Trimming (TACT), a method that identifies and removes non-causal components from representations for test distributions. TACT applies data augmentations that preserve causal features while varying non-causal ones. By analyzing the changes in the representations using Principal Component Analysis, TACT identifies the highest variance directions associated with non-causal features. It trims the representations by removing their projections on the identified directions, and uses the trimmed representations for the predictions. During adaptation, TACT continuously tracks and refines these directions to get a better estimate of non-causal features. We theoretically analyze the effectiveness of this approach and empirically validate TACT on real-world out-of-distribution benchmarks. TACT consistently outperforms state-of-the-art methods by a significant margin.
<div id='section'>Paperid: <span id='pid'>2, <a href='https://arxiv.org/pdf/2510.03258.pdf' target='_blank'>https://arxiv.org/pdf/2510.03258.pdf</a></span>   <span><a href='https://github.com/ycarobot/POEM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chang'an Yi, Xiaohui Deng, Shuaicheng Niu, Yan Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.03258">POEM: Explore Unexplored Reliable Samples to Enhance Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) aims to transfer knowledge from a source model to unknown test data with potential distribution shifts in an online manner. Many existing TTA methods rely on entropy as a confidence metric to optimize the model. However, these approaches are sensitive to the predefined entropy threshold, influencing which samples are chosen for model adaptation. Consequently, potentially reliable target samples are often overlooked and underutilized. For instance, a sample's entropy might slightly exceed the threshold initially, but fall below it after the model is updated. Such samples can provide stable supervised information and offer a normal range of gradients to guide model adaptation. In this paper, we propose a general approach, \underline{POEM}, to promote TTA via ex\underline{\textbf{p}}loring the previously unexpl\underline{\textbf{o}}red reliabl\underline{\textbf{e}} sa\underline{\textbf{m}}ples. Additionally, we introduce an extra Adapt Branch network to strike a balance between extracting domain-agnostic representations and achieving high performance on target data. Comprehensive experiments across multiple architectures demonstrate that POEM consistently outperforms existing TTA methods in both challenging scenarios and real-world domain shifts, while remaining computationally efficient. The effectiveness of POEM is evaluated through extensive analyses and thorough ablation studies. Moreover, the core idea behind POEM can be employed as an augmentation strategy to boost the performance of existing TTA approaches. The source code is publicly available at \emph{https://github.com/ycarobot/POEM}
<div id='section'>Paperid: <span id='pid'>3, <a href='https://arxiv.org/pdf/2510.03258.pdf' target='_blank'>https://arxiv.org/pdf/2510.03258.pdf</a></span>   <span><a href='https://github.com/ycarobot/POEM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chang'an Yi, Xiaohui Deng, Shuaicheng Niu, Yan Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.03258">POEM: Explore Unexplored Reliable Samples to Enhance Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) aims to transfer knowledge from a source model to unknown test data with potential distribution shifts in an online manner. Many existing TTA methods rely on entropy as a confidence metric to optimize the model. However, these approaches are sensitive to the predefined entropy threshold, influencing which samples are chosen for model adaptation. Consequently, potentially reliable target samples are often overlooked and underutilized. For instance, a sample's entropy might slightly exceed the threshold initially, but fall below it after the model is updated. Such samples can provide stable supervised information and offer a normal range of gradients to guide model adaptation. In this paper, we propose a general approach, \underline{POEM}, to promote TTA via ex\underline{\textbf{p}}loring the previously unexpl\underline{\textbf{o}}red reliabl\underline{\textbf{e}} sa\underline{\textbf{m}}ples. Additionally, we introduce an extra Adapt Branch network to strike a balance between extracting domain-agnostic representations and achieving high performance on target data. Comprehensive experiments across multiple architectures demonstrate that POEM consistently outperforms existing TTA methods in both challenging scenarios and real-world domain shifts, while remaining computationally efficient. The effectiveness of POEM is evaluated through extensive analyses and thorough ablation studies. Moreover, the core idea behind POEM can be employed as an augmentation strategy to boost the performance of existing TTA approaches. The source code is publicly available at \emph{https://github.com/ycarobot/POEM}
<div id='section'>Paperid: <span id='pid'>4, <a href='https://arxiv.org/pdf/2510.00458.pdf' target='_blank'>https://arxiv.org/pdf/2510.00458.pdf</a></span>   <span><a href='https://github.com/imatif17/VLOD-TTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Atif Belal, Heitor R. Medeiros, Marco Pedersoli, Eric Granger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.00458">VLOD-TTA: Test-Time Adaptation of Vision-Language Object Detectors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-language object detectors (VLODs) such as YOLO-World and Grounding DINO achieve impressive zero-shot recognition by aligning region proposals with text representations. However, their performance often degrades under domain shift. We introduce VLOD-TTA, a test-time adaptation (TTA) framework for VLODs that leverages dense proposal overlap and image-conditioned prompt scores. First, an IoU-weighted entropy objective is proposed that concentrates adaptation on spatially coherent proposal clusters and reduces confirmation bias from isolated boxes. Second, image-conditioned prompt selection is introduced, which ranks prompts by image-level compatibility and fuses the most informative prompts with the detector logits. Our benchmarking across diverse distribution shifts -- including stylized domains, driving scenes, low-light conditions, and common corruptions -- shows the effectiveness of our method on two state-of-the-art VLODs, YOLO-World and Grounding DINO, with consistent improvements over the zero-shot and TTA baselines. Code : https://github.com/imatif17/VLOD-TTA
<div id='section'>Paperid: <span id='pid'>5, <a href='https://arxiv.org/pdf/2510.00458.pdf' target='_blank'>https://arxiv.org/pdf/2510.00458.pdf</a></span>   <span><a href='https://github.com/imatif17/VLOD-TTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Atif Belal, Heitor R. Medeiros, Marco Pedersoli, Eric Granger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.00458">VLOD-TTA: Test-Time Adaptation of Vision-Language Object Detectors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-language object detectors (VLODs) such as YOLO-World and Grounding DINO achieve impressive zero-shot recognition by aligning region proposals with text representations. However, their performance often degrades under domain shift. We introduce VLOD-TTA, a test-time adaptation (TTA) framework for VLODs that leverages dense proposal overlap and image-conditioned prompt scores. First, an IoU-weighted entropy objective is proposed that concentrates adaptation on spatially coherent proposal clusters and reduces confirmation bias from isolated boxes. Second, image-conditioned prompt selection is introduced, which ranks prompts by image-level compatibility and fuses the most informative prompts with the detector logits. Our benchmarking across diverse distribution shifts -- including stylized domains, driving scenes, low-light conditions, and common corruptions -- shows the effectiveness of our method on two state-of-the-art VLODs, YOLO-World and Grounding DINO, with consistent improvements over the zero-shot and TTA baselines. Code : https://github.com/imatif17/VLOD-TTA
<div id='section'>Paperid: <span id='pid'>6, <a href='https://arxiv.org/pdf/2509.25692.pdf' target='_blank'>https://arxiv.org/pdf/2509.25692.pdf</a></span>   <span><a href='https://github.com/tingyushi/CPATTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tingyu Shi, Fan Lyu, Shaoliang Peng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.25692">Annotation-Efficient Active Test-Time Adaptation with Conformal Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Active Test-Time Adaptation (ATTA) improves model robustness under domain shift by selectively querying human annotations at deployment, but existing methods use heuristic uncertainty measures and suffer from low data selection efficiency, wasting human annotation budget. We propose Conformal Prediction Active TTA (CPATTA), which first brings principled, coverage-guaranteed uncertainty into ATTA. CPATTA employs smoothed conformal scores with a top-K certainty measure, an online weight-update algorithm driven by pseudo coverage, a domain-shift detector that adapts human supervision, and a staged update scheme balances human-labeled and model-labeled data. Extensive experiments demonstrate that CPATTA consistently outperforms the state-of-the-art ATTA methods by around 5% in accuracy. Our code and datasets are available at https://github.com/tingyushi/CPATTA.
<div id='section'>Paperid: <span id='pid'>7, <a href='https://arxiv.org/pdf/2509.25692.pdf' target='_blank'>https://arxiv.org/pdf/2509.25692.pdf</a></span>   <span><a href='https://github.com/tingyushi/CPATTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tingyu Shi, Fan Lyu, Shaoliang Peng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.25692">Annotation-Efficient Active Test-Time Adaptation with Conformal Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Active Test-Time Adaptation (ATTA) improves model robustness under domain shift by selectively querying human annotations at deployment, but existing methods use heuristic uncertainty measures and suffer from low data selection efficiency, wasting human annotation budget. We propose Conformal Prediction Active TTA (CPATTA), which first brings principled, coverage-guaranteed uncertainty into ATTA. CPATTA employs smoothed conformal scores with a top-K certainty measure, an online weight-update algorithm driven by pseudo coverage, a domain-shift detector that adapts human supervision, and a staged update scheme balances human-labeled and model-labeled data. Extensive experiments demonstrate that CPATTA consistently outperforms the state-of-the-art ATTA methods by around 5% in accuracy. Our code and datasets are available at https://github.com/tingyushi/CPATTA.
<div id='section'>Paperid: <span id='pid'>8, <a href='https://arxiv.org/pdf/2509.25692.pdf' target='_blank'>https://arxiv.org/pdf/2509.25692.pdf</a></span>   <span><a href='https://github.com/tingyushi/CPATTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tingyu Shi, Fan Lyu, Shaoliang Peng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.25692">Annotation-Efficient Active Test-Time Adaptation with Conformal Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Active Test-Time Adaptation (ATTA) improves model robustness under domain shift by selectively querying human annotations at deployment, but existing methods use heuristic uncertainty measures and suffer from low data selection efficiency, wasting human annotation budget. We propose Conformal Prediction Active TTA (CPATTA), which first brings principled, coverage-guaranteed uncertainty into ATTA. CPATTA employs smoothed conformal scores with a top-K certainty measure, an online weight-update algorithm driven by pseudo coverage, a domain-shift detector that adapts human supervision, and a staged update scheme balances human-labeled and model-labeled data. Extensive experiments demonstrate that CPATTA consistently outperforms the state-of-the-art ATTA methods by around 5% in accuracy. Our code and datasets are available at https://github.com/tingyushi/CPATTA.
<div id='section'>Paperid: <span id='pid'>9, <a href='https://arxiv.org/pdf/2509.25692.pdf' target='_blank'>https://arxiv.org/pdf/2509.25692.pdf</a></span>   <span><a href='https://github.com/tingyushi/CPATTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tingyu Shi, Fan Lyu, Shaoliang Peng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.25692">Annotation-Efficient Active Test-Time Adaptation with Conformal Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Active Test-Time Adaptation (ATTA) improves model robustness under domain shift by selectively querying human annotations at deployment, but existing methods use heuristic uncertainty measures and suffer from low data selection efficiency, wasting human annotation budget. We propose Conformal Prediction Active TTA (CPATTA), which first brings principled, coverage-guaranteed uncertainty into ATTA. CPATTA employs smoothed conformal scores with a top-K certainty measure, an online weight-update algorithm driven by pseudo coverage, a domain-shift detector that adapts human supervision, and a staged update scheme balances human-labeled and model-labeled data. Extensive experiments demonstrate that CPATTA consistently outperforms the state-of-the-art ATTA methods by around 5% in accuracy. Our code and datasets are available at https://github.com/tingyushi/CPATTA.
<div id='section'>Paperid: <span id='pid'>10, <a href='https://arxiv.org/pdf/2509.24700.pdf' target='_blank'>https://arxiv.org/pdf/2509.24700.pdf</a></span>   <span><a href='https://github.com/lyyi599/MDM-TENT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Suli Wang, Yang-yang Li, Siqi Cai, Haizhou Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.24700">A Robust Multi-Scale Framework with Test-Time Adaptation for sEEG-Based Speech Decoding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Decoding speech from stereo-electroencephalography (sEEG) signals has emerged as a promising direction for brain-computer interfaces (BCIs). Its clinical applicability, however, is limited by the inherent non-stationarity of neural signals, which causes domain shifts between training and testing, undermining decoding reliability. To address this challenge, a two-stage framework is proposed for enhanced robustness. First, a multi-scale decomposable mixing (MDM) module is introduced to model the hierarchical temporal dynamics of speech production, learning stable multi-timescale representations from sEEG signals. Second, a source-free online test-time adaptation (TTA) method performs entropy minimization to adapt the model to distribution shifts during inference. Evaluations on the public DU-IN spoken word decoding benchmark show that the approach outperforms state-of-the-art models, particularly in challenging cases. This study demonstrates that combining invariant feature learning with online adaptation is a principled strategy for developing reliable BCI systems. Our code is available at https://github.com/lyyi599/MDM-TENT.
<div id='section'>Paperid: <span id='pid'>11, <a href='https://arxiv.org/pdf/2509.24700.pdf' target='_blank'>https://arxiv.org/pdf/2509.24700.pdf</a></span>   <span><a href='https://github.com/lyyi599/MDM-TENT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Suli Wang, Yang-yang Li, Siqi Cai, Haizhou Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.24700">A Robust Multi-Scale Framework with Test-Time Adaptation for sEEG-Based Speech Decoding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Decoding speech from stereo-electroencephalography (sEEG) signals has emerged as a promising direction for brain-computer interfaces (BCIs). Its clinical applicability, however, is limited by the inherent non-stationarity of neural signals, which causes domain shifts between training and testing, undermining decoding reliability. To address this challenge, a two-stage framework is proposed for enhanced robustness. First, a multi-scale decomposable mixing (MDM) module is introduced to model the hierarchical temporal dynamics of speech production, learning stable multi-timescale representations from sEEG signals. Second, a source-free online test-time adaptation (TTA) method performs entropy minimization to adapt the model to distribution shifts during inference. Evaluations on the public DU-IN spoken word decoding benchmark show that the approach outperforms state-of-the-art models, particularly in challenging cases. This study demonstrates that combining invariant feature learning with online adaptation is a principled strategy for developing reliable BCI systems. Our code is available at https://github.com/lyyi599/MDM-TENT.
<div id='section'>Paperid: <span id='pid'>12, <a href='https://arxiv.org/pdf/2509.17925.pdf' target='_blank'>https://arxiv.org/pdf/2509.17925.pdf</a></span>   <span><a href='https://github.com/baiyou1234/SmaRT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuanhan Wang, Yifei Chen, Shuo Jiang, Wenjing Yu, Mingxuan Liu, Beining Wu, Jinying Zong, Feiwei Qin, Changmiao Wang, Qiyuan Tian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.17925">SmaRT: Style-Modulated Robust Test-Time Adaptation for Cross-Domain Brain Tumor Segmentation in MRI</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable brain tumor segmentation in MRI is indispensable for treatment planning and outcome monitoring, yet models trained on curated benchmarks often fail under domain shifts arising from scanner and protocol variability as well as population heterogeneity. Such gaps are especially severe in low-resource and pediatric cohorts, where conventional test-time or source-free adaptation strategies often suffer from instability and structural inconsistency. We propose SmaRT, a style-modulated robust test-time adaptation framework that enables source-free cross-domain generalization. SmaRT integrates style-aware augmentation to mitigate appearance discrepancies, a dual-branch momentum strategy for stable pseudo-label refinement, and structural priors enforcing consistency, integrity, and connectivity. This synergy ensures both adaptation stability and anatomical fidelity under extreme domain shifts. Extensive evaluations on sub-Saharan Africa and pediatric glioma datasets show that SmaRT consistently outperforms state-of-the-art methods, with notable gains in Dice accuracy and boundary precision. Overall, SmaRT bridges the gap between algorithmic advances and equitable clinical applicability, supporting robust deployment of MRI-based neuro-oncology tools in diverse clinical environments. Our source code is available at https://github.com/baiyou1234/SmaRT.
<div id='section'>Paperid: <span id='pid'>13, <a href='https://arxiv.org/pdf/2509.17925.pdf' target='_blank'>https://arxiv.org/pdf/2509.17925.pdf</a></span>   <span><a href='https://github.com/baiyou1234/SmaRT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuanhan Wang, Yifei Chen, Shuo Jiang, Wenjing Yu, Mingxuan Liu, Beining Wu, Jinying Zong, Feiwei Qin, Changmiao Wang, Qiyuan Tian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.17925">SmaRT: Style-Modulated Robust Test-Time Adaptation for Cross-Domain Brain Tumor Segmentation in MRI</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reliable brain tumor segmentation in MRI is indispensable for treatment planning and outcome monitoring, yet models trained on curated benchmarks often fail under domain shifts arising from scanner and protocol variability as well as population heterogeneity. Such gaps are especially severe in low-resource and pediatric cohorts, where conventional test-time or source-free adaptation strategies often suffer from instability and structural inconsistency. We propose SmaRT, a style-modulated robust test-time adaptation framework that enables source-free cross-domain generalization. SmaRT integrates style-aware augmentation to mitigate appearance discrepancies, a dual-branch momentum strategy for stable pseudo-label refinement, and structural priors enforcing consistency, integrity, and connectivity. This synergy ensures both adaptation stability and anatomical fidelity under extreme domain shifts. Extensive evaluations on sub-Saharan Africa and pediatric glioma datasets show that SmaRT consistently outperforms state-of-the-art methods, with notable gains in Dice accuracy and boundary precision. Overall, SmaRT bridges the gap between algorithmic advances and equitable clinical applicability, supporting robust deployment of MRI-based neuro-oncology tools in diverse clinical environments. Our source code is available at https://github.com/baiyou1234/SmaRT.
<div id='section'>Paperid: <span id='pid'>14, <a href='https://arxiv.org/pdf/2509.17598.pdf' target='_blank'>https://arxiv.org/pdf/2509.17598.pdf</a></span>   <span><a href='https://github.com/NUDT-Bai-Group/COLA-TTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Aiming Zhang, Tianyuan Yu, Liang Bai, Jun Tang, Yanming Guo, Yirun Ruan, Yun Zhou, Zhihe Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.17598">COLA: Context-aware Language-driven Test-time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) has gained increasing popularity due to its efficacy in addressing ``distribution shift'' issue while simultaneously protecting data privacy. However, most prior methods assume that a paired source domain model and target domain sharing the same label space coexist, heavily limiting their applicability. In this paper, we investigate a more general source model capable of adaptation to multiple target domains without needing shared labels. This is achieved by using a pre-trained vision-language model (VLM), \egno, CLIP, that can recognize images through matching with class descriptions. While the zero-shot performance of VLMs is impressive, they struggle to effectively capture the distinctive attributes of a target domain. To that end, we propose a novel method -- Context-aware Language-driven TTA (COLA). The proposed method incorporates a lightweight context-aware module that consists of three key components: a task-aware adapter, a context-aware unit, and a residual connection unit for exploring task-specific knowledge, domain-specific knowledge from the VLM and prior knowledge of the VLM, respectively. It is worth noting that the context-aware module can be seamlessly integrated into a frozen VLM, ensuring both minimal effort and parameter efficiency. Additionally, we introduce a Class-Balanced Pseudo-labeling (CBPL) strategy to mitigate the adverse effects caused by class imbalance. We demonstrate the effectiveness of our method not only in TTA scenarios but also in class generalisation tasks. The source code is available at https://github.com/NUDT-Bai-Group/COLA-TTA.
<div id='section'>Paperid: <span id='pid'>15, <a href='https://arxiv.org/pdf/2509.17598.pdf' target='_blank'>https://arxiv.org/pdf/2509.17598.pdf</a></span>   <span><a href='https://github.com/NUDT-Bai-Group/COLA-TTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Aiming Zhang, Tianyuan Yu, Liang Bai, Jun Tang, Yanming Guo, Yirun Ruan, Yun Zhou, Zhihe Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.17598">COLA: Context-aware Language-driven Test-time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) has gained increasing popularity due to its efficacy in addressing ``distribution shift'' issue while simultaneously protecting data privacy. However, most prior methods assume that a paired source domain model and target domain sharing the same label space coexist, heavily limiting their applicability. In this paper, we investigate a more general source model capable of adaptation to multiple target domains without needing shared labels. This is achieved by using a pre-trained vision-language model (VLM), \egno, CLIP, that can recognize images through matching with class descriptions. While the zero-shot performance of VLMs is impressive, they struggle to effectively capture the distinctive attributes of a target domain. To that end, we propose a novel method -- Context-aware Language-driven TTA (COLA). The proposed method incorporates a lightweight context-aware module that consists of three key components: a task-aware adapter, a context-aware unit, and a residual connection unit for exploring task-specific knowledge, domain-specific knowledge from the VLM and prior knowledge of the VLM, respectively. It is worth noting that the context-aware module can be seamlessly integrated into a frozen VLM, ensuring both minimal effort and parameter efficiency. Additionally, we introduce a Class-Balanced Pseudo-labeling (CBPL) strategy to mitigate the adverse effects caused by class imbalance. We demonstrate the effectiveness of our method not only in TTA scenarios but also in class generalisation tasks. The source code is available at https://github.com/NUDT-Bai-Group/COLA-TTA.
<div id='section'>Paperid: <span id='pid'>16, <a href='https://arxiv.org/pdf/2509.16509.pdf' target='_blank'>https://arxiv.org/pdf/2509.16509.pdf</a></span>   <span><a href='https://github.com/XuanLu11/SlowFast-SCI' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Haijin Zeng, Xuan Lu, Yurong Zhang, Yongyong Chen, Jingyong Su, Jie Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.16509">SlowFast-SCI: Slow-Fast Deep Unfolding Learning for Spectral Compressive Imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Humans learn in two complementary ways: a slow, cumulative process that builds broad, general knowledge, and a fast, on-the-fly process that captures specific experiences. Existing deep-unfolding methods for spectral compressive imaging (SCI) mirror only the slow component-relying on heavy pre-training with many unfolding stages-yet they lack the rapid adaptation needed to handle new optical configurations. As a result, they falter on out-of-distribution cameras, especially in bespoke spectral setups unseen during training. This depth also incurs heavy computation and slow inference. To bridge this gap, we introduce SlowFast-SCI, a dual-speed framework seamlessly integrated into any deep unfolding network beyond SCI systems. During slow learning, we pre-train or reuse a priors-based backbone and distill it via imaging guidance into a compact fast-unfolding model. In the fast learning stage, lightweight adaptation modules are embedded within each block and trained self-supervised at test time via a dual-domain loss-without retraining the backbone. To the best of our knowledge, SlowFast-SCI is the first test-time adaptation-driven deep unfolding framework for efficient, self-adaptive spectral reconstruction. Its dual-stage design unites offline robustness with on-the-fly per-sample calibration-yielding over 70% reduction in parameters and FLOPs, up to 5.79 dB PSNR improvement on out-of-distribution data, preserved cross-domain adaptability, and a 4x faster adaptation speed. In addition, its modularity integrates with any deep-unfolding network, paving the way for self-adaptive, field-deployable imaging and expanded computational imaging modalities. Code and models are available at https://github.com/XuanLu11/SlowFast-SCI.
<div id='section'>Paperid: <span id='pid'>17, <a href='https://arxiv.org/pdf/2509.16509.pdf' target='_blank'>https://arxiv.org/pdf/2509.16509.pdf</a></span>   <span><a href='https://github.com/XuanLu11/SlowFast-SCI' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Haijin Zeng, Xuan Lu, Yurong Zhang, Yongyong Chen, Jingyong Su, Jie Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.16509">SlowFast-SCI: Slow-Fast Deep Unfolding Learning for Spectral Compressive Imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Humans learn in two complementary ways: a slow, cumulative process that builds broad, general knowledge, and a fast, on-the-fly process that captures specific experiences. Existing deep-unfolding methods for spectral compressive imaging (SCI) mirror only the slow component-relying on heavy pre-training with many unfolding stages-yet they lack the rapid adaptation needed to handle new optical configurations. As a result, they falter on out-of-distribution cameras, especially in bespoke spectral setups unseen during training. This depth also incurs heavy computation and slow inference. To bridge this gap, we introduce SlowFast-SCI, a dual-speed framework seamlessly integrated into any deep unfolding network beyond SCI systems. During slow learning, we pre-train or reuse a priors-based backbone and distill it via imaging guidance into a compact fast-unfolding model. In the fast learning stage, lightweight adaptation modules are embedded within each block and trained self-supervised at test time via a dual-domain loss-without retraining the backbone. To the best of our knowledge, SlowFast-SCI is the first test-time adaptation-driven deep unfolding framework for efficient, self-adaptive spectral reconstruction. Its dual-stage design unites offline robustness with on-the-fly per-sample calibration-yielding over 70% reduction in parameters and FLOPs, up to 5.79 dB PSNR improvement on out-of-distribution data, preserved cross-domain adaptability, and a 4x faster adaptation speed. In addition, its modularity integrates with any deep-unfolding network, paving the way for self-adaptive, field-deployable imaging and expanded computational imaging modalities. Code and models are available at https://github.com/XuanLu11/SlowFast-SCI.
<div id='section'>Paperid: <span id='pid'>18, <a href='https://arxiv.org/pdf/2509.09785.pdf' target='_blank'>https://arxiv.org/pdf/2509.09785.pdf</a></span>   <span><a href='https://github.com/MosyMosy/Purge-Gate' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Moslem Yazdanpanah, Ali Bahri, Mehrdad Noori, Sahar Dastani, Gustavo Adolfo Vargas Hakim, David Osowiechi, Ismail Ben Ayed, Christian Desrosiers
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.09785">Purge-Gate: Backpropagation-Free Test-Time Adaptation for Point Clouds Classification via Token Purging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) is crucial for mitigating performance degradation caused by distribution shifts in 3D point cloud classification. In this work, we introduce Token Purging (PG), a novel backpropagation-free approach that removes tokens highly affected by domain shifts before they reach attention layers. Unlike existing TTA methods, PG operates at the token level, ensuring robust adaptation without iterative updates. We propose two variants: PG-SP, which leverages source statistics, and PG-SF, a fully source-free version relying on CLS-token-driven adaptation. Extensive evaluations on ModelNet40-C, ShapeNet-C, and ScanObjectNN-C demonstrate that PG-SP achieves an average of +10.3\% higher accuracy than state-of-the-art backpropagation-free methods, while PG-SF sets new benchmarks for source-free adaptation. Moreover, PG is 12.4 times faster and 5.5 times more memory efficient than our baseline, making it suitable for real-world deployment. Code is available at \hyperlink{https://github.com/MosyMosy/Purge-Gate}{https://github.com/MosyMosy/Purge-Gate}
<div id='section'>Paperid: <span id='pid'>19, <a href='https://arxiv.org/pdf/2509.09785.pdf' target='_blank'>https://arxiv.org/pdf/2509.09785.pdf</a></span>   <span><a href='https://github.com/MosyMosy/Purge-Gate' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Moslem Yazdanpanah, Ali Bahri, Mehrdad Noori, Sahar Dastani, Gustavo Adolfo Vargas Hakim, David Osowiechi, Ismail Ben Ayed, Christian Desrosiers
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.09785">Purge-Gate: Backpropagation-Free Test-Time Adaptation for Point Clouds Classification via Token Purging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) is crucial for mitigating performance degradation caused by distribution shifts in 3D point cloud classification. In this work, we introduce Token Purging (PG), a novel backpropagation-free approach that removes tokens highly affected by domain shifts before they reach attention layers. Unlike existing TTA methods, PG operates at the token level, ensuring robust adaptation without iterative updates. We propose two variants: PG-SP, which leverages source statistics, and PG-SF, a fully source-free version relying on CLS-token-driven adaptation. Extensive evaluations on ModelNet40-C, ShapeNet-C, and ScanObjectNN-C demonstrate that PG-SP achieves an average of +10.3\% higher accuracy than state-of-the-art backpropagation-free methods, while PG-SF sets new benchmarks for source-free adaptation. Moreover, PG is 12.4 times faster and 5.5 times more memory efficient than our baseline, making it suitable for real-world deployment. Code is available at \hyperlink{https://github.com/MosyMosy/Purge-Gate}{https://github.com/MosyMosy/Purge-Gate}
<div id='section'>Paperid: <span id='pid'>20, <a href='https://arxiv.org/pdf/2508.20029.pdf' target='_blank'>https://arxiv.org/pdf/2508.20029.pdf</a></span>   <span><a href='https://manogna-s.github.io/segassist/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Manogna Sreenivas, Soma Biswas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.20029">Segmentation Assisted Incremental Test Time Adaptation in an Open World</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In dynamic environments, unfamiliar objects and distribution shifts are often encountered, which challenge the generalization abilities of the deployed trained models. This work addresses Incremental Test Time Adaptation of Vision Language Models, tackling scenarios where unseen classes and unseen domains continuously appear during testing. Unlike traditional Test Time Adaptation approaches, where the test stream comes only from a predefined set of classes, our framework allows models to adapt simultaneously to both covariate and label shifts, actively incorporating new classes as they emerge. Towards this goal, we establish a new benchmark for ITTA, integrating single image TTA methods for VLMs with active labeling techniques that query an oracle for samples potentially representing unseen classes during test time. We propose a segmentation assisted active labeling module, termed SegAssist, which is training free and repurposes the segmentation capabilities of VLMs to refine active sample selection, prioritizing samples likely to belong to unseen classes. Extensive experiments on several benchmark datasets demonstrate the potential of SegAssist to enhance the performance of VLMs in real world scenarios, where continuous adaptation to emerging data is essential. Project-page:https://manogna-s.github.io/segassist/
<div id='section'>Paperid: <span id='pid'>21, <a href='https://arxiv.org/pdf/2508.18751.pdf' target='_blank'>https://arxiv.org/pdf/2508.18751.pdf</a></span>   <span><a href='https://github.com/powerpowe/PAF-KIP-OSTTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Byung-Joon Lee, Jin-Seop Lee, Jee-Hyong Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.18751">Stabilizing Open-Set Test-Time Adaptation via Primary-Auxiliary Filtering and Knowledge-Integrated Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks demonstrate strong performance under aligned training-test distributions. However, real-world test data often exhibit domain shifts. Test-Time Adaptation (TTA) addresses this challenge by adapting the model to test data during inference. While most TTA studies assume that the training and test data share the same class set (closed-set TTA), real-world scenarios often involve open-set data (open-set TTA), which can degrade closed-set accuracy. A recent study showed that identifying open-set data during adaptation and maximizing its entropy is an effective solution. However, the previous method relies on the source model for filtering, resulting in suboptimal filtering accuracy on domain-shifted test data. In contrast, we found that the adapting model, which learns domain knowledge from noisy test streams, tends to be unstable and leads to error accumulation when used for filtering. To address this problem, we propose Primary-Auxiliary Filtering (PAF), which employs an auxiliary filter to validate data filtered by the primary filter. Furthermore, we propose Knowledge-Integrated Prediction (KIP), which calibrates the outputs of the adapting model, EMA model, and source model to integrate their complementary knowledge for OSTTA. We validate our approach across diverse closed-set and open-set datasets. Our method enhances both closed-set accuracy and open-set discrimination over existing methods. The code is available at https://github.com/powerpowe/PAF-KIP-OSTTA .
<div id='section'>Paperid: <span id='pid'>22, <a href='https://arxiv.org/pdf/2508.05989.pdf' target='_blank'>https://arxiv.org/pdf/2508.05989.pdf</a></span>   <span><a href='https://fuzzythecat.github.io/eta' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Younjoon Chung, Hyoungseob Park, Patrick Rim, Xiaoran Zhang, Jihe He, Ziyao Zeng, Safa Cicek, Byung-Woo Hong, James S. Duncan, Alex Wong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.05989">ETA: Energy-based Test-time Adaptation for Depth Completion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a method for test-time adaptation of pretrained depth completion models. Depth completion models, trained on some ``source'' data, often predict erroneous outputs when transferred to ``target'' data captured in novel environmental conditions due to a covariate shift. The crux of our method lies in quantifying the likelihood of depth predictions belonging to the source data distribution. The challenge is in the lack of access to out-of-distribution (target) data prior to deployment. Hence, rather than making assumptions regarding the target distribution, we utilize adversarial perturbations as a mechanism to explore the data space. This enables us to train an energy model that scores local regions of depth predictions as in- or out-of-distribution. We update the parameters of pretrained depth completion models at test time to minimize energy, effectively aligning test-time predictions to those of the source distribution. We call our method ``Energy-based Test-time Adaptation'', or ETA for short. We evaluate our method across three indoor and three outdoor datasets, where ETA improve over the previous state-of-the-art method by an average of 6.94% for outdoors and 10.23% for indoors. Project Page: https://fuzzythecat.github.io/eta.
<div id='section'>Paperid: <span id='pid'>23, <a href='https://arxiv.org/pdf/2508.05898.pdf' target='_blank'>https://arxiv.org/pdf/2508.05898.pdf</a></span>   <span><a href='https://github.com/hamidreza-dastmalchi/ETTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hamidreza Dastmalchi, Aijun An, Ali cheraghian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.05898">ETTA: Efficient Test-Time Adaptation for Vision-Language Models through Dynamic Embedding Updates</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pretrained vision-language models (VLMs) like CLIP show strong zero-shot performance but struggle with generalization under distribution shifts. Test-Time Adaptation (TTA) addresses this by adapting VLMs to unlabeled test data in new domains. While some TTA methods rely on prompt-tuning, training-free cache-based approaches are preferred for efficiency. However, current cache-based TTA models store only a limited set of high-confidence samples, restricting the decision boundary to these samples and ignoring the influence of other incoming test data. To address this, we propose Efficient Test-Time Adaptation (ETTA), introducing a Recursive Updating module that integrates all incoming test samples, progressively refining the decision boundary. This strategy mimics an unbounded cache, dynamically updating contextual embeddings for improved accuracy with minimal memory and computational overhead. ETTA also includes an Adaptive Ensemble module to reduce prompt dependency in image-to-text scores by dynamically selecting optimal prompts for each class. Furthermore, ETTA adaptively combines scores from both modules based on confidence levels, leveraging their complementary strengths. Extensive experiments on two benchmarks confirm that ETTA surpasses the state-of-the-art TTA models in computational complexity and accuracy, setting a new standard for effective, efficient test-time adaptation. The code has been released at https://github.com/hamidreza-dastmalchi/ETTA.
<div id='section'>Paperid: <span id='pid'>24, <a href='https://arxiv.org/pdf/2508.05547.pdf' target='_blank'>https://arxiv.org/pdf/2508.05547.pdf</a></span>   <span><a href='https://github.com/tim-learn/Awesome-LabelFree-VLMs' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/tim-learn/Awesome-LabelFree-VLMs' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Dong, Lijun Sheng, Jian Liang, Ran He, Eleni Chatzi, Olga Fink
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.05547">Adapting Vision-Language Models Without Labels: A Comprehensive Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-Language Models (VLMs) have demonstrated remarkable generalization capabilities across a wide range of tasks. However, their performance often remains suboptimal when directly applied to specific downstream scenarios without task-specific adaptation. To enhance their utility while preserving data efficiency, recent research has increasingly focused on unsupervised adaptation methods that do not rely on labeled data. Despite the growing interest in this area, there remains a lack of a unified, task-oriented survey dedicated to unsupervised VLM adaptation. To bridge this gap, we present a comprehensive and structured overview of the field. We propose a taxonomy based on the availability and nature of unlabeled visual data, categorizing existing approaches into four key paradigms: Data-Free Transfer (no data), Unsupervised Domain Transfer (abundant data), Episodic Test-Time Adaptation (batch data), and Online Test-Time Adaptation (streaming data). Within this framework, we analyze core methodologies and adaptation strategies associated with each paradigm, aiming to establish a systematic understanding of the field. Additionally, we review representative benchmarks across diverse applications and highlight open challenges and promising directions for future research. An actively maintained repository of relevant literature is available at https://github.com/tim-learn/Awesome-LabelFree-VLMs.
<div id='section'>Paperid: <span id='pid'>25, <a href='https://arxiv.org/pdf/2508.02180.pdf' target='_blank'>https://arxiv.org/pdf/2508.02180.pdf</a></span>   <span><a href='https://github.com/DengZeshuai/ZOA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zeshuai Deng, Guohao Chen, Shuaicheng Niu, Hui Luo, Shuhai Zhang, Yifan Yang, Renjie Chen, Wei Luo, Mingkui Tan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.02180">Test-Time Model Adaptation for Quantized Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quantizing deep models prior to deployment is a widely adopted technique to speed up inference for various real-time applications, such as autonomous driving. However, quantized models often suffer from severe performance degradation in dynamic environments with potential domain shifts and this degradation is significantly more pronounced compared with their full-precision counterparts, as shown by our theoretical and empirical illustrations. To address the domain shift problem, test-time adaptation (TTA) has emerged as an effective solution by enabling models to learn adaptively from test data. Unfortunately, existing TTA methods are often impractical for quantized models as they typically rely on gradient backpropagation--an operation that is unsupported on quantized models due to vanishing gradients, as well as memory and latency constraints. In this paper, we focus on TTA for quantized models to improve their robustness and generalization ability efficiently. We propose a continual zeroth-order adaptation (ZOA) framework that enables efficient model adaptation using only two forward passes, eliminating the computational burden of existing methods. Moreover, we propose a domain knowledge management scheme to store and reuse different domain knowledge with negligible memory consumption, reducing the interference of different domain knowledge and fostering the knowledge accumulation during long-term adaptation. Experimental results on three classical architectures, including quantized transformer-based and CNN-based models, demonstrate the superiority of our methods for quantized model adaptation. On the quantized W6A6 ViT-B model, our ZOA is able to achieve a 5.0\% improvement over the state-of-the-art FOA on ImageNet-C dataset. The source code is available at https://github.com/DengZeshuai/ZOA.
<div id='section'>Paperid: <span id='pid'>26, <a href='https://arxiv.org/pdf/2508.01225.pdf' target='_blank'>https://arxiv.org/pdf/2508.01225.pdf</a></span>   <span><a href='https://zhaihaotian.github.io/MCP-ICCV25/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinyu Chen, Haotian Zhai, Can Zhang, Xiupeng Shi, Ruirui Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.01225">Multi-Cache Enhanced Prototype Learning for Test-Time Generalization of Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In zero-shot setting, test-time adaptation adjusts pre-trained models using unlabeled data from the test phase to enhance performance on unknown test distributions. Existing cache-enhanced TTA methods rely on a low-entropy criterion to select samples for prototype construction, assuming intra-class compactness. However, low-entropy samples may be unreliable under distribution shifts, and the resulting prototypes may not ensure compact intra-class distributions. This study identifies a positive correlation between cache-enhanced performance and intra-class compactness. Based on this observation, we propose a Multi-Cache enhanced Prototype-based Test-Time Adaptation (MCP) featuring three caches: an entropy cache for initializing prototype representations with low-entropy samples, an align cache for integrating visual and textual information to achieve compact intra-class distributions, and a negative cache for prediction calibration using high-entropy samples. We further developed MCP++, a framework incorporating cross-modal prototype alignment and residual learning, introducing prototype residual fine-tuning. Comparative and ablation experiments across 15 downstream tasks demonstrate that the proposed method and framework achieve state-of-the-art generalization performance. Project Page available at: https://zhaihaotian.github.io/MCP-ICCV25/
<div id='section'>Paperid: <span id='pid'>27, <a href='https://arxiv.org/pdf/2508.00766.pdf' target='_blank'>https://arxiv.org/pdf/2508.00766.pdf</a></span>   <span><a href='https://github.com/Sample-Aware-TTA/Code' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Irene Iele, Francesco Di Feola, Valerio Guarrasi, Paolo Soda
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.00766">Sample-Aware Test-Time Adaptation for Medical Image-to-Image Translation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Image-to-image translation has emerged as a powerful technique in medical imaging, enabling tasks such as image denoising and cross-modality conversion. However, it suffers from limitations in handling out-of-distribution samples without causing performance degradation. To address this limitation, we propose a novel Test-Time Adaptation (TTA) framework that dynamically adjusts the translation process based on the characteristics of each test sample. Our method introduces a Reconstruction Module to quantify the domain shift and a Dynamic Adaptation Block that selectively modifies the internal features of a pretrained translation model to mitigate the shift without compromising the performance on in-distribution samples that do not require adaptation. We evaluate our approach on two medical image-to-image translation tasks: low-dose CT denoising and T1 to T2 MRI translation, showing consistent improvements over both the baseline translation model without TTA and prior TTA methods. Our analysis highlights the limitations of the state-of-the-art that uniformly apply the adaptation to both out-of-distribution and in-distribution samples, demonstrating that dynamic, sample-specific adjustment offers a promising path to improve model resilience in real-world scenarios. The code is available at: https://github.com/Sample-Aware-TTA/Code.
<div id='section'>Paperid: <span id='pid'>28, <a href='https://arxiv.org/pdf/2508.00766.pdf' target='_blank'>https://arxiv.org/pdf/2508.00766.pdf</a></span>   <span><a href='https://github.com/Sample-Aware-TTA/Code' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Irene Iele, Francesco Di Feola, Valerio Guarrasi, Paolo Soda
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.00766">Sample-Aware Test-Time Adaptation for Medical Image-to-Image Translation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Image-to-image translation has emerged as a powerful technique in medical imaging, enabling tasks such as image denoising and cross-modality conversion. However, it suffers from limitations in handling out-of-distribution samples without causing performance degradation. To address this limitation, we propose a novel Test-Time Adaptation (TTA) framework that dynamically adjusts the translation process based on the characteristics of each test sample. Our method introduces a Reconstruction Module to quantify the domain shift and a Dynamic Adaptation Block that selectively modifies the internal features of a pretrained translation model to mitigate the shift without compromising the performance on in-distribution samples that do not require adaptation. We evaluate our approach on two medical image-to-image translation tasks: low-dose CT denoising and T1 to T2 MRI translation, showing consistent improvements over both the baseline translation model without TTA and prior TTA methods. Our analysis highlights the limitations of the state-of-the-art that uniformly apply the adaptation to both out-of-distribution and in-distribution samples, demonstrating that dynamic, sample-specific adjustment offers a promising path to improve model resilience in real-world scenarios. The code is available at: https://github.com/Sample-Aware-TTA/Code.
<div id='section'>Paperid: <span id='pid'>29, <a href='https://arxiv.org/pdf/2507.21494.pdf' target='_blank'>https://arxiv.org/pdf/2507.21494.pdf</a></span>   <span><a href='https://github.com/baowenxuan/Latte' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenxuan Bao, Ruxi Deng, Ruizhong Qiu, Tianxin Wei, Hanghang Tong, Jingrui He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.21494">Latte: Collaborative Test-Time Adaptation of Vision-Language Models in Federated Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation with pre-trained vision-language models has gained increasing attention for addressing distribution shifts during testing. Among these approaches, memory-based algorithms stand out due to their training-free nature and ability to leverage historical test data. However, existing test-time adaptation methods are typically designed for a single domain with abundant data. In decentralized settings such as federated learning, applying these methods individually to each client suffers from limited test data, while directly sharing a single global memory via the server prevents proper personalization to each client's unique distribution. To address this, we propose Latte, a novel framework where each client maintains a local memory to store embeddings from its own historical test data and an external memory to store class prototypes from other relevant clients. During communication, each client retrieves prototypes from similar clients under the server's coordination to expand its memory. For local adaptation, Latte utilizes both embedding similarity and uncertainty to enhance model performance. Our theoretical analysis shows that Latte effectively leverages in-distribution clients while remaining robust to out-of-distribution clients. Extensive experiments on domain adaptation and corruption benchmarks validate that Latte achieves superior performance in decentralized settings, while introducing only negligible communication and computation costs. Our code is available at https://github.com/baowenxuan/Latte .
<div id='section'>Paperid: <span id='pid'>30, <a href='https://arxiv.org/pdf/2507.19064.pdf' target='_blank'>https://arxiv.org/pdf/2507.19064.pdf</a></span>   <span><a href='https://github.com/hhc1997/NEAT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Haochen Han, Alex Jinpeng Wang, Fangming Liu, Jun Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.19064">Negation-Aware Test-Time Adaptation for Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we study a practical but less-touched problem in Vision-Language Models (VLMs), \ie, negation understanding. Specifically, many real-world applications require models to explicitly identify what is false or non-existent, \eg, radiologists may search for images that exclude specific conditions. Despite the impressive transferability of VLMs through large-scale training, they suffer from a critical limitation that fails to handle negation. To address this challenge, existing methods attribute its root cause to the scarcity of negation training data and propose to fine-tune VLMs on massive data containing explicit negation. Undoubtedly, such data-centric solutions demand substantial data and computational resources, limiting their sustainable widespread adoption. To tackle negation in a low-carbon manner, we empirically observe that the key obstacle lies in the dual-concept shifts between the affirmation and negation distributions. Therefore, we propose a Negation-Aware Test-Time Adaptation (NEAT) method to efficiently adjust distribution-related parameters during inference. In brief, NEAT can reduce distribution shift in consistent semantics while eliminating false distributional consistency in unrelated semantics. Extensive experiments on the various negation understanding tasks verify the effectiveness of the proposed method. Remarkably, with less than 0.01\% of trainable parameters, NEAT achieves comparable or superior performance to state-of-the-art post-training approaches. Our code is available at https://github.com/hhc1997/NEAT.
<div id='section'>Paperid: <span id='pid'>31, <a href='https://arxiv.org/pdf/2507.14172.pdf' target='_blank'>https://arxiv.org/pdf/2507.14172.pdf</a></span>   <span><a href='https://github.com/flowersteam/SOAR' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Julien Pourcel, CÃ©dric Colas, Pierre-Yves Oudeyer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.14172">Self-Improving Language Models for Evolutionary Program Synthesis: A Case Study on ARC-AGI</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many program synthesis tasks prove too challenging for even state-of-the-art language models to solve in single attempts. Search-based evolutionary methods offer a promising alternative by exploring solution spaces iteratively, but their effectiveness remain limited by the fixed capabilities of the underlying generative model.
  We propose SOAR, a method that learns program synthesis by integrating language models into a self-improving evolutionary loop.
  SOAR alternates between (1) an evolutionary search that uses an LLM to sample and refine candidate solutions, and (2) a hindsight learning phase that converts search attempts into valid problem-solution pairs used to fine-tune the LLM's sampling and refinement capabilities\, -- \,enabling increasingly effective search in subsequent iterations.
  On the challenging ARC-AGI benchmark, SOAR achieves significant performance gains across model scales and iterations, leveraging positive transfer between the sampling and refinement finetuning tasks. These improvements carry over to test-time adaptation, enabling SOAR to solve 52\% of the public test set. Our code is open-sourced at: https://github.com/flowersteam/SOAR
<div id='section'>Paperid: <span id='pid'>32, <a href='https://arxiv.org/pdf/2507.09885.pdf' target='_blank'>https://arxiv.org/pdf/2507.09885.pdf</a></span>   <span><a href='https://github.com/Fibonaccirabbit/MCGA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhanjiang Yang, Lijun Sun, Jiawei Dong, Xiaoxin An, Yang Liu, Meng Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.09885">MCGA: Mixture of Codebooks Hyperspectral Reconstruction via Grayscale-Aware Attention</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reconstructing hyperspectral images (HSIs) from RGB inputs provides a cost-effective alternative to hyperspectral cameras, but reconstructing high-dimensional spectra from three channels is inherently ill-posed. Existing methods typically directly regress RGB-to-HSI mappings using large attention networks, which are computationally expensive and handle ill-posedness only implicitly. We propose MCGA, a Mixture-of-Codebooks with Grayscale-aware Attention framework that explicitly addresses these challenges using spectral priors and photometric consistency. MCGA first learns transferable spectral priors via a mixture-of-codebooks (MoC) from heterogeneous HSI datasets, then aligns RGB features with these priors through grayscale-aware photometric attention (GANet). Efficiency and robustness are further improved via top-K attention design and test-time adaptation (TTA). Experiments on benchmarks and real-world data demonstrate the state-of-the-art accuracy, strong cross-dataset generalization, and 4-5x faster inference. Codes will be available once acceptance at https://github.com/Fibonaccirabbit/MCGA.
<div id='section'>Paperid: <span id='pid'>33, <a href='https://arxiv.org/pdf/2507.09885.pdf' target='_blank'>https://arxiv.org/pdf/2507.09885.pdf</a></span>   <span><a href='https://github.com/Fibonaccirabbit/MCGA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhanjiang Yang, Lijun Sun, Jiawei Dong, Xiaoxin An, Yang Liu, Meng Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.09885">MCGA: Mixture of Codebooks Hyperspectral Reconstruction via Grayscale-Aware Attention</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reconstructing hyperspectral images (HSIs) from RGB inputs provides a cost-effective alternative to hyperspectral cameras, but reconstructing high-dimensional spectra from three channels is inherently ill-posed. Existing methods typically directly regress RGB-to-HSI mappings using large attention networks, which are computationally expensive and handle ill-posedness only implicitly. We propose MCGA, a Mixture-of-Codebooks with Grayscale-aware Attention framework that explicitly addresses these challenges using spectral priors and photometric consistency. MCGA first learns transferable spectral priors via a mixture-of-codebooks (MoC) from heterogeneous HSI datasets, then aligns RGB features with these priors through grayscale-aware photometric attention (GANet). Efficiency and robustness are further improved via top-K attention design and test-time adaptation (TTA). Experiments on benchmarks and real-world data demonstrate the state-of-the-art accuracy, strong cross-dataset generalization, and 4-5x faster inference. Codes will be available once acceptance at https://github.com/Fibonaccirabbit/MCGA.
<div id='section'>Paperid: <span id='pid'>34, <a href='https://arxiv.org/pdf/2507.09500.pdf' target='_blank'>https://arxiv.org/pdf/2507.09500.pdf</a></span>   <span><a href='https://github.com/Evelyn1ywliang/ReTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiwen Liang, Hui Chen, Yizhe Xiong, Zihan Zhou, Mengyao Lyu, Zijia Lin, Shuaicheng Niu, Sicheng Zhao, Jungong Han, Guiguang Ding
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.09500">Advancing Reliable Test-Time Adaptation of Vision-Language Models under Visual Variations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-language models (VLMs) exhibit remarkable zero-shot capabilities but struggle with distribution shifts in downstream tasks when labeled data is unavailable, which has motivated the development of Test-Time Adaptation (TTA) to improve VLMs' performance during inference without annotations. Among various TTA approaches, cache-based methods show promise by preserving historical knowledge from low-entropy samples in a dynamic cache and fostering efficient adaptation. However, these methods face two critical reliability challenges: (1) entropy often becomes unreliable under distribution shifts, causing error accumulation in the cache and degradation in adaptation performance; (2) the final predictions may be unreliable due to inflexible decision boundaries that fail to accommodate large downstream shifts. To address these challenges, we propose a Reliable Test-time Adaptation (ReTA) method that integrates two complementary strategies to enhance reliability from two perspectives. First, to mitigate the unreliability of entropy as a sample selection criterion for cache construction, we introduce Consistency-aware Entropy Reweighting (CER), which incorporates consistency constraints to weight entropy during cache updating. While conventional approaches rely solely on low entropy for cache prioritization and risk introducing noise, our method leverages predictive consistency to maintain a high-quality cache and facilitate more robust adaptation. Second, we present Diversity-driven Distribution Calibration (DDC), which models class-wise text embeddings as multivariate Gaussian distributions, enabling adaptive decision boundaries for more accurate predictions across visually diverse content. Extensive experiments demonstrate that ReTA consistently outperforms state-of-the-art methods, particularly under real-world distribution shifts. Code: https://github.com/Evelyn1ywliang/ReTA.
<div id='section'>Paperid: <span id='pid'>35, <a href='https://arxiv.org/pdf/2507.08607.pdf' target='_blank'>https://arxiv.org/pdf/2507.08607.pdf</a></span>   <span><a href='https://github.com/cuishuang99/BayesTTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuang Cui, Jinglin Xu, Yi Li, Xiongxin Tang, Jiangmeng Li, Jiahuan Zhou, Fanjiang Xu, Fuchun Sun, Hui Xiong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.08607">BayesTTA: Continual-Temporal Test-Time Adaptation for Vision-Language Models via Gaussian Discriminant Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-language models (VLMs) such as CLIP achieve strong zero-shot recognition but degrade significantly under \textit{temporally evolving distribution shifts} common in real-world scenarios (e.g., gradual illumination or seasonal changes). Existing continual test-time adaptation (CTTA) methods are typically built around sudden and severe distribution shifts and neglect temporal continuity, leading to three core defects: limited memory cache restricts long-range distribution modeling, causing catastrophic forgetting; entropy-based confidence becomes unreliable under temporal drift, worsening error accumulation; and static visual representations misalign with evolving inputs. We formalize this practical problem as \textit{Continual-Temporal Test-Time Adaptation (CT-TTA)}, where test distributions evolve gradually over time. To address it, we propose \textit{BayesTTA}, a Bayesian adaptation framework that enforces temporally consistent predictions and dynamically aligns visual representations. Specifically, BayesTTA incrementally estimates class-conditional Gaussian mixture distributions without storing raw data, adaptively selects covariance structures through statistical hypothesis testing, and performs calibrated inference using Gaussian discriminant analysis (GDA). These calibrated predictions supervise self-paced adaptation of normalization layers, ensuring efficient and stable representation alignment. We establish a comprehensive CT-TTA benchmark across four temporally evolving datasets and further evaluate generalization on ten standard TTA datasets. Extensive experiments show that BayesTTA consistently outperforms state-of-the-art methods, achieving significant gains while maintaining efficiency. Code is available at \href{https://github.com/cuishuang99/BayesTTA}{https://github.com/cuishuang99/BayesTTA}.
<div id='section'>Paperid: <span id='pid'>36, <a href='https://arxiv.org/pdf/2507.02437.pdf' target='_blank'>https://arxiv.org/pdf/2507.02437.pdf</a></span>   <span><a href='https://github.com/mar-cry/F2TTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei Li, Jingyang Zhang, Lihao Liu, Guoan Wang, Junjun He, Yang Chen, Lixu Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.02437">F^2TTA: Free-Form Test-Time Adaptation on Cross-Domain Medical Image Classification via Image-Level Disentangled Prompt Tuning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-Time Adaptation (TTA) has emerged as a promising solution for adapting a source model to unseen medical sites using unlabeled test data, due to the high cost of data annotation. Existing TTA methods consider scenarios where data from one or multiple domains arrives in complete domain units. However, in clinical practice, data usually arrives in domain fragments of arbitrary lengths and in random arrival orders, due to resource constraints and patient variability. This paper investigates a practical Free-Form Test-Time Adaptation (F$^{2}$TTA) task, where a source model is adapted to such free-form domain fragments, with shifts occurring between fragments unpredictably. In this setting, these shifts could distort the adaptation process. To address this problem, we propose a novel Image-level Disentangled Prompt Tuning (I-DiPT) framework. I-DiPT employs an image-invariant prompt to explore domain-invariant representations for mitigating the unpredictable shifts, and an image-specific prompt to adapt the source model to each test image from the incoming fragments. The prompts may suffer from insufficient knowledge representation since only one image is available for training. To overcome this limitation, we first introduce Uncertainty-oriented Masking (UoM), which encourages the prompts to extract sufficient information from the incoming image via masked consistency learning driven by the uncertainty of the source model representations. Then, we further propose a Parallel Graph Distillation (PGD) method that reuses knowledge from historical image-specific and image-invariant prompts through parallel graph networks. Experiments on breast cancer and glaucoma classification demonstrate the superiority of our method over existing TTA approaches in F$^{2}$TTA. Code is available at https://github.com/mar-cry/F2TTA.
<div id='section'>Paperid: <span id='pid'>37, <a href='https://arxiv.org/pdf/2506.24000.pdf' target='_blank'>https://arxiv.org/pdf/2506.24000.pdf</a></span>   <span><a href='https://github.com/TomSheng21/tta-vlm' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lijun Sheng, Jian Liang, Ran He, Zilei Wang, Tieniu Tan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.24000">The Illusion of Progress? A Critical Look at Test-Time Adaptation for Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) methods have gained significant attention for enhancing the performance of vision-language models (VLMs) such as CLIP during inference, without requiring additional labeled data. However, current TTA researches generally suffer from major limitations such as duplication of baseline results, limited evaluation metrics, inconsistent experimental settings, and insufficient analysis. These problems hinder fair comparisons between TTA methods and obscure their practical strengths and weaknesses. To address these challenges, we introduce TTA-VLM, a comprehensive benchmark for evaluating TTA methods on VLMs. Our benchmark implements 8 episodic TTA and 7 online TTA methods within a unified and reproducible framework, and evaluates them across 15 widely used datasets. Unlike prior studies focused solely on CLIP, we extend the evaluation to SigLIP--a model trained with a Sigmoid loss--and include training-time tuning methods such as CoOp, MaPLe, and TeCoA to assess generality. Beyond classification accuracy, TTA-VLM incorporates various evaluation metrics, including robustness, calibration, out-of-distribution detection, and stability, enabling a more holistic assessment of TTA methods. Through extensive experiments, we find that 1) existing TTA methods produce limited gains compared to the previous pioneering work; 2) current TTA methods exhibit poor collaboration with training-time fine-tuning methods; 3) accuracy gains frequently come at the cost of reduced model trustworthiness. We release TTA-VLM to provide fair comparison and comprehensive evaluation of TTA methods for VLMs, and we hope it encourages the community to develop more reliable and generalizable TTA strategies.
<div id='section'>Paperid: <span id='pid'>38, <a href='https://arxiv.org/pdf/2506.24000.pdf' target='_blank'>https://arxiv.org/pdf/2506.24000.pdf</a></span>   <span><a href='https://github.com/TomSheng21/tta-vlm' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lijun Sheng, Jian Liang, Ran He, Zilei Wang, Tieniu Tan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.24000">The Illusion of Progress? A Critical Look at Test-Time Adaptation for Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) methods have gained significant attention for enhancing the performance of vision-language models (VLMs) such as CLIP during inference, without requiring additional labeled data. However, current TTA researches generally suffer from major limitations such as duplication of baseline results, limited evaluation metrics, inconsistent experimental settings, and insufficient analysis. These problems hinder fair comparisons between TTA methods and make it difficult to assess their practical strengths and weaknesses. To address these challenges, we introduce TTA-VLM, a comprehensive benchmark for evaluating TTA methods on VLMs. Our benchmark implements 8 episodic TTA and 7 online TTA methods within a unified and reproducible framework, and evaluates them across 15 widely used datasets. Unlike prior studies focused solely on CLIP, we extend the evaluation to SigLIP--a model trained with a Sigmoid loss--and include training-time tuning methods such as CoOp, MaPLe, and TeCoA to assess generality. Beyond classification accuracy, TTA-VLM incorporates various evaluation metrics, including robustness, calibration, out-of-distribution detection, and stability, enabling a more holistic assessment of TTA methods. Through extensive experiments, we find that 1) existing TTA methods produce limited gains compared to the previous pioneering work; 2) current TTA methods exhibit poor collaboration with training-time fine-tuning methods; 3) accuracy gains frequently come at the cost of reduced model trustworthiness. We release TTA-VLM to provide fair comparison and comprehensive evaluation of TTA methods for VLMs, and we hope it encourages the community to develop more reliable and generalizable TTA strategies.
<div id='section'>Paperid: <span id='pid'>39, <a href='https://arxiv.org/pdf/2506.23724.pdf' target='_blank'>https://arxiv.org/pdf/2506.23724.pdf</a></span>   <span><a href='https://github.com/ycarobot/COCA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chang'an Yi, Xiaohui Deng, Guohao Chen, Yan Zhou, Qinghua Lu, Shuaicheng Niu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.23724">When Small Guides Large: Cross-Model Co-Learning for Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time Adaptation (TTA) adapts a given model to testing domain data with potential domain shifts through online unsupervised learning, yielding impressive performance. However, to date, existing TTA methods primarily focus on single-model adaptation. In this work, we investigate an intriguing question: how does cross-model knowledge influence the TTA process? Our findings reveal that, in TTA's unsupervised online setting, each model can provide complementary, confident knowledge to the others, even when there are substantial differences in model size. For instance, a smaller model like MobileViT (10.6M parameters) can effectively guide a larger model like ViT-Base (86.6M parameters). In light of this, we propose COCA, a Cross-Model Co-Learning framework for TTA, which mainly consists of two main strategies. 1) Co-adaptation adaptively integrates complementary knowledge from other models throughout the TTA process, reducing individual model biases. 2) Self-adaptation enhances each model's unique strengths via unsupervised learning, enabling diverse adaptation to the target domain. Extensive experiments show that COCA, which can also serve as a plug-and-play module, significantly boosts existing SOTAs, on models with various sizes--including ResNets, ViTs, and Mobile-ViTs--via cross-model co-learned TTA. For example, with Mobile-ViT's guidance, COCA raises ViT-Base's average adaptation accuracy on ImageNet-C from 51.7% to 64.5%. The code is publicly available at https://github.com/ycarobot/COCA.
<div id='section'>Paperid: <span id='pid'>40, <a href='https://arxiv.org/pdf/2506.23705.pdf' target='_blank'>https://arxiv.org/pdf/2506.23705.pdf</a></span>   <span><a href='https://github.com/smriti-joshi/muvi.git' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Smriti Joshi, Richard Osuala, Lidia Garrucho, Kaisar Kushibar, Dimitri Kessler, Oliver Diaz, Karim Lekadir
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.23705">Single Image Test-Time Adaptation via Multi-View Co-Training</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation enables a trained model to adjust to a new domain during inference, making it particularly valuable in clinical settings where such on-the-fly adaptation is required. However, existing techniques depend on large target domain datasets, which are often impractical and unavailable in medical scenarios that demand per-patient, real-time inference. Moreover, current methods commonly focus on two-dimensional images, failing to leverage the volumetric richness of medical imaging data. Bridging this gap, we propose a Patch-Based Multi-View Co-Training method for Single Image Test-Time adaptation. Our method enforces feature and prediction consistency through uncertainty-guided self-training, enabling effective volumetric segmentation in the target domain with only a single test-time image. Validated on three publicly available breast magnetic resonance imaging datasets for tumor segmentation, our method achieves performance close to the upper bound supervised benchmark while also outperforming all existing state-of-the-art methods, on average by a Dice Similarity Coefficient of 3.75%. We publicly share our accessible codebase, readily integrable with the popular nnUNet framework, at https://github.com/smriti-joshi/muvi.git.
<div id='section'>Paperid: <span id='pid'>41, <a href='https://arxiv.org/pdf/2506.23424.pdf' target='_blank'>https://arxiv.org/pdf/2506.23424.pdf</a></span>   <span><a href='https://github.com/BorealisAI/PETSA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Heitor R. Medeiros, Hossein Sharifi-Noghabi, Gabriel L. Oliveira, Saghar Irandoust
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.23424">Accurate Parameter-Efficient Test-Time Adaptation for Time Series Forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Real-world time series often exhibit a non-stationary nature, degrading the performance of pre-trained forecasting models. Test-Time Adaptation (TTA) addresses this by adjusting models during inference, but existing methods typically update the full model, increasing memory and compute costs. We propose PETSA, a parameter-efficient method that adapts forecasters at test time by only updating small calibration modules on the input and output. PETSA uses low-rank adapters and dynamic gating to adjust representations without retraining. To maintain accuracy despite limited adaptation capacity, we introduce a specialized loss combining three components: (1) a robust term, (2) a frequency-domain term to preserve periodicity, and (3) a patch-wise structural term for structural alignment. PETSA improves the adaptability of various forecasting backbones while requiring fewer parameters than baselines. Experimental results on benchmark datasets show that PETSA achieves competitive or better performance across all horizons. Our code is available at: https://github.com/BorealisAI/PETSA
<div id='section'>Paperid: <span id='pid'>42, <a href='https://arxiv.org/pdf/2506.20254.pdf' target='_blank'>https://arxiv.org/pdf/2506.20254.pdf</a></span>   <span><a href='https://github.com/CAMMA-public/SPA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kun Yuan, Tingxuan Chen, Shi Li, Joel L. Lavanchy, Christian Heiliger, Ege Ãzsoy, Yiming Huang, Long Bai, Nassir Navab, Vinkle Srivastav, Hongliang Ren, Nicolas Padoy
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.20254">Recognizing Surgical Phases Anywhere: Few-Shot Test-time Adaptation and Task-graph Guided Refinement</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The complexity and diversity of surgical workflows, driven by heterogeneous operating room settings, institutional protocols, and anatomical variability, present a significant challenge in developing generalizable models for cross-institutional and cross-procedural surgical understanding. While recent surgical foundation models pretrained on large-scale vision-language data offer promising transferability, their zero-shot performance remains constrained by domain shifts, limiting their utility in unseen surgical environments. To address this, we introduce Surgical Phase Anywhere (SPA), a lightweight framework for versatile surgical workflow understanding that adapts foundation models to institutional settings with minimal annotation. SPA leverages few-shot spatial adaptation to align multi-modal embeddings with institution-specific surgical scenes and phases. It also ensures temporal consistency through diffusion modeling, which encodes task-graph priors derived from institutional procedure protocols. Finally, SPA employs dynamic test-time adaptation, exploiting the mutual agreement between multi-modal phase prediction streams to adapt the model to a given test video in a self-supervised manner, enhancing the reliability under test-time distribution shifts. SPA is a lightweight adaptation framework, allowing hospitals to rapidly customize phase recognition models by defining phases in natural language text, annotating a few images with the phase labels, and providing a task graph defining phase transitions. The experimental results show that the SPA framework achieves state-of-the-art performance in few-shot surgical phase recognition across multiple institutions and procedures, even outperforming full-shot models with 32-shot labeled data. Code is available at https://github.com/CAMMA-public/SPA
<div id='section'>Paperid: <span id='pid'>43, <a href='https://arxiv.org/pdf/2506.16819.pdf' target='_blank'>https://arxiv.org/pdf/2506.16819.pdf</a></span>   <span><a href='https://github.com/Kamichanw/Loupe' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuchu Jiang, Jiaming Chu, Jian Zhao, Xin Zhang, Xu Yang, Lei Jin, Chi Zhang, Xuelong Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.16819">Loupe: A Generalizable and Adaptive Framework for Image Forgery Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The proliferation of generative models has raised serious concerns about visual content forgery. Existing deepfake detection methods primarily target either image-level classification or pixel-wise localization. While some achieve high accuracy, they often suffer from limited generalization across manipulation types or rely on complex architectures. In this paper, we propose Loupe, a lightweight yet effective framework for joint deepfake detection and localization. Loupe integrates a patch-aware classifier and a segmentation module with conditional queries, allowing simultaneous global authenticity classification and fine-grained mask prediction. To enhance robustness against distribution shifts of test set, Loupe introduces a pseudo-label-guided test-time adaptation mechanism by leveraging patch-level predictions to supervise the segmentation head. Extensive experiments on the DDL dataset demonstrate that Loupe achieves state-of-the-art performance, securing the first place in the IJCAI 2025 Deepfake Detection and Localization Challenge with an overall score of 0.846. Our results validate the effectiveness of the proposed patch-level fusion and conditional query design in improving both classification accuracy and spatial localization under diverse forgery patterns. The code is available at https://github.com/Kamichanw/Loupe.
<div id='section'>Paperid: <span id='pid'>44, <a href='https://arxiv.org/pdf/2506.12481.pdf' target='_blank'>https://arxiv.org/pdf/2506.12481.pdf</a></span>   <span><a href='https://github.com/keikeiqi/Audio-Assisted-TTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Runhao Zeng, Qi Deng, Ronghao Zhang, Shuaicheng Niu, Jian Chen, Xiping Hu, Victor C. M. Leung
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.12481">Exploring Audio Cues for Enhanced Test-Time Video Model Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) aims to boost the generalization capability of a trained model by conducting self-/unsupervised learning during the testing phase. While most existing TTA methods for video primarily utilize visual supervisory signals, they often overlook the potential contribution of inherent audio data. To address this gap, we propose a novel approach that incorporates audio information into video TTA. Our method capitalizes on the rich semantic content of audio to generate audio-assisted pseudo-labels, a new concept in the context of video TTA. Specifically, we propose an audio-to-video label mapping method by first employing pre-trained audio models to classify audio signals extracted from videos and then mapping the audio-based predictions to video label spaces through large language models, thereby establishing a connection between the audio categories and video labels. To effectively leverage the generated pseudo-labels, we present a flexible adaptation cycle that determines the optimal number of adaptation iterations for each sample, based on changes in loss and consistency across different views. This enables a customized adaptation process for each sample. Experimental results on two widely used datasets (UCF101-C and Kinetics-Sounds-C), as well as on two newly constructed audio-video TTA datasets (AVE-C and AVMIT-C) with various corruption types, demonstrate the superiority of our approach. Our method consistently improves adaptation performance across different video classification models and represents a significant step forward in integrating audio information into video TTA. Code: https://github.com/keikeiqi/Audio-Assisted-TTA.
<div id='section'>Paperid: <span id='pid'>45, <a href='https://arxiv.org/pdf/2506.06818.pdf' target='_blank'>https://arxiv.org/pdf/2506.06818.pdf</a></span>   <span><a href='https://github.com/ycyinchao/RDVP-MSD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chao Yin, Hao Li, Kequan Yang, Jide Li, Pinpin Zhu, Xiaoqiang Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.06818">Stepwise Decomposition and Dual-stream Focus: A Novel Approach for Training-free Camouflaged Object Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While promptable segmentation (\textit{e.g.}, SAM) has shown promise for various segmentation tasks, it still requires manual visual prompts for each object to be segmented. In contrast, task-generic promptable segmentation aims to reduce the need for such detailed prompts by employing only a task-generic prompt to guide segmentation across all test samples. However, when applied to Camouflaged Object Segmentation (COS), current methods still face two critical issues: 1) \textit{\textbf{semantic ambiguity in getting instance-specific text prompts}}, which arises from insufficient discriminative cues in holistic captions, leading to foreground-background confusion; 2) \textit{\textbf{semantic discrepancy combined with spatial separation in getting instance-specific visual prompts}}, which results from global background sampling far from object boundaries with low feature correlation, causing SAM to segment irrelevant regions. To address the issues above, we propose \textbf{RDVP-MSD}, a novel training-free test-time adaptation framework that synergizes \textbf{R}egion-constrained \textbf{D}ual-stream \textbf{V}isual \textbf{P}rompting (RDVP) via \textbf{M}ultimodal \textbf{S}tepwise \textbf{D}ecomposition Chain of Thought (MSD-CoT). MSD-CoT progressively disentangles image captions to eliminate semantic ambiguity, while RDVP injects spatial constraints into visual prompting and independently samples visual prompts for foreground and background points, effectively mitigating semantic discrepancy and spatial separation. Without requiring any training or supervision, RDVP-MSD achieves a state-of-the-art segmentation result on multiple COS benchmarks and delivers a faster inference speed than previous methods, demonstrating significantly improved accuracy and efficiency. The codes will be available at \href{https://github.com/ycyinchao/RDVP-MSD}{https://github.com/ycyinchao/RDVP-MSD}
<div id='section'>Paperid: <span id='pid'>46, <a href='https://arxiv.org/pdf/2506.05221.pdf' target='_blank'>https://arxiv.org/pdf/2506.05221.pdf</a></span>   <span><a href='https://github.com/JianghaoWu/SAM-TTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianghao Wu, Yicheng Wu, Yutong Xie, Wenjia Bai, You Zhang, Feilong Tang, Yulong Li, Yasmeen George, Imran Razzak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.05221">SAM-aware Test-time Adaptation for Universal Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Universal medical image segmentation using the Segment Anything Model (SAM) remains challenging due to its limited adaptability to medical domains. Existing adaptations, such as MedSAM, enhance SAM's performance in medical imaging but at the cost of reduced generalization to unseen data. Therefore, in this paper, we propose SAM-aware Test-Time Adaptation (SAM-TTA), a fundamentally different pipeline that preserves the generalization of SAM while improving its segmentation performance in medical imaging via a test-time framework. SAM-TTA tackles two key challenges: (1) input-level discrepancies caused by differences in image acquisition between natural and medical images and (2) semantic-level discrepancies due to fundamental differences in object definition between natural and medical domains (e.g., clear boundaries vs. ambiguous structures). Specifically, our SAM-TTA framework comprises (1) Self-adaptive Bezier Curve-based Transformation (SBCT), which adaptively converts single-channel medical images into three-channel SAM-compatible inputs while maintaining structural integrity, to mitigate the input gap between medical and natural images, and (2) Dual-scale Uncertainty-driven Mean Teacher adaptation (DUMT), which employs consistency learning to align SAM's internal representations to medical semantics, enabling efficient adaptation without auxiliary supervision or expensive retraining. Extensive experiments on five public datasets demonstrate that our SAM-TTA outperforms existing TTA approaches and even surpasses fully fine-tuned models such as MedSAM in certain scenarios, establishing a new paradigm for universal medical image segmentation. Code can be found at https://github.com/JianghaoWu/SAM-TTA.
<div id='section'>Paperid: <span id='pid'>47, <a href='https://arxiv.org/pdf/2506.03190.pdf' target='_blank'>https://arxiv.org/pdf/2506.03190.pdf</a></span>   <span><a href='https://github.com/Jamieyi2004/MINT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaming Yi, Ruirui Pan, Jishen Yang, Xiulong Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.03190">MINT: Memory-Infused Prompt Tuning at Test-time for CLIP</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Improving the generalization ability of Vision-Language Pre-trained Models (VLMs) under test-time data distribution shifts remains a critical challenge. The existing Test-Time Adaptation (TTA) methods fall short in fully leveraging the model's internal knowledge, particularly in dynamically adapting to complex and hierarchical visual semantic information. In this paper, we propose Memory-Infused Prompt Tuning (MINT), a novel framework to address this issue. Inspired by human associative memory theory, MINT introduces a Memory Prompt Bank (MPB), which stores learnable key-value prompt pairs that work as a memory of previously seen samples. During the test time, relevant prompt pairs in the MPB are retrieved by the hierarchical visual features of test images to dynamically assemble Associative Prompts. The associative prompts are then injected into the image encoder for fine-grained, customized visual contextual guidance. MINT also utilizes learnable text prompts. MINT thus enables rapid, precise VLM adaptation at test time by leveraging this MPB-acquired memory, without source data or retraining. The code is available at https://github.com/Jamieyi2004/MINT.
<div id='section'>Paperid: <span id='pid'>48, <a href='https://arxiv.org/pdf/2506.00358.pdf' target='_blank'>https://arxiv.org/pdf/2506.00358.pdf</a></span>   <span><a href='https://github.com/sarthaxxxxx/AV-C-Robustness-Benchmark' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Sarthak Kumar Maharana, Saksham Singh Kushwaha, Baoming Zhang, Adrian Rodriguez, Songtao Wei, Yapeng Tian, Yunhui Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.00358">$\texttt{AVROBUSTBENCH}$: Benchmarking the Robustness of Audio-Visual Recognition Models at Test-Time</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While recent audio-visual models have demonstrated impressive performance, their robustness to distributional shifts at test-time remains not fully understood. Existing robustness benchmarks mainly focus on single modalities, making them insufficient for thoroughly assessing the robustness of audio-visual models. Motivated by real-world scenarios where shifts can occur $\textit{simultaneously}$ in both audio and visual modalities, we introduce $\texttt{AVROBUSTBENCH}$, a comprehensive benchmark designed to evaluate the test-time robustness of audio-visual recognition models. $\texttt{AVROBUSTBENCH}$ comprises four audio-visual benchmark datasets, $\texttt{AUDIOSET-2C}$, $\texttt{VGGSOUND-2C}$, $\texttt{KINETICS-2C}$, and $\texttt{EPICKITCHENS-2C}$, each incorporating 75 bimodal audio-visual corruptions that are $\textit{co-occurring}$ and $\textit{correlated}$. Through extensive evaluations, we observe that state-of-the-art supervised and self-supervised audio-visual models exhibit declining robustness as corruption severity increases. Furthermore, online test-time adaptation (TTA) methods, on $\texttt{VGGSOUND-2C}$ and $\texttt{KINETICS-2C}$, offer minimal improvements in performance under bimodal corruptions. We further propose $\texttt{AV2C}$, a simple TTA approach enabling on-the-fly cross-modal fusion by penalizing high-entropy samples, which achieves improvements on $\texttt{VGGSOUND-2C}$. We hope that $\texttt{AVROBUSTBENCH}$ will steer the development of more effective and robust audio-visual TTA approaches. Our code is available $\href{https://github.com/sarthaxxxxx/AV-C-Robustness-Benchmark}{here}$.
<div id='section'>Paperid: <span id='pid'>49, <a href='https://arxiv.org/pdf/2506.00358.pdf' target='_blank'>https://arxiv.org/pdf/2506.00358.pdf</a></span>   <span><a href='https://github.com/sarthaxxxxx/AV-C-Robustness-Benchmark' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Sarthak Kumar Maharana, Saksham Singh Kushwaha, Baoming Zhang, Adrian Rodriguez, Songtao Wei, Yapeng Tian, Yunhui Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.00358">$\texttt{AVROBUSTBENCH}$: Benchmarking the Robustness of Audio-Visual Recognition Models at Test-Time</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While recent audio-visual models have demonstrated impressive performance, their robustness to distributional shifts at test-time remains not fully understood. Existing robustness benchmarks mainly focus on single modalities, making them insufficient for thoroughly assessing the robustness of audio-visual models. Motivated by real-world scenarios where shifts can occur $\textit{simultaneously}$ in both audio and visual modalities, we introduce $\texttt{AVROBUSTBENCH}$, a comprehensive benchmark designed to evaluate the test-time robustness of audio-visual recognition models. $\texttt{AVROBUSTBENCH}$ comprises four audio-visual benchmark datasets, $\texttt{AUDIOSET-2C}$, $\texttt{VGGSOUND-2C}$, $\texttt{KINETICS-2C}$, and $\texttt{EPICKITCHENS-2C}$, each incorporating 75 bimodal audio-visual corruptions that are $\textit{co-occurring}$ and $\textit{correlated}$. Through extensive evaluations, we observe that state-of-the-art supervised and self-supervised audio-visual models exhibit declining robustness as corruption severity increases. Furthermore, online test-time adaptation (TTA) methods, on $\texttt{VGGSOUND-2C}$ and $\texttt{KINETICS-2C}$, offer minimal improvements in performance under bimodal corruptions. We further propose $\texttt{AV2C}$, a simple TTA approach enabling on-the-fly cross-modal fusion by penalizing high-entropy samples, which achieves improvements on $\texttt{VGGSOUND-2C}$. We hope that $\texttt{AVROBUSTBENCH}$ will steer the development of more effective and robust audio-visual TTA approaches. Our code is available $\href{https://github.com/sarthaxxxxx/AV-C-Robustness-Benchmark}{here}$.
<div id='section'>Paperid: <span id='pid'>50, <a href='https://arxiv.org/pdf/2505.19166.pdf' target='_blank'>https://arxiv.org/pdf/2505.19166.pdf</a></span>   <span><a href='https://ericbill21.github.io/JEDI/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Eric Tillmann Bill, Enis Simsar, Thomas Hofmann
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.19166">JEDI: The Force of Jensen-Shannon Divergence in Disentangling Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce JEDI, a test-time adaptation method that enhances subject separation and compositional alignment in diffusion models without requiring retraining or external supervision. JEDI operates by minimizing semantic entanglement in attention maps using a novel Jensen-Shannon divergence based objective. To improve efficiency, we leverage adversarial optimization, reducing the number of updating steps required. JEDI is model-agnostic and applicable to architectures such as Stable Diffusion 1.5 and 3.5, consistently improving prompt alignment and disentanglement in complex scenes. Additionally, JEDI provides a lightweight, CLIP-free disentanglement score derived from internal attention distributions, offering a principled benchmark for compositional alignment under test-time conditions. Code and results are available at https://ericbill21.github.io/JEDI/.
<div id='section'>Paperid: <span id='pid'>51, <a href='https://arxiv.org/pdf/2505.18787.pdf' target='_blank'>https://arxiv.org/pdf/2505.18787.pdf</a></span>   <span><a href='https://github.com/HongHanh2104/T2A-Think-Twice-Before-Adaptation' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hong-Hanh Nguyen-Le, Van-Tuan Tran, Dinh-Thuc Nguyen, Nhien-An Le-Khac
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.18787">Think Twice before Adaptation: Improving Adaptability of DeepFake Detection via Online Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deepfake (DF) detectors face significant challenges when deployed in real-world environments, particularly when encountering test samples deviated from training data through either postprocessing manipulations or distribution shifts. We demonstrate postprocessing techniques can completely obscure generation artifacts presented in DF samples, leading to performance degradation of DF detectors. To address these challenges, we propose Think Twice before Adaptation (\texttt{T$^2$A}), a novel online test-time adaptation method that enhances the adaptability of detectors during inference without requiring access to source training data or labels. Our key idea is to enable the model to explore alternative options through an Uncertainty-aware Negative Learning objective rather than solely relying on its initial predictions as commonly seen in entropy minimization (EM)-based approaches. We also introduce an Uncertain Sample Prioritization strategy and Gradients Masking technique to improve the adaptation by focusing on important samples and model parameters. Our theoretical analysis demonstrates that the proposed negative learning objective exhibits complementary behavior to EM, facilitating better adaptation capability. Empirically, our method achieves state-of-the-art results compared to existing test-time adaptation (TTA) approaches and significantly enhances the resilience and generalization of DF detectors during inference. Code is available \href{https://github.com/HongHanh2104/T2A-Think-Twice-Before-Adaptation}{here}.
<div id='section'>Paperid: <span id='pid'>52, <a href='https://arxiv.org/pdf/2505.18514.pdf' target='_blank'>https://arxiv.org/pdf/2505.18514.pdf</a></span>   <span><a href='https://github.com/taeckyung/BiTTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Taeckyung Lee, Sorn Chottananurak, Junsu Kim, Jinwoo Shin, Taesik Gong, Sung-Ju Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.18514">Test-Time Adaptation with Binary Feedback</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning models perform poorly when domain shifts exist between training and test data. Test-time adaptation (TTA) is a paradigm to mitigate this issue by adapting pre-trained models using only unlabeled test samples. However, existing TTA methods can fail under severe domain shifts, while recent active TTA approaches requiring full-class labels are impractical due to high labeling costs. To address this issue, we introduce a new setting of TTA with binary feedback. This setting uses a few binary feedback inputs from annotators to indicate whether model predictions are correct, thereby significantly reducing the labeling burden of annotators. Under the setting, we propose BiTTA, a novel dual-path optimization framework that leverages reinforcement learning to balance binary feedback-guided adaptation on uncertain samples with agreement-based self-adaptation on confident predictions. Experiments show BiTTA achieves 13.3%p accuracy improvements over state-of-the-art baselines, demonstrating its effectiveness in handling severe distribution shifts with minimal labeling effort. The source code is available at https://github.com/taeckyung/BiTTA.
<div id='section'>Paperid: <span id='pid'>53, <a href='https://arxiv.org/pdf/2505.16441.pdf' target='_blank'>https://arxiv.org/pdf/2505.16441.pdf</a></span>   <span><a href='https://github.com/pilsHan/rem' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jisu Han, Jaemin Na, Wonjun Hwang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.16441">Ranked Entropy Minimization for Continual Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation aims to adapt to realistic environments in an online manner by learning during test time. Entropy minimization has emerged as a principal strategy for test-time adaptation due to its efficiency and adaptability. Nevertheless, it remains underexplored in continual test-time adaptation, where stability is more important. We observe that the entropy minimization method often suffers from model collapse, where the model converges to predicting a single class for all images due to a trivial solution. We propose ranked entropy minimization to mitigate the stability problem of the entropy minimization method and extend its applicability to continuous scenarios. Our approach explicitly structures the prediction difficulty through a progressive masking strategy. Specifically, it gradually aligns the model's probability distributions across different levels of prediction difficulty while preserving the rank order of entropy. The proposed method is extensively evaluated across various benchmarks, demonstrating its effectiveness through empirical results. Our code is available at https://github.com/pilsHan/rem
<div id='section'>Paperid: <span id='pid'>54, <a href='https://arxiv.org/pdf/2505.14511.pdf' target='_blank'>https://arxiv.org/pdf/2505.14511.pdf</a></span>   <span><a href='https://github.com/LTS5/ReservoirTTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Guillaume Vray, Devavrat Tomar, Xufeng Gao, Jean-Philippe Thiran, Evan Shelhamer, Behzad Bozorgtabar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.14511">ReservoirTTA: Prolonged Test-time Adaptation for Evolving and Recurring Domains</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces ReservoirTTA, a novel plug-in framework designed for prolonged test-time adaptation (TTA) in scenarios where the test domain continuously shifts over time, including cases where domains recur or evolve gradually. At its core, ReservoirTTA maintains a reservoir of domain-specialized models -- an adaptive test-time model ensemble -- that both detects new domains via online clustering over style features of incoming samples and routes each sample to the appropriate specialized model, and thereby enables domain-specific adaptation. This multi-model strategy overcomes key limitations of single model adaptation, such as catastrophic forgetting, inter-domain interference, and error accumulation, ensuring robust and stable performance on sustained non-stationary test distributions. Our theoretical analysis reveals key components that bound parameter variance and prevent model collapse, while our plug-in TTA module mitigates catastrophic forgetting of previously encountered domains. Extensive experiments on scene-level corruption benchmarks (ImageNet-C, CIFAR-10/100-C), object-level style shifts (DomainNet-126, PACS), and semantic segmentation (Cityscapes->ACDC) covering recurring and continuously evolving domain shifts -- show that ReservoirTTA substantially improves adaptation accuracy and maintains stable performance across prolonged, recurring shifts, outperforming state-of-the-art methods. Our code is publicly available at https://github.com/LTS5/ReservoirTTA.
<div id='section'>Paperid: <span id='pid'>55, <a href='https://arxiv.org/pdf/2505.14511.pdf' target='_blank'>https://arxiv.org/pdf/2505.14511.pdf</a></span>   <span><a href='https://github.com/LTS5/ReservoirTTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Guillaume Vray, Devavrat Tomar, Xufeng Gao, Jean-Philippe Thiran, Evan Shelhamer, Behzad Bozorgtabar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.14511">ReservoirTTA: Prolonged Test-time Adaptation for Evolving and Recurring Domains</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper introduces ReservoirTTA, a novel plug-in framework designed for prolonged test-time adaptation (TTA) in scenarios where the test domain continuously shifts over time, including cases where domains recur or evolve gradually. At its core, ReservoirTTA maintains a reservoir of domain-specialized models -- an adaptive test-time model ensemble -- that both detects new domains via online clustering over style features of incoming samples and routes each sample to the appropriate specialized model, and thereby enables domain-specific adaptation. This multi-model strategy overcomes key limitations of single model adaptation, such as catastrophic forgetting, inter-domain interference, and error accumulation, ensuring robust and stable performance on sustained non-stationary test distributions. Our theoretical analysis reveals key components that bound parameter variance and prevent model collapse, while our plug-in TTA module mitigates catastrophic forgetting of previously encountered domains. Extensive experiments on scene-level corruption benchmarks (ImageNet-C, CIFAR-10/100-C), object-level style shifts (DomainNet-126, PACS), and semantic segmentation (Cityscapes->ACDC) covering recurring and continuously evolving domain shifts -- show that ReservoirTTA substantially improves adaptation accuracy and maintains stable performance across prolonged, recurring shifts, outperforming state-of-the-art methods. Our code is publicly available at https://github.com/LTS5/ReservoirTTA.
<div id='section'>Paperid: <span id='pid'>56, <a href='https://arxiv.org/pdf/2505.13233.pdf' target='_blank'>https://arxiv.org/pdf/2505.13233.pdf</a></span>   <span><a href='https://github.com/BIT-DA/ABS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Lincan Cai, Jingxuan Kang, Shuang Li, Wenxuan Ma, Binhui Xie, Zhida Qin, Jian Liang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.13233">From Local Details to Global Context: Advancing Vision-Language Models with Attention-Based Selection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pretrained vision-language models (VLMs), e.g., CLIP, demonstrate impressive zero-shot capabilities on downstream tasks. Prior research highlights the crucial role of visual augmentation techniques, like random cropping, in alignment with fine-grained class descriptions generated by large language models (LLMs), significantly enhancing zero-shot performance by incorporating multi-view information. However, the inherent randomness of these augmentations can inevitably introduce background artifacts and cause models to overly focus on local details, compromising global semantic understanding. To address these issues, we propose an \textbf{A}ttention-\textbf{B}ased \textbf{S}election (\textbf{ABS}) method from local details to global context, which applies attention-guided cropping in both raw images and feature space, supplement global semantic information through strategic feature selection. Additionally, we introduce a soft matching technique to effectively filter LLM descriptions for better alignment. \textbf{ABS} achieves state-of-the-art performance on out-of-distribution generalization and zero-shot classification tasks. Notably, \textbf{ABS} is training-free and even rivals few-shot and test-time adaptation methods. Our code is available at \href{https://github.com/BIT-DA/ABS}{\textcolor{darkgreen}{https://github.com/BIT-DA/ABS}}.
<div id='section'>Paperid: <span id='pid'>57, <a href='https://arxiv.org/pdf/2505.12912.pdf' target='_blank'>https://arxiv.org/pdf/2505.12912.pdf</a></span>   <span><a href='https://github.com/kzkadc/uninfo' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kazuki Adachi, Shin'ya Yamaguchi, Tomoki Hamagami
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.12912">Uniformity First: Uniformity-aware Test-time Adaptation of Vision-language Models against Image Corruption</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pre-trained vision-language models such as contrastive language-image pre-training (CLIP) have demonstrated a remarkable generalizability, which has enabled a wide range of applications represented by zero-shot classification. However, vision-language models still suffer when they face datasets with large gaps from training ones, i.e., distribution shifts. We found that CLIP is especially vulnerable to sensor degradation, a type of realistic distribution shift caused by sensor conditions such as weather, light, or noise. Collecting a new dataset from a test distribution for fine-tuning highly costs since sensor degradation occurs unexpectedly and has a range of variety. Thus, we investigate test-time adaptation (TTA) of zero-shot classification, which enables on-the-fly adaptation to the test distribution with unlabeled test data. Existing TTA methods for CLIP mainly focus on modifying image and text embeddings or predictions to address distribution shifts. Although these methods can adapt to domain shifts, such as fine-grained labels spaces or different renditions in input images, they fail to adapt to distribution shifts caused by sensor degradation. We found that this is because image embeddings are "corrupted" in terms of uniformity, a measure related to the amount of information. To make models robust to sensor degradation, we propose a novel method called uniformity-aware information-balanced TTA (UnInfo). To address the corruption of image embeddings, we introduce uniformity-aware confidence maximization, information-aware loss balancing, and knowledge distillation from the exponential moving average (EMA) teacher. Through experiments, we demonstrate that our UnInfo improves accuracy under sensor degradation by retaining information in terms of uniformity.
<div id='section'>Paperid: <span id='pid'>58, <a href='https://arxiv.org/pdf/2505.11883.pdf' target='_blank'>https://arxiv.org/pdf/2505.11883.pdf</a></span>   <span><a href='https://github.com/zihuanqiu/MINGLE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zihuan Qiu, Yi Xu, Chiyuan He, Fanman Meng, Linfeng Xu, Qingbo Wu, Hongliang Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11883">MINGLE: Mixture of Null-Space Gated Low-Rank Experts for Test-Time Continual Model Merging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual model merging integrates independently fine-tuned models sequentially without access to the original training data, offering a scalable and efficient solution for continual learning. However, existing methods face two critical challenges: parameter interference among tasks, which leads to catastrophic forgetting, and limited adaptability to evolving test distributions. To address these issues, we introduce the task of Test-Time Continual Model Merging (TTCMM), which leverages a small set of unlabeled test samples during inference to alleviate parameter conflicts and handle distribution shifts. We propose MINGLE, a novel framework for TTCMM. MINGLE employs a mixture-of-experts architecture with parameter-efficient, low-rank experts, which enhances adaptability to evolving test distributions while dynamically merging models to mitigate conflicts. To further reduce forgetting, we propose Null-Space Constrained Gating, which restricts gating updates to subspaces orthogonal to prior task representations, thereby suppressing activations on old tasks and preserving past knowledge. We further introduce an Adaptive Relaxation Strategy that adjusts constraint strength dynamically based on interference signals observed during test-time adaptation, striking a balance between stability and adaptability. Extensive experiments on standard continual merging benchmarks demonstrate that MINGLE achieves robust generalization, significantly reduces forgetting, and consistently surpasses previous state-of-the-art methods by 7-9\% on average across diverse task orders. Our code is available at: https://github.com/zihuanqiu/MINGLE
<div id='section'>Paperid: <span id='pid'>59, <a href='https://arxiv.org/pdf/2505.11883.pdf' target='_blank'>https://arxiv.org/pdf/2505.11883.pdf</a></span>   <span><a href='https://github.com/zihuanqiu/MINGLE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zihuan Qiu, Yi Xu, Chiyuan He, Fanman Meng, Linfeng Xu, Qingbo Wu, Hongliang Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11883">MINGLE: Mixture of Null-Space Gated Low-Rank Experts for Test-Time Continual Model Merging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual model merging integrates independently fine-tuned models sequentially without access to the original training data, offering a scalable and efficient solution for continual learning. However, existing methods face two critical challenges: parameter interference among tasks, which leads to catastrophic forgetting, and limited adaptability to evolving test distributions. To address these issues, we introduce the task of Test-Time Continual Model Merging (TTCMM), which leverages a small set of unlabeled test samples during inference to alleviate parameter conflicts and handle distribution shifts. We propose MINGLE, a novel framework for TTCMM. MINGLE employs a mixture-of-experts architecture with parameter-efficient, low-rank experts, which enhances adaptability to evolving test distributions while dynamically merging models to mitigate conflicts. To further reduce forgetting, we propose Null-Space Constrained Gating, which restricts gating updates to subspaces orthogonal to prior task representations, thereby suppressing activations on old tasks and preserving past knowledge. We further introduce an Adaptive Relaxation Strategy that adjusts constraint strength dynamically based on interference signals observed during test-time adaptation, striking a balance between stability and adaptability. Extensive experiments on standard continual merging benchmarks demonstrate that MINGLE achieves robust generalization, significantly reduces forgetting, and consistently surpasses previous state-of-the-art methods by 7-9\% on average across diverse task orders. Our code is available at: https://github.com/zihuanqiu/MINGLE
<div id='section'>Paperid: <span id='pid'>60, <a href='https://arxiv.org/pdf/2505.09971.pdf' target='_blank'>https://arxiv.org/pdf/2505.09971.pdf</a></span>   <span><a href='https://github.com/Gaoyuan2/APCoTTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuan Gao, Shaobo Xia, Sheng Nie, Cheng Wang, Xiaohuan Xi, Bisheng Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.09971">APCoTTA: Continual Test-Time Adaptation for Semantic Segmentation of Airborne LiDAR Point Clouds</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Airborne laser scanning (ALS) point cloud segmentation is a fundamental task for large-scale 3D scene understanding. In real-world applications, models are typically fixed after training. However, domain shifts caused by changes in the environment, sensor types, or sensor degradation often lead to a decline in model performance. Continuous Test-Time Adaptation (CTTA) offers a solution by adapting a source-pretrained model to evolving, unlabeled target domains. Despite its potential, research on ALS point clouds remains limited, facing challenges such as the absence of standardized datasets and the risk of catastrophic forgetting and error accumulation during prolonged adaptation. To tackle these challenges, we propose APCoTTA, the first CTTA method tailored for ALS point cloud semantic segmentation. We propose a dynamic trainable layer selection module. This module utilizes gradient information to select low-confidence layers for training, and the remaining layers are kept frozen, mitigating catastrophic forgetting. To further reduce error accumulation, we propose an entropy-based consistency loss. By losing such samples based on entropy, we apply consistency loss only to the reliable samples, enhancing model stability. In addition, we propose a random parameter interpolation mechanism, which randomly blends parameters from the selected trainable layers with those of the source model. This approach helps balance target adaptation and source knowledge retention, further alleviating forgetting. Finally, we construct two benchmarks, ISPRSC and H3DC, to address the lack of CTTA benchmarks for ALS point cloud segmentation. Experimental results demonstrate that APCoTTA achieves the best performance on two benchmarks, with mIoU improvements of approximately 9% and 14% over direct inference. The new benchmarks and code are available at https://github.com/Gaoyuan2/APCoTTA.
<div id='section'>Paperid: <span id='pid'>61, <a href='https://arxiv.org/pdf/2505.02325.pdf' target='_blank'>https://arxiv.org/pdf/2505.02325.pdf</a></span>   <span><a href='https://github.com/wangzhichuan123/TeDA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhichuan Wang, Yang Zhou, Jinhai Xiang, Yulong Wang, Xinwei He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.02325">TeDA: Boosting Vision-Lanuage Models for Zero-Shot 3D Object Retrieval via Testing-time Distribution Alignment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning discriminative 3D representations that generalize well to unknown testing categories is an emerging requirement for many real-world 3D applications. Existing well-established methods often struggle to attain this goal due to insufficient 3D training data from broader concepts. Meanwhile, pre-trained large vision-language models (e.g., CLIP) have shown remarkable zero-shot generalization capabilities. Yet, they are limited in extracting suitable 3D representations due to substantial gaps between their 2D training and 3D testing distributions. To address these challenges, we propose Testing-time Distribution Alignment (TeDA), a novel framework that adapts a pretrained 2D vision-language model CLIP for unknown 3D object retrieval at test time. To our knowledge, it is the first work that studies the test-time adaptation of a vision-language model for 3D feature learning. TeDA projects 3D objects into multi-view images, extracts features using CLIP, and refines 3D query embeddings with an iterative optimization strategy by confident query-target sample pairs in a self-boosting manner. Additionally, TeDA integrates textual descriptions generated by a multimodal language model (InternVL) to enhance 3D object understanding, leveraging CLIP's aligned feature space to fuse visual and textual cues. Extensive experiments on four open-set 3D object retrieval benchmarks demonstrate that TeDA greatly outperforms state-of-the-art methods, even those requiring extensive training. We also experimented with depth maps on Objaverse-LVIS, further validating its effectiveness. Code is available at https://github.com/wangzhichuan123/TeDA.
<div id='section'>Paperid: <span id='pid'>62, <a href='https://arxiv.org/pdf/2504.06908.pdf' target='_blank'>https://arxiv.org/pdf/2504.06908.pdf</a></span>   <span><a href='https://emmanuelleb985.github.io/ukbob' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Emmanuelle Bourigault, Amir Jamaludin, Abdullah Hamdi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.06908">UKBOB: One Billion MRI Labeled Masks for Generalizable 3D Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In medical imaging, the primary challenge is collecting large-scale labeled data due to privacy concerns, logistics, and high labeling costs. In this work, we present the UK Biobank Organs and Bones (UKBOB), the largest labeled dataset of body organs, comprising 51,761 MRI 3D samples (equivalent to 17.9 million 2D images) and more than 1.37 billion 2D segmentation masks of 72 organs, all based on the UK Biobank MRI dataset. We utilize automatic labeling, introduce an automated label cleaning pipeline with organ-specific filters, and manually annotate a subset of 300 MRIs with 11 abdominal classes to validate the quality (referred to as UKBOB-manual). This approach allows for scaling up the dataset collection while maintaining confidence in the labels. We further confirm the validity of the labels by demonstrating zero-shot generalization of trained models on the filtered UKBOB to other small labeled datasets from similar domains (e.g., abdominal MRI). To further mitigate the effect of noisy labels, we propose a novel method called Entropy Test-time Adaptation (ETTA) to refine the segmentation output. We use UKBOB to train a foundation model, Swin-BOB, for 3D medical image segmentation based on the Swin-UNetr architecture, achieving state-of-the-art results in several benchmarks in 3D medical imaging, including the BRATS brain MRI tumor challenge (with a 0.4% improvement) and the BTCV abdominal CT scan benchmark (with a 1.3% improvement). The pre-trained models and the code are available at https://emmanuelleb985.github.io/ukbob , and the filtered labels will be made available with the UK Biobank.
<div id='section'>Paperid: <span id='pid'>63, <a href='https://arxiv.org/pdf/2504.02298.pdf' target='_blank'>https://arxiv.org/pdf/2504.02298.pdf</a></span>   <span><a href='https://github.com/ethanxyluo/SPACE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinyu Luo, Kecheng Chen, Pao-Sheng Vincent Sun, Chris Xing Tian, Arindam Basu, Haoliang Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.02298">SPACE: SPike-Aware Consistency Enhancement for Test-Time Adaptation in Spiking Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Spiking Neural Networks (SNNs), as a biologically plausible alternative to Artificial Neural Networks (ANNs), have demonstrated advantages in terms of energy efficiency, temporal processing, and biological plausibility. However, SNNs are highly sensitive to distribution shifts, which can significantly degrade their performance in real-world scenarios. Traditional test-time adaptation (TTA) methods designed for ANNs often fail to address the unique computational dynamics of SNNs, such as sparsity and temporal spiking behavior. To address these challenges, we propose SPike-Aware Consistency Enhancement (SPACE), the first source-free and single-instance TTA method specifically designed for SNNs. SPACE leverages the inherent spike dynamics of SNNs to maximize the consistency of spike-behavior-based local feature maps across augmented versions of a single test sample, enabling robust adaptation without requiring source data. We evaluate SPACE on multiple datasets. Furthermore, SPACE exhibits robust generalization across diverse network architectures, consistently enhancing the performance of SNNs on CNNs, Transformer, and ConvLSTM architectures. Experimental results show that SPACE outperforms state-of-the-art ANN methods while maintaining lower computational cost, highlighting its effectiveness and robustness for SNNs in real-world settings. The code will be available at https://github.com/ethanxyluo/SPACE.
<div id='section'>Paperid: <span id='pid'>64, <a href='https://arxiv.org/pdf/2504.02298.pdf' target='_blank'>https://arxiv.org/pdf/2504.02298.pdf</a></span>   <span><a href='https://github.com/ethanxyluo/SPACE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinyu Luo, Kecheng Chen, Pao-Sheng Vincent Sun, Chris Xing Tian, Arindam Basu, Haoliang Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.02298">SPACE: SPike-Aware Consistency Enhancement for Test-Time Adaptation in Spiking Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Spiking Neural Networks (SNNs), as a biologically plausible alternative to Artificial Neural Networks (ANNs), have demonstrated advantages in terms of energy efficiency, temporal processing, and biological plausibility. However, SNNs are highly sensitive to distribution shifts, which can significantly degrade their performance in real-world scenarios. Traditional test-time adaptation (TTA) methods designed for ANNs often fail to address the unique computational dynamics of SNNs, such as sparsity and temporal spiking behavior. To address these challenges, we propose SPike-Aware Consistency Enhancement (SPACE), the first source-free and single-instance TTA method specifically designed for SNNs. SPACE leverages the inherent spike dynamics of SNNs to maximize the consistency of spike-behavior-based local feature maps across augmented versions of a single test sample, enabling robust adaptation without requiring source data. We evaluate SPACE on multiple datasets. Furthermore, SPACE exhibits robust generalization across diverse network architectures, consistently enhancing the performance of SNNs on CNNs, Transformer, and ConvLSTM architectures. Experimental results show that SPACE outperforms state-of-the-art ANN methods while maintaining lower computational cost, highlighting its effectiveness and robustness for SNNs in real-world settings. The code will be available at https://github.com/ethanxyluo/SPACE.
<div id='section'>Paperid: <span id='pid'>65, <a href='https://arxiv.org/pdf/2503.14564.pdf' target='_blank'>https://arxiv.org/pdf/2503.14564.pdf</a></span>   <span><a href='https://github.com/flash1803/EATTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Guowei Wang, Changxing Ding
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.14564">Effortless Active Labeling for Long-Term Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Long-term test-time adaptation (TTA) is a challenging task due to error accumulation. Recent approaches tackle this issue by actively labeling a small proportion of samples in each batch, yet the annotation burden quickly grows as the batch number increases. In this paper, we investigate how to achieve effortless active labeling so that a maximum of one sample is selected for annotation in each batch. First, we annotate the most valuable sample in each batch based on the single-step optimization perspective in the TTA context. In this scenario, the samples that border between the source- and target-domain data distributions are considered the most feasible for the model to learn in one iteration. Then, we introduce an efficient strategy to identify these samples using feature perturbation. Second, we discover that the gradient magnitudes produced by the annotated and unannotated samples have significant variations. Therefore, we propose balancing their impact on model optimization using two dynamic weights. Extensive experiments on the popular ImageNet-C, -R, -K, -A and PACS databases demonstrate that our approach consistently outperforms state-of-the-art methods with significantly lower annotation costs.
<div id='section'>Paperid: <span id='pid'>66, <a href='https://arxiv.org/pdf/2503.13012.pdf' target='_blank'>https://arxiv.org/pdf/2503.13012.pdf</a></span>   <span><a href='https://github.com/Yore0/TTDG-MGM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xingguo Lv, Xingbo Dong, Liwen Wang, Jiewen Yang, Lei Zhao, Bin Pu, Zhe Jin, Xuejun Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.13012">Test-Time Domain Generalization via Universe Learning: A Multi-Graph Matching Approach for Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite domain generalization (DG) has significantly addressed the performance degradation of pre-trained models caused by domain shifts, it often falls short in real-world deployment. Test-time adaptation (TTA), which adjusts a learned model using unlabeled test data, presents a promising solution. However, most existing TTA methods struggle to deliver strong performance in medical image segmentation, primarily because they overlook the crucial prior knowledge inherent to medical images. To address this challenge, we incorporate morphological information and propose a framework based on multi-graph matching. Specifically, we introduce learnable universe embeddings that integrate morphological priors during multi-source training, along with novel unsupervised test-time paradigms for domain adaptation. This approach guarantees cycle-consistency in multi-matching while enabling the model to more effectively capture the invariant priors of unseen data, significantly mitigating the effects of domain shifts. Extensive experiments demonstrate that our method outperforms other state-of-the-art approaches on two medical image segmentation benchmarks for both multi-source and single-source domain generalization tasks. The source code is available at https://github.com/Yore0/TTDG-MGM.
<div id='section'>Paperid: <span id='pid'>67, <a href='https://arxiv.org/pdf/2503.12866.pdf' target='_blank'>https://arxiv.org/pdf/2503.12866.pdf</a></span>   <span><a href='https://github.com/zhoujiahuan1991/CVPR2025-SCAP' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenyu Zhang, Kunlun Xu, Zichen Liu, Yuxin Peng, Jiahuan Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.12866">SCAP: Transductive Test-Time Adaptation via Supportive Clique-based Attribute Prompting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-language models (VLMs) encounter considerable challenges when adapting to domain shifts stemming from changes in data distribution. Test-time adaptation (TTA) has emerged as a promising approach to enhance VLM performance under such conditions. In practice, test data often arrives in batches, leading to increasing interest in the transductive TTA setting. However, existing TTA methods primarily focus on individual test samples, overlooking crucial cross-sample correlations within a batch. While recent ViT-based TTA methods have introduced batch-level adaptation, they remain suboptimal for VLMs due to inadequate integration of the text modality. To address these limitations, we propose a novel transductive TTA framework, Supportive Clique-based Attribute Prompting (SCAP), which effectively combines visual and textual information to enhance adaptation by generating fine-grained attribute prompts across test batches. SCAP first forms supportive cliques of test samples in an unsupervised manner based on visual similarity and learns an attribute prompt for each clique, capturing shared attributes critical for adaptation. For each test sample, SCAP aggregates attribute prompts from its associated cliques, providing enriched contextual information. To ensure adaptability over time, we incorporate a retention module that dynamically updates attribute prompts and their associated attributes as new data arrives. Comprehensive experiments across multiple benchmarks demonstrate that SCAP outperforms existing state-of-the-art methods, significantly advancing VLM generalization under domain shifts. Our code is available at https://github.com/zhoujiahuan1991/CVPR2025-SCAP.
<div id='section'>Paperid: <span id='pid'>68, <a href='https://arxiv.org/pdf/2503.12858.pdf' target='_blank'>https://arxiv.org/pdf/2503.12858.pdf</a></span>   <span><a href='https://github.com/dukenguyenxyz/dialect-adaptation' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Duke Nguyen, Aditya Joshi, Flora Salim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.12858">Harnessing Test-time Adaptation for NLU tasks Involving Dialects of English</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) is an excellent method which helps generalize models across domains, tasks, and distributions without the use of labeled datasets. Thus, TTA is very useful in natural language processing (NLP) in the dialectal setting, since oftentimes, models are trained on Standard American English (SAE), evaluated on Indian English or Nigerian English, of which distribution differs significantly from the former. This is especially useful since dialectal datasets are scarce. In this paper, we explore one of the most famous TTA techniques, SHOT, in dialectal NLP. We finetune and evaluate SHOT on different combinations of dialectal GLUE. Our findings show that SHOT is a viable technique when labeled datasets are unavailable. We also theoretically propose the concept of dialectal gap and show that it has a positive correlation with the effectiveness of SHOT. We also find that in many cases, finetuning on SAE yields higher performance than finetuning on dialectal data. Our code is available at https://github.com/dukenguyenxyz/dialect-adaptation
<div id='section'>Paperid: <span id='pid'>69, <a href='https://arxiv.org/pdf/2503.04501.pdf' target='_blank'>https://arxiv.org/pdf/2503.04501.pdf</a></span>   <span><a href='https://xinxinzuo2353.github.io/imfine/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhihao Shi, Dong Huo, Yuhongze Zhou, Kejia Yin, Yan Min, Juwei Lu, Xinxin Zuo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.04501">IMFine: 3D Inpainting via Geometry-guided Multi-view Refinement</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current 3D inpainting and object removal methods are largely limited to front-facing scenes, facing substantial challenges when applied to diverse, "unconstrained" scenes where the camera orientation and trajectory are unrestricted. To bridge this gap, we introduce a novel approach that produces inpainted 3D scenes with consistent visual quality and coherent underlying geometry across both front-facing and unconstrained scenes. Specifically, we propose a robust 3D inpainting pipeline that incorporates geometric priors and a multi-view refinement network trained via test-time adaptation, building on a pre-trained image inpainting model. Additionally, we develop a novel inpainting mask detection technique to derive targeted inpainting masks from object masks, boosting the performance in handling unconstrained scenes. To validate the efficacy of our approach, we create a challenging and diverse benchmark that spans a wide range of scenes. Comprehensive experiments demonstrate that our proposed method substantially outperforms existing state-of-the-art approaches.
<div id='section'>Paperid: <span id='pid'>70, <a href='https://arxiv.org/pdf/2503.02616.pdf' target='_blank'>https://arxiv.org/pdf/2503.02616.pdf</a></span>   <span><a href='https://github.com/zrguo/SuMi' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zirun Guo, Tao Jin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.02616">Smoothing the Shift: Towards Stable Test-Time Adaptation under Complex Multimodal Noises</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-Time Adaptation (TTA) aims to tackle distribution shifts using unlabeled test data without access to the source data. In the context of multimodal data, there are more complex noise patterns than unimodal data such as simultaneous corruptions for multiple modalities and missing modalities. Besides, in real-world applications, corruptions from different distribution shifts are always mixed. Existing TTA methods always fail in such multimodal scenario because the abrupt distribution shifts will destroy the prior knowledge from the source model, thus leading to performance degradation. To this end, we reveal a new challenge named multimodal wild TTA. To address this challenging problem, we propose two novel strategies: sample identification with interquartile range Smoothing and unimodal assistance, and Mutual information sharing (SuMi). SuMi smooths the adaptation process by interquartile range which avoids the abrupt distribution shifts. Then, SuMi fully utilizes the unimodal features to select low-entropy samples with rich multimodal information for optimization. Furthermore, mutual information sharing is introduced to align the information, reduce the discrepancies and enhance the information utilization across different modalities. Extensive experiments on two public datasets show the effectiveness and superiority over existing methods under the complex noise patterns in multimodal data. Code is available at https://github.com/zrguo/SuMi.
<div id='section'>Paperid: <span id='pid'>71, <a href='https://arxiv.org/pdf/2502.14604.pdf' target='_blank'>https://arxiv.org/pdf/2502.14604.pdf</a></span>   <span><a href='https://github.com/tmlr-group/ZS-NTTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chentao Cao, Zhun Zhong, Zhanke Zhou, Tongliang Liu, Yang Liu, Kun Zhang, Bo Han
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.14604">Noisy Test-Time Adaptation in Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) aims to address distribution shifts between source and target data by relying solely on target data during testing. In open-world scenarios, models often encounter noisy samples, i.e., samples outside the in-distribution (ID) label space. Leveraging the zero-shot capability of pre-trained vision-language models (VLMs), this paper introduces Zero-Shot Noisy TTA (ZS-NTTA), focusing on adapting the model to target data with noisy samples during test-time in a zero-shot manner. We find existing TTA methods underperform under ZS-NTTA, often lagging behind even the frozen model. We conduct comprehensive experiments to analyze this phenomenon, revealing that the negative impact of unfiltered noisy data outweighs the benefits of clean data during model updating. Also, adapting a classifier for ID classification and noise detection hampers both sub-tasks. Built on this, we propose a framework that decouples the classifier and detector, focusing on developing an individual detector while keeping the classifier frozen. Technically, we introduce the Adaptive Noise Detector (AdaND), which utilizes the frozen model's outputs as pseudo-labels to train a noise detector. To handle clean data streams, we further inject Gaussian noise during adaptation, preventing the detector from misclassifying clean samples as noisy. Beyond the ZS-NTTA, AdaND can also improve the zero-shot out-of-distribution (ZS-OOD) detection ability of VLMs. Experiments show that AdaND outperforms in both ZS-NTTA and ZS-OOD detection. On ImageNet, AdaND achieves a notable improvement of $8.32\%$ in harmonic mean accuracy ($\text{Acc}_\text{H}$) for ZS-NTTA and $9.40\%$ in FPR95 for ZS-OOD detection, compared to SOTA methods. Importantly, AdaND is computationally efficient and comparable to the model-frozen method. The code is publicly available at: https://github.com/tmlr-group/ZS-NTTA.
<div id='section'>Paperid: <span id='pid'>72, <a href='https://arxiv.org/pdf/2502.08774.pdf' target='_blank'>https://arxiv.org/pdf/2502.08774.pdf</a></span>   <span><a href='https://github.com/joshuaomolegan/TTA-for-3D-Fetal-Subcortical-Segmentation' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Joshua Omolegan, Pak Hei Yeung, Madeleine K. Wyburd, Linde Hesse, Monique Haak, Intergrowth-21st Consortium, Ana I. L. Namburete, Nicola K. Dinsdale
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.08774">Exploring Test Time Adaptation for Subcortical Segmentation of the Fetal Brain in 3D Ultrasound</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Monitoring the growth of subcortical regions of the fetal brain in ultrasound (US) images can help identify the presence of abnormal development. Manually segmenting these regions is a challenging task, but recent work has shown that it can be automated using deep learning. However, applying pretrained models to unseen freehand US volumes often leads to a degradation of performance due to the vast differences in acquisition and alignment. In this work, we first demonstrate that test time adaptation (TTA) can be used to improve model performance in the presence of both real and simulated domain shifts. We further propose a novel TTA method by incorporating a normative atlas as a prior for anatomy. In the presence of various types of domain shifts, we benchmark the performance of different TTA methods and demonstrate the improvements brought by our proposed approach, which may further facilitate automated monitoring of fetal brain development. Our code is available at https://github.com/joshuaomolegan/TTA-for-3D-Fetal-Subcortical-Segmentation.
<div id='section'>Paperid: <span id='pid'>73, <a href='https://arxiv.org/pdf/2502.06019.pdf' target='_blank'>https://arxiv.org/pdf/2502.06019.pdf</a></span>   <span><a href='https://github.com/Razaimam45/TNT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Raza Imam, Asif Hanif, Jian Zhang, Khaled Waleed Dawoud, Yova Kementchedjhieva, Mohammad Yaqub
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.06019">Noise is an Efficient Learner for Zero-Shot Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, test-time adaptation has garnered attention as a method for tuning models without labeled data. The conventional modus operandi for adapting pre-trained vision-language models (VLMs) during test-time primarily focuses on tuning learnable prompts; however, this approach overlooks potential distribution shifts in the visual representations themselves. In this work, we address this limitation by introducing Test-Time Noise Tuning (TNT), a novel method for handling unpredictable shifts in the visual space. TNT leverages, for the first time, a noise adaptation strategy that optimizes learnable noise directly in the visual input space, enabling adaptive feature learning from a single test sample. We further introduce a novel approach for inter-view representation alignment by explicitly enforcing coherence in embedding distances, ensuring consistent feature representations across views. Combined with scaled logits and confident view selection at inference, TNT substantially enhances VLM generalization and calibration, achieving average gains of +7.38% on natural distributions benchmark and +0.80% on cross-dataset evaluations over zero-shot CLIP. These improvements lay a strong foundation for adaptive out-of-distribution handling.
<div id='section'>Paperid: <span id='pid'>74, <a href='https://arxiv.org/pdf/2502.03777.pdf' target='_blank'>https://arxiv.org/pdf/2502.03777.pdf</a></span>   <span><a href='https://github.com/Jinx630/ML-TTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiangyu Wu, Feng Yu, Qing-Guo Chen, Yang Yang, Jianfeng Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.03777">Multi-Label Test-Time Adaptation with Bound Entropy Minimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Mainstream test-time adaptation (TTA) techniques endeavor to mitigate distribution shifts via entropy minimization for multi-class classification, inherently increasing the probability of the most confident class. However, when encountering multi-label instances, the primary challenge stems from the varying number of labels per image, and prioritizing only the highest probability class inevitably undermines the adaptation of other positive labels. To address this issue, we investigate TTA within multi-label scenario (ML--TTA), developing Bound Entropy Minimization (BEM) objective to simultaneously increase the confidence of multiple top predicted labels. Specifically, to determine the number of labels for each augmented view, we retrieve a paired caption with yielded textual labels for that view. These labels are allocated to both the view and caption, called weak label set and strong label set with the same size k. Following this, the proposed BEM considers the highest top-k predicted labels from view and caption as a single entity, respectively, learning both view and caption prompts concurrently. By binding top-k predicted labels, BEM overcomes the limitation of vanilla entropy minimization, which exclusively optimizes the most confident class. Across the MSCOCO, VOC, and NUSWIDE multi-label datasets, our ML--TTA framework equipped with BEM exhibits superior performance compared to the latest SOTA methods, across various model architectures, prompt initialization, and varying label scenarios. The code is available at https://github.com/Jinx630/ML-TTA.
<div id='section'>Paperid: <span id='pid'>75, <a href='https://arxiv.org/pdf/2501.18592.pdf' target='_blank'>https://arxiv.org/pdf/2501.18592.pdf</a></span>   <span><a href='https://github.com/donghao51/Awesome-Multimodal-Adaptation' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/donghao51/Awesome-Multimodal-Adaptation' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Dong, Moru Liu, Kaiyang Zhou, Eleni Chatzi, Juho Kannala, Cyrill Stachniss, Olga Fink
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.18592">Advances in Multimodal Adaptation and Generalization: From Traditional Approaches to Foundation Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In real-world scenarios, achieving domain adaptation and generalization poses significant challenges, as models must adapt to or generalize across unknown target distributions. Extending these capabilities to unseen multimodal distributions, i.e., multimodal domain adaptation and generalization, is even more challenging due to the distinct characteristics of different modalities. Significant progress has been made over the years, with applications ranging from action recognition to semantic segmentation. Besides, the recent advent of large-scale pre-trained multimodal foundation models, such as CLIP, has inspired works leveraging these models to enhance adaptation and generalization performances or adapting them to downstream tasks. This survey provides the first comprehensive review of recent advances from traditional approaches to foundation models, covering: (1) Multimodal domain adaptation; (2) Multimodal test-time adaptation; (3) Multimodal domain generalization; (4) Domain adaptation and generalization with the help of multimodal foundation models; and (5) Adaptation of multimodal foundation models. For each topic, we formally define the problem and thoroughly review existing methods. Additionally, we analyze relevant datasets and applications, highlighting open challenges and potential future research directions. We maintain an active repository that contains up-to-date literature at https://github.com/donghao51/Awesome-Multimodal-Adaptation.
<div id='section'>Paperid: <span id='pid'>76, <a href='https://arxiv.org/pdf/2501.18592.pdf' target='_blank'>https://arxiv.org/pdf/2501.18592.pdf</a></span>   <span><a href='https://github.com/donghao51/Awesome-Multimodal-Adaptation' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/donghao51/Awesome-Multimodal-Adaptation' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Dong, Moru Liu, Kaiyang Zhou, Eleni Chatzi, Juho Kannala, Cyrill Stachniss, Olga Fink
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.18592">Advances in Multimodal Adaptation and Generalization: From Traditional Approaches to Foundation Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In real-world scenarios, achieving domain adaptation and generalization poses significant challenges, as models must adapt to or generalize across unknown target distributions. Extending these capabilities to unseen multimodal distributions, i.e., multimodal domain adaptation and generalization, is even more challenging due to the distinct characteristics of different modalities. Significant progress has been made over the years, with applications ranging from action recognition to semantic segmentation. Besides, the recent advent of large-scale pre-trained multimodal foundation models, such as CLIP, has inspired works leveraging these models to enhance adaptation and generalization performances or adapting them to downstream tasks. This survey provides the first comprehensive review of recent advances from traditional approaches to foundation models, covering: (1) Multimodal domain adaptation; (2) Multimodal test-time adaptation; (3) Multimodal domain generalization; (4) Domain adaptation and generalization with the help of multimodal foundation models; and (5) Adaptation of multimodal foundation models. For each topic, we formally define the problem and thoroughly review existing methods. Additionally, we analyze relevant datasets and applications, highlighting open challenges and potential future research directions. We maintain an active repository that contains up-to-date literature at https://github.com/donghao51/Awesome-Multimodal-Adaptation.
<div id='section'>Paperid: <span id='pid'>77, <a href='https://arxiv.org/pdf/2501.14319.pdf' target='_blank'>https://arxiv.org/pdf/2501.14319.pdf</a></span>   <span><a href='https://github.com/Xiaohao-Xu/SLAM-under-Perturbation' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaohao Xu, Tianyi Zhang, Shibo Zhao, Xiang Li, Sibo Wang, Yongqi Chen, Ye Li, Bhiksha Raj, Matthew Johnson-Roberson, Sebastian Scherer, Xiaonan Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.14319">Scalable Benchmarking and Robust Learning for Noise-Free Ego-Motion and 3D Reconstruction from Noisy Video</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We aim to redefine robust ego-motion estimation and photorealistic 3D reconstruction by addressing a critical limitation: the reliance on noise-free data in existing models. While such sanitized conditions simplify evaluation, they fail to capture the unpredictable, noisy complexities of real-world environments. Dynamic motion, sensor imperfections, and synchronization perturbations lead to sharp performance declines when these models are deployed in practice, revealing an urgent need for frameworks that embrace and excel under real-world noise. To bridge this gap, we tackle three core challenges: scalable data generation, comprehensive benchmarking, and model robustness enhancement. First, we introduce a scalable noisy data synthesis pipeline that generates diverse datasets simulating complex motion, sensor imperfections, and synchronization errors. Second, we leverage this pipeline to create Robust-Ego3D, a benchmark rigorously designed to expose noise-induced performance degradation, highlighting the limitations of current learning-based methods in ego-motion accuracy and 3D reconstruction quality. Third, we propose Correspondence-guided Gaussian Splatting (CorrGS), a novel test-time adaptation method that progressively refines an internal clean 3D representation by aligning noisy observations with rendered RGB-D frames from clean 3D map, enhancing geometric alignment and appearance restoration through visual correspondence. Extensive experiments on synthetic and real-world data demonstrate that CorrGS consistently outperforms prior state-of-the-art methods, particularly in scenarios involving rapid motion and dynamic illumination.
<div id='section'>Paperid: <span id='pid'>78, <a href='https://arxiv.org/pdf/2501.13924.pdf' target='_blank'>https://arxiv.org/pdf/2501.13924.pdf</a></span>   <span><a href='https://github.com/donghao51/AEO' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Dong, Eleni Chatzi, Olga Fink
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.13924">Towards Robust Multimodal Open-set Test-time Adaptation via Adaptive Entropy-aware Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) has demonstrated significant potential in addressing distribution shifts between training and testing data. Open-set test-time adaptation (OSTTA) aims to adapt a source pre-trained model online to an unlabeled target domain that contains unknown classes. This task becomes more challenging when multiple modalities are involved. Existing methods have primarily focused on unimodal OSTTA, often filtering out low-confidence samples without addressing the complexities of multimodal data. In this work, we present Adaptive Entropy-aware Optimization (AEO), a novel framework specifically designed to tackle Multimodal Open-set Test-time Adaptation (MM-OSTTA) for the first time. Our analysis shows that the entropy difference between known and unknown samples in the target domain strongly correlates with MM-OSTTA performance. To leverage this, we propose two key components: Unknown-aware Adaptive Entropy Optimization (UAE) and Adaptive Modality Prediction Discrepancy Optimization (AMP). These components enhance the ability of model to distinguish unknown class samples during online adaptation by amplifying the entropy difference between known and unknown samples. To thoroughly evaluate our proposed methods in the MM-OSTTA setting, we establish a new benchmark derived from existing datasets. This benchmark includes two downstream tasks and incorporates five modalities. Extensive experiments across various domain shift situations demonstrate the efficacy and versatility of the AEO framework. Additionally, we highlight the strong performance of AEO in long-term and continual MM-OSTTA settings, both of which are challenging and highly relevant to real-world applications. Our source code is available at https://github.com/donghao51/AEO.
<div id='section'>Paperid: <span id='pid'>79, <a href='https://arxiv.org/pdf/2501.05661.pdf' target='_blank'>https://arxiv.org/pdf/2501.05661.pdf</a></span>   <span><a href='https://github.com/yhzhu99/TAMER' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yinghao Zhu, Xiaochen Zheng, Ahmed Allam, Michael Krauthammer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.05661">TAMER: A Test-Time Adaptive MoE-Driven Framework for EHR Representation Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose TAMER, a Test-time Adaptive MoE-driven framework for Electronic Health Record (EHR) Representation learning. TAMER introduces a framework where a Mixture-of-Experts (MoE) architecture is co-designed with Test-Time Adaptation (TTA) to jointly mitigate the intertwined challenges of patient heterogeneity and distribution shifts in EHR modeling. The MoE focuses on latent patient subgroups through domain-aware expert specialization, while TTA enables real-time adaptation to evolving health status distributions when new patient samples are introduced. Extensive experiments across four real-world EHR datasets demonstrate that TAMER consistently improves predictive performance for both mortality and readmission risk tasks when combined with diverse EHR modeling backbones. TAMER offers a promising approach for dynamic and personalized EHR-based predictions in practical clinical settings.
<div id='section'>Paperid: <span id='pid'>80, <a href='https://arxiv.org/pdf/2501.04970.pdf' target='_blank'>https://arxiv.org/pdf/2501.04970.pdf</a></span>   <span><a href='https://github.com/kimanki/TAFAS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>HyunGi Kim, Siwon Kim, Jisoo Mok, Sungroh Yoon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.04970">Battling the Non-stationarity in Time Series Forecasting via Test-time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep Neural Networks have spearheaded remarkable advancements in time series forecasting (TSF), one of the major tasks in time series modeling. Nonetheless, the non-stationarity of time series undermines the reliability of pre-trained source time series forecasters in mission-critical deployment settings. In this study, we introduce a pioneering test-time adaptation framework tailored for TSF (TSF-TTA). TAFAS, the proposed approach to TSF-TTA, flexibly adapts source forecasters to continuously shifting test distributions while preserving the core semantic information learned during pre-training. The novel utilization of partially-observed ground truth and gated calibration module enables proactive, robust, and model-agnostic adaptation of source forecasters. Experiments on diverse benchmark datasets and cutting-edge architectures demonstrate the efficacy and generality of TAFAS, especially in long-term forecasting scenarios that suffer from significant distribution shifts. The code is available at https://github.com/kimanki/TAFAS.
<div id='section'>Paperid: <span id='pid'>81, <a href='https://arxiv.org/pdf/2501.04352.pdf' target='_blank'>https://arxiv.org/pdf/2501.04352.pdf</a></span>   <span><a href='https://github.com/cfuchs2023/OGA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>ClÃ©ment Fuchs, Maxime Zanella, Christophe De Vleeschouwer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.04352">Online Gaussian Test-Time Adaptation of Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Online test-time adaptation (OTTA) of vision-language models (VLMs) has recently garnered increased attention to take advantage of data observed along a stream to improve future predictions. Unfortunately, existing methods rely on dataset-specific hyperparameters, significantly limiting their adaptability to unseen tasks. In response, we propose Online Gaussian Adaptation (OGA), a novel method that models the likelihoods of visual features using Gaussian distributions and incorporates zero-shot priors into an interpretable Maximum A Posteriori (MAP) estimation framework with fixed hyper-parameters across all datasets. We demonstrate that OGA outperforms state-of-the-art methods on most datasets and runs. Additionally, we show that combining OTTA with popular few-shot techniques (a practical yet overlooked setting in prior research) is highly beneficial. Furthermore, our experimental study reveals that common OTTA evaluation protocols, which average performance over at most three runs per dataset, are inadequate due to the substantial variability observed across runs for all OTTA methods. Therefore, we advocate for more rigorous evaluation practices, including increasing the number of runs and considering additional quantitative metrics, such as our proposed Expected Tail Accuracy (ETA), calculated as the average accuracy in the worst 10% of runs. We hope these contributions will encourage more rigorous and diverse evaluation practices in the OTTA community. Code is available at https://github.com/cfuchs2023/OGA .
<div id='section'>Paperid: <span id='pid'>82, <a href='https://arxiv.org/pdf/2501.03729.pdf' target='_blank'>https://arxiv.org/pdf/2501.03729.pdf</a></span>   <span><a href='https://github.com/MaxZanella/StatA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Maxime Zanella, ClÃ©ment Fuchs, Christophe De Vleeschouwer, Ismail Ben Ayed
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.03729">Realistic Test-Time Adaptation of Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The zero-shot capabilities of Vision-Language Models (VLMs) have been widely leveraged to improve predictive performance. However, previous works on transductive or test-time adaptation (TTA) often make strong assumptions about the data distribution, such as the presence of all classes. Our work challenges these favorable deployment scenarios, and introduces a more realistic evaluation framework, including: (i) a variable number of effective classes for adaptation within a single batch, and (ii) non-i.i.d. batches of test samples in online adaptation settings. We provide comprehensive evaluations, comparisons, and ablation studies that demonstrate how current transductive or TTA methods for VLMs systematically compromise the models' initial zero-shot robustness across various realistic scenarios, favoring performance gains under advantageous assumptions about the test samples' distributions. Furthermore, we introduce StatA, a versatile method that could handle a wide range of deployment scenarios, including those with a variable number of effective classes at test time. Our approach incorporates a novel regularization term designed specifically for VLMs, which acts as a statistical anchor preserving the initial text-encoder knowledge, particularly in low-data regimes. Code available at https://github.com/MaxZanella/StatA.
<div id='section'>Paperid: <span id='pid'>83, <a href='https://arxiv.org/pdf/2501.00873.pdf' target='_blank'>https://arxiv.org/pdf/2501.00873.pdf</a></span>   <span><a href='https://kiwixr.github.io/projects/dusa' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/BIT-DA/DUSA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingjia Li, Shuang Li, Tongrui Su, Longhui Yuan, Jian Liang, Wei Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.00873">Exploring Structured Semantic Priors Underlying Diffusion Score for Test-time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Capitalizing on the complementary advantages of generative and discriminative models has always been a compelling vision in machine learning, backed by a growing body of research. This work discloses the hidden semantic structure within score-based generative models, unveiling their potential as effective discriminative priors. Inspired by our theoretical findings, we propose DUSA to exploit the structured semantic priors underlying diffusion score to facilitate the test-time adaptation of image classifiers or dense predictors. Notably, DUSA extracts knowledge from a single timestep of denoising diffusion, lifting the curse of Monte Carlo-based likelihood estimation over timesteps. We demonstrate the efficacy of our DUSA in adapting a wide variety of competitive pre-trained discriminative models on diverse test-time scenarios. Additionally, a thorough ablation study is conducted to dissect the pivotal elements in DUSA. Code is publicly available at https://github.com/BIT-DA/DUSA.
<div id='section'>Paperid: <span id='pid'>84, <a href='https://arxiv.org/pdf/2412.10871.pdf' target='_blank'>https://arxiv.org/pdf/2412.10871.pdf</a></span>   <span><a href='https://wnjxyk.github.io/FTTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhi Zhou, Kun-Yang Yu, Lan-Zhe Guo, Yu-Feng Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.10871">Fully Test-time Adaptation for Tabular Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Tabular data plays a vital role in various real-world scenarios and finds extensive applications. Although recent deep tabular models have shown remarkable success, they still struggle to handle data distribution shifts, leading to performance degradation when testing distributions change. To remedy this, a robust tabular model must adapt to generalize to unknown distributions during testing. In this paper, we investigate the problem of fully test-time adaptation (FTTA) for tabular data, where the model is adapted using only the testing data. We identify three key challenges: the existence of label and covariate distribution shifts, the lack of effective data augmentation, and the sensitivity of adaptation, which render existing FTTA methods ineffective for tabular data. To this end, we propose the Fully Test-time Adaptation for Tabular data, namely FTAT, which enables FTTA methods to robustly optimize the label distribution of predictions, adapt to shifted covariate distributions, and suit a variety of tasks and models effectively. We conduct comprehensive experiments on six benchmark datasets, which are evaluated using three metrics. The experimental results demonstrate that FTAT outperforms state-of-the-art methods by a margin.
<div id='section'>Paperid: <span id='pid'>85, <a href='https://arxiv.org/pdf/2412.09308.pdf' target='_blank'>https://arxiv.org/pdf/2412.09308.pdf</a></span>   <span><a href='https://github.com/Cadezzyr/PAINT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chaoran Cui, Yongrui Zhen, Shuai Gong, Chunyun Zhang, Hui Liu, Yilong Yin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.09308">Dynamic Prompt Allocation and Tuning for Continual Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual test-time adaptation (CTTA) has recently emerged to adapt a pre-trained source model to continuously evolving target distributions, which accommodates the dynamic nature of real-world environments. To mitigate the risk of catastrophic forgetting in CTTA, existing methods typically incorporate explicit regularization terms to constrain the variation of model parameters. However, they cannot fundamentally resolve catastrophic forgetting because they rely on a single shared model to adapt across all target domains, which inevitably leads to severe inter-domain interference. In this paper, we introduce learnable domain-specific prompts that guide the model to adapt to corresponding target domains, thereby partially disentangling the parameter space of different domains. In the absence of domain identity for target samples, we propose a novel dynamic Prompt AllocatIon aNd Tuning (PAINT) method, which utilizes a query mechanism to dynamically determine whether the current samples come from a known domain or an unexplored one. For known domains, the corresponding domain-specific prompt is directly selected, while for previously unseen domains, a new prompt is allocated. Prompt tuning is subsequently performed using mutual information maximization along with structural regularization. Extensive experiments on three benchmark datasets demonstrate the effectiveness of our PAINT method for CTTA. We have released our code at https://github.com/Cadezzyr/PAINT.
<div id='section'>Paperid: <span id='pid'>86, <a href='https://arxiv.org/pdf/2412.07121.pdf' target='_blank'>https://arxiv.org/pdf/2412.07121.pdf</a></span>   <span><a href='https://github.com/zrguo/CASP' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zirun Guo, Tao Jin, Wenlong Xu, Wang Lin, Yangyang Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.07121">Bridging the Gap for Test-Time Multimodal Sentiment Analysis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multimodal sentiment analysis (MSA) is an emerging research topic that aims to understand and recognize human sentiment or emotions through multiple modalities. However, in real-world dynamic scenarios, the distribution of target data is always changing and different from the source data used to train the model, which leads to performance degradation. Common adaptation methods usually need source data, which could pose privacy issues or storage overheads. Therefore, test-time adaptation (TTA) methods are introduced to improve the performance of the model at inference time. Existing TTA methods are always based on probabilistic models and unimodal learning, and thus can not be applied to MSA which is often considered as a multimodal regression task. In this paper, we propose two strategies: Contrastive Adaptation and Stable Pseudo-label generation (CASP) for test-time adaptation for multimodal sentiment analysis. The two strategies deal with the distribution shifts for MSA by enforcing consistency and minimizing empirical risk, respectively. Extensive experiments show that CASP brings significant and consistent improvements to the performance of the model across various distribution shift settings and with different backbones, demonstrating its effectiveness and versatility. Our codes are available at https://github.com/zrguo/CASP.
<div id='section'>Paperid: <span id='pid'>87, <a href='https://arxiv.org/pdf/2412.02837.pdf' target='_blank'>https://arxiv.org/pdf/2412.02837.pdf</a></span>   <span><a href='https://github.com/sarthaxxxxx/BATCLIP' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Sarthak Kumar Maharana, Baoming Zhang, Leonid Karlinsky, Rogerio Feris, Yunhui Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.02837">$\texttt{BATCLIP}$: Bimodal Online Test-Time Adaptation for CLIP</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Although open-vocabulary classification models like Contrastive Language Image Pretraining (CLIP) have demonstrated strong zero-shot learning capabilities, their robustness to common image corruptions remains poorly understood. Through extensive experiments, we show that zero-shot CLIP lacks robustness to common image corruptions during test-time, necessitating the adaptation of CLIP to unlabeled corrupted images using test-time adaptation (TTA). However, we found that existing TTA methods have severe limitations in adapting CLIP due to their unimodal nature. To address these limitations, we propose $\texttt{BATCLIP}$, a bimodal $\textbf{online}$ TTA method designed to improve CLIP's robustness to common image corruptions. The key insight of our approach is not only to adapt the visual encoders for improving image features but also to strengthen the alignment between image and text features by promoting a stronger association between the image class prototype, computed using pseudo-labels, and the corresponding text feature. We evaluate our approach on benchmark image corruption datasets and achieve state-of-the-art results in online TTA for CLIP. Furthermore, we evaluate our proposed TTA approach on various domain generalization datasets to demonstrate its generalization capabilities. Our code is available at https://github.com/sarthaxxxxx/BATCLIP
<div id='section'>Paperid: <span id='pid'>88, <a href='https://arxiv.org/pdf/2411.18855.pdf' target='_blank'>https://arxiv.org/pdf/2411.18855.pdf</a></span>   <span><a href='https://wvuvl.github.io/SiamABC/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ram Zaveri, Shivang Patel, Yu Gu, Gianfranco Doretto
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.18855">Improving Accuracy and Generalization for Efficient Visual Tracking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Efficient visual trackers overfit to their training distributions and lack generalization abilities, resulting in them performing well on their respective in-distribution (ID) test sets and not as well on out-of-distribution (OOD) sequences, imposing limitations to their deployment in-the-wild under constrained resources. We introduce SiamABC, a highly efficient Siamese tracker that significantly improves tracking performance, even on OOD sequences. SiamABC takes advantage of new architectural designs in the way it bridges the dynamic variability of the target, and of new losses for training. Also, it directly addresses OOD tracking generalization by including a fast backward-free dynamic test-time adaptation method that continuously adapts the model according to the dynamic visual changes of the target. Our extensive experiments suggest that SiamABC shows remarkable performance gains in OOD sets while maintaining accurate performance on the ID benchmarks. SiamABC outperforms MixFormerV2-S by 7.6\% on the OOD AVisT benchmark while being 3x faster (100 FPS) on a CPU. Our code and models are available at https://wvuvl.github.io/SiamABC/.
<div id='section'>Paperid: <span id='pid'>89, <a href='https://arxiv.org/pdf/2411.16657.pdf' target='_blank'>https://arxiv.org/pdf/2411.16657.pdf</a></span>   <span><a href='https://zunwang1.github.io/DreamRunner' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zun Wang, Jialu Li, Han Lin, Jaehong Yoon, Mohit Bansal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.16657">DreamRunner: Fine-Grained Compositional Story-to-Video Generation with Retrieval-Augmented Motion Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Storytelling video generation (SVG) aims to produce coherent and visually rich multi-scene videos that follow a structured narrative. Existing methods primarily employ LLM for high-level planning to decompose a story into scene-level descriptions, which are then independently generated and stitched together. However, these approaches struggle with generating high-quality videos aligned with the complex single-scene description, as visualizing such complex description involves coherent composition of multiple characters and events, complex motion synthesis and muti-character customization. To address these challenges, we propose DreamRunner, a novel story-to-video generation method: First, we structure the input script using a large language model (LLM) to facilitate both coarse-grained scene planning as well as fine-grained object-level layout and motion planning. Next, DreamRunner presents retrieval-augmented test-time adaptation to capture target motion priors for objects in each scene, supporting diverse motion customization based on retrieved videos, thus facilitating the generation of new videos with complex, scripted motions. Lastly, we propose a novel spatial-temporal region-based 3D attention and prior injection module SR3AI for fine-grained object-motion binding and frame-by-frame semantic control. We compare DreamRunner with various SVG baselines, demonstrating state-of-the-art performance in character consistency, text alignment, and smooth transitions. Additionally, DreamRunner exhibits strong fine-grained condition-following ability in compositional text-to-video generation, significantly outperforming baselines on T2V-ComBench. Finally, we validate DreamRunner's robust ability to generate multi-object interactions with qualitative examples.
<div id='section'>Paperid: <span id='pid'>90, <a href='https://arxiv.org/pdf/2411.15735.pdf' target='_blank'>https://arxiv.org/pdf/2411.15735.pdf</a></span>   <span><a href='https://github.com/BaoshunWq/clip-TAEA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Baoshun Tong, Kaiyu Song, Hanjiang Lai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.15735">Test-time Alignment-Enhanced Adapter for Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation with pre-trained vision-language models (VLMs) has attracted increasing attention for tackling the issue of distribution shift during the test phase. While prior methods have shown effectiveness in addressing distribution shift by adjusting classification logits, they are not optimal due to keeping text features unchanged. To address this issue, we introduce a new approach called Test-time Alignment-Enhanced Adapter (TAEA), which trains an adapter with test samples to adjust text features during the test phase. We can enhance the text-to-image alignment prediction by utilizing an adapter to adapt text features. Furthermore, we also propose to adopt the negative cache from TDA as enhancement module, which further improves the performance of TAEA. Our approach outperforms the state-of-the-art TTA method of pre-trained VLMs by an average of 0.75% on the out-of-distribution benchmark and 2.5% on the cross-domain benchmark, with an acceptable training time. Code will be available at https://github.com/BaoshunWq/clip-TAEA.
<div id='section'>Paperid: <span id='pid'>91, <a href='https://arxiv.org/pdf/2411.14495.pdf' target='_blank'>https://arxiv.org/pdf/2411.14495.pdf</a></span>   <span><a href='https://github.com/hamidreza-dastmalchi/3DD-TTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hamidreza Dastmalchi, Aijun An, Ali Cheraghian, Shafin Rahman, Sameera Ramasinghe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.14495">Test-Time Adaptation of 3D Point Clouds via Denoising Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) of 3D point clouds is crucial for mitigating discrepancies between training and testing samples in real-world scenarios, particularly when handling corrupted point clouds. LiDAR data, for instance, can be affected by sensor failures or environmental factors, causing domain gaps. Adapting models to these distribution shifts online is crucial, as training for every possible variation is impractical. Existing methods often focus on fine-tuning pre-trained models based on self-supervised learning or pseudo-labeling, which can lead to forgetting valuable source domain knowledge over time and reduce generalization on future tests. In this paper, we introduce a novel 3D test-time adaptation method, termed 3DD-TTA, which stands for 3D Denoising Diffusion Test-Time Adaptation. This method uses a diffusion strategy that adapts input point cloud samples to the source domain while keeping the source model parameters intact. The approach uses a Variational Autoencoder (VAE) to encode the corrupted point cloud into a shape latent and latent points. These latent points are corrupted with Gaussian noise and subjected to a denoising diffusion process. During this process, both the shape latent and latent points are updated to preserve fidelity, guiding the denoising toward generating consistent samples that align more closely with the source domain. We conduct extensive experiments on the ShapeNet dataset and investigate its generalizability on ModelNet40 and ScanObjectNN, achieving state-of-the-art results. The code has been released at \url{https://github.com/hamidreza-dastmalchi/3DD-TTA}.
<div id='section'>Paperid: <span id='pid'>92, <a href='https://arxiv.org/pdf/2411.13284.pdf' target='_blank'>https://arxiv.org/pdf/2411.13284.pdf</a></span>   <span><a href='https://github.com/StrohmayerJ/DATTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Julian Strohmayer, Rafael Sterzinger, Matthias WÃ¶dlinger, Martin Kampel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.13284">DATTA: Domain-Adversarial Test-Time Adaptation for Cross-Domain WiFi-Based Human Activity Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cross-domain generalization is an open problem in WiFi-based sensing due to variations in environments, devices, and subjects, causing domain shifts in channel state information. To address this, we propose Domain-Adversarial Test-Time Adaptation (DATTA), a novel framework combining domain-adversarial training (DAT), test-time adaptation (TTA), and weight resetting to facilitate adaptation to unseen target domains and to prevent catastrophic forgetting. DATTA is integrated into a lightweight, flexible architecture optimized for speed. We conduct a comprehensive evaluation of DATTA, including an ablation study on all key components using publicly available data, and verify its suitability for real-time applications such as human activity recognition. When combining a SotA video-based variant of TTA with WiFi-based DAT and comparing it to DATTA, our method achieves an 8.1% higher F1-Score. The PyTorch implementation of DATTA is publicly available at: https://github.com/StrohmayerJ/DATTA.
<div id='section'>Paperid: <span id='pid'>93, <a href='https://arxiv.org/pdf/2411.08706.pdf' target='_blank'>https://arxiv.org/pdf/2411.08706.pdf</a></span>   <span><a href='https://github.com/clement-bonnet/lpn' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Matthew V Macfarlane, ClÃ©ment Bonnet
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.08706">Searching Latent Program Spaces</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>General intelligence requires systems that acquire new skills efficiently and generalize beyond their training distributions. Although program synthesis approaches have strong generalization power, they face scaling issues due to large combinatorial spaces that quickly make them impractical and require human-generated DSLs or pre-trained priors to narrow this search space. On the other hand, deep learning methods have had high successes, but they lack structured test-time adaptation and rely on heavy stochastic sampling or expensive gradient updates for fine-tuning. In this work, we propose the Latent Program Network (LPN), a new architecture that builds in test-time search directly into neural models. LPN learns a latent space of implicit programs--neurally mapping inputs to outputs--through which it can search using gradients at test time. LPN combines the adaptability of symbolic approaches and the scalability of neural methods. It searches through a compact latent space at test time and bypasses the need for pre-defined domain-specific languages. On a range of programming-by-examples tasks, LPN either outperforms or matches performance compared to in-context learning and test-time training methods. Tested on the ARC-AGI benchmark, we demonstrate that LPN can both learn a compact program space and search through it at test time to adapt to novel tasks. LPN doubles its performance on out-of-distribution tasks when test-time search is switched on.
<div id='section'>Paperid: <span id='pid'>94, <a href='https://arxiv.org/pdf/2411.06921.pdf' target='_blank'>https://arxiv.org/pdf/2411.06921.pdf</a></span>   <span><a href='https://github.com/GIT-LJc/UMFC' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiachen Liang, Ruibing Hou, Minyang Hu, Hong Chang, Shiguang Shan, Xilin Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.06921">UMFC: Unsupervised Multi-Domain Feature Calibration for Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pre-trained vision-language models (e.g., CLIP) have shown powerful zero-shot transfer capabilities. But they still struggle with domain shifts and typically require labeled data to adapt to downstream tasks, which could be costly. In this work, we aim to leverage unlabeled data that naturally spans multiple domains to enhance the transferability of vision-language models. Under this unsupervised multi-domain setting, we have identified inherent model bias within CLIP, notably in its visual and text encoders. Specifically, we observe that CLIP's visual encoder tends to prioritize encoding domain over discriminative category information, meanwhile its text encoder exhibits a preference for domain-relevant classes. To mitigate this model bias, we propose a training-free and label-free feature calibration method, Unsupervised Multi-domain Feature Calibration (UMFC). UMFC estimates image-level biases from domain-specific features and text-level biases from the direction of domain transition. These biases are subsequently subtracted from original image and text features separately, to render them domain-invariant. We evaluate our method on multiple settings including transductive learning and test-time adaptation. Extensive experiments show that our method outperforms CLIP and performs on par with the state-of-the-arts that need additional annotations or optimization. Our code is available at https://github.com/GIT-LJc/UMFC.
<div id='section'>Paperid: <span id='pid'>95, <a href='https://arxiv.org/pdf/2410.15674.pdf' target='_blank'>https://arxiv.org/pdf/2410.15674.pdf</a></span>   <span><a href='https://github.com/blue-531/TALoS' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/blue-531/TALoS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyun-Kurl Jang, Jihun Kim, Hyeokjun Kweon, Kuk-Jin Yoon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.15674">TALoS: Enhancing Semantic Scene Completion via Test-time Adaptation on the Line of Sight</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semantic Scene Completion (SSC) aims to perform geometric completion and semantic segmentation simultaneously. Despite the promising results achieved by existing studies, the inherently ill-posed nature of the task presents significant challenges in diverse driving scenarios. This paper introduces TALoS, a novel test-time adaptation approach for SSC that excavates the information available in driving environments. Specifically, we focus on that observations made at a certain moment can serve as Ground Truth (GT) for scene completion at another moment. Given the characteristics of the LiDAR sensor, an observation of an object at a certain location confirms both 1) the occupation of that location and 2) the absence of obstacles along the line of sight from the LiDAR to that point. TALoS utilizes these observations to obtain self-supervision about occupancy and emptiness, guiding the model to adapt to the scene in test time. In a similar manner, we aggregate reliable SSC predictions among multiple moments and leverage them as semantic pseudo-GT for adaptation. Further, to leverage future observations that are not accessible at the current time, we present a dual optimization scheme using the model in which the update is delayed until the future observation is available. Evaluations on the SemanticKITTI validation and test sets demonstrate that TALoS significantly improves the performance of the pre-trained SSC model. Our code is available at https://github.com/blue-531/TALoS.
<div id='section'>Paperid: <span id='pid'>96, <a href='https://arxiv.org/pdf/2410.12790.pdf' target='_blank'>https://arxiv.org/pdf/2410.12790.pdf</a></span>   <span><a href='https://github.com/zhangce01/DPE-CLIP' target='_blank'>  GitHub</a></span> <span><a href='https://zhangce01.github.io/DPE-CLIP' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ce Zhang, Simon Stepputtis, Katia Sycara, Yaqi Xie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.12790">Dual Prototype Evolving for Test-Time Generalization of Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation, which enables models to generalize to diverse data with unlabeled test samples, holds significant value in real-world scenarios. Recently, researchers have applied this setting to advanced pre-trained vision-language models (VLMs), developing approaches such as test-time prompt tuning to further extend their practical applicability. However, these methods typically focus solely on adapting VLMs from a single modality and fail to accumulate task-specific knowledge as more samples are processed. To address this, we introduce Dual Prototype Evolving (DPE), a novel test-time adaptation approach for VLMs that effectively accumulates task-specific knowledge from multi-modalities. Specifically, we create and evolve two sets of prototypes--textual and visual--to progressively capture more accurate multi-modal representations for target classes during test time. Moreover, to promote consistent multi-modal representations, we introduce and optimize learnable residuals for each test sample to align the prototypes from both modalities. Extensive experimental results on 15 benchmark datasets demonstrate that our proposed DPE consistently outperforms previous state-of-the-art methods while also exhibiting competitive computational efficiency. Code is available at https://github.com/zhangce01/DPE-CLIP.
<div id='section'>Paperid: <span id='pid'>97, <a href='https://arxiv.org/pdf/2410.10639.pdf' target='_blank'>https://arxiv.org/pdf/2410.10639.pdf</a></span>   <span><a href='https://github.com/bubble65/Paragon' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenglei Shen, Jiahao Zhao, Xiao Zhang, Weijie Yu, Ming He, Jianping Fan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.10639">Paragon: Parameter Generation for Controllable Multi-Task Recommendation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Commercial recommender systems face the challenge that task requirements from platforms or users often change dynamically (e.g., varying preferences for accuracy or diversity). Ideally, the model should be re-trained after resetting a new objective function, adapting to these changes in task requirements. However, in practice, the high computational costs associated with retraining make this process impractical for models already deployed to online environments. This raises a new challenging problem: how to efficiently adapt the learned model to different task requirements by controlling the model parameters after deployment, without the need for retraining. To address this issue, we propose a novel controllable learning approach via \textbf{para}meter \textbf{g}eneration for c\textbf{on}trollable multi-task recommendation (\textbf{Paragon}), which allows the customization and adaptation of recommendation model parameters to new task requirements without retraining. Specifically, we first obtain the optimized model parameters through adapter tunning based on the feasible task requirements. Then, we utilize the generative model as a parameter generator, employing classifier-free guidance in conditional training to learn the distribution of optimized model parameters under various task requirements. Finally, the parameter generator is applied to effectively generate model parameters in a test-time adaptation manner given task requirements. Moreover, Paragon seamlessly integrates with various existing recommendation models to enhance their controllability. Extensive experiments on two public datasets and one commercial dataset demonstrate that Paragon can efficiently generate model parameters instead of retraining, reducing computational time by at least 94.6\%. The code is released at \href{https://github.com/bubble65/Paragon}{https://github.com/bubble65/Paragon}.
<div id='section'>Paperid: <span id='pid'>98, <a href='https://arxiv.org/pdf/2410.07395.pdf' target='_blank'>https://arxiv.org/pdf/2410.07395.pdf</a></span>   <span><a href='https://github.com/namkoong-lab/LLM-Tabular-Shifts' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yibo Zeng, Jiashuo Liu, Henry Lam, Hongseok Namkoong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.07395">LLM Embeddings Improve Test-time Adaptation to Tabular $Y|X$-Shifts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>For tabular datasets, the change in the relationship between the label and covariates ($Y|X$-shifts) is common due to missing variables (a.k.a. confounders). Since it is impossible to generalize to a completely new and unknown domain, we study models that are easy to adapt to the target domain even with few labeled examples. We focus on building more informative representations of tabular data that can mitigate $Y|X$-shifts, and propose to leverage the prior world knowledge in LLMs by serializing (write down) the tabular data to encode it. We find LLM embeddings alone provide inconsistent improvements in robustness, but models trained on them can be well adapted/finetuned to the target domain even using 32 labeled observations. Our finding is based on a comprehensive and systematic study consisting of 7650 source-target pairs and benchmark against 261,000 model configurations trained by 22 algorithms. Our observation holds when ablating the size of accessible target data and different adaptation strategies. The code is available at https://github.com/namkoong-lab/LLM-Tabular-Shifts.
<div id='section'>Paperid: <span id='pid'>99, <a href='https://arxiv.org/pdf/2410.06976.pdf' target='_blank'>https://arxiv.org/pdf/2410.06976.pdf</a></span>   <span><a href='https://github.com/baowenxuan/Matcha' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenxuan Bao, Zhichen Zeng, Zhining Liu, Hanghang Tong, Jingrui He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.06976">Matcha: Mitigating Graph Structure Shifts with Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Powerful as they are, graph neural networks (GNNs) are known to be vulnerable to distribution shifts. Recently, test-time adaptation (TTA) has attracted attention due to its ability to adapt a pre-trained model to a target domain, without re-accessing the source domain. However, existing TTA algorithms are primarily designed for attribute shifts in vision tasks, where samples are independent. These methods perform poorly on graph data that experience structure shifts, where node connectivity differs between source and target graphs. We attribute this performance gap to the distinct impact of node attribute shifts versus graph structure shifts: the latter significantly degrades the quality of node representations and blurs the boundaries between different node categories. To address structure shifts in graphs, we propose Matcha, an innovative framework designed for effective and efficient adaptation to structure shifts by adjusting the htop-aggregation parameters in GNNs. To enhance the representation quality, we design a prediction-informed clustering loss to encourage the formation of distinct clusters for different node categories. Additionally, Matcha seamlessly integrates with existing TTA algorithms, allowing it to handle attribute shifts effectively while improving overall performance under combined structure and attribute shifts. We validate the effectiveness of Matcha on both synthetic and real-world datasets, demonstrating its robustness across various combinations of structure and attribute shifts. Our code is available at https://github.com/baowenxuan/Matcha .
<div id='section'>Paperid: <span id='pid'>100, <a href='https://arxiv.org/pdf/2410.05270.pdf' target='_blank'>https://arxiv.org/pdf/2410.05270.pdf</a></span>   <span><a href='https://github.com/astra-vision/ProLIP' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammad Fahes, Tuan-Hung Vu, Andrei Bursuc, Patrick PÃ©rez, Raoul de Charette
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.05270">CLIP's Visual Embedding Projector is a Few-shot Cornucopia</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider the problem of adapting a contrastively pretrained vision-language model like CLIP (Radford et al., 2021) for few-shot classification. The literature addresses this problem by learning a linear classifier of the frozen visual features, optimizing word embeddings, or learning external feature adapters. We introduce an alternative way for few-shot CLIP adaptation without adding ''external'' parameters to optimize. We find that simply fine-tuning the embedding projection matrix of the vision encoder leads to better performance than all baselines. Furthermore, we show that regularizing training with the distance between the fine-tuned and pretrained matrices adds reliability for adapting CLIP, making the results stable across different learning rates in the ''validation-free'' setting. This simple approach, coined ProLIP, yields state-of-the-art performance on 11 few-shot classification benchmarks, few-shot cross-dataset transfer, domain generalization, and base-to-new class generalization. We also show that ProLIP significantly outperforms prompt tuning when extended to another task of test-time adaptation, while being one order of magnitude faster to train. Code will be made available at: https://github.com/astra-vision/ProLIP .
<div id='section'>Paperid: <span id='pid'>101, <a href='https://arxiv.org/pdf/2410.04682.pdf' target='_blank'>https://arxiv.org/pdf/2410.04682.pdf</a></span>   <span><a href='https://github.com/Gorilla-Lab-SCUT/RTTDP' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yongyi Su, Yushu Li, Nanqing Liu, Kui Jia, Xulei Yang, Chuan-Sheng Foo, Xun Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.04682">On the Adversarial Risk of Test Time Adaptation: An Investigation into Realistic Test-Time Data Poisoning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) updates the model weights during the inference stage using testing data to enhance generalization. However, this practice exposes TTA to adversarial risks. Existing studies have shown that when TTA is updated with crafted adversarial test samples, also known as test-time poisoned data, the performance on benign samples can deteriorate. Nonetheless, the perceived adversarial risk may be overstated if the poisoned data is generated under overly strong assumptions. In this work, we first review realistic assumptions for test-time data poisoning, including white-box versus grey-box attacks, access to benign data, attack order, and more. We then propose an effective and realistic attack method that better produces poisoned samples without access to benign samples, and derive an effective in-distribution attack objective. We also design two TTA-aware attack objectives. Our benchmarks of existing attack methods reveal that the TTA methods are more robust than previously believed. In addition, we analyze effective defense strategies to help develop adversarially robust TTA methods. The source code is available at https://github.com/Gorilla-Lab-SCUT/RTTDP.
<div id='section'>Paperid: <span id='pid'>102, <a href='https://arxiv.org/pdf/2410.04298.pdf' target='_blank'>https://arxiv.org/pdf/2410.04298.pdf</a></span>   <span><a href='https://github.com/JotaBravo/spacecraft-tta' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Juan Ignacio Bravo PÃ©rez-Villar, Ãlvaro GarcÃ­a-MartÃ­n, JesÃºs BescÃ³s, Juan C. SanMiguel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.04298">Test-Time Adaptation for Keypoint-Based Spacecraft Pose Estimation Based on Predicted-View Synthesis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Due to the difficulty of replicating the real conditions during training, supervised algorithms for spacecraft pose estimation experience a drop in performance when trained on synthetic data and applied to real operational data. To address this issue, we propose a test-time adaptation approach that leverages the temporal redundancy between images acquired during close proximity operations. Our approach involves extracting features from sequential spacecraft images, estimating their poses, and then using this information to synthesise a reconstructed view. We establish a self-supervised learning objective by comparing the synthesised view with the actual one. During training, we supervise both pose estimation and image synthesis, while at test-time, we optimise the self-supervised objective. Additionally, we introduce a regularisation loss to prevent solutions that are not consistent with the keypoint structure of the spacecraft. Our code is available at: https://github.com/JotaBravo/spacecraft-tta.
<div id='section'>Paperid: <span id='pid'>103, <a href='https://arxiv.org/pdf/2410.01573.pdf' target='_blank'>https://arxiv.org/pdf/2410.01573.pdf</a></span>   <span><a href='https://github.com/EndoluminalSurgicalVision-IMR/PASS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chuyan Zhang, Hao Zheng, Xin You, Yefeng Zheng, Yun Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.01573">PASS:Test-Time Prompting to Adapt Styles and Semantic Shapes in Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) has emerged as a promising paradigm to handle the domain shifts at test time for medical images from different institutions without using extra training data. However, existing TTA solutions for segmentation tasks suffer from (1) dependency on modifying the source training stage and access to source priors or (2) lack of emphasis on shape-related semantic knowledge that is crucial for segmentation tasks.Recent research on visual prompt learning achieves source-relaxed adaptation by extended parameter space but still neglects the full utilization of semantic features, thus motivating our work on knowledge-enriched deep prompt learning. Beyond the general concern of image style shifts, we reveal that shape variability is another crucial factor causing the performance drop. To address this issue, we propose a TTA framework called PASS (Prompting to Adapt Styles and Semantic shapes), which jointly learns two types of prompts: the input-space prompt to reformulate the style of the test image to fit into the pretrained model and the semantic-aware prompts to bridge high-level shape discrepancy across domains. Instead of naively imposing a fixed prompt, we introduce an input decorator to generate the self-regulating visual prompt conditioned on the input data. To retrieve the knowledge representations and customize target-specific shape prompts for each test sample, we propose a cross-attention prompt modulator, which performs interaction between target representations and an enriched shape prompt bank. Extensive experiments demonstrate the superior performance of PASS over state-of-the-art methods on multiple medical image segmentation datasets. The code is available at https://github.com/EndoluminalSurgicalVision-IMR/PASS.
<div id='section'>Paperid: <span id='pid'>104, <a href='https://arxiv.org/pdf/2409.11884.pdf' target='_blank'>https://arxiv.org/pdf/2409.11884.pdf</a></span>   <span><a href='https://github.com/shuolucs/Awesome-Out-Of-Distribution-Detection' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuo Lu, Yingsheng Wang, Lijun Sheng, Lingxiao He, Aihua Zheng, Jian Liang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.11884">Out-of-Distribution Detection: A Task-Oriented Survey of Recent Advances</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection aims to detect test samples outside the training category space, which is an essential component in building reliable machine learning systems. Existing reviews on OOD detection primarily focus on method taxonomy, surveying the field by categorizing various approaches. However, many recent works concentrate on non-traditional OOD detection scenarios, such as test-time adaptation, multi-modal data sources and other novel contexts. In this survey, we uniquely review recent advances in OOD detection from the task-oriented perspective for the first time. According to the user's access to the model, that is, whether the OOD detection method is allowed to modify or retrain the model, we classify the methods as training-driven or training-agnostic. Besides, considering the rapid development of pre-trained models, large pre-trained model-based OOD detection is also regarded as an important category and discussed separately. Furthermore, we provide a discussion of the evaluation scenarios, a variety of applications, and several future research directions. We believe this survey with new taxonomy will benefit the proposal of new methods and the expansion of more practical scenarios. A curated list of related papers is provided in the Github repository: https://github.com/shuolucs/Awesome-Out-Of-Distribution-Detection.
<div id='section'>Paperid: <span id='pid'>105, <a href='https://arxiv.org/pdf/2409.09251.pdf' target='_blank'>https://arxiv.org/pdf/2409.09251.pdf</a></span>   <span><a href='https://github.com/afsharshamsi/ETAGE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Afshar Shamsi, Rejisa Becirovic, Ahmadreza Argha, Ehsan Abbasnejad, Hamid Alinejad-Rokny, Arash Mohammadi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.09251">ETAGE: Enhanced Test Time Adaptation with Integrated Entropy and Gradient Norms for Robust Model Performance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test time adaptation (TTA) equips deep learning models to handle unseen test data that deviates from the training distribution, even when source data is inaccessible. While traditional TTA methods often rely on entropy as a confidence metric, its effectiveness can be limited, particularly in biased scenarios. Extending existing approaches like the Pseudo Label Probability Difference (PLPD), we introduce ETAGE, a refined TTA method that integrates entropy minimization with gradient norms and PLPD, to enhance sample selection and adaptation. Our method prioritizes samples that are less likely to cause instability by combining high entropy with high gradient norms out of adaptation, thus avoiding the overfitting to noise often observed in previous methods. Extensive experiments on CIFAR-10-C and CIFAR-100-C datasets demonstrate that our approach outperforms existing TTA techniques, particularly in challenging and biased scenarios, leading to more robust and consistent model performance across diverse test scenarios. The codebase for ETAGE is available on https://github.com/afsharshamsi/ETAGE.
<div id='section'>Paperid: <span id='pid'>106, <a href='https://arxiv.org/pdf/2408.13983.pdf' target='_blank'>https://arxiv.org/pdf/2408.13983.pdf</a></span>   <span><a href='https://github.com/yushuntang/DPAL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yushun Tang, Shuoshuo Chen, Zhihe Lu, Xinchao Wang, Zhihai He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.13983">Dual-Path Adversarial Lifting for Domain Shift Correction in Online Test-time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Transformer-based methods have achieved remarkable success in various machine learning tasks. How to design efficient test-time adaptation methods for transformer models becomes an important research task. In this work, motivated by the dual-subband wavelet lifting scheme developed in multi-scale signal processing which is able to efficiently separate the input signals into principal components and noise components, we introduce a dual-path token lifting for domain shift correction in test time adaptation. Specifically, we introduce an extra token, referred to as \textit{domain shift token}, at each layer of the transformer network. We then perform dual-path lifting with interleaved token prediction and update between the path of domain shift tokens and the path of class tokens at all network layers. The prediction and update networks are learned in an adversarial manner. Specifically, the task of the prediction network is to learn the residual noise of domain shift which should be largely invariant across all classes and all samples in the target domain. In other words, the predicted domain shift noise should be indistinguishable between all sample classes. On the other hand, the task of the update network is to update the class tokens by removing the domain shift from the input image samples so that input samples become more discriminative between different classes in the feature space. To effectively learn the prediction and update networks with two adversarial tasks, both theoretically and practically, we demonstrate that it is necessary to use smooth optimization for the update network but non-smooth optimization for the prediction network. Experimental results on the benchmark datasets demonstrate that our proposed method significantly improves the online fully test-time domain adaptation performance. Code is available at \url{https://github.com/yushuntang/DPAL}.
<div id='section'>Paperid: <span id='pid'>107, <a href='https://arxiv.org/pdf/2408.11309.pdf' target='_blank'>https://arxiv.org/pdf/2408.11309.pdf</a></span>   <span><a href='https://github.com/salehsargolzaee/Hopfield-integrated-test' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Saleh Sargolzaei, Luis Rueda
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.11309">Improving Out-of-Distribution Data Handling and Corruption Resistance via Modern Hopfield Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study explores the potential of Modern Hopfield Networks (MHN) in improving the ability of computer vision models to handle out-of-distribution data. While current computer vision models can generalize to unseen samples from the same distribution, they are susceptible to minor perturbations such as blurring, which limits their effectiveness in real-world applications. We suggest integrating MHN into the baseline models to enhance their robustness. This integration can be implemented during the test time for any model and combined with any adversarial defense method. Our research shows that the proposed integration consistently improves model performance on the MNIST-C dataset, achieving a state-of-the-art increase of 13.84% in average corruption accuracy, a 57.49% decrease in mean Corruption Error (mCE), and a 60.61% decrease in relative mCE compared to the baseline model. Additionally, we investigate the capability of MHN to converge to the original non-corrupted data. Notably, our method does not require test-time adaptation or augmentation with corruptions, underscoring its practical viability for real-world deployment. (Source code publicly available at: https://github.com/salehsargolzaee/Hopfield-integrated-test)
<div id='section'>Paperid: <span id='pid'>108, <a href='https://arxiv.org/pdf/2408.07343.pdf' target='_blank'>https://arxiv.org/pdf/2408.07343.pdf</a></span>   <span><a href='https://github.com/Chen-Ziyang/GraTa' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziyang Chen, Yiwen Ye, Yongsheng Pan, Yong Xia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.07343">Gradient Alignment Improves Test-Time Adaptation for Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Although recent years have witnessed significant advancements in medical image segmentation, the pervasive issue of domain shift among medical images from diverse centres hinders the effective deployment of pre-trained models. Many Test-time Adaptation (TTA) methods have been proposed to address this issue by fine-tuning pre-trained models with test data during inference. These methods, however, often suffer from less-satisfactory optimization due to suboptimal optimization direction (dictated by the gradient) and fixed step-size (predicated on the learning rate). In this paper, we propose the Gradient alignment-based Test-time adaptation (GraTa) method to improve both the gradient direction and learning rate in the optimization procedure. Unlike conventional TTA methods, which primarily optimize the pseudo gradient derived from a self-supervised objective, our method incorporates an auxiliary gradient with the pseudo one to facilitate gradient alignment. Such gradient alignment enables the model to excavate the similarities between different gradients and correct the gradient direction to approximate the empirical gradient related to the current segmentation task. Additionally, we design a dynamic learning rate based on the cosine similarity between the pseudo and auxiliary gradients, thereby empowering the adaptive fine-tuning of pre-trained models on diverse test data. Extensive experiments establish the effectiveness of the proposed gradient alignment and dynamic learning rate and substantiate the superiority of our GraTa method over other state-of-the-art TTA methods on a benchmark medical image segmentation task. The code and weights of pre-trained source models are available at https://github.com/Chen-Ziyang/GraTa.
<div id='section'>Paperid: <span id='pid'>109, <a href='https://arxiv.org/pdf/2407.20080.pdf' target='_blank'>https://arxiv.org/pdf/2407.20080.pdf</a></span>   <span><a href='https://github.com/LeapLabTHU/UniTTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chaoqun Du, Yulin Wang, Jiayi Guo, Yizeng Han, Jie Zhou, Gao Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.20080">UniTTA: Unified Benchmark and Versatile Framework Towards Realistic Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-Time Adaptation (TTA) aims to adapt pre-trained models to the target domain during testing. In reality, this adaptability can be influenced by multiple factors. Researchers have identified various challenging scenarios and developed diverse methods to address these challenges, such as dealing with continual domain shifts, mixed domains, and temporally correlated or imbalanced class distributions. Despite these efforts, a unified and comprehensive benchmark has yet to be established. To this end, we propose a Unified Test-Time Adaptation (UniTTA) benchmark, which is comprehensive and widely applicable. Each scenario within the benchmark is fully described by a Markov state transition matrix for sampling from the original dataset. The UniTTA benchmark considers both domain and class as two independent dimensions of data and addresses various combinations of imbalance/balance and i.i.d./non-i.i.d./continual conditions, covering a total of \( (2 \times 3)^2 = 36 \) scenarios. It establishes a comprehensive evaluation benchmark for realistic TTA and provides a guideline for practitioners to select the most suitable TTA method. Alongside this benchmark, we propose a versatile UniTTA framework, which includes a Balanced Domain Normalization (BDN) layer and a COrrelated Feature Adaptation (COFA) method--designed to mitigate distribution gaps in domain and class, respectively. Extensive experiments demonstrate that our UniTTA framework excels within the UniTTA benchmark and achieves state-of-the-art performance on average. Our code is available at \url{https://github.com/LeapLabTHU/UniTTA}.
<div id='section'>Paperid: <span id='pid'>110, <a href='https://arxiv.org/pdf/2407.16193.pdf' target='_blank'>https://arxiv.org/pdf/2407.16193.pdf</a></span>   <span><a href='https://github.com/shimazing/CloudFixer' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hajin Shim, Changhun Kim, Eunho Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.16193">CloudFixer: Test-Time Adaptation for 3D Point Clouds via Diffusion-Guided Geometric Transformation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>3D point clouds captured from real-world sensors frequently encompass noisy points due to various obstacles, such as occlusion, limited resolution, and variations in scale. These challenges hinder the deployment of pre-trained point cloud recognition models trained on clean point clouds, leading to significant performance degradation. While test-time adaptation (TTA) strategies have shown promising results on this issue in the 2D domain, their application to 3D point clouds remains under-explored. Among TTA methods, an input adaptation approach, which directly converts test instances to the source domain using a pre-trained diffusion model, has been proposed in the 2D domain. Despite its robust TTA performance in practical situations, naively adopting this into the 3D domain may be suboptimal due to the neglect of inherent properties of point clouds, and its prohibitive computational cost. Motivated by these limitations, we propose CloudFixer, a test-time input adaptation method tailored for 3D point clouds, employing a pre-trained diffusion model. Specifically, CloudFixer optimizes geometric transformation parameters with carefully designed objectives that leverage the geometric properties of point clouds. We also substantially improve computational efficiency by avoiding backpropagation through the diffusion model and a prohibitive generation process. Furthermore, we propose an online model adaptation strategy by aligning the original model prediction with that of the adapted input. Extensive experiments showcase the superiority of CloudFixer over various TTA baselines, excelling in handling common corruptions and natural distribution shifts across diverse real-world scenarios. Our code is available at https://github.com/shimazing/CloudFixer
<div id='section'>Paperid: <span id='pid'>111, <a href='https://arxiv.org/pdf/2407.15773.pdf' target='_blank'>https://arxiv.org/pdf/2407.15773.pdf</a></span>   <span><a href='https://github.com/yuyongcan/STAMP' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yongcan Yu, Lijun Sheng, Ran He, Jian Liang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.15773">STAMP: Outlier-Aware Test-Time Adaptation with Stable Memory Replay</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) aims to address the distribution shift between the training and test data with only unlabeled data at test time. Existing TTA methods often focus on improving recognition performance specifically for test data associated with classes in the training set. However, during the open-world inference process, there are inevitably test data instances from unknown classes, commonly referred to as outliers. This paper pays attention to the problem that conducts both sample recognition and outlier rejection during inference while outliers exist. To address this problem, we propose a new approach called STAble Memory rePlay (STAMP), which performs optimization over a stable memory bank instead of the risky mini-batch. In particular, the memory bank is dynamically updated by selecting low-entropy and label-consistent samples in a class-balanced manner. In addition, we develop a self-weighted entropy minimization strategy that assigns higher weight to low-entropy samples. Extensive results demonstrate that STAMP outperforms existing TTA methods in terms of both recognition and outlier detection performance. The code is released at https://github.com/yuyongcan/STAMP.
<div id='section'>Paperid: <span id='pid'>112, <a href='https://arxiv.org/pdf/2407.13588.pdf' target='_blank'>https://arxiv.org/pdf/2407.13588.pdf</a></span>   <span><a href='https://github.com/Bala93/CLIPCalib' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Balamurali Murugesan, Julio Silva-Rodriguez, Ismail Ben Ayed, Jose Dolz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.13588">Robust Calibration of Large Vision-Language Adapters</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper addresses the critical issue of miscalibration in CLIP-based model adaptation, particularly in the challenging scenario of out-of-distribution (OOD) samples, which has been overlooked in the existing literature on CLIP adaptation. We empirically demonstrate that popular CLIP adaptation approaches, such as Adapters, Prompt Learning, and Test-Time Adaptation, substantially degrade the calibration capabilities of the zero-shot baseline in the presence of distributional drift. We identify the increase in logit ranges as the underlying cause of miscalibration of CLIP adaptation methods, contrasting with previous work on calibrating fully-supervised models. Motivated by these observations, we present a simple and model-agnostic solution to mitigate miscalibration, by scaling the logit range of each sample to its zero-shot prediction logits. We explore three different alternatives to achieve this, which can be either integrated during adaptation or directly used at inference time. Comprehensive experiments on popular OOD classification benchmarks demonstrate the effectiveness of the proposed approaches in mitigating miscalibration while maintaining discriminative performance, whose improvements are consistent across the three families of these increasingly popular approaches. The code is publicly available at: https://github.com/Bala93/CLIPCalib
<div id='section'>Paperid: <span id='pid'>113, <a href='https://arxiv.org/pdf/2407.12387.pdf' target='_blank'>https://arxiv.org/pdf/2407.12387.pdf</a></span>   <span><a href='https://github.com/tpzou/HGL' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianpei Zou, Sanqing Qu, Zhijun Li, Alois Knoll, Lianghua He, Guang Chen, Changjun Jiang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.12387">HGL: Hierarchical Geometry Learning for Test-time Adaptation in 3D Point Cloud Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>3D point cloud segmentation has received significant interest for its growing applications. However, the generalization ability of models suffers in dynamic scenarios due to the distribution shift between test and training data. To promote robustness and adaptability across diverse scenarios, test-time adaptation (TTA) has recently been introduced. Nevertheless, most existing TTA methods are developed for images, and limited approaches applicable to point clouds ignore the inherent hierarchical geometric structures in point cloud streams, i.e., local (point-level), global (object-level), and temporal (frame-level) structures. In this paper, we delve into TTA in 3D point cloud segmentation and propose a novel Hierarchical Geometry Learning (HGL) framework. HGL comprises three complementary modules from local, global to temporal learning in a bottom-up manner.Technically, we first construct a local geometry learning module for pseudo-label generation. Next, we build prototypes from the global geometry perspective for pseudo-label fine-tuning. Furthermore, we introduce a temporal consistency regularization module to mitigate negative transfer. Extensive experiments on four datasets demonstrate the effectiveness and superiority of our HGL. Remarkably, on the SynLiDAR to SemanticKITTI task, HGL achieves an overall mIoU of 46.91\%, improving GIPSO by 3.0\% and significantly reducing the required adaptation time by 80\%. The code is available at https://github.com/tpzou/HGL.
<div id='section'>Paperid: <span id='pid'>114, <a href='https://arxiv.org/pdf/2407.09367.pdf' target='_blank'>https://arxiv.org/pdf/2407.09367.pdf</a></span>   <span><a href='https://github.com/z1358/OBAO' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhilin Zhu, Xiaopeng Hong, Zhiheng Ma, Weijun Zhuang, Yaohui Ma, Yong Dai, Yaowei Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.09367">Reshaping the Online Data Buffering and Organizing Mechanism for Continual Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual Test-Time Adaptation (CTTA) involves adapting a pre-trained source model to continually changing unsupervised target domains. In this paper, we systematically analyze the challenges of this task: online environment, unsupervised nature, and the risks of error accumulation and catastrophic forgetting under continual domain shifts. To address these challenges, we reshape the online data buffering and organizing mechanism for CTTA. We propose an uncertainty-aware buffering approach to identify and aggregate significant samples with high certainty from the unsupervised, single-pass data stream. Based on this, we propose a graph-based class relation preservation constraint to overcome catastrophic forgetting. Furthermore, a pseudo-target replay objective is used to mitigate error accumulation. Extensive experiments demonstrate the superiority of our method in both segmentation and classification CTTA tasks. Code is available at https://github.com/z1358/OBAO.
<div id='section'>Paperid: <span id='pid'>115, <a href='https://arxiv.org/pdf/2407.02253.pdf' target='_blank'>https://arxiv.org/pdf/2407.02253.pdf</a></span>   <span><a href='https://github.com/JiaxuTian/PSMT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaxu Tian, Fan Lyu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.02253">Parameter-Selective Continual Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual Test-Time Adaptation (CTTA) aims to adapt a pretrained model to ever-changing environments during the test time under continuous domain shifts. Most existing CTTA approaches are based on the Mean Teacher (MT) structure, which contains a student and a teacher model, where the student is updated using the pseudo-labels from the teacher model, and the teacher is then updated by exponential moving average strategy. However, these methods update the MT model indiscriminately on all parameters of the model. That is, some critical parameters involving sharing knowledge across different domains may be erased, intensifying error accumulation and catastrophic forgetting. In this paper, we introduce Parameter-Selective Mean Teacher (PSMT) method, which is capable of effectively updating the critical parameters within the MT network under domain shifts. First, we introduce a selective distillation mechanism in the student model, which utilizes past knowledge to regularize novel knowledge, thereby mitigating the impact of error accumulation. Second, to avoid catastrophic forgetting, in the teacher model, we create a mask through Fisher information to selectively update parameters via exponential moving average, with preservation measures applied to crucial parameters. Extensive experimental results verify that PSMT outperforms state-of-the-art methods across multiple benchmark datasets. Our code is available at \url{https://github.com/JiaxuTian/PSMT}.
<div id='section'>Paperid: <span id='pid'>116, <a href='https://arxiv.org/pdf/2407.02112.pdf' target='_blank'>https://arxiv.org/pdf/2407.02112.pdf</a></span>   <span><a href='https://github.com/atschalz/dc_tabeval' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Andrej Tschalzev, Sascha Marton, Stefan LÃ¼dtke, Christian Bartelt, Heiner Stuckenschmidt
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.02112">A Data-Centric Perspective on Evaluating Machine Learning Models for Tabular Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Tabular data is prevalent in real-world machine learning applications, and new models for supervised learning of tabular data are frequently proposed. Comparative studies assessing the performance of models typically consist of model-centric evaluation setups with overly standardized data preprocessing. This paper demonstrates that such model-centric evaluations are biased, as real-world modeling pipelines often require dataset-specific preprocessing and feature engineering. Therefore, we propose a data-centric evaluation framework. We select 10 relevant datasets from Kaggle competitions and implement expert-level preprocessing pipelines for each dataset. We conduct experiments with different preprocessing pipelines and hyperparameter optimization (HPO) regimes to quantify the impact of model selection, HPO, feature engineering, and test-time adaptation. Our main findings are: 1. After dataset-specific feature engineering, model rankings change considerably, performance differences decrease, and the importance of model selection reduces. 2. Recent models, despite their measurable progress, still significantly benefit from manual feature engineering. This holds true for both tree-based models and neural networks. 3. While tabular data is typically considered static, samples are often collected over time, and adapting to distribution shifts can be important even in supposedly static data. These insights suggest that research efforts should be directed toward a data-centric perspective, acknowledging that tabular data requires feature engineering and often exhibits temporal characteristics. Our framework is available under: https://github.com/atschalz/dc_tabeval.
<div id='section'>Paperid: <span id='pid'>117, <a href='https://arxiv.org/pdf/2406.16439.pdf' target='_blank'>https://arxiv.org/pdf/2406.16439.pdf</a></span>   <span><a href='https://github.com/ShileiCao/AMROD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Shilei Cao, Juepeng Zheng, Yan Liu, Baoquan Zhao, Ziqi Yuan, Weijia Li, Runmin Dong, Haohuan Fu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.16439">Exploring Test-Time Adaptation for Object Detection in Continually Changing Environments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Real-world application models are commonly deployed in dynamic environments, where the target domain distribution undergoes temporal changes. Continual Test-Time Adaptation (CTTA) has recently emerged as a promising technique to gradually adapt a source-trained model to continually changing target domains. Despite recent advancements in addressing CTTA, two critical issues remain: 1) Fixed thresholds for pseudo-labeling in existing methodologies lead to low-quality pseudo-labels, as model confidence varies across categories and domains; 2) Stochastic parameter restoration methods for mitigating catastrophic forgetting fail to preserve critical information effectively, due to their intrinsic randomness. To tackle these challenges for detection models in CTTA scenarios, we present AMROD, featuring three core components. Firstly, the object-level contrastive learning module extracts object-level features for contrastive learning to refine the feature representation in the target domain. Secondly, the adaptive monitoring module dynamically skips unnecessary adaptation and updates the category-specific threshold based on predicted confidence scores to enable efficiency and improve the quality of pseudo-labels. Lastly, the adaptive randomized restoration mechanism selectively reset inactive parameters with higher possibilities, ensuring the retention of essential knowledge. We demonstrate the effectiveness of AMROD on four CTTA object detection tasks, where AMROD outperforms existing methods, especially achieving a 3.2 mAP improvement and a 20\% increase in efficiency on the Cityscapes-to-Cityscapes-C CTTA task. The code of this work is available at https://github.com/ShileiCao/AMROD.
<div id='section'>Paperid: <span id='pid'>118, <a href='https://arxiv.org/pdf/2406.14878.pdf' target='_blank'>https://arxiv.org/pdf/2406.14878.pdf</a></span>   <span><a href='https://github.com/zhuoxiao-chen/MOS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhuoxiao Chen, Junjie Meng, Mahsa Baktashmotlagh, Yonggang Zhang, Zi Huang, Yadan Luo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.14878">MOS: Model Synergy for Test-Time Adaptation on LiDAR-Based 3D Object Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>LiDAR-based 3D object detection is crucial for various applications but often experiences performance degradation in real-world deployments due to domain shifts. While most studies focus on cross-dataset shifts, such as changes in environments and object geometries, practical corruptions from sensor variations and weather conditions remain underexplored. In this work, we propose a novel online test-time adaptation framework for 3D detectors that effectively tackles these shifts, including a challenging cross-corruption scenario where cross-dataset shifts and corruptions co-occur. By leveraging long-term knowledge from previous test batches, our approach mitigates catastrophic forgetting and adapts effectively to diverse shifts. Specifically, we propose a Model Synergy (MOS) strategy that dynamically selects historical checkpoints with diverse knowledge and assembles them to best accommodate the current test batch. This assembly is directed by our proposed Synergy Weights (SW), which perform a weighted averaging of the selected checkpoints, minimizing redundancy in the composite model. The SWs are computed by evaluating the similarity of predicted bounding boxes on the test data and the independence of features between checkpoint pairs in the model bank. To maintain an efficient and informative model bank, we discard checkpoints with the lowest average SW scores, replacing them with newly updated models. Our method was rigorously tested against existing test-time adaptation strategies across three datasets and eight types of corruptions, demonstrating superior adaptability to dynamic scenes and conditions. Notably, it achieved a 67.3% improvement in a challenging cross-corruption scenario, offering a more comprehensive benchmark for adaptation. Source code: https://github.com/zhuoxiao-chen/MOS.
<div id='section'>Paperid: <span id='pid'>119, <a href='https://arxiv.org/pdf/2406.13875.pdf' target='_blank'>https://arxiv.org/pdf/2406.13875.pdf</a></span>   <span><a href='https://github.com/Mehrdad-Noori/WATT.git' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>David Osowiechi, Mehrdad Noori, Gustavo Adolfo Vargas Hakim, Moslem Yazdanpanah, Ali Bahri, Milad Cheraghalikhani, Sahar Dastani, Farzad Beizaee, Ismail Ben Ayed, Christian Desrosiers
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.13875">WATT: Weight Average Test-Time Adaptation of CLIP</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-Language Models (VLMs) such as CLIP have yielded unprecedented performance for zero-shot image classification, yet their generalization capability may still be seriously challenged when confronted to domain shifts. In response, we present Weight Average Test-Time Adaptation (WATT) of CLIP, a pioneering approach facilitating full test-time adaptation (TTA) of this VLM. Our method employs a diverse set of templates for text prompts, augmenting the existing framework of CLIP. Predictions are utilized as pseudo labels for model updates, followed by weight averaging to consolidate the learned information globally. Furthermore, we introduce a text ensemble strategy, enhancing overall test performance by aggregating diverse textual cues. Our findings underscore the efficacy of WATT in enhancing performance across diverse datasets, including CIFAR-10-C, CIFAR-10.1, CIFAR-100-C, VisDA-C, and several other challenging datasets, effectively covering a wide range of domain shifts. Notably, these enhancements are achieved without necessitating additional model transformations or trainable modules. Moreover, compared to other Test-Time Adaptation methods, our approach can operate effectively with just a single image. Highlighting the potential of innovative test-time strategies, this research emphasizes their role in fortifying the adaptability of VLMs. The implementation is available at: \url{https://github.com/Mehrdad-Noori/WATT.git}.
<div id='section'>Paperid: <span id='pid'>120, <a href='https://arxiv.org/pdf/2406.04295.pdf' target='_blank'>https://arxiv.org/pdf/2406.04295.pdf</a></span>   <span><a href='https://github.com/SHI-Labs/Diffusion-Driven-Test-Time-Adaptation-via-Synthetic-Domain-Alignment' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/SHI-Labs/Diffusion-Driven-Test-Time-Adaptation-via-Synthetic-Domain-Alignment' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiayi Guo, Junhao Zhao, Chaoqun Du, Yulin Wang, Chunjiang Ge, Zanlin Ni, Shiji Song, Humphrey Shi, Gao Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.04295">Everything to the Synthetic: Diffusion-driven Test-time Adaptation via Synthetic-Domain Alignment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) aims to improve the performance of source-domain pre-trained models on previously unseen, shifted target domains. Traditional TTA methods primarily adapt model weights based on target data streams, making model performance sensitive to the amount and order of target data. The recently proposed diffusion-driven TTA methods mitigate this by adapting model inputs instead of weights, where an unconditional diffusion model, trained on the source domain, transforms target-domain data into a synthetic domain that is expected to approximate the source domain. However, in this paper, we reveal that although the synthetic data in diffusion-driven TTA seems indistinguishable from the source data, it is unaligned with, or even markedly different from the latter for deep networks. To address this issue, we propose a \textbf{S}ynthetic-\textbf{D}omain \textbf{A}lignment (SDA) framework. Our key insight is to fine-tune the source model with synthetic data to ensure better alignment. Specifically, we first employ a conditional diffusion model to generate labeled samples, creating a synthetic dataset. Subsequently, we use the aforementioned unconditional diffusion model to add noise to and denoise each sample before fine-tuning. This Mix of Diffusion (MoD) process mitigates the potential domain misalignment between the conditional and unconditional models. Extensive experiments across classifiers, segmenters, and multimodal large language models (MLLMs, \eg, LLaVA) demonstrate that SDA achieves superior domain alignment and consistently outperforms existing diffusion-driven TTA methods. Our code is available at https://github.com/SHI-Labs/Diffusion-Driven-Test-Time-Adaptation-via-Synthetic-Domain-Alignment.
<div id='section'>Paperid: <span id='pid'>121, <a href='https://arxiv.org/pdf/2406.00481.pdf' target='_blank'>https://arxiv.org/pdf/2406.00481.pdf</a></span>   <span><a href='https://manogna-s.github.io/rosita/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Manogna Sreenivas, Soma Biswas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.00481">Efficient Open Set Single Image Test Time Adaptation of Vision Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Adapting models to dynamic, real-world environments characterized by shifting data distributions and unseen test scenarios is a critical challenge in deep learning. In this paper, we consider a realistic and challenging Test-Time Adaptation setting, where a model must continuously adapt to test samples that arrive sequentially, one at a time, while distinguishing between known and unknown classes. Current Test-Time Adaptation methods operate under closed-set assumptions or batch processing, differing from the real-world open-set scenarios. We address this limitation by establishing a comprehensive benchmark for {\em Open-set Single-image Test-Time Adaptation using Vision-Language Models}. Furthermore, we propose ROSITA, a novel framework that leverages dynamically updated feature banks to identify reliable test samples and employs a contrastive learning objective to improve the separation between known and unknown classes. Our approach effectively adapts models to domain shifts for known classes while rejecting unfamiliar samples. Extensive experiments across diverse real-world benchmarks demonstrate that ROSITA sets a new state-of-the-art in open-set TTA, achieving both strong performance and computational efficiency for real-time deployment. Our code can be found at the project site https://manogna-s.github.io/rosita/
<div id='section'>Paperid: <span id='pid'>122, <a href='https://arxiv.org/pdf/2405.18911.pdf' target='_blank'>https://arxiv.org/pdf/2405.18911.pdf</a></span>   <span><a href='https://github.com/Yushu-Li/HILTTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yushu Li, Yongyi Su, Xulei Yang, Kui Jia, Xun Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.18911">Exploring Human-in-the-Loop Test-Time Adaptation by Synergizing Active Learning and Model Selection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing test-time adaptation (TTA) approaches often adapt models with the unlabeled testing data stream. A recent attempt relaxed the assumption by introducing limited human annotation, referred to as Human-In-the-Loop Test-Time Adaptation (HILTTA) in this study. The focus of existing HILTTA studies lies in selecting the most informative samples to label, a.k.a. active learning. In this work, we are motivated by a pitfall of TTA, i.e. sensitivity to hyper-parameters, and propose to approach HILTTA by synergizing active learning and model selection. Specifically, we first select samples for human annotation (active learning) and then use the labeled data to select optimal hyper-parameters (model selection). To prevent the model selection process from overfitting to local distributions, multiple regularization techniques are employed to complement the validation objective. A sample selection strategy is further tailored by considering the balance between active learning and model selection purposes. We demonstrate on 5 TTA datasets that the proposed HILTTA approach is compatible with off-the-shelf TTA methods and such combinations substantially outperform the state-of-the-art HILTTA methods. Importantly, our proposed method can always prevent choosing the worst hyper-parameters on all off-the-shelf TTA methods. The source code is available at https://github.com/Yushu-Li/HILTTA.
<div id='section'>Paperid: <span id='pid'>123, <a href='https://arxiv.org/pdf/2405.18330.pdf' target='_blank'>https://arxiv.org/pdf/2405.18330.pdf</a></span>   <span><a href='https://github.com/FarinaMatteo/zero' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Matteo Farina, Gianni Franchi, Giovanni Iacca, Massimiliano Mancini, Elisa Ricci
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.18330">Frustratingly Easy Test-Time Adaptation of Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-Language Models seamlessly discriminate among arbitrary semantic categories, yet they still suffer from poor generalization when presented with challenging examples. For this reason, Episodic Test-Time Adaptation (TTA) strategies have recently emerged as powerful techniques to adapt VLMs in the presence of a single unlabeled image. The recent literature on TTA is dominated by the paradigm of prompt tuning by Marginal Entropy Minimization, which, relying on online backpropagation, inevitably slows down inference while increasing memory. In this work, we theoretically investigate the properties of this approach and unveil that a surprisingly strong TTA method lies dormant and hidden within it. We term this approach ZERO (TTA with "zero" temperature), whose design is both incredibly effective and frustratingly simple: augment N times, predict, retain the most confident predictions, and marginalize after setting the Softmax temperature to zero. Remarkably, ZERO requires a single batched forward pass through the vision encoder only and no backward passes. We thoroughly evaluate our approach following the experimental protocol established in the literature and show that ZERO largely surpasses or compares favorably w.r.t. the state-of-the-art while being almost 10x faster and 13x more memory-friendly than standard Test-Time Prompt Tuning. Thanks to its simplicity and comparatively negligible computation, ZERO can serve as a strong baseline for future work in this field. The code is available at https://github.com/FarinaMatteo/zero.
<div id='section'>Paperid: <span id='pid'>124, <a href='https://arxiv.org/pdf/2405.16486.pdf' target='_blank'>https://arxiv.org/pdf/2405.16486.pdf</a></span>   <span><a href='https://github.com/RoyZry98/MoASE-Pytorch' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Rongyu Zhang, Aosong Cheng, Yulin Luo, Gaole Dai, Huanrui Yang, Jiaming Liu, Ran Xu, Li Du, Yuan Du, Yanbing Jiang, Shanghang Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.16486">Decomposing the Neurons: Activation Sparsity via Mixture of Experts for Continual Test Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual Test-Time Adaptation (CTTA), which aims to adapt the pre-trained model to ever-evolving target domains, emerges as an important task for vision models. As current vision models appear to be heavily biased towards texture, continuously adapting the model from one domain distribution to another can result in serious catastrophic forgetting. Drawing inspiration from the human visual system's adeptness at processing both shape and texture according to the famous Trichromatic Theory, we explore the integration of a Mixture-of-Activation-Sparsity-Experts (MoASE) as an adapter for the CTTA task. Given the distinct reaction of neurons with low/high activation to domain-specific/agnostic features, MoASE decomposes the neural activation into high-activation and low-activation components with a non-differentiable Spatial Differentiate Dropout (SDD). Based on the decomposition, we devise a multi-gate structure comprising a Domain-Aware Gate (DAG) that utilizes domain information to adaptive combine experts that process the post-SDD sparse activations of different strengths, and the Activation Sparsity Gate (ASG) that adaptively assigned feature selection threshold of the SDD for different experts for more precise feature decomposition. Finally, we introduce a Homeostatic-Proximal (HP) loss to bypass the error accumulation problem when continuously adapting the model. Extensive experiments on four prominent benchmarks substantiate that our methodology achieves state-of-the-art performance in both classification and segmentation CTTA tasks. Our code is now available at https://github.com/RoyZry98/MoASE-Pytorch.
<div id='section'>Paperid: <span id='pid'>125, <a href='https://arxiv.org/pdf/2405.14977.pdf' target='_blank'>https://arxiv.org/pdf/2405.14977.pdf</a></span>   <span><a href='https://github.com/mariodoebler/test-time-adaptation' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mario DÃ¶bler, Robert A. Marsden, Tobias Raichle, Bin Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.14977">A Lost Opportunity for Vision-Language Models: A Comparative Study of Online Test-Time Adaptation for Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In deep learning, maintaining model robustness against distribution shifts is critical. This work explores a broad range of possibilities to adapt vision-language foundation models at test-time, with a particular emphasis on CLIP and its variants. The study systematically examines prompt-based techniques and existing test-time adaptation methods, aiming to improve the robustness under distribution shift in diverse real-world scenarios. Specifically, the investigation covers various prompt engineering strategies, including handcrafted prompts, prompt ensembles, and prompt learning techniques. Additionally, we introduce a vision-text-space ensemble that substantially enhances average performance compared to text-space-only ensembles. Since online test-time adaptation has shown to be effective to mitigate performance drops under distribution shift, the study extends its scope to evaluate the effectiveness of existing test-time adaptation methods that were originally designed for vision-only classification models. Through extensive experimental evaluations conducted across multiple datasets and diverse model architectures, the research demonstrates the effectiveness of these adaptation strategies. Code is available at: https://github.com/mariodoebler/test-time-adaptation
<div id='section'>Paperid: <span id='pid'>126, <a href='https://arxiv.org/pdf/2405.01527.pdf' target='_blank'>https://arxiv.org/pdf/2405.01527.pdf</a></span>   <span><a href='https://homangab.github.io/track2act/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Homanga Bharadhwaj, Roozbeh Mottaghi, Abhinav Gupta, Shubham Tulsiani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.01527">Track2Act: Predicting Point Tracks from Internet Videos enables Generalizable Robot Manipulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We seek to learn a generalizable goal-conditioned policy that enables zero-shot robot manipulation: interacting with unseen objects in novel scenes without test-time adaptation. While typical approaches rely on a large amount of demonstration data for such generalization, we propose an approach that leverages web videos to predict plausible interaction plans and learns a task-agnostic transformation to obtain robot actions in the real world. Our framework,Track2Act predicts tracks of how points in an image should move in future time-steps based on a goal, and can be trained with diverse videos on the web including those of humans and robots manipulating everyday objects. We use these 2D track predictions to infer a sequence of rigid transforms of the object to be manipulated, and obtain robot end-effector poses that can be executed in an open-loop manner. We then refine this open-loop plan by predicting residual actions through a closed loop policy trained with a few embodiment-specific demonstrations. We show that this approach of combining scalably learned track prediction with a residual policy requiring minimal in-domain robot-specific data enables diverse generalizable robot manipulation, and present a wide array of real-world robot manipulation results across unseen tasks, objects, and scenes. https://homangab.github.io/track2act/
<div id='section'>Paperid: <span id='pid'>127, <a href='https://arxiv.org/pdf/2405.00754.pdf' target='_blank'>https://arxiv.org/pdf/2405.00754.pdf</a></span>   <span><a href='https://github.com/dosowiechi/CLIPArTT.git' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Gustavo Adolfo Vargas Hakim, David Osowiechi, Mehrdad Noori, Milad Cheraghalikhani, Ali Bahri, Moslem Yazdanpanah, Ismail Ben Ayed, Christian Desrosiers
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.00754">CLIPArTT: Adaptation of CLIP to New Domains at Test Time</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pre-trained vision-language models (VLMs), exemplified by CLIP, demonstrate remarkable adaptability across zero-shot classification tasks without additional training. However, their performance diminishes in the presence of domain shifts. In this study, we introduce CLIP Adaptation duRing Test-Time (CLIPArTT), a fully test-time adaptation (TTA) approach for CLIP, which involves automatic text prompts construction during inference for their use as text supervision. Our method employs a unique, minimally invasive text prompt tuning process, wherein multiple predicted classes are aggregated into a single new text prompt, used as \emph{pseudo label} to re-classify inputs in a transductive manner. Additionally, we pioneer the standardization of TTA benchmarks (e.g., TENT) in the realm of VLMs. Our findings demonstrate that, without requiring additional transformations nor new trainable modules, CLIPArTT enhances performance dynamically across non-corrupted datasets such as CIFAR-100, corrupted datasets like CIFAR-100-C and ImageNet-C, alongside synthetic datasets such as VisDA-C. This research underscores the potential for improving VLMs' adaptability through novel test-time strategies, offering insights for robust performance across varied datasets and environments. The code can be found at: https://github.com/dosowiechi/CLIPArTT.git
<div id='section'>Paperid: <span id='pid'>128, <a href='https://arxiv.org/pdf/2404.18135.pdf' target='_blank'>https://arxiv.org/pdf/2404.18135.pdf</a></span>   <span><a href='https://github.com/iSEE-Laboratory/DGTR' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Guo-Hao Xu, Yi-Lin Wei, Dian Zheng, Xiao-Ming Wu, Wei-Shi Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.18135">Dexterous Grasp Transformer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we propose a novel discriminative framework for dexterous grasp generation, named Dexterous Grasp TRansformer (DGTR), capable of predicting a diverse set of feasible grasp poses by processing the object point cloud with only one forward pass. We formulate dexterous grasp generation as a set prediction task and design a transformer-based grasping model for it. However, we identify that this set prediction paradigm encounters several optimization challenges in the field of dexterous grasping and results in restricted performance. To address these issues, we propose progressive strategies for both the training and testing phases. First, the dynamic-static matching training (DSMT) strategy is presented to enhance the optimization stability during the training phase. Second, we introduce the adversarial-balanced test-time adaptation (AB-TTA) with a pair of adversarial losses to improve grasping quality during the testing phase. Experimental results on the DexGraspNet dataset demonstrate the capability of DGTR to predict dexterous grasp poses with both high quality and diversity. Notably, while keeping high quality, the diversity of grasp poses predicted by DGTR significantly outperforms previous works in multiple metrics without any data pre-processing. Codes are available at https://github.com/iSEE-Laboratory/DGTR .
<div id='section'>Paperid: <span id='pid'>129, <a href='https://arxiv.org/pdf/2404.11225.pdf' target='_blank'>https://arxiv.org/pdf/2404.11225.pdf</a></span>   <span><a href='https://github.com/HITsz-TMG/ICL-State-Vector' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Dongfang Li, Zhenyu Liu, Xinshuo Hu, Zetian Sun, Baotian Hu, Min Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.11225">In-Context Learning State Vector with Inner and Momentum Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large Language Models (LLMs) have exhibited an impressive ability to perform In-Context Learning (ICL) from only a few examples. Recent works have indicated that the functions learned by ICL can be represented through compressed vectors derived from the transformer. However, the working mechanisms and optimization of these vectors are yet to be thoroughly explored. In this paper, we address this gap by presenting a comprehensive analysis of these compressed vectors, drawing parallels to the parameters trained with gradient descent, and introduce the concept of state vector. Inspired by the works on model soup and momentum-based gradient descent, we propose inner and momentum optimization methods that are applied to refine the state vector progressively as test-time adaptation. Moreover, we simulate state vector aggregation in the multiple example setting, where demonstrations comprising numerous examples are usually too lengthy for regular ICL, and further propose a divide-and-conquer aggregation method to address this challenge. We conduct extensive experiments using Llama-2 and GPT-J in both zero-shot setting and few-shot setting. The experimental results show that our optimization method effectively enhances the state vector and achieves the state-of-the-art performance on diverse tasks. Code is available at https://github.com/HITsz-TMG/ICL-State-Vector
<div id='section'>Paperid: <span id='pid'>130, <a href='https://arxiv.org/pdf/2404.10966.pdf' target='_blank'>https://arxiv.org/pdf/2404.10966.pdf</a></span>   <span><a href='https://github.com/gist-ailab/domain-specific-block-selection-and-paired-view-pseudo-labeling-for-online-TTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yeonguk Yu, Sungho Shin, Seunghyeok Back, Minhwan Ko, Sangjun Noh, Kyoobin Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.10966">Domain-Specific Block Selection and Paired-View Pseudo-Labeling for Online Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) aims to adapt a pre-trained model to a new test domain without access to source data after deployment. Existing approaches typically rely on self-training with pseudo-labels since ground-truth cannot be obtained from test data. Although the quality of pseudo labels is important for stable and accurate long-term adaptation, it has not been previously addressed. In this work, we propose DPLOT, a simple yet effective TTA framework that consists of two components: (1) domain-specific block selection and (2) pseudo-label generation using paired-view images. Specifically, we select blocks that involve domain-specific feature extraction and train these blocks by entropy minimization. After blocks are adjusted for current test domain, we generate pseudo-labels by averaging given test images and corresponding flipped counterparts. By simply using flip augmentation, we prevent a decrease in the quality of the pseudo-labels, which can be caused by the domain gap resulting from strong augmentation. Our experimental results demonstrate that DPLOT outperforms previous TTA methods in CIFAR10-C, CIFAR100-C, and ImageNet-C benchmarks, reducing error by up to 5.4%, 9.1%, and 2.9%, respectively. Also, we provide an extensive analysis to demonstrate effectiveness of our framework. Code is available at https://github.com/gist-ailab/domain-specific-block-selection-and-paired-view-pseudo-labeling-for-online-TTA.
<div id='section'>Paperid: <span id='pid'>131, <a href='https://arxiv.org/pdf/2404.08392.pdf' target='_blank'>https://arxiv.org/pdf/2404.08392.pdf</a></span>   <span><a href='https://github.com/GustavoVargasHakim/NCTTT.git' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>David Osowiechi, Gustavo A. Vargas Hakim, Mehrdad Noori, Milad Cheraghalikhani, Ali Bahri, Moslem Yazdanpanah, Ismail Ben Ayed, Christian Desrosiers
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.08392">NC-TTT: A Noise Contrastive Approach for Test-Time Training</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite their exceptional performance in vision tasks, deep learning models often struggle when faced with domain shifts during testing. Test-Time Training (TTT) methods have recently gained popularity by their ability to enhance the robustness of models through the addition of an auxiliary objective that is jointly optimized with the main task. Being strictly unsupervised, this auxiliary objective is used at test time to adapt the model without any access to labels. In this work, we propose Noise-Contrastive Test-Time Training (NC-TTT), a novel unsupervised TTT technique based on the discrimination of noisy feature maps. By learning to classify noisy views of projected feature maps, and then adapting the model accordingly on new domains, classification performance can be recovered by an important margin. Experiments on several popular test-time adaptation baselines demonstrate the advantages of our method compared to recent approaches for this task. The code can be found at:https://github.com/GustavoVargasHakim/NCTTT.git
<div id='section'>Paperid: <span id='pid'>132, <a href='https://arxiv.org/pdf/2404.06362.pdf' target='_blank'>https://arxiv.org/pdf/2404.06362.pdf</a></span>   <span><a href='https://github.com/aleemsidra/SaLIP' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Sidra Aleem, Fangyijie Wang, Mayug Maniparambil, Eric Arazo, Julia Dietlmeier, Guenole Silvestre, Kathleen Curran, Noel E. O'Connor, Suzanne Little
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.06362">Test-Time Adaptation with SaLIP: A Cascade of SAM and CLIP for Zero shot Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The Segment Anything Model (SAM) and CLIP are remarkable vision foundation models (VFMs). SAM, a prompt driven segmentation model, excels in segmentation tasks across diverse domains, while CLIP is renowned for its zero shot recognition capabilities. However, their unified potential has not yet been explored in medical image segmentation. To adapt SAM to medical imaging, existing methods primarily rely on tuning strategies that require extensive data or prior prompts tailored to the specific task, making it particularly challenging when only a limited number of data samples are available. This work presents an in depth exploration of integrating SAM and CLIP into a unified framework for medical image segmentation. Specifically, we propose a simple unified framework, SaLIP, for organ segmentation. Initially, SAM is used for part based segmentation within the image, followed by CLIP to retrieve the mask corresponding to the region of interest (ROI) from the pool of SAM generated masks. Finally, SAM is prompted by the retrieved ROI to segment a specific organ. Thus, SaLIP is training and fine tuning free and does not rely on domain expertise or labeled data for prompt engineering. Our method shows substantial enhancements in zero shot segmentation, showcasing notable improvements in DICE scores across diverse segmentation tasks like brain (63.46%), lung (50.11%), and fetal head (30.82%), when compared to un prompted SAM. Code and text prompts are available at: https://github.com/aleemsidra/SaLIP.
<div id='section'>Paperid: <span id='pid'>133, <a href='https://arxiv.org/pdf/2404.06065.pdf' target='_blank'>https://arxiv.org/pdf/2404.06065.pdf</a></span>   <span><a href='https://github.com/gaozhengqing/UniEnt' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhengqing Gao, Xu-Yao Zhang, Cheng-Lin Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.06065">Unified Entropy Optimization for Open-Set Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) aims at adapting a model pre-trained on the labeled source domain to the unlabeled target domain. Existing methods usually focus on improving TTA performance under covariate shifts, while neglecting semantic shifts. In this paper, we delve into a realistic open-set TTA setting where the target domain may contain samples from unknown classes. Many state-of-the-art closed-set TTA methods perform poorly when applied to open-set scenarios, which can be attributed to the inaccurate estimation of data distribution and model confidence. To address these issues, we propose a simple but effective framework called unified entropy optimization (UniEnt), which is capable of simultaneously adapting to covariate-shifted in-distribution (csID) data and detecting covariate-shifted out-of-distribution (csOOD) data. Specifically, UniEnt first mines pseudo-csID and pseudo-csOOD samples from test data, followed by entropy minimization on the pseudo-csID data and entropy maximization on the pseudo-csOOD data. Furthermore, we introduce UniEnt+ to alleviate the noise caused by hard data partition leveraging sample-level confidence. Extensive experiments on CIFAR benchmarks and Tiny-ImageNet-C show the superiority of our framework. The code is available at https://github.com/gaozhengqing/UniEnt
<div id='section'>Paperid: <span id='pid'>134, <a href='https://arxiv.org/pdf/2404.05094.pdf' target='_blank'>https://arxiv.org/pdf/2404.05094.pdf</a></span>   <span><a href='https://github.com/divelab/ATTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Shurui Gui, Xiner Li, Shuiwang Ji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.05094">Active Test-Time Adaptation: Theoretical Analyses and An Algorithm</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) addresses distribution shifts for streaming test data in unsupervised settings. Currently, most TTA methods can only deal with minor shifts and rely heavily on heuristic and empirical studies.
  To advance TTA under domain shifts, we propose the novel problem setting of active test-time adaptation (ATTA) that integrates active learning within the fully TTA setting.
  We provide a learning theory analysis, demonstrating that incorporating limited labeled test instances enhances overall performances across test domains with a theoretical guarantee. We also present a sample entropy balancing for implementing ATTA while avoiding catastrophic forgetting (CF). We introduce a simple yet effective ATTA algorithm, known as SimATTA, using real-time sample selection techniques. Extensive experimental results confirm consistency with our theoretical analyses and show that the proposed ATTA method yields substantial performance improvements over TTA methods while maintaining efficiency and shares similar effectiveness to the more demanding active domain adaptation (ADA) methods. Our code is available at https://github.com/divelab/ATTA
<div id='section'>Paperid: <span id='pid'>135, <a href='https://arxiv.org/pdf/2404.01351.pdf' target='_blank'>https://arxiv.org/pdf/2404.01351.pdf</a></span>   <span><a href='https://github.com/taeckyung/AETTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Taeckyung Lee, Sorn Chottananurak, Taesik Gong, Sung-Ju Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.01351">AETTA: Label-Free Accuracy Estimation for Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) has emerged as a viable solution to adapt pre-trained models to domain shifts using unlabeled test data. However, TTA faces challenges of adaptation failures due to its reliance on blind adaptation to unknown test samples in dynamic scenarios. Traditional methods for out-of-distribution performance estimation are limited by unrealistic assumptions in the TTA context, such as requiring labeled data or re-training models. To address this issue, we propose AETTA, a label-free accuracy estimation algorithm for TTA. We propose the prediction disagreement as the accuracy estimate, calculated by comparing the target model prediction with dropout inferences. We then improve the prediction disagreement to extend the applicability of AETTA under adaptation failures. Our extensive evaluation with four baselines and six TTA methods demonstrates that AETTA shows an average of 19.8%p more accurate estimation compared with the baselines. We further demonstrate the effectiveness of accuracy estimation with a model recovery case study, showcasing the practicality of our model recovery based on accuracy estimation. The source code is available at https://github.com/taeckyung/AETTA.
<div id='section'>Paperid: <span id='pid'>136, <a href='https://arxiv.org/pdf/2403.18442.pdf' target='_blank'>https://arxiv.org/pdf/2403.18442.pdf</a></span>   <span><a href='https://github.com/abie-e/BFTT3D' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yanshuo Wang, Ali Cheraghian, Zeeshan Hayder, Jie Hong, Sameera Ramasinghe, Shafin Rahman, David Ahmedt-Aristizabal, Xuesong Li, Lars Petersson, Mehrtash Harandi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.18442">Backpropagation-free Network for 3D Test-time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Real-world systems often encounter new data over time, which leads to experiencing target domain shifts. Existing Test-Time Adaptation (TTA) methods tend to apply computationally heavy and memory-intensive backpropagation-based approaches to handle this. Here, we propose a novel method that uses a backpropagation-free approach for TTA for the specific case of 3D data. Our model uses a two-stream architecture to maintain knowledge about the source domain as well as complementary target-domain-specific information. The backpropagation-free property of our model helps address the well-known forgetting problem and mitigates the error accumulation issue. The proposed method also eliminates the need for the usually noisy process of pseudo-labeling and reliance on costly self-supervised training. Moreover, our method leverages subspace learning, effectively reducing the distribution variance between the two domains. Furthermore, the source-domain-specific and the target-domain-specific streams are aligned using a novel entropy-based adaptive fusion strategy. Extensive experiments on popular benchmarks demonstrate the effectiveness of our method. The code will be available at \url{https://github.com/abie-e/BFTT3D}.
<div id='section'>Paperid: <span id='pid'>137, <a href='https://arxiv.org/pdf/2403.18293.pdf' target='_blank'>https://arxiv.org/pdf/2403.18293.pdf</a></span>   <span><a href='https://kdiaaa.github.io/tda/' target='_blank'>  GitHub</a></span> <span><a href='https://kdiaaa.github.io/tda/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Adilbek Karmanov, Dayan Guan, Shijian Lu, Abdulmotaleb El Saddik, Eric Xing
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.18293">Efficient Test-Time Adaptation of Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation with pre-trained vision-language models has attracted increasing attention for tackling distribution shifts during the test time. Though prior studies have achieved very promising performance, they involve intensive computation which is severely unaligned with test-time adaptation. We design TDA, a training-free dynamic adapter that enables effective and efficient test-time adaptation with vision-language models. TDA works with a lightweight key-value cache that maintains a dynamic queue with few-shot pseudo labels as values and the corresponding test-sample features as keys. Leveraging the key-value cache, TDA allows adapting to test data gradually via progressive pseudo label refinement which is super-efficient without incurring any backpropagation. In addition, we introduce negative pseudo labeling that alleviates the adverse impact of pseudo label noises by assigning pseudo labels to certain negative classes when the model is uncertain about its pseudo label predictions. Extensive experiments over two benchmarks demonstrate TDA's superior effectiveness and efficiency as compared with the state-of-the-art. The code has been released in \url{https://kdiaaa.github.io/tda/}.
<div id='section'>Paperid: <span id='pid'>138, <a href='https://arxiv.org/pdf/2403.15647.pdf' target='_blank'>https://arxiv.org/pdf/2403.15647.pdf</a></span>   <span><a href='https://github.com/zgy600/RetiGen' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ze Chen, Gongyu Zhang, Jiayu Huo, Joan Nunez do Rio, Charalampos Komninos, Yang Liu, Rachel Sparks, Sebastien Ourselin, Christos Bergeles, Timothy Jackson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.15647">RetiGen: A Framework for Generalized Retinal Diagnosis Using Multi-View Fundus Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study introduces a novel framework for enhancing domain generalization in medical imaging, specifically focusing on utilizing unlabelled multi-view colour fundus photographs. Unlike traditional approaches that rely on single-view imaging data and face challenges in generalizing across diverse clinical settings, our method leverages the rich information in the unlabelled multi-view imaging data to improve model robustness and accuracy. By incorporating a class balancing method, a test-time adaptation technique and a multi-view optimization strategy, we address the critical issue of domain shift that often hampers the performance of machine learning models in real-world applications. Experiments comparing various state-of-the-art domain generalization and test-time optimization methodologies show that our approach consistently outperforms when combined with existing baseline and state-of-the-art methods. We also show our online method improves all existing techniques. Our framework demonstrates improvements in domain generalization capabilities and offers a practical solution for real-world deployment by facilitating online adaptation to new, unseen datasets. Our code is available at https://github.com/zgy600/RetiGen .
<div id='section'>Paperid: <span id='pid'>139, <a href='https://arxiv.org/pdf/2403.14119.pdf' target='_blank'>https://arxiv.org/pdf/2403.14119.pdf</a></span>   <span><a href='https://github.com/hee-suk-yoon/C-TPT' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hee Suk Yoon, Eunseop Yoon, Joshua Tian Jin Tee, Mark Hasegawa-Johnson, Yingzhen Li, Chang D. Yoo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.14119">C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In deep learning, test-time adaptation has gained attention as a method for model fine-tuning without the need for labeled data. A prime exemplification is the recently proposed test-time prompt tuning for large-scale vision-language models such as CLIP. Unfortunately, these prompts have been mainly developed to improve accuracy, overlooking the importance of calibration, which is a crucial aspect for quantifying prediction uncertainty. However, traditional calibration methods rely on substantial amounts of labeled data, making them impractical for test-time scenarios. To this end, this paper explores calibration during test-time prompt tuning by leveraging the inherent properties of CLIP. Through a series of observations, we find that the prompt choice significantly affects the calibration in CLIP, where the prompts leading to higher text feature dispersion result in better-calibrated predictions. Introducing the Average Text Feature Dispersion (ATFD), we establish its relationship with calibration error and present a novel method, Calibrated Test-time Prompt Tuning (C-TPT), for optimizing prompts during test-time with enhanced calibration. Through extensive experiments on different CLIP architectures and datasets, we show that C-TPT can effectively improve the calibration of test-time prompt tuning without needing labeled data. The code is publicly accessible at https://github.com/hee-suk-yoon/C-TPT.
<div id='section'>Paperid: <span id='pid'>140, <a href='https://arxiv.org/pdf/2403.07366.pdf' target='_blank'>https://arxiv.org/pdf/2403.07366.pdf</a></span>   <span><a href='https://whitesnowdrop.github.io/DeYO/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jonghyun Lee, Dahuin Jung, Saehyung Lee, Junsung Park, Juhyeon Shin, Uiwon Hwang, Sungroh Yoon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.07366">Entropy is not Enough for Test-Time Adaptation: From the Perspective of Disentangled Factors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) fine-tunes pre-trained deep neural networks for unseen test data. The primary challenge of TTA is limited access to the entire test dataset during online updates, causing error accumulation. To mitigate it, TTA methods have utilized the model output's entropy as a confidence metric that aims to determine which samples have a lower likelihood of causing error. Through experimental studies, however, we observed the unreliability of entropy as a confidence metric for TTA under biased scenarios and theoretically revealed that it stems from the neglect of the influence of latent disentangled factors of data on predictions. Building upon these findings, we introduce a novel TTA method named Destroy Your Object (DeYO), which leverages a newly proposed confidence metric named Pseudo-Label Probability Difference (PLPD). PLPD quantifies the influence of the shape of an object on prediction by measuring the difference between predictions before and after applying an object-destructive transformation. DeYO consists of sample selection and sample weighting, which employ entropy and PLPD concurrently. For robust adaptation, DeYO prioritizes samples that dominantly incorporate shape information when making predictions. Our extensive experiments demonstrate the consistent superiority of DeYO over baseline methods across various scenarios, including biased and wild. Project page is publicly available at https://whitesnowdrop.github.io/DeYO/.
<div id='section'>Paperid: <span id='pid'>141, <a href='https://arxiv.org/pdf/2403.06461.pdf' target='_blank'>https://arxiv.org/pdf/2403.06461.pdf</a></span>   <span><a href='https://github.com/AronCao49/Latte-plusplus' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Haozhi Cao, Yuecong Xu, Pengyu Yin, Xingyu Ji, Shenghai Yuan, Jianfei Yang, Lihua Xie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.06461">Latte++: Spatial-Temporal Voxel-based Test-Time Adaptation for Multi-Modal Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-modal test-time adaptation (MM-TTA) is proposed to adapt models to an unlabeled target domain by leveraging the complementary multi-modal inputs in an online manner. Previous MM-TTA methods for 3D segmentation rely on predictions of cross-modal information in each input frame, while they ignore the fact that predictions of geometric neighborhoods within consecutive frames are highly correlated, leading to unstable predictions across time. To fulfill this gap, we propose ReLiable Spatial-temporal Voxels (Latte), an MM-TTA method that leverages reliable cross-modal spatial-temporal correspondences for multi-modal 3D segmentation. Motivated by the fact that reliable predictions should be consistent with their spatial-temporal correspondences, Latte aggregates consecutive frames in a sliding-window manner and constructs Spatial-Temporal (ST) voxels to capture temporally local prediction consistency for each modality. After filtering out ST voxels with high ST entropy, Latte conducts cross-modal learning for each point and pixel by attending to those with reliable and consistent predictions among both spatial and temporal neighborhoods. Considering the prediction consistency might vary under different sliding windows, we further propose Latte++ which leverages ST voxels generated under various sliding windows to more thoroughly evaluate intra-modal prediction consistency before the cross-modal fusion. Experimental results show that both Latte and Latte++ achieve state-of-the-art performance on five MM-TTA benchmarks compared to previous MM-TTA or TTA methods. Code will be available at https://github.com/AronCao49/Latte-plusplus.
<div id='section'>Paperid: <span id='pid'>142, <a href='https://arxiv.org/pdf/2403.03662.pdf' target='_blank'>https://arxiv.org/pdf/2403.03662.pdf</a></span>   <span><a href='http://github.com/MKashifAli/MetaVideoStab' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Muhammad Kashif Ali, Eun Woo Im, Dongjin Kim, Tae Hyun Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.03662">Harnessing Meta-Learning for Improving Full-Frame Video Stabilization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Video stabilization is a longstanding computer vision problem, particularly pixel-level synthesis solutions for video stabilization which synthesize full frames add to the complexity of this task. These techniques aim to stabilize videos by synthesizing full frames while enhancing the stability of the considered video. This intensifies the complexity of the task due to the distinct mix of unique motion profiles and visual content present in each video sequence, making robust generalization with fixed parameters difficult. In our study, we introduce a novel approach to enhance the performance of pixel-level synthesis solutions for video stabilization by adapting these models to individual input video sequences. The proposed adaptation exploits low-level visual cues accessible during test-time to improve both the stability and quality of resulting videos. We highlight the efficacy of our methodology of "test-time adaptation" through simple fine-tuning of one of these models, followed by significant stability gain via the integration of meta-learning techniques. Notably, significant improvement is achieved with only a single adaptation step. The versatility of the proposed algorithm is demonstrated by consistently improving the performance of various pixel-level synthesis models for video stabilization in real-world scenarios.
<div id='section'>Paperid: <span id='pid'>143, <a href='https://arxiv.org/pdf/2402.09604.pdf' target='_blank'>https://arxiv.org/pdf/2402.09604.pdf</a></span>   <span><a href='https://github.com/mazurowski-lab/single-image-test-time-adaptation' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Haoyu Dong, Nicholas Konz, Hanxue Gu, Maciej A. Mazurowski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.09604">Medical Image Segmentation with InTEnt: Integrated Entropy Weighting for Single Image Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) refers to adapting a trained model to a new domain during testing. Existing TTA techniques rely on having multiple test images from the same domain, yet this may be impractical in real-world applications such as medical imaging, where data acquisition is expensive and imaging conditions vary frequently. Here, we approach such a task, of adapting a medical image segmentation model with only a single unlabeled test image. Most TTA approaches, which directly minimize the entropy of predictions, fail to improve performance significantly in this setting, in which we also observe the choice of batch normalization (BN) layer statistics to be a highly important yet unstable factor due to only having a single test domain example. To overcome this, we propose to instead integrate over predictions made with various estimates of target domain statistics between the training and test statistics, weighted based on their entropy statistics. Our method, validated on 24 source/target domain splits across 3 medical image datasets surpasses the leading method by 2.9% Dice coefficient on average.
<div id='section'>Paperid: <span id='pid'>144, <a href='https://arxiv.org/pdf/2401.08328.pdf' target='_blank'>https://arxiv.org/pdf/2401.08328.pdf</a></span>   <span><a href='https://github.com/devavratTomar/unmixtns' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Devavrat Tomar, Guillaume Vray, Jean-Philippe Thiran, Behzad Bozorgtabar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.08328">Un-Mixing Test-Time Normalization Statistics: Combatting Label Temporal Correlation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent test-time adaptation methods heavily rely on nuanced adjustments of batch normalization (BN) parameters. However, one critical assumption often goes overlooked: that of independently and identically distributed (i.i.d.) test batches with respect to unknown labels. This oversight leads to skewed BN statistics and undermines the reliability of the model under non-i.i.d. scenarios. To tackle this challenge, this paper presents a novel method termed 'Un-Mixing Test-Time Normalization Statistics' (UnMix-TNS). Our method re-calibrates the statistics for each instance within a test batch by mixing it with multiple distinct statistics components, thus inherently simulating the i.i.d. scenario. The core of this method hinges on a distinctive online unmixing procedure that continuously updates these statistics components by incorporating the most similar instances from new test batches. Remarkably generic in its design, UnMix-TNS seamlessly integrates with a wide range of leading test-time adaptation methods and pre-trained architectures equipped with BN layers. Empirical evaluations corroborate the robustness of UnMix-TNS under varied scenarios-ranging from single to continual and mixed domain shifts, particularly excelling with temporally correlated test data and corrupted non-i.i.d. real-world streams. This adaptability is maintained even with very small batch sizes or single instances. Our results highlight UnMix-TNS's capacity to markedly enhance stability and performance across various benchmarks. Our code is publicly available at https://github.com/devavratTomar/unmixtns.
<div id='section'>Paperid: <span id='pid'>145, <a href='https://arxiv.org/pdf/2401.04148.pdf' target='_blank'>https://arxiv.org/pdf/2401.04148.pdf</a></span>   <span><a href='https://github.com/Pengxin-Guo/ADCSD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Pengxin Guo, Pengrong Jin, Ziyue Li, Lei Bai, Yu Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.04148">Online Test-Time Adaptation of Spatial-Temporal Traffic Flow Forecasting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate spatial-temporal traffic flow forecasting is crucial in aiding traffic managers in implementing control measures and assisting drivers in selecting optimal travel routes. Traditional deep-learning based methods for traffic flow forecasting typically rely on historical data to train their models, which are then used to make predictions on future data. However, the performance of the trained model usually degrades due to the temporal drift between the historical and future data. To make the model trained on historical data better adapt to future data in a fully online manner, this paper conducts the first study of the online test-time adaptation techniques for spatial-temporal traffic flow forecasting problems. To this end, we propose an Adaptive Double Correction by Series Decomposition (ADCSD) method, which first decomposes the output of the trained model into seasonal and trend-cyclical parts and then corrects them by two separate modules during the testing phase using the latest observed data entry by entry. In the proposed ADCSD method, instead of fine-tuning the whole trained model during the testing phase, a lite network is attached after the trained model, and only the lite network is fine-tuned in the testing process each time a data entry is observed. Moreover, to satisfy that different time series variables may have different levels of temporal drift, two adaptive vectors are adopted to provide different weights for different time series variables. Extensive experiments on four real-world traffic flow forecasting datasets demonstrate the effectiveness of the proposed ADCSD method. The code is available at https://github.com/Pengxin-Guo/ADCSD.
<div id='section'>Paperid: <span id='pid'>146, <a href='https://arxiv.org/pdf/2312.11976.pdf' target='_blank'>https://arxiv.org/pdf/2312.11976.pdf</a></span>   <span><a href='https://github.com/carrtesy/M2N2' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Dongmin Kim, Sunghyun Park, Jaegul Choo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.11976">When Model Meets New Normals: Test-time Adaptation for Unsupervised Time-series Anomaly Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Time-series anomaly detection deals with the problem of detecting anomalous timesteps by learning normality from the sequence of observations. However, the concept of normality evolves over time, leading to a "new normal problem", where the distribution of normality can be changed due to the distribution shifts between training and test data. This paper highlights the prevalence of the new normal problem in unsupervised time-series anomaly detection studies. To tackle this issue, we propose a simple yet effective test-time adaptation strategy based on trend estimation and a self-supervised approach to learning new normalities during inference. Extensive experiments on real-world benchmarks demonstrate that incorporating the proposed strategy into the anomaly detector consistently improves the model's performance compared to the baselines, leading to robustness to the distribution shifts.
<div id='section'>Paperid: <span id='pid'>147, <a href='https://arxiv.org/pdf/2312.09486.pdf' target='_blank'>https://arxiv.org/pdf/2312.09486.pdf</a></span>   <span><a href='https://github.com/kiwi12138/RealisticTTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zixian Su, Jingwei Guo, Kai Yao, Xi Yang, Qiufeng Wang, Kaizhu Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.09486">Unraveling Batch Normalization for Realistic Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While recent test-time adaptations exhibit efficacy by adjusting batch normalization to narrow domain disparities, their effectiveness diminishes with realistic mini-batches due to inaccurate target estimation. As previous attempts merely introduce source statistics to mitigate this issue, the fundamental problem of inaccurate target estimation still persists, leaving the intrinsic test-time domain shifts unresolved. This paper delves into the problem of mini-batch degradation. By unraveling batch normalization, we discover that the inexact target statistics largely stem from the substantially reduced class diversity in batch. Drawing upon this insight, we introduce a straightforward tool, Test-time Exponential Moving Average (TEMA), to bridge the class diversity gap between training and testing batches. Importantly, our TEMA adaptively extends the scope of typical methods beyond the current batch to incorporate a diverse set of class information, which in turn boosts an accurate target estimation. Built upon this foundation, we further design a novel layer-wise rectification strategy to consistently promote test-time performance. Our proposed method enjoys a unique advantage as it requires neither training nor tuning parameters, offering a truly hassle-free solution. It significantly enhances model robustness against shifted domains and maintains resilience in diverse real-world scenarios with various batch sizes, achieving state-of-the-art performance on several major benchmarks. Code is available at \url{https://github.com/kiwi12138/RealisticTTA}.
<div id='section'>Paperid: <span id='pid'>148, <a href='https://arxiv.org/pdf/2312.07374.pdf' target='_blank'>https://arxiv.org/pdf/2312.07374.pdf</a></span>   <span><a href='https://lwpyh.github.io/GenSAM/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jian Hu, Jiayi Lin, Weitong Cai, Shaogang Gong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.07374">Relax Image-Specific Prompt Requirement in SAM: A Single Generic Prompt for Segmenting Camouflaged Objects</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Camouflaged object detection (COD) approaches heavily rely on pixel-level annotated datasets. Weakly-supervised COD (WSCOD) approaches use sparse annotations like scribbles or points to reduce annotation effort, but this can lead to decreased accuracy. The Segment Anything Model (SAM) shows remarkable segmentation ability with sparse prompts like points. However, manual prompt is not always feasible, as it may not be accessible in real-world application. Additionally, it only provides localization information instead of semantic one, which can intrinsically cause ambiguity in interpreting the targets. In this work, we aim to eliminate the need for manual prompt. The key idea is to employ Cross-modal Chains of Thought Prompting (CCTP) to reason visual prompts using the semantic information given by a generic text prompt. To that end, we introduce a test-time adaptation per-instance mechanism called Generalizable SAM (GenSAM) to automatically enerate and optimize visual prompts the generic task prompt for WSCOD. In particular, CCTP maps a single generic text prompt onto image-specific consensus foreground and background heatmaps using vision-language models, acquiring reliable visual prompts. Moreover, to test-time adapt the visual prompts, we further propose Progressive Mask Generation (PMG) to iteratively reweight the input image, guiding the model to focus on the targets in a coarse-to-fine manner. Crucially, all network parameters are fixed, avoiding the need for additional training. Experiments demonstrate the superiority of GenSAM. Experiments on three benchmarks demonstrate that GenSAM outperforms point supervision approaches and achieves comparable results to scribble supervision ones, solely relying on general task descriptions as prompts. our codes is in: https://lwpyh.github.io/GenSAM/.
<div id='section'>Paperid: <span id='pid'>149, <a href='https://arxiv.org/pdf/2312.06275.pdf' target='_blank'>https://arxiv.org/pdf/2312.06275.pdf</a></span>   <span><a href='https://github.com/multimodallearning/DG-TTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Christian Weihsbach, Christian N. Kruse, Alexander Bigalke, Mattias P. Heinrich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.06275">DG-TTA: Out-of-domain Medical Image Segmentation through Augmentation and Descriptor-driven Domain Generalization and Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Purpose: Applying pre-trained medical deep learning segmentation models on out-of-domain images often yields predictions of insufficient quality. In this study, we propose to use a powerful generalizing descriptor along with augmentation to enable domain-generalized pre-training and test-time adaptation, achieving high-quality segmentation in unseen domains.
  Materials and Methods: In this retrospective study five different publicly available datasets (2012 to 2022) including 3D CT and MRI images are used to evaluate segmentation performance in out-of-domain scenarios. The settings include abdominal, spine, and cardiac imaging. The data is randomly split into training and test samples. Domain-generalized pre-training on source data is used to obtain the best initial performance in the target domain. We introduce the combination of the generalizing SSC descriptor and GIN intensity augmentation for optimal generalization. Segmentation results are subsequently optimized at test time, where we propose to adapt the pre-trained models for every unseen scan with a consistency scheme using the same augmentation-descriptor combination. The segmentation is evaluated using Dice similarity and Hausdorff distance and the significance of improvements is tested with the Wilcoxon signed-rank test.
  Results: The proposed generalized pre-training and subsequent test-time adaptation improves model performance significantly in CT to MRI cross-domain prediction for abdominal (+46.2% and +28.2% Dice), spine (+72.9%), and cardiac (+14.2% and +55.7% Dice) scenarios (p<0.001).
  Conclusion: Our method enables optimal, independent usage of medical image source and target data and bridges domain gaps successfully with a compact and efficient methodology. Open-source code available at: https://github.com/multimodallearning/DG-TTA
<div id='section'>Paperid: <span id='pid'>150, <a href='https://arxiv.org/pdf/2312.02197.pdf' target='_blank'>https://arxiv.org/pdf/2312.02197.pdf</a></span>   <span><a href='https://github.com/XLearning-SCU/2024-ICML-TAO' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuanbiao Gou, Haiyu Zhao, Boyun Li, Xinyan Xiao, Xi Peng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.02197">Test-Time Degradation Adaptation for Open-Set Image Restoration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In contrast to close-set scenarios that restore images from a predefined set of degradations, open-set image restoration aims to handle the unknown degradations that were unforeseen during the pretraining phase, which is less-touched as far as we know. This work study this challenging problem and reveal its essence as unidentified distribution shifts between the test and training data. Recently, test-time adaptation has emerged as a fundamental method to address this inherent disparities. Inspired by it, we propose a test-time degradation adaptation framework for open-set image restoration, which consists of three components, \textit{i.e.}, i) a pre-trained and degradation-agnostic diffusion model for generating clean images, ii) a test-time degradation adapter adapts the unknown degradations based on the input image during the testing phase, and iii) the adapter-guided image restoration guides the model through the adapter to produce the corresponding clean image. Through experiments on multiple degradations, we show that our method achieves comparable even better performance than those task-specific methods. The code is available at https://github.com/XLearning-SCU/2024-ICML-TAO.
<div id='section'>Paperid: <span id='pid'>151, <a href='https://arxiv.org/pdf/2311.18363.pdf' target='_blank'>https://arxiv.org/pdf/2311.18363.pdf</a></span>   <span><a href='https://github.com/Chen-Ziyang/VPTTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziyang Chen, Yongsheng Pan, Yiwen Ye, Mengkang Lu, Yong Xia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.18363">Each Test Image Deserves A Specific Prompt: Continual Test-Time Adaptation for 2D Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Distribution shift widely exists in medical images acquired from different medical centres and poses a significant obstacle to deploying the pre-trained semantic segmentation model in real-world applications. Test-time adaptation has proven its effectiveness in tackling the cross-domain distribution shift during inference. However, most existing methods achieve adaptation by updating the pre-trained models, rendering them susceptible to error accumulation and catastrophic forgetting when encountering a series of distribution shifts (i.e., under the continual test-time adaptation setup). To overcome these challenges caused by updating the models, in this paper, we freeze the pre-trained model and propose the Visual Prompt-based Test-Time Adaptation (VPTTA) method to train a specific prompt for each test image to align the statistics in the batch normalization layers. Specifically, we present the low-frequency prompt, which is lightweight with only a few parameters and can be effectively trained in a single iteration. To enhance prompt initialization, we equip VPTTA with a memory bank to benefit the current prompt from previous ones. Additionally, we design a warm-up mechanism, which mixes source and target statistics to construct warm-up statistics, thereby facilitating the training process. Extensive experiments demonstrate the superiority of our VPTTA over other state-of-the-art methods on two medical image segmentation benchmark tasks. The code and weights of pre-trained source models are available at https://github.com/Chen-Ziyang/VPTTA.
<div id='section'>Paperid: <span id='pid'>152, <a href='https://arxiv.org/pdf/2311.18193.pdf' target='_blank'>https://arxiv.org/pdf/2311.18193.pdf</a></span>   <span><a href='https://hthieu166.github.io/petta' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Trung-Hieu Hoang, Duc Minh Vo, Minh N. Do
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.18193">Persistent Test-time Adaptation in Recurring Testing Scenarios</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current test-time adaptation (TTA) approaches aim to adapt a machine learning model to environments that change continuously. Yet, it is unclear whether TTA methods can maintain their adaptability over prolonged periods. To answer this question, we introduce a diagnostic setting - recurring TTA where environments not only change but also recur over time, creating an extensive data stream. This setting allows us to examine the error accumulation of TTA models, in the most basic scenario, when they are regularly exposed to previous testing environments. Furthermore, we simulate a TTA process on a simple yet representative $Îµ$-perturbed Gaussian Mixture Model Classifier, deriving theoretical insights into the dataset- and algorithm-dependent factors contributing to gradual performance degradation. Our investigation leads us to propose persistent TTA (PeTTA), which senses when the model is diverging towards collapse and adjusts the adaptation strategy, striking a balance between the dual objectives of adaptation and model collapse prevention. The supreme stability of PeTTA over existing approaches, in the face of lifelong TTA scenarios, has been demonstrated over comprehensive experiments on various benchmarks. Our project page is available at https://hthieu166.github.io/petta.
<div id='section'>Paperid: <span id='pid'>153, <a href='https://arxiv.org/pdf/2311.16102.pdf' target='_blank'>https://arxiv.org/pdf/2311.16102.pdf</a></span>   <span><a href='https://diffusion-tta.github.io/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mihir Prabhudesai, Tsung-Wei Ke, Alexander C. Li, Deepak Pathak, Katerina Fragkiadaki
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.16102">Diffusion-TTA: Test-time Adaptation of Discriminative Models via Generative Feedback</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The advancements in generative modeling, particularly the advent of diffusion models, have sparked a fundamental question: how can these models be effectively used for discriminative tasks? In this work, we find that generative models can be great test-time adapters for discriminative models. Our method, Diffusion-TTA, adapts pre-trained discriminative models such as image classifiers, segmenters and depth predictors, to each unlabelled example in the test set using generative feedback from a diffusion model. We achieve this by modulating the conditioning of the diffusion model using the output of the discriminative model. We then maximize the image likelihood objective by backpropagating the gradients to discriminative model's parameters. We show Diffusion-TTA significantly enhances the accuracy of various large-scale pre-trained discriminative models, such as, ImageNet classifiers, CLIP models, image pixel labellers and image depth predictors. Diffusion-TTA outperforms existing test-time adaptation methods, including TTT-MAE and TENT, and particularly shines in online adaptation setups, where the discriminative model is continually adapted to each example in the test set. We provide access to code, results, and visualizations on our website: https://diffusion-tta.github.io/.
<div id='section'>Paperid: <span id='pid'>154, <a href='https://arxiv.org/pdf/2311.14402.pdf' target='_blank'>https://arxiv.org/pdf/2311.14402.pdf</a></span>   <span><a href='https://github.com/yuanyige/tea' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yige Yuan, Bingbing Xu, Liang Hou, Fei Sun, Huawei Shen, Xueqi Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.14402">TEA: Test-time Energy Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) aims to improve model generalizability when test data diverges from training distribution, offering the distinct advantage of not requiring access to training data and processes, especially valuable in the context of large pre-trained models. However, current TTA methods fail to address the fundamental issue: covariate shift, i.e., the decreased generalizability can be attributed to the model's reliance on the marginal distribution of the training data, which may impair model calibration and introduce confirmation bias. To address this, we propose a novel energy-based perspective, enhancing the model's perception of target data distributions without requiring access to training data or processes. Building on this perspective, we introduce $\textbf{T}$est-time $\textbf{E}$nergy $\textbf{A}$daptation ($\textbf{TEA}$), which transforms the trained classifier into an energy-based model and aligns the model's distribution with the test data's, enhancing its ability to perceive test distributions and thus improving overall generalizability. Extensive experiments across multiple tasks, benchmarks and architectures demonstrate TEA's superior generalization performance against state-of-the-art methods. Further in-depth analyses reveal that TEA can equip the model with a comprehensive perception of test distribution, ultimately paving the way toward improved generalization and calibration.
<div id='section'>Paperid: <span id='pid'>155, <a href='https://arxiv.org/pdf/2311.13209.pdf' target='_blank'>https://arxiv.org/pdf/2311.13209.pdf</a></span>   <span><a href='https://github.com/Feliciaxyao/ICML2024-FSTTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Junyu Gao, Xuan Yao, Changsheng Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.13209">Fast-Slow Test-Time Adaptation for Online Vision-and-Language Navigation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The ability to accurately comprehend natural language instructions and navigate to the target location is essential for an embodied agent. Such agents are typically required to execute user instructions in an online manner, leading us to explore the use of unlabeled test samples for effective online model adaptation. However, for online Vision-and-Language Navigation (VLN), due to the intrinsic nature of inter-sample online instruction execution and intra-sample multi-step action decision, frequent updates can result in drastic changes in model parameters, while occasional updates can make the model ill-equipped to handle dynamically changing environments. Therefore, we propose a Fast-Slow Test-Time Adaptation (FSTTA) approach for online VLN by performing joint decomposition-accumulation analysis for both gradients and parameters in a unified framework. Extensive experiments show that our method obtains impressive performance gains on four popular benchmarks. Code is available at https://github.com/Feliciaxyao/ICML2024-FSTTA.
<div id='section'>Paperid: <span id='pid'>156, <a href='https://arxiv.org/pdf/2311.07538.pdf' target='_blank'>https://arxiv.org/pdf/2311.07538.pdf</a></span>   <span><a href='https://github.com/WeiKangda/TALC.git' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kangda Wei, Sayan Ghosh, Rakesh R. Menon, Shashank Srivastava
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.07538">Leveraging Multiple Teachers for Test-Time Adaptation of Language-Guided Classifiers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent approaches have explored language-guided classifiers capable of classifying examples from novel tasks when provided with task-specific natural language explanations, instructions or prompts (Sanh et al., 2022; R. Menon et al., 2022). While these classifiers can generalize in zero-shot settings, their task performance often varies substantially between different language explanations in unpredictable ways (Lu et al., 2022; Gonen et al., 2022). Also, current approaches fail to leverage unlabeled examples that may be available in many scenarios. Here, we introduce TALC, a framework that uses data programming to adapt a language-guided classifier for a new task during inference when provided with explanations from multiple teachers and unlabeled test examples. Our results show that TALC consistently outperforms a competitive baseline from prior work by an impressive 9.3% (relative improvement). Further, we demonstrate the robustness of TALC to variations in the quality and quantity of provided explanations, highlighting its potential in scenarios where learning from multiple teachers or a crowd is involved. Our code is available at: https://github.com/WeiKangda/TALC.git.
<div id='section'>Paperid: <span id='pid'>157, <a href='https://arxiv.org/pdf/2310.20271.pdf' target='_blank'>https://arxiv.org/pdf/2310.20271.pdf</a></span>   <span><a href='https://github.com/WenRuxue/DeTTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ruxue Wen, Hangjie Yuan, Dong Ni, Wenbo Xiao, Yaoyao Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.20271">From Denoising Training to Test-Time Adaptation: Enhancing Domain Generalization for Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In medical image segmentation, domain generalization poses a significant challenge due to domain shifts caused by variations in data acquisition devices and other factors. These shifts are particularly pronounced in the most common scenario, which involves only single-source domain data due to privacy concerns. To address this, we draw inspiration from the self-supervised learning paradigm that effectively discourages overfitting to the source domain. We propose the Denoising Y-Net (DeY-Net), a novel approach incorporating an auxiliary denoising decoder into the basic U-Net architecture. The auxiliary decoder aims to perform denoising training, augmenting the domain-invariant representation that facilitates domain generalization. Furthermore, this paradigm provides the potential to utilize unlabeled data. Building upon denoising training, we propose Denoising Test Time Adaptation (DeTTA) that further: (i) adapts the model to the target domain in a sample-wise manner, and (ii) adapts to the noise-corrupted input. Extensive experiments conducted on widely-adopted liver segmentation benchmarks demonstrate significant domain generalization improvements over our baseline and state-of-the-art results compared to other methods. Code is available at https://github.com/WenRuxue/DeTTA.
<div id='section'>Paperid: <span id='pid'>158, <a href='https://arxiv.org/pdf/2310.20199.pdf' target='_blank'>https://arxiv.org/pdf/2310.20199.pdf</a></span>   <span><a href='https://github.com/Jo-wang/OTTA_ViT_survey' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zixin Wang, Yadan Luo, Liang Zheng, Zhuoxiao Chen, Sen Wang, Zi Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.20199">In Search of Lost Online Test-time Adaptation: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This article presents a comprehensive survey of online test-time adaptation (OTTA), focusing on effectively adapting machine learning models to distributionally different target data upon batch arrival. Despite the recent proliferation of OTTA methods, conclusions from previous studies are inconsistent due to ambiguous settings, outdated backbones, and inconsistent hyperparameter tuning, which obscure core challenges and hinder reproducibility. To enhance clarity and enable rigorous comparison, we classify OTTA techniques into three primary categories and benchmark them using a modern backbone, the Vision Transformer (ViT). Our benchmarks cover conventional corrupted datasets such as CIFAR-10/100-C and ImageNet-C, as well as real-world shifts represented by CIFAR-10.1, OfficeHome, and CIFAR-10-Warehouse. The CIFAR-10-Warehouse dataset includes a variety of variations from different search engines and synthesized data generated through diffusion models. To measure efficiency in online scenarios, we introduce novel evaluation metrics, including GFLOPs, wall clock time, and GPU memory usage, providing a clearer picture of the trade-offs between adaptation accuracy and computational overhead. Our findings diverge from existing literature, revealing that (1) transformers demonstrate heightened resilience to diverse domain shifts, (2) the efficacy of many OTTA methods relies on large batch sizes, and (3) stability in optimization and resistance to perturbations are crucial during adaptation, particularly when the batch size is 1. Based on these insights, we highlight promising directions for future research. Our benchmarking toolkit and source code are available at https://github.com/Jo-wang/OTTA_ViT_survey.
<div id='section'>Paperid: <span id='pid'>159, <a href='https://arxiv.org/pdf/2310.19011.pdf' target='_blank'>https://arxiv.org/pdf/2310.19011.pdf</a></span>   <span><a href='https://github.com/DengZeshuai/SRTTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zeshuai Deng, Zhuokun Chen, Shuaicheng Niu, Thomas H. Li, Bohan Zhuang, Mingkui Tan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.19011">Efficient Test-Time Adaptation for Super-Resolution with Second-Order Degradation and Reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Image super-resolution (SR) aims to learn a mapping from low-resolution (LR) to high-resolution (HR) using paired HR-LR training images. Conventional SR methods typically gather the paired training data by synthesizing LR images from HR images using a predetermined degradation model, e.g., Bicubic down-sampling. However, the realistic degradation type of test images may mismatch with the training-time degradation type due to the dynamic changes of the real-world scenarios, resulting in inferior-quality SR images. To address this, existing methods attempt to estimate the degradation model and train an image-specific model, which, however, is quite time-consuming and impracticable to handle rapidly changing domain shifts. Moreover, these methods largely concentrate on the estimation of one degradation type (e.g., blur degradation), overlooking other degradation types like noise and JPEG in real-world test-time scenarios, thus limiting their practicality. To tackle these problems, we present an efficient test-time adaptation framework for SR, named SRTTA, which is able to quickly adapt SR models to test domains with different/unknown degradation types. Specifically, we design a second-order degradation scheme to construct paired data based on the degradation type of the test image, which is predicted by a pre-trained degradation classifier. Then, we adapt the SR model by implementing feature-level reconstruction learning from the initial test image to its second-order degraded counterparts, which helps the SR model generate plausible HR images. Extensive experiments are conducted on newly synthesized corrupted DIV2K datasets with 8 different degradations and several real-world datasets, demonstrating that our SRTTA framework achieves an impressive improvement over existing methods with satisfying speed. The source code is available at https://github.com/DengZeshuai/SRTTA.
<div id='section'>Paperid: <span id='pid'>160, <a href='https://arxiv.org/pdf/2310.18816.pdf' target='_blank'>https://arxiv.org/pdf/2310.18816.pdf</a></span>   <span><a href='https://github.com/baowenxuan/ATP' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenxuan Bao, Tianxin Wei, Haohan Wang, Jingrui He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.18816">Adaptive Test-Time Personalization for Federated Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Personalized federated learning algorithms have shown promising results in adapting models to various distribution shifts. However, most of these methods require labeled data on testing clients for personalization, which is usually unavailable in real-world scenarios. In this paper, we introduce a novel setting called test-time personalized federated learning (TTPFL), where clients locally adapt a global model in an unsupervised way without relying on any labeled data during test-time. While traditional test-time adaptation (TTA) can be used in this scenario, most of them inherently assume training data come from a single domain, while they come from multiple clients (source domains) with different distributions. Overlooking these domain interrelationships can result in suboptimal generalization. Moreover, most TTA algorithms are designed for a specific kind of distribution shift and lack the flexibility to handle multiple kinds of distribution shifts in FL. In this paper, we find that this lack of flexibility partially results from their pre-defining which modules to adapt in the model. To tackle this challenge, we propose a novel algorithm called ATP to adaptively learns the adaptation rates for each module in the model from distribution shifts among source domains. Theoretical analysis proves the strong generalization of ATP. Extensive experiments demonstrate its superiority in handling various distribution shifts including label shift, image corruptions, and domain shift, outperforming existing TTA methods across multiple datasets and model architectures. Our code is available at https://github.com/baowenxuan/ATP .
<div id='section'>Paperid: <span id='pid'>161, <a href='https://arxiv.org/pdf/2310.18562.pdf' target='_blank'>https://arxiv.org/pdf/2310.18562.pdf</a></span>   <span><a href='https://github.com/Claydon-Wang/OFTTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuoyuan Wang, Jindong Wang, HuaJun Xi, Bob Zhang, Lei Zhang, Hongxin Wei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.18562">Optimization-Free Test-Time Adaptation for Cross-Person Activity Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Human Activity Recognition (HAR) models often suffer from performance degradation in real-world applications due to distribution shifts in activity patterns across individuals. Test-Time Adaptation (TTA) is an emerging learning paradigm that aims to utilize the test stream to adjust predictions in real-time inference, which has not been explored in HAR before. However, the high computational cost of optimization-based TTA algorithms makes it intractable to run on resource-constrained edge devices. In this paper, we propose an Optimization-Free Test-Time Adaptation (OFTTA) framework for sensor-based HAR. OFTTA adjusts the feature extractor and linear classifier simultaneously in an optimization-free manner. For the feature extractor, we propose Exponential DecayTest-time Normalization (EDTN) to replace the conventional batch normalization (CBN) layers. EDTN combines CBN and Test-time batch Normalization (TBN) to extract reliable features against domain shifts with TBN's influence decreasing exponentially in deeper layers. For the classifier, we adjust the prediction by computing the distance between the feature and the prototype, which is calculated by a maintained support set. In addition, the update of the support set is based on the pseudo label, which can benefit from reliable features extracted by EDTN. Extensive experiments on three public cross-person HAR datasets and two different TTA settings demonstrate that OFTTA outperforms the state-of-the-art TTA approaches in both classification performance and computational efficiency. Finally, we verify the superiority of our proposed OFTTA on edge devices, indicating possible deployment in real applications. Our code is available at https://github.com/Claydon-Wang/OFTTA.
<div id='section'>Paperid: <span id='pid'>162, <a href='https://arxiv.org/pdf/2310.11482.pdf' target='_blank'>https://arxiv.org/pdf/2310.11482.pdf</a></span>   <span><a href='https://github.com/IemProg/PLASTIC' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Imad Eddine Marouf, Subhankar Roy, StÃ©phane LathuiliÃ¨re, Enzo Tartaglione
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.11482">Enhancing Plasticity for First Session Adaptation Continual Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The integration of large pre-trained models (PTMs) into Class-Incremental Learning (CIL) has facilitated the development of computationally efficient strategies such as First-Session Adaptation (FSA), which fine-tunes the model solely on the first task while keeping it frozen for subsequent tasks. Although effective in homogeneous task sequences, these approaches struggle when faced with the heterogeneity of real-world task distributions. We introduce Plasticity-Enhanced Test-Time Adaptation in Class-Incremental Learning (PLASTIC), a method that reinstates plasticity in CIL while preserving model stability. PLASTIC leverages Test-Time Adaptation (TTA) by dynamically fine-tuning LayerNorm parameters on unlabeled test data, enabling adaptability to evolving tasks and improving robustness against data corruption. To prevent TTA-induced model divergence and maintain stable learning across tasks, we introduce a teacher-student distillation framework, ensuring that adaptation remains controlled and generalizable. Extensive experiments across multiple benchmarks demonstrate that PLASTIC consistently outperforms both conventional and state-of-the-art PTM-based CIL approaches, while also exhibiting inherent robustness to data corruptions. Code is available at: https://github.com/IemProg/PLASTIC.
<div id='section'>Paperid: <span id='pid'>163, <a href='https://arxiv.org/pdf/2310.10074.pdf' target='_blank'>https://arxiv.org/pdf/2310.10074.pdf</a></span>   <span><a href='https://github.com/taeckyung/SoTTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Taesik Gong, Yewon Kim, Taeckyung Lee, Sorn Chottananurak, Sung-Ju Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.10074">SoTTA: Robust Test-Time Adaptation on Noisy Data Streams</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) aims to address distributional shifts between training and testing data using only unlabeled test data streams for continual model adaptation. However, most TTA methods assume benign test streams, while test samples could be unexpectedly diverse in the wild. For instance, an unseen object or noise could appear in autonomous driving. This leads to a new threat to existing TTA algorithms; we found that prior TTA algorithms suffer from those noisy test samples as they blindly adapt to incoming samples. To address this problem, we present Screening-out Test-Time Adaptation (SoTTA), a novel TTA algorithm that is robust to noisy samples. The key enabler of SoTTA is two-fold: (i) input-wise robustness via high-confidence uniform-class sampling that effectively filters out the impact of noisy samples and (ii) parameter-wise robustness via entropy-sharpness minimization that improves the robustness of model parameters against large gradients from noisy samples. Our evaluation with standard TTA benchmarks with various noisy scenarios shows that our method outperforms state-of-the-art TTA methods under the presence of noisy samples and achieves comparable accuracy to those methods without noisy samples. The source code is available at https://github.com/taeckyung/SoTTA .
<div id='section'>Paperid: <span id='pid'>164, <a href='https://arxiv.org/pdf/2310.05341.pdf' target='_blank'>https://arxiv.org/pdf/2310.05341.pdf</a></span>   <span><a href='https://github.com/ycarobot/TTAP' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chang'an Yi, Haotian Chen, Yifan Zhang, Yonghui Xu, Yan Zhou, Lizhen Cui
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.05341">From Question to Exploration: Test-Time Adaptation in Semantic Segmentation?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) aims to adapt a model, initially trained on training data, to test data with potential distribution shifts. Most existing TTA methods focus on classification problems. The pronounced success of classification might lead numerous newcomers and engineers to assume that classic TTA techniques can be directly applied to the more challenging task of semantic segmentation. However, this belief is still an open question. In this paper, we investigate the applicability of existing classic TTA strategies in semantic segmentation. Our comprehensive results have led to three key observations. First, the classic normalization updating strategy only brings slight performance improvement, and in some cases, it might even adversely affect the results. Even with the application of advanced distribution estimation techniques like batch renormalization, the problem remains unresolved. Second, although the teacher-student scheme does enhance the training stability for segmentation TTA in the presence of noisy pseudo-labels and temporal correlation, it cannot directly result in performance improvement compared to the original model without TTA under complex data distribution. Third, segmentation TTA suffers a severe long-tailed class-imbalance problem, which is substantially more complex than that in TTA for classification. This long-tailed challenge negatively affects segmentation TTA performance, even when the accuracy of pseudo-labels is high. Besides those observations, we find that visual prompt tuning (VisPT) is promising in segmentation TTA and propose a novel method named TTAP. The outstanding performance of TTAP has also been verified. We hope the community can give more attention to this challenging, yet important, segmentation TTA task in the future. The source code is available at: \textit{https://github.com/ycarobot/TTAP
<div id='section'>Paperid: <span id='pid'>165, <a href='https://arxiv.org/pdf/2310.01926.pdf' target='_blank'>https://arxiv.org/pdf/2310.01926.pdf</a></span>   <span><a href='https://github.com/mattiasegu/darth' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mattia Segu, Bernt Schiele, Fisher Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.01926">DARTH: Holistic Test-time Adaptation for Multiple Object Tracking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multiple object tracking (MOT) is a fundamental component of perception systems for autonomous driving, and its robustness to unseen conditions is a requirement to avoid life-critical failures. Despite the urge of safety in driving systems, no solution to the MOT adaptation problem to domain shift in test-time conditions has ever been proposed. However, the nature of a MOT system is manifold - requiring object detection and instance association - and adapting all its components is non-trivial. In this paper, we analyze the effect of domain shift on appearance-based trackers, and introduce DARTH, a holistic test-time adaptation framework for MOT. We propose a detection consistency formulation to adapt object detection in a self-supervised fashion, while adapting the instance appearance representations via our novel patch contrastive loss. We evaluate our method on a variety of domain shifts - including sim-to-real, outdoor-to-indoor, indoor-to-outdoor - and substantially improve the source model performance on all metrics. Code: https://github.com/mattiasegu/darth.
<div id='section'>Paperid: <span id='pid'>166, <a href='https://arxiv.org/pdf/2309.14949.pdf' target='_blank'>https://arxiv.org/pdf/2309.14949.pdf</a></span>   <span><a href='https://github.com/Gorilla-Lab-SCUT/TRIBE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yongyi Su, Xun Xu, Kui Jia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.14949">Towards Real-World Test-Time Adaptation: Tri-Net Self-Training with Balanced Normalization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-Time Adaptation aims to adapt source domain model to testing data at inference stage with success demonstrated in adapting to unseen corruptions. However, these attempts may fail under more challenging real-world scenarios. Existing works mainly consider real-world test-time adaptation under non-i.i.d. data stream and continual domain shift. In this work, we first complement the existing real-world TTA protocol with a globally class imbalanced testing set. We demonstrate that combining all settings together poses new challenges to existing methods. We argue the failure of state-of-the-art methods is first caused by indiscriminately adapting normalization layers to imbalanced testing data. To remedy this shortcoming, we propose a balanced batchnorm layer to swap out the regular batchnorm at inference stage. The new batchnorm layer is capable of adapting without biasing towards majority classes. We are further inspired by the success of self-training (ST) in learning from unlabeled data and adapt ST for test-time adaptation. However, ST alone is prone to over adaption which is responsible for the poor performance under continual domain shift. Hence, we propose to improve self-training under continual domain shift by regularizing model updates with an anchored loss. The final TTA model, termed as TRIBE, is built upon a tri-net architecture with balanced batchnorm layers. We evaluate TRIBE on four datasets representing real-world TTA settings. TRIBE consistently achieves the state-of-the-art performance across multiple evaluation protocols. The code is available at https://github.com/Gorilla-Lab-SCUT/TRIBE.
<div id='section'>Paperid: <span id='pid'>167, <a href='https://arxiv.org/pdf/2309.10109.pdf' target='_blank'>https://arxiv.org/pdf/2309.10109.pdf</a></span>   <span><a href='https://github.com/dmn-sjk/AR-TTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Damian SÃ³jka, Sebastian Cygert, BartÅomiej Twardowski, Tomasz TrzciÅski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.10109">AR-TTA: A Simple Method for Real-World Continual Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation is a promising research direction that allows the source model to adapt itself to changes in data distribution without any supervision. Yet, current methods are usually evaluated on benchmarks that are only a simplification of real-world scenarios. Hence, we propose to validate test-time adaptation methods using the recently introduced datasets for autonomous driving, namely CLAD-C and SHIFT. We observe that current test-time adaptation methods struggle to effectively handle varying degrees of domain shift, often resulting in degraded performance that falls below that of the source model. We noticed that the root of the problem lies in the inability to preserve the knowledge of the source model and adapt to dynamically changing, temporally correlated data streams. Therefore, we enhance the well-established self-training framework by incorporating a small memory buffer to increase model stability and at the same time perform dynamic adaptation based on the intensity of domain shift. The proposed method, named AR-TTA, outperforms existing approaches on both synthetic and more real-world benchmarks and shows robustness across a variety of TTA scenarios. The code is available at https://github.com/dmn-sjk/AR-TTA.
<div id='section'>Paperid: <span id='pid'>168, <a href='https://arxiv.org/pdf/2309.05994.pdf' target='_blank'>https://arxiv.org/pdf/2309.05994.pdf</a></span>   <span><a href='https://github.com/gaozhitong/ATTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhitong Gao, Shipeng Yan, Xuming He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.05994">ATTA: Anomaly-aware Test-Time Adaptation for Out-of-Distribution Detection in Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements in dense out-of-distribution (OOD) detection have primarily focused on scenarios where the training and testing datasets share a similar domain, with the assumption that no domain shift exists between them. However, in real-world situations, domain shift often exits and significantly affects the accuracy of existing out-of-distribution (OOD) detection models. In this work, we propose a dual-level OOD detection framework to handle domain shift and semantic shift jointly. The first level distinguishes whether domain shift exists in the image by leveraging global low-level features, while the second level identifies pixels with semantic shift by utilizing dense high-level feature maps. In this way, we can selectively adapt the model to unseen domains as well as enhance model's capacity in detecting novel classes. We validate the efficacy of our proposed method on several OOD segmentation benchmarks, including those with significant domain shifts and those without, observing consistent performance improvements across various baseline models. Code is available at ${\href{https://github.com/gaozhitong/ATTA}{https://github.com/gaozhitong/ATTA}}$.
<div id='section'>Paperid: <span id='pid'>169, <a href='https://arxiv.org/pdf/2309.00846.pdf' target='_blank'>https://arxiv.org/pdf/2309.00846.pdf</a></span>   <span><a href='https://manogna-s.github.io/pstarc' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Manogna Sreenivas, Goirik Chakrabarty, Soma Biswas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.00846">pSTarC: Pseudo Source Guided Target Clustering for Fully Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test Time Adaptation (TTA) is a pivotal concept in machine learning, enabling models to perform well in real-world scenarios, where test data distribution differs from training. In this work, we propose a novel approach called pseudo Source guided Target Clustering (pSTarC) addressing the relatively unexplored area of TTA under real-world domain shifts. This method draws inspiration from target clustering techniques and exploits the source classifier for generating pseudo-source samples. The test samples are strategically aligned with these pseudo-source samples, facilitating their clustering and thereby enhancing TTA performance. pSTarC operates solely within the fully test-time adaptation protocol, removing the need for actual source data. Experimental validation on a variety of domain shift datasets, namely VisDA, Office-Home, DomainNet-126, CIFAR-100C verifies pSTarC's effectiveness. This method exhibits significant improvements in prediction accuracy along with efficient computational requirements. Furthermore, we also demonstrate the universality of the pSTarC framework by showing its effectiveness for the continuous TTA framework. The source code for our method is available at https://manogna-s.github.io/pstarc
<div id='section'>Paperid: <span id='pid'>170, <a href='https://arxiv.org/pdf/2309.00082.pdf' target='_blank'>https://arxiv.org/pdf/2309.00082.pdf</a></span>   <span><a href='https://zchuning.github.io/repo-website/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chuning Zhu, Max Simchowitz, Siri Gadipudi, Abhishek Gupta
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.00082">RePo: Resilient Model-Based Reinforcement Learning by Regularizing Posterior Predictability</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Visual model-based RL methods typically encode image observations into low-dimensional representations in a manner that does not eliminate redundant information. This leaves them susceptible to spurious variations -- changes in task-irrelevant components such as background distractors or lighting conditions. In this paper, we propose a visual model-based RL method that learns a latent representation resilient to such spurious variations. Our training objective encourages the representation to be maximally predictive of dynamics and reward, while constraining the information flow from the observation to the latent representation. We demonstrate that this objective significantly bolsters the resilience of visual model-based RL methods to visual distractors, allowing them to operate in dynamic environments. We then show that while the learned encoder is resilient to spirious variations, it is not invariant under significant distribution shift. To address this, we propose a simple reward-free alignment procedure that enables test time adaptation of the encoder. This allows for quick adaptation to widely differing environments without having to relearn the dynamics and policy. Our effort is a step towards making model-based RL a practical and useful tool for dynamic, diverse domains. We show its effectiveness in simulation benchmarks with significant spurious variations as well as a real-world egocentric navigation task with noisy TVs in the background. Videos and code at https://zchuning.github.io/repo-website/.
<div id='section'>Paperid: <span id='pid'>171, <a href='https://arxiv.org/pdf/2308.10297.pdf' target='_blank'>https://arxiv.org/pdf/2308.10297.pdf</a></span>   <span><a href='https://github.com/koncle/DomainAdaptor' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jian Zhang, Lei Qi, Yinghuan Shi, Yang Gao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.10297">DomainAdaptor: A Novel Approach to Test-time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To deal with the domain shift between training and test samples, current methods have primarily focused on learning generalizable features during training and ignore the specificity of unseen samples that are also critical during the test. In this paper, we investigate a more challenging task that aims to adapt a trained CNN model to unseen domains during the test. To maximumly mine the information in the test data, we propose a unified method called DomainAdaptor for the test-time adaptation, which consists of an AdaMixBN module and a Generalized Entropy Minimization (GEM) loss. Specifically, AdaMixBN addresses the domain shift by adaptively fusing training and test statistics in the normalization layer via a dynamic mixture coefficient and a statistic transformation operation. To further enhance the adaptation ability of AdaMixBN, we design a GEM loss that extends the Entropy Minimization loss to better exploit the information in the test data. Extensive experiments show that DomainAdaptor consistently outperforms the state-of-the-art methods on four benchmarks. Furthermore, our method brings more remarkable improvement against existing methods on the few-data unseen domain. The code is available at https://github.com/koncle/DomainAdaptor.
<div id='section'>Paperid: <span id='pid'>172, <a href='https://arxiv.org/pdf/2308.09544.pdf' target='_blank'>https://arxiv.org/pdf/2308.09544.pdf</a></span>   <span><a href='https://github.com/fszatkowski/cl-teacher-adaptation' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Filip Szatkowski, Mateusz Pyla, Marcin PrzewiÄÅºlikowski, Sebastian Cygert, BartÅomiej Twardowski, Tomasz TrzciÅski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.09544">Adapt Your Teacher: Improving Knowledge Distillation for Exemplar-free Continual Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we investigate exemplar-free class incremental learning (CIL) with knowledge distillation (KD) as a regularization strategy, aiming to prevent forgetting. KD-based methods are successfully used in CIL, but they often struggle to regularize the model without access to exemplars of the training data from previous tasks. Our analysis reveals that this issue originates from substantial representation shifts in the teacher network when dealing with out-of-distribution data. This causes large errors in the KD loss component, leading to performance degradation in CIL models. Inspired by recent test-time adaptation methods, we introduce Teacher Adaptation (TA), a method that concurrently updates the teacher and the main models during incremental training. Our method seamlessly integrates with KD-based CIL approaches and allows for consistent enhancement of their performance across multiple exemplar-free CIL benchmarks. The source code for our method is available at https://github.com/fszatkowski/cl-teacher-adaptation.
<div id='section'>Paperid: <span id='pid'>173, <a href='https://arxiv.org/pdf/2308.06554.pdf' target='_blank'>https://arxiv.org/pdf/2308.06554.pdf</a></span>   <span><a href='https://github.com/hygenie1228/CycleAdapt_RELEASE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyeongjin Nam, Daniel Sungho Jung, Yeonguk Oh, Kyoung Mu Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.06554">Cyclic Test-Time Adaptation on Monocular Video for 3D Human Mesh Reconstruction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite recent advances in 3D human mesh reconstruction, domain gap between training and test data is still a major challenge. Several prior works tackle the domain gap problem via test-time adaptation that fine-tunes a network relying on 2D evidence (e.g., 2D human keypoints) from test images. However, the high reliance on 2D evidence during adaptation causes two major issues. First, 2D evidence induces depth ambiguity, preventing the learning of accurate 3D human geometry. Second, 2D evidence is noisy or partially non-existent during test time, and such imperfect 2D evidence leads to erroneous adaptation. To overcome the above issues, we introduce CycleAdapt, which cyclically adapts two networks: a human mesh reconstruction network (HMRNet) and a human motion denoising network (MDNet), given a test video. In our framework, to alleviate high reliance on 2D evidence, we fully supervise HMRNet with generated 3D supervision targets by MDNet. Our cyclic adaptation scheme progressively elaborates the 3D supervision targets, which compensate for imperfect 2D evidence. As a result, our CycleAdapt achieves state-of-the-art performance compared to previous test-time adaptation methods. The codes are available at https://github.com/hygenie1228/CycleAdapt_RELEASE.
<div id='section'>Paperid: <span id='pid'>174, <a href='https://arxiv.org/pdf/2308.04638.pdf' target='_blank'>https://arxiv.org/pdf/2308.04638.pdf</a></span>   <span><a href='https://github.com/csiro-robotics/GeoAdapt' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Joshua Knights, Stephen Hausler, Sridha Sridharan, Clinton Fookes, Peyman Moghadam
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.04638">GeoAdapt: Self-Supervised Test-Time Adaptation in LiDAR Place Recognition Using Geometric Priors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>LiDAR place recognition approaches based on deep learning suffer from significant performance degradation when there is a shift between the distribution of training and test datasets, often requiring re-training the networks to achieve peak performance. However, obtaining accurate ground truth data for new training data can be prohibitively expensive, especially in complex or GPS-deprived environments. To address this issue we propose GeoAdapt, which introduces a novel auxiliary classification head to generate pseudo-labels for re-training on unseen environments in a self-supervised manner. GeoAdapt uses geometric consistency as a prior to improve the robustness of our generated pseudo-labels against domain shift, improving the performance and reliability of our Test-Time Adaptation approach. Comprehensive experiments show that GeoAdapt significantly boosts place recognition performance across moderate to severe domain shifts, and is competitive with fully supervised test-time adaptation approaches. Our code is available at https://github.com/csiro-robotics/GeoAdapt.
<div id='section'>Paperid: <span id='pid'>175, <a href='https://arxiv.org/pdf/2307.15645.pdf' target='_blank'>https://arxiv.org/pdf/2307.15645.pdf</a></span>   <span><a href='https://github.com/SplinterLi/SaTTCA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhihao Li, Jiancheng Yang, Yongchao Xu, Li Zhang, Wenhui Dong, Bo Du
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.15645">Scale-aware Test-time Click Adaptation for Pulmonary Nodule and Mass Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pulmonary nodules and masses are crucial imaging features in lung cancer screening that require careful management in clinical diagnosis. Despite the success of deep learning-based medical image segmentation, the robust performance on various sizes of lesions of nodule and mass is still challenging. In this paper, we propose a multi-scale neural network with scale-aware test-time adaptation to address this challenge. Specifically, we introduce an adaptive Scale-aware Test-time Click Adaptation method based on effortlessly obtainable lesion clicks as test-time cues to enhance segmentation performance, particularly for large lesions. The proposed method can be seamlessly integrated into existing networks. Extensive experiments on both open-source and in-house datasets consistently demonstrate the effectiveness of the proposed method over some CNN and Transformer-based segmentation methods. Our code is available at https://github.com/SplinterLi/SaTTCA
<div id='section'>Paperid: <span id='pid'>176, <a href='https://arxiv.org/pdf/2307.03133.pdf' target='_blank'>https://arxiv.org/pdf/2307.03133.pdf</a></span>   <span><a href='https://github.com/yuyongcan/Benchmark-TTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yongcan Yu, Lijun Sheng, Ran He, Jian Liang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.03133">Benchmarking Test-Time Adaptation against Distribution Shifts in Image Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) is a technique aimed at enhancing the generalization performance of models by leveraging unlabeled samples solely during prediction. Given the need for robustness in neural network systems when faced with distribution shifts, numerous TTA methods have recently been proposed. However, evaluating these methods is often done under different settings, such as varying distribution shifts, backbones, and designing scenarios, leading to a lack of consistent and fair benchmarks to validate their effectiveness. To address this issue, we present a benchmark that systematically evaluates 13 prominent TTA methods and their variants on five widely used image classification datasets: CIFAR-10-C, CIFAR-100-C, ImageNet-C, DomainNet, and Office-Home. These methods encompass a wide range of adaptation scenarios (e.g. online adaptation v.s. offline adaptation, instance adaptation v.s. batch adaptation v.s. domain adaptation). Furthermore, we explore the compatibility of different TTA methods with diverse network backbones. To implement this benchmark, we have developed a unified framework in PyTorch, which allows for consistent evaluation and comparison of the TTA methods across the different datasets and network architectures. By establishing this benchmark, we aim to provide researchers and practitioners with a reliable means of assessing and comparing the effectiveness of TTA methods in improving model robustness and generalization performance. Our code is available at https://github.com/yuyongcan/Benchmark-TTA.
<div id='section'>Paperid: <span id='pid'>177, <a href='https://arxiv.org/pdf/2306.03536.pdf' target='_blank'>https://arxiv.org/pdf/2306.03536.pdf</a></span>   <span><a href='https://github.com/lins-lab/ttab' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Zhao, Yuejiang Liu, Alexandre Alahi, Tao Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.03536">On Pitfalls of Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-Time Adaptation (TTA) has recently emerged as a promising approach for tackling the robustness challenge under distribution shifts. However, the lack of consistent settings and systematic studies in prior literature hinders thorough assessments of existing methods. To address this issue, we present TTAB, a test-time adaptation benchmark that encompasses ten state-of-the-art algorithms, a diverse array of distribution shifts, and two evaluation protocols. Through extensive experiments, our benchmark reveals three common pitfalls in prior efforts. First, selecting appropriate hyper-parameters, especially for model selection, is exceedingly difficult due to online batch dependency. Second, the effectiveness of TTA varies greatly depending on the quality and properties of the model being adapted. Third, even under optimal algorithmic conditions, none of the existing methods are capable of addressing all common types of distribution shifts. Our findings underscore the need for future research in the field to conduct rigorous evaluations on a broader set of models and shifts, and to re-examine the assumptions behind the empirical success of TTA. Our code is available at \url{https://github.com/lins-lab/ttab}.
<div id='section'>Paperid: <span id='pid'>178, <a href='https://arxiv.org/pdf/2306.01981.pdf' target='_blank'>https://arxiv.org/pdf/2306.01981.pdf</a></span>   <span><a href='https://github.com/drumpt/SGEM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Changhun Kim, Joonhyung Park, Hajin Shim, Eunho Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.01981">SGEM: Test-Time Adaptation for Automatic Speech Recognition via Sequential-Level Generalized Entropy Minimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automatic speech recognition (ASR) models are frequently exposed to data distribution shifts in many real-world scenarios, leading to erroneous predictions. To tackle this issue, an existing test-time adaptation (TTA) method has recently been proposed to adapt the pre-trained ASR model on unlabeled test instances without source data. Despite decent performance gain, this work relies solely on naive greedy decoding and performs adaptation across timesteps at a frame level, which may not be optimal given the sequential nature of the model output. Motivated by this, we propose a novel TTA framework, dubbed SGEM, for general ASR models. To treat the sequential output, SGEM first exploits beam search to explore candidate output logits and selects the most plausible one. Then, it utilizes generalized entropy minimization and negative sampling as unsupervised objectives to adapt the model. SGEM achieves state-of-the-art performance for three mainstream ASR models under various domain shifts.
<div id='section'>Paperid: <span id='pid'>179, <a href='https://arxiv.org/pdf/2306.00650.pdf' target='_blank'>https://arxiv.org/pdf/2306.00650.pdf</a></span>   <span><a href='https://github.com/mariodoebler/test-time-adaptation' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Robert A. Marsden, Mario DÃ¶bler, Bin Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.00650">Universal Test-time Adaptation through Weight Ensembling, Diversity Weighting, and Prior Correction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Since distribution shifts are likely to occur during test-time and can drastically decrease the model's performance, online test-time adaptation (TTA) continues to update the model after deployment, leveraging the current test data. Clearly, a method proposed for online TTA has to perform well for all kinds of environmental conditions. By introducing the variable factors domain non-stationarity and temporal correlation, we first unfold all practically relevant settings and define the entity as universal TTA. We want to highlight that this is the first work that covers such a broad spectrum, which is indispensable for the use in practice. To tackle the problem of universal TTA, we identify and highlight several challenges a self-training based method has to deal with: 1) model bias and the occurrence of trivial solutions when performing entropy minimization on varying sequence lengths with and without multiple domain shifts, 2) loss of generalization which exacerbates the adaptation to multiple domain shifts and the occurrence of catastrophic forgetting, and 3) performance degradation due to shifts in class prior. To prevent the model from becoming biased, we leverage a dataset and model-agnostic certainty and diversity weighting. In order to maintain generalization and prevent catastrophic forgetting, we propose to continually weight-average the source and adapted model. To compensate for disparities in the class prior during test-time, we propose an adaptive prior correction scheme that reweights the model's predictions. We evaluate our approach, named ROID, on a wide range of settings, datasets, and models, setting new standards in the field of universal TTA. Code is available at: https://github.com/mariodoebler/test-time-adaptation
<div id='section'>Paperid: <span id='pid'>180, <a href='https://arxiv.org/pdf/2305.18010.pdf' target='_blank'>https://arxiv.org/pdf/2305.18010.pdf</a></span>   <span><a href='https://github.com/mzhaoshuai/RLCF' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/mzhaoshuai/RLCF' target='_blank'>  GitHub</a></span> <span><a href='https://mzhaoshuai.github.io/RLCF/,' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuai Zhao, Xiaohan Wang, Linchao Zhu, Yi Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.18010">Test-Time Adaptation with CLIP Reward for Zero-Shot Generalization in Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>One fascinating aspect of pre-trained vision-language models~(VLMs) learning under language supervision is their impressive zero-shot generalization capability. However, this ability is hindered by distribution shifts between the training and testing data. Previous test time adaptation~(TTA) methods for VLMs in zero-shot classification rely on minimizing the entropy of model outputs, tending to be stuck in incorrect model predictions. In this work, we propose TTA with feedback to rectify the model output and prevent the model from becoming blindly confident. Specifically, a CLIP model is adopted as the reward model during TTA and provides feedback for the VLM. Given a single test sample, the VLM is forced to maximize the CLIP reward between the input and sampled results from the VLM output distribution. The proposed \textit{reinforcement learning with CLIP feedback~(RLCF)} framework is highly flexible and universal. Beyond the classification task, with task-specific sampling strategies and a proper reward baseline choice, RLCF can be easily extended to not only discrimination tasks like retrieval but also generalization tasks like image captioning, improving the zero-shot generalization capacity of VLMs. According to the characteristics of these VL tasks, we build different fully TTA pipelines with RLCF to improve the zero-shot generalization ability of various VLMs. Extensive experiments along with promising empirical results demonstrate the effectiveness of RLCF. The code is available at https://github.com/mzhaoshuai/RLCF.
<div id='section'>Paperid: <span id='pid'>181, <a href='https://arxiv.org/pdf/2305.13284.pdf' target='_blank'>https://arxiv.org/pdf/2305.13284.pdf</a></span>   <span><a href='https://github.com/Rakshith-2905/SiSTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kowshik Thopalli, Rakshith Subramanyam, Pavan Turaga, Jayaraman J. Thiagarajan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.13284">Target-Aware Generative Augmentations for Single-Shot Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we address the problem of adapting models from a source domain to a target domain, a task that has become increasingly important due to the brittle generalization of deep neural networks. While several test-time adaptation techniques have emerged, they typically rely on synthetic toolbox data augmentations in cases of limited target data availability. We consider the challenging setting of single-shot adaptation and explore the design of augmentation strategies. We argue that augmentations utilized by existing methods are insufficient to handle large distribution shifts, and hence propose a new approach SiSTA, which first fine-tunes a generative model from the source domain using a single-shot target, and then employs novel sampling strategies for curating synthetic target data. Using experiments on a variety of benchmarks, distribution shifts and image corruptions, we find that SiSTA produces significantly improved generalization over existing baselines in face attribute detection and multi-class object recognition. Furthermore, SiSTA performs competitively to models obtained by training on larger target datasets. Our codes can be accessed at https://github.com/Rakshith-2905/SiSTA.
<div id='section'>Paperid: <span id='pid'>182, <a href='https://arxiv.org/pdf/2304.12566.pdf' target='_blank'>https://arxiv.org/pdf/2304.12566.pdf</a></span>   <span><a href='https://github.com/yfzhang114/AdaNPC' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yi-Fan Zhang, Xue Wang, Kexin Jin, Kun Yuan, Zhang Zhang, Liang Wang, Rong Jin, Tieniu Tan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.12566">AdaNPC: Exploring Non-Parametric Classifier for Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many recent machine learning tasks focus to develop models that can generalize to unseen distributions. Domain generalization (DG) has become one of the key topics in various fields. Several literatures show that DG can be arbitrarily hard without exploiting target domain information. To address this issue, test-time adaptive (TTA) methods are proposed. Existing TTA methods require offline target data or extra sophisticated optimization procedures during the inference stage. In this work, we adopt Non-Parametric Classifier to perform the test-time Adaptation (AdaNPC). In particular, we construct a memory that contains the feature and label pairs from training domains. During inference, given a test instance, AdaNPC first recalls K closed samples from the memory to vote for the prediction, and then the test feature and predicted label are added to the memory. In this way, the sample distribution in the memory can be gradually changed from the training distribution towards the test distribution with very little extra computation cost. We theoretically justify the rationality behind the proposed method. Besides, we test our model on extensive numerical experiments. AdaNPC significantly outperforms competitive baselines on various DG benchmarks. In particular, when the adaptation target is a series of domains, the adaptation accuracy of AdaNPC is 50% higher than advanced TTA methods. The code is available at https://github.com/yfzhang114/AdaNPC.
<div id='section'>Paperid: <span id='pid'>183, <a href='https://arxiv.org/pdf/2304.04494.pdf' target='_blank'>https://arxiv.org/pdf/2304.04494.pdf</a></span>   <span><a href='https://github.com/liangchen527/ITTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Liang Chen, Yong Zhang, Yibing Song, Ying Shan, Lingqiao Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.04494">Improved Test-Time Adaptation for Domain Generalization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The main challenge in domain generalization (DG) is to handle the distribution shift problem that lies between the training and test data. Recent studies suggest that test-time training (TTT), which adapts the learned model with test data, might be a promising solution to the problem. Generally, a TTT strategy hinges its performance on two main factors: selecting an appropriate auxiliary TTT task for updating and identifying reliable parameters to update during the test phase. Both previous arts and our experiments indicate that TTT may not improve but be detrimental to the learned model if those two factors are not properly considered. This work addresses those two factors by proposing an Improved Test-Time Adaptation (ITTA) method. First, instead of heuristically defining an auxiliary objective, we propose a learnable consistency loss for the TTT task, which contains learnable parameters that can be adjusted toward better alignment between our TTT task and the main prediction task. Second, we introduce additional adaptive parameters for the trained model, and we suggest only updating the adaptive parameters during the test phase. Through extensive experiments, we show that the proposed two strategies are beneficial for the learned model (see Figure 1), and ITTA could achieve superior performance to the current state-of-the-art methods on several DG benchmarks. Code is available at https://github.com/liangchen527/ITTA.
<div id='section'>Paperid: <span id='pid'>184, <a href='https://arxiv.org/pdf/2303.15361.pdf' target='_blank'>https://arxiv.org/pdf/2303.15361.pdf</a></span>   <span><a href='https://github.com/tim-learn/awesome-test-time-adaptation' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/tim-learn/awesome-test-time-adaptation' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jian Liang, Ran He, Tieniu Tan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.15361">A Comprehensive Survey on Test-Time Adaptation under Distribution Shifts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning methods strive to acquire a robust model during the training process that can effectively generalize to test samples, even in the presence of distribution shifts. However, these methods often suffer from performance degradation due to unknown test distributions. Test-time adaptation (TTA), an emerging paradigm, has the potential to adapt a pre-trained model to unlabeled data during testing, before making predictions. Recent progress in this paradigm has highlighted the significant benefits of using unlabeled data to train self-adapted models prior to inference. In this survey, we categorize TTA into several distinct groups based on the form of test data, namely, test-time domain adaptation, test-time batch adaptation, and online test-time adaptation. For each category, we provide a comprehensive taxonomy of advanced algorithms and discuss various learning scenarios. Furthermore, we analyze relevant applications of TTA and discuss open challenges and promising areas for future research. For a comprehensive list of TTA methods, kindly refer to \url{https://github.com/tim-learn/awesome-test-time-adaptation}.
<div id='section'>Paperid: <span id='pid'>185, <a href='https://arxiv.org/pdf/2303.13899.pdf' target='_blank'>https://arxiv.org/pdf/2303.13899.pdf</a></span>   <span><a href='https://github.com/BIT-DA/RoTTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Longhui Yuan, Binhui Xie, Shuang Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.13899">Robust Test-Time Adaptation in Dynamic Scenarios</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) intends to adapt the pretrained model to test distributions with only unlabeled test data streams. Most of the previous TTA methods have achieved great success on simple test data streams such as independently sampled data from single or multiple distributions. However, these attempts may fail in dynamic scenarios of real-world applications like autonomous driving, where the environments gradually change and the test data is sampled correlatively over time. In this work, we explore such practical test data streams to deploy the model on the fly, namely practical test-time adaptation (PTTA). To do so, we elaborate a Robust Test-Time Adaptation (RoTTA) method against the complex data stream in PTTA. More specifically, we present a robust batch normalization scheme to estimate the normalization statistics. Meanwhile, a memory bank is utilized to sample category-balanced data with consideration of timeliness and uncertainty. Further, to stabilize the training procedure, we develop a time-aware reweighting strategy with a teacher-student model. Extensive experiments prove that RoTTA enables continual testtime adaptation on the correlatively sampled data streams. Our method is easy to implement, making it a good choice for rapid deployment. The code is publicly available at https://github.com/BIT-DA/RoTTA
<div id='section'>Paperid: <span id='pid'>186, <a href='https://arxiv.org/pdf/2303.10902.pdf' target='_blank'>https://arxiv.org/pdf/2303.10902.pdf</a></span>   <span><a href='https://github.com/SakurajimaMaiii/TSD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuai Wang, Daoan Zhang, Zipei Yan, Jianguo Zhang, Rui Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.10902">Feature Alignment and Uniformity for Test Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test time adaptation (TTA) aims to adapt deep neural networks when receiving out of distribution test domain samples. In this setting, the model can only access online unlabeled test samples and pre-trained models on the training domains. We first address TTA as a feature revision problem due to the domain gap between source domains and target domains. After that, we follow the two measurements alignment and uniformity to discuss the test time feature revision. For test time feature uniformity, we propose a test time self-distillation strategy to guarantee the consistency of uniformity between representations of the current batch and all the previous batches. For test time feature alignment, we propose a memorized spatial local clustering strategy to align the representations among the neighborhood samples for the upcoming batch. To deal with the common noisy label problem, we propound the entropy and consistency filters to select and drop the possible noisy labels. To prove the scalability and efficacy of our method, we conduct experiments on four domain generalization benchmarks and four medical image segmentation tasks with various backbones. Experiment results show that our method not only improves baseline stably but also outperforms existing state-of-the-art test time adaptation methods. Code is available at \href{https://github.com/SakurajimaMaiii/TSD}{https://github.com/SakurajimaMaiii/TSD}.
<div id='section'>Paperid: <span id='pid'>187, <a href='https://arxiv.org/pdf/2303.01433.pdf' target='_blank'>https://arxiv.org/pdf/2303.01433.pdf</a></span>   <span><a href='https://github.com/DebugML/sqrl' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Aaditya Naik, Yinjun Wu, Mayur Naik, Eric Wong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.01433">Do Machine Learning Models Learn Statistical Rules Inferred from Data?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning models can make critical errors that are easily hidden within vast amounts of data. Such errors often run counter to rules based on human intuition. However, rules based on human knowledge are challenging to scale or to even formalize. We thereby seek to infer statistical rules from the data and quantify the extent to which a model has learned them. We propose a framework SQRL that integrates logic-based methods with statistical inference to derive these rules from a model's training data without supervision. We further show how to adapt models at test time to reduce rule violations and produce more coherent predictions. SQRL generates up to 300K rules over datasets from vision, tabular, and language settings. We uncover up to 158K violations of those rules by state-of-the-art models for classification, object detection, and data imputation. Test-time adaptation reduces these violations by up to 68.7% with relative performance improvement up to 32%. SQRL is available at https://github.com/DebugML/sqrl.
<div id='section'>Paperid: <span id='pid'>188, <a href='https://arxiv.org/pdf/2212.09713.pdf' target='_blank'>https://arxiv.org/pdf/2212.09713.pdf</a></span>   <span><a href='https://github.com/dhanajitb/petal' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Dhanajit Brahma, Piyush Rai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.09713">A Probabilistic Framework for Lifelong Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) is the problem of updating a pre-trained source model at inference time given test input(s) from a different target domain. Most existing TTA approaches assume the setting in which the target domain is stationary, i.e., all the test inputs come from a single target domain. However, in many practical settings, the test input distribution might exhibit a lifelong/continual shift over time. Moreover, existing TTA approaches also lack the ability to provide reliable uncertainty estimates, which is crucial when distribution shifts occur between the source and target domain. To address these issues, we present PETAL (Probabilistic lifElong Test-time Adaptation with seLf-training prior), which solves lifelong TTA using a probabilistic approach, and naturally results in (1) a student-teacher framework, where the teacher model is an exponential moving average of the student model, and (2) regularizing the model updates at inference time using the source model as a regularizer. To prevent model drift in the lifelong/continual TTA setting, we also propose a data-driven parameter restoration technique which contributes to reducing the error accumulation and maintaining the knowledge of recent domains by restoring only the irrelevant parameters. In terms of predictive error rate as well as uncertainty based metrics such as Brier score and negative log-likelihood, our method achieves better results than the current state-of-the-art for online lifelong test-time adaptation across various benchmarks, such as CIFAR-10C, CIFAR-100C, ImageNetC, and ImageNet3DCC datasets. The source code for our approach is accessible at https://github.com/dhanajitb/petal.
<div id='section'>Paperid: <span id='pid'>189, <a href='https://arxiv.org/pdf/2211.15393.pdf' target='_blank'>https://arxiv.org/pdf/2211.15393.pdf</a></span>   <span><a href='https://github.com/wlin-at/ViTTA' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei Lin, Muhammad Jehanzeb Mirza, Mateusz Kozinski, Horst Possegger, Hilde Kuehne, Horst Bischof
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.15393">Video Test-Time Adaptation for Action Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Although action recognition systems can achieve top performance when evaluated on in-distribution test points, they are vulnerable to unanticipated distribution shifts in test data. However, test-time adaptation of video action recognition models against common distribution shifts has so far not been demonstrated. We propose to address this problem with an approach tailored to spatio-temporal models that is capable of adaptation on a single video sample at a step. It consists in a feature distribution alignment technique that aligns online estimates of test set statistics towards the training statistics. We further enforce prediction consistency over temporally augmented views of the same test video sample. Evaluations on three benchmark action recognition datasets show that our proposed technique is architecture-agnostic and able to significantly boost the performance on both, the state of the art convolutional architecture TANet and the Video Swin Transformer. Our proposed method demonstrates a substantial performance gain over existing test-time adaptation approaches in both evaluations of a single distribution shift and the challenging case of random distribution shifts. Code will be available at \url{https://github.com/wlin-at/ViTTA}.
<div id='section'>Paperid: <span id='pid'>190, <a href='https://arxiv.org/pdf/2210.03885.pdf' target='_blank'>https://arxiv.org/pdf/2210.03885.pdf</a></span>   <span><a href='https://github.com/n3il666/Meta-DMoE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tao Zhong, Zhixiang Chi, Li Gu, Yang Wang, Yuanhao Yu, Jin Tang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.03885">Meta-DMoE: Adapting to Domain Shift by Meta-Distillation from Mixture-of-Experts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we tackle the problem of domain shift. Most existing methods perform training on multiple source domains using a single model, and the same trained model is used on all unseen target domains. Such solutions are sub-optimal as each target domain exhibits its own specialty, which is not adapted. Furthermore, expecting single-model training to learn extensive knowledge from multiple source domains is counterintuitive. The model is more biased toward learning only domain-invariant features and may result in negative knowledge transfer. In this work, we propose a novel framework for unsupervised test-time adaptation, which is formulated as a knowledge distillation process to address domain shift. Specifically, we incorporate Mixture-of-Experts (MoE) as teachers, where each expert is separately trained on different source domains to maximize their specialty. Given a test-time target domain, a small set of unlabeled data is sampled to query the knowledge from MoE. As the source domains are correlated to the target domains, a transformer-based aggregator then combines the domain knowledge by examining the interconnection among them. The output is treated as a supervision signal to adapt a student prediction network toward the target domain. We further employ meta-learning to enforce the aggregator to distill positive knowledge and the student network to achieve fast adaptation. Extensive experiments demonstrate that the proposed method outperforms the state-of-the-art and validates the effectiveness of each proposed component. Our code is available at https://github.com/n3il666/Meta-DMoE.
<div id='section'>Paperid: <span id='pid'>191, <a href='https://arxiv.org/pdf/2208.08767.pdf' target='_blank'>https://arxiv.org/pdf/2208.08767.pdf</a></span>   <span><a href='https://github.com/tommiekerssies/Evaluating-Continual-Test-Time-Adaptation-for-Contextual-and-Semantic-Domain-Shifts' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tommie Kerssies, Mert KÄ±lÄ±Ã§kaya, Joaquin Vanschoren
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2208.08767">Evaluating Continual Test-Time Adaptation for Contextual and Semantic Domain Shifts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, our goal is to adapt a pre-trained convolutional neural network to domain shifts at test time. We do so continually with the incoming stream of test batches, without labels. The existing literature mostly operates on artificial shifts obtained via adversarial perturbations of a test image. Motivated by this, we evaluate the state of the art on two realistic and challenging sources of domain shifts, namely contextual and semantic shifts. Contextual shifts correspond to the environment types, for example, a model pre-trained on indoor context has to adapt to the outdoor context on CORe-50. Semantic shifts correspond to the capture types, for example a model pre-trained on natural images has to adapt to cliparts, sketches, and paintings on DomainNet. We include in our analysis recent techniques such as Prediction-Time Batch Normalization (BN), Test Entropy Minimization (TENT) and Continual Test-Time Adaptation (CoTTA). Our findings are three-fold: i) Test-time adaptation methods perform better and forget less on contextual shifts compared to semantic shifts, ii) TENT outperforms other methods on short-term adaptation, whereas CoTTA outpeforms other methods on long-term adaptation, iii) BN is most reliable and robust. Our code is available at https://github.com/tommiekerssies/Evaluating-Continual-Test-Time-Adaptation-for-Contextual-and-Semantic-Domain-Shifts.
<div id='section'>Paperid: <span id='pid'>192, <a href='https://arxiv.org/pdf/2208.05117.pdf' target='_blank'>https://arxiv.org/pdf/2208.05117.pdf</a></span>   <span><a href='https://github.com/TaesikGong/NOTE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Taesik Gong, Jongheon Jeong, Taewon Kim, Yewon Kim, Jinwoo Shin, Sung-Ju Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2208.05117">NOTE: Robust Continual Test-time Adaptation Against Temporal Correlation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) is an emerging paradigm that addresses distributional shifts between training and testing phases without additional data acquisition or labeling cost; only unlabeled test data streams are used for continual model adaptation. Previous TTA schemes assume that the test samples are independent and identically distributed (i.i.d.), even though they are often temporally correlated (non-i.i.d.) in application scenarios, e.g., autonomous driving. We discover that most existing TTA methods fail dramatically under such scenarios. Motivated by this, we present a new test-time adaptation scheme that is robust against non-i.i.d. test data streams. Our novelty is mainly two-fold: (a) Instance-Aware Batch Normalization (IABN) that corrects normalization for out-of-distribution samples, and (b) Prediction-balanced Reservoir Sampling (PBRS) that simulates i.i.d. data stream from non-i.i.d. stream in a class-balanced manner. Our evaluation with various datasets, including real-world non-i.i.d. streams, demonstrates that the proposed robust TTA not only outperforms state-of-the-art TTA algorithms in the non-i.i.d. setting, but also achieves comparable performance to those algorithms under the i.i.d. assumption. Code is available at https://github.com/TaesikGong/NOTE.
<div id='section'>Paperid: <span id='pid'>193, <a href='https://arxiv.org/pdf/2206.07240.pdf' target='_blank'>https://arxiv.org/pdf/2206.07240.pdf</a></span>   <span><a href='https://saynaebrahimi.github.io/DocTTA.html' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Sayna Ebrahimi, Sercan O. Arik, Tomas Pfister
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.07240">Test-Time Adaptation for Visual Document Understanding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>For visual document understanding (VDU), self-supervised pretraining has been shown to successfully generate transferable representations, yet, effective adaptation of such representations to distribution shifts at test-time remains to be an unexplored area. We propose DocTTA, a novel test-time adaptation method for documents, that does source-free domain adaptation using unlabeled target document data. DocTTA leverages cross-modality self-supervised learning via masked visual language modeling, as well as pseudo labeling to adapt models learned on a \textit{source} domain to an unlabeled \textit{target} domain at test time. We introduce new benchmarks using existing public datasets for various VDU tasks, including entity recognition, key-value extraction, and document visual question answering. DocTTA shows significant improvements on these compared to the source model performance, up to 1.89\% in (F1 score), 3.43\% (F1 score), and 17.68\% (ANLS score), respectively. Our benchmark datasets are available at \url{https://saynaebrahimi.github.io/DocTTA.html}.
<div id='section'>Paperid: <span id='pid'>194, <a href='https://arxiv.org/pdf/2410.09398.pdf' target='_blank'>https://arxiv.org/pdf/2410.09398.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yige Yuan, Bingbing Xu, Teng Xiao, Liang Hou, Fei Sun, Huawei Shen, Xueqi Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.09398">MITA: Bridging the Gap between Model and Data for Test-time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-Time Adaptation (TTA) has emerged as a promising paradigm for enhancing the generalizability of models. However, existing mainstream TTA methods, predominantly operating at batch level, often exhibit suboptimal performance in complex real-world scenarios, particularly when confronting outliers or mixed distributions. This phenomenon stems from a pronounced over-reliance on statistical patterns over the distinct characteristics of individual instances, resulting in a divergence between the distribution captured by the model and data characteristics. To address this challenge, we propose Meet-In-The-Middle based Test-Time Adaptation ($\textbf{MITA}$), which introduces energy-based optimization to encourage mutual adaptation of the model and data from opposing directions, thereby meeting in the middle. MITA pioneers a significant departure from traditional approaches that focus solely on aligning the model to the data, facilitating a more effective bridging of the gap between model's distribution and data characteristics. Comprehensive experiments with MITA across three distinct scenarios (Outlier, Mixture, and Pure) demonstrate its superior performance over SOTA methods, highlighting its potential to significantly enhance generalizability in practical applications.
<div id='section'>Paperid: <span id='pid'>195, <a href='https://arxiv.org/pdf/2403.17735.pdf' target='_blank'>https://arxiv.org/pdf/2403.17735.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiang Tao, Mingqing Zhang, Qiang Liu, Shu Wu, Liang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.17735">Out-of-distribution Rumor Detection via Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Due to the rapid spread of rumors on social media, rumor detection has become an extremely important challenge. Existing methods for rumor detection have achieved good performance, as they have collected enough corpus from the same data distribution for model training. However, significant distribution shifts between the training data and real-world test data occur due to differences in news topics, social media platforms, languages and the variance in propagation scale caused by news popularity. This leads to a substantial decline in the performance of these existing methods in Out-Of-Distribution (OOD) situations. To address this problem, we propose a simple and efficient method named Test-time Adaptation for Rumor Detection under distribution shifts (TARD). This method models the propagation of news in the form of a propagation graph, and builds propagation graph test-time adaptation framework, enhancing the model's adaptability and robustness when facing OOD problems. Extensive experiments conducted on two group datasets collected from real-world social platforms demonstrate that our framework outperforms the state-of-the-art methods in performance.
<div id='section'>Paperid: <span id='pid'>196, <a href='https://arxiv.org/pdf/2409.01341.pdf' target='_blank'>https://arxiv.org/pdf/2409.01341.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Siqi Luo, Yi Xin, Yuntao Du, Zhongwei Wan, Tao Tan, Guangtao Zhai, Xiaohong Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.01341">Enhancing Test Time Adaptation with Few-shot Guidance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks often encounter significant performance drops while facing with domain shifts between training (source) and test (target) data. To address this issue, Test Time Adaptation (TTA) methods have been proposed to adapt pre-trained source model to handle out-of-distribution streaming target data. Although these methods offer some relief, they lack a reliable mechanism for domain shift correction, which can often be erratic in real-world applications. In response, we develop Few-Shot Test Time Adaptation (FS-TTA), a novel and practical setting that utilizes a few-shot support set on top of TTA. Adhering to the principle of few inputs, big gains, FS-TTA reduces blind exploration in unseen target domains. Furthermore, we propose a two-stage framework to tackle FS-TTA, including (i) fine-tuning the pre-trained source model with few-shot support set, along with using feature diversity augmentation module to avoid overfitting, (ii) implementing test time adaptation based on prototype memory bank guidance to produce high quality pseudo-label for model adaptation. Through extensive experiments on three cross-domain classification benchmarks, we demonstrate the superior performance and reliability of our FS-TTA and framework.
<div id='section'>Paperid: <span id='pid'>197, <a href='https://arxiv.org/pdf/2403.06461.pdf' target='_blank'>https://arxiv.org/pdf/2403.06461.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haozhi Cao, Yuecong Xu, Pengyu Yin, Xingyu Ji, Shenghai Yuan, Jianfei Yang, Lihua Xie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.06461">Interactive Test-Time Adaptation with Reliable Spatial-Temporal Voxels for Multi-Modal Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-modal test-time adaptation (MM-TTA) adapts models to an unlabeled target domain by leveraging the complementary multi-modal inputs in an online manner. While previous MM-TTA methods for 3D segmentation offer a promising solution by leveraging self-refinement per frame, they suffer from two major limitations: 1) unstable frame-wise predictions caused by temporal inconsistency, and 2) consistently incorrect predictions that violate the assumption of reliable modality guidance. To address these limitations, this work introduces a comprehensive two-fold framework. Firstly, building upon our previous work ReLiable Spatial-temporal Voxels (Latte), we propose Latte++ that better suppresses the unstable frame-wise predictions with more informative geometric correspondences. Instead of utilizing a universal sliding window, Latte++ employs multi-window aggregation to capture more reliable correspondences to better evaluate the local prediction consistency of different semantic categories. Secondly, to tackle the consistently incorrect predictions, we propose Interactive Test-Time Adaptation (ITTA), a flexible add-on to empower effortless human feedback with existing MM-TTA methods. ITTA introduces a novel human-in-the-loop approach that efficiently integrates minimal human feedback through interactive segmentation, requiring only simple point clicks and bounding box annotations. Instead of using independent interactive networks, ITTA employs a lightweight promptable branch with a momentum gradient module to capture and reuse knowledge from scarce human feedback during online inference. Extensive experiments across five MM-TTA benchmarks demonstrate that ITTA achieves consistent and notable improvements with robust performance gains for target classes of interest in challenging imbalanced scenarios, while Latte++ provides complementary benefits for temporal stability.
<div id='section'>Paperid: <span id='pid'>198, <a href='https://arxiv.org/pdf/2403.06461.pdf' target='_blank'>https://arxiv.org/pdf/2403.06461.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haozhi Cao, Yuecong Xu, Pengyu Yin, Xingyu Ji, Shenghai Yuan, Jianfei Yang, Lihua Xie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.06461">Interactive Test-Time Adaptation with Reliable Spatial-Temporal Voxels for Multi-Modal Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-modal test-time adaptation (MM-TTA) adapts models to an unlabeled target domain by leveraging the complementary multi-modal inputs in an online manner. While previous MM-TTA methods for 3D segmentation offer a promising solution by leveraging self-refinement per frame, they suffer from two major limitations: 1) unstable frame-wise predictions caused by temporal inconsistency, and 2) consistently incorrect predictions that violate the assumption of reliable modality guidance. To address these limitations, this work introduces a comprehensive two-fold framework. Firstly, building upon our previous work ReLiable Spatial-temporal Voxels (Latte), we propose Latte++ that better suppresses the unstable frame-wise predictions with more informative geometric correspondences. Instead of utilizing a universal sliding window, Latte++ employs multi-window aggregation to capture more reliable correspondences to better evaluate the local prediction consistency of different semantic categories. Secondly, to tackle the consistently incorrect predictions, we propose Interactive Test-Time Adaptation (ITTA), a flexible add-on to empower effortless human feedback with existing MM-TTA methods. ITTA introduces a novel human-in-the-loop approach that efficiently integrates minimal human feedback through interactive segmentation, requiring only simple point clicks and bounding box annotations. Instead of using independent interactive networks, ITTA employs a lightweight promptable branch with a momentum gradient module to capture and reuse knowledge from scarce human feedback during online inference. Extensive experiments across five MM-TTA benchmarks demonstrate that ITTA achieves consistent and notable improvements with robust performance gains for target classes of interest in challenging imbalanced scenarios, while Latte++ provides complementary benefits for temporal stability.
<div id='section'>Paperid: <span id='pid'>199, <a href='https://arxiv.org/pdf/2303.10457.pdf' target='_blank'>https://arxiv.org/pdf/2303.10457.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haozhi Cao, Yuecong Xu, Jianfei Yang, Pengyu Yin, Shenghai Yuan, Lihua Xie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.10457">Multi-Modal Continual Test-Time Adaptation for 3D Semantic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual Test-Time Adaptation (CTTA) generalizes conventional Test-Time Adaptation (TTA) by assuming that the target domain is dynamic over time rather than stationary. In this paper, we explore Multi-Modal Continual Test-Time Adaptation (MM-CTTA) as a new extension of CTTA for 3D semantic segmentation. The key to MM-CTTA is to adaptively attend to the reliable modality while avoiding catastrophic forgetting during continual domain shifts, which is out of the capability of previous TTA or CTTA methods. To fulfill this gap, we propose an MM-CTTA method called Continual Cross-Modal Adaptive Clustering (CoMAC) that addresses this task from two perspectives. On one hand, we propose an adaptive dual-stage mechanism to generate reliable cross-modal predictions by attending to the reliable modality based on the class-wise feature-centroid distance in the latent space. On the other hand, to perform test-time adaptation without catastrophic forgetting, we design class-wise momentum queues that capture confident target features for adaptation while stochastically restoring pseudo-source features to revisit source knowledge. We further introduce two new benchmarks to facilitate the exploration of MM-CTTA in the future. Our experimental results show that our method achieves state-of-the-art performance on both benchmarks.
<div id='section'>Paperid: <span id='pid'>200, <a href='https://arxiv.org/pdf/2410.15430.pdf' target='_blank'>https://arxiv.org/pdf/2410.15430.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Taolin Zhang, Jinpeng Wang, Hang Guo, Tao Dai, Bin Chen, Shu-Tao Xia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.15430">BoostAdapter: Improving Vision-Language Test-Time Adaptation via Regional Bootstrapping</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Adaptation of pretrained vision-language models such as CLIP to various downstream tasks have raised great interest in recent researches. Previous works have proposed a variety of test-time adaptation (TTA) methods to achieve strong generalization without any knowledge of the target domain. However, existing training-required TTA approaches like TPT necessitate entropy minimization that involves large computational overhead, while training-free methods like TDA overlook the potential for information mining from the test samples themselves. In this paper, we break down the design of existing popular training-required and training-free TTA methods and bridge the gap between them within our framework. Specifically, we maintain a light-weight key-value memory for feature retrieval from instance-agnostic historical samples and instance-aware boosting samples. The historical samples are filtered from the testing data stream and serve to extract useful information from the target distribution, while the boosting samples are drawn from regional bootstrapping and capture the knowledge of the test sample itself. We theoretically justify the rationality behind our method and empirically verify its effectiveness on both the out-of-distribution and the cross-domain datasets, showcasing its applicability in real-world situations.
<div id='section'>Paperid: <span id='pid'>201, <a href='https://arxiv.org/pdf/2312.12480.pdf' target='_blank'>https://arxiv.org/pdf/2312.12480.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaming Liu, Ran Xu, Senqiao Yang, Renrui Zhang, Qizhe Zhang, Zehui Chen, Yandong Guo, Shanghang Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.12480">Continual-MAE: Adaptive Distribution Masked Autoencoders for Continual Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual Test-Time Adaptation (CTTA) is proposed to migrate a source pre-trained model to continually changing target distributions, addressing real-world dynamism. Existing CTTA methods mainly rely on entropy minimization or teacher-student pseudo-labeling schemes for knowledge extraction in unlabeled target domains. However, dynamic data distributions cause miscalibrated predictions and noisy pseudo-labels in existing self-supervised learning methods, hindering the effective mitigation of error accumulation and catastrophic forgetting problems during the continual adaptation process. To tackle these issues, we propose a continual self-supervised method, Adaptive Distribution Masked Autoencoders (ADMA), which enhances the extraction of target domain knowledge while mitigating the accumulation of distribution shifts. Specifically, we propose a Distribution-aware Masking (DaM) mechanism to adaptively sample masked positions, followed by establishing consistency constraints between the masked target samples and the original target samples. Additionally, for masked tokens, we utilize an efficient decoder to reconstruct a hand-crafted feature descriptor (e.g., Histograms of Oriented Gradients), leveraging its invariant properties to boost task-relevant representations. Through conducting extensive experiments on four widely recognized benchmarks, our proposed method attains state-of-the-art performance in both classification and segmentation CTTA tasks. Our project page: https://sites.google.com/view/continual-mae/home.
<div id='section'>Paperid: <span id='pid'>202, <a href='https://arxiv.org/pdf/2309.13604.pdf' target='_blank'>https://arxiv.org/pdf/2309.13604.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiayi Ni, Senqiao Yang, Ran Xu, Jiaming Liu, Xiaoqi Li, Wenyu Jiao, Zehui Chen, Yi Liu, Shanghang Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.13604">Distribution-Aware Continual Test-Time Adaptation for Semantic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Since autonomous driving systems usually face dynamic and ever-changing environments, continual test-time adaptation (CTTA) has been proposed as a strategy for transferring deployed models to continually changing target domains. However, the pursuit of long-term adaptation often introduces catastrophic forgetting and error accumulation problems, which impede the practical implementation of CTTA in the real world. Recently, existing CTTA methods mainly focus on utilizing a majority of parameters to fit target domain knowledge through self-training. Unfortunately, these approaches often amplify the challenge of error accumulation due to noisy pseudo-labels, and pose practical limitations stemming from the heavy computational costs associated with entire model updates. In this paper, we propose a distribution-aware tuning (DAT) method to make the semantic segmentation CTTA efficient and practical in real-world applications. DAT adaptively selects and updates two small groups of trainable parameters based on data distribution during the continual adaptation process, including domain-specific parameters (DSP) and task-relevant parameters (TRP). Specifically, DSP exhibits sensitivity to outputs with substantial distribution shifts, effectively mitigating the problem of error accumulation. In contrast, TRP are allocated to positions that are responsive to outputs with minor distribution shifts, which are fine-tuned to avoid the catastrophic forgetting problem. In addition, since CTTA is a temporal task, we introduce the Parameter Accumulation Update (PAU) strategy to collect the updated DSP and TRP in target domain sequences. We conduct extensive experiments on two widely-used semantic segmentation CTTA benchmarks, achieving promising performance compared to previous state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>203, <a href='https://arxiv.org/pdf/2306.04344.pdf' target='_blank'>https://arxiv.org/pdf/2306.04344.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaming Liu, Senqiao Yang, Peidong Jia, Renrui Zhang, Ming Lu, Yandong Guo, Wei Xue, Shanghang Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.04344">ViDA: Homeostatic Visual Domain Adapter for Continual Test Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Since real-world machine systems are running in non-stationary environments, Continual Test-Time Adaptation (CTTA) task is proposed to adapt the pre-trained model to continually changing target domains. Recently, existing methods mainly focus on model-based adaptation, which aims to leverage a self-training manner to extract the target domain knowledge. However, pseudo labels can be noisy and the updated model parameters are unreliable under dynamic data distributions, leading to error accumulation and catastrophic forgetting in the continual adaptation process. To tackle these challenges and maintain the model plasticity, we design a Visual Domain Adapter (ViDA) for CTTA, explicitly handling both domain-specific and domain-shared knowledge. Specifically, we first comprehensively explore the different domain representations of the adapters with trainable high-rank or low-rank embedding spaces. Then we inject ViDAs into the pre-trained model, which leverages high-rank and low-rank features to adapt the current domain distribution and maintain the continual domain-shared knowledge, respectively. To exploit the low-rank and high-rank ViDAs more effectively, we further propose a Homeostatic Knowledge Allotment (HKA) strategy, which adaptively combines different knowledge from each ViDA. Extensive experiments conducted on four widely used benchmarks demonstrate that our proposed method achieves state-of-the-art performance in both classification and segmentation CTTA tasks. Note that, our method can be regarded as a novel transfer paradigm for large-scale models, delivering promising results in adaptation to continually changing distributions. Project page: https://sites.google.com/view/iclr2024-vida/home.
<div id='section'>Paperid: <span id='pid'>204, <a href='https://arxiv.org/pdf/2303.09792.pdf' target='_blank'>https://arxiv.org/pdf/2303.09792.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Senqiao Yang, Jiarui Wu, Jiaming Liu, Xiaoqi Li, Qizhe Zhang, Mingjie Pan, Yulu Gan, Zehui Chen, Shanghang Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.09792">Exploring Sparse Visual Prompt for Domain Adaptive Dense Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The visual prompts have provided an efficient manner in addressing visual cross-domain problems. In previous works, Visual Domain Prompt (VDP) first introduces domain prompts to tackle the classification Test-Time Adaptation (TTA) problem by warping image-level prompts on the input and fine-tuning prompts for each target domain. However, since the image-level prompts mask out continuous spatial details in the prompt-allocated region, it will suffer from inaccurate contextual information and limited domain knowledge extraction, particularly when dealing with dense prediction TTA problems. To overcome these challenges, we propose a novel Sparse Visual Domain Prompts (SVDP) approach, which holds minimal trainable parameters (e.g., 0.1\%) in the image-level prompt and reserves more spatial information of the input. To better apply SVDP in extracting domain-specific knowledge, we introduce the Domain Prompt Placement (DPP) method to adaptively allocates trainable parameters of SVDP on the pixels with large distribution shifts. Furthermore, recognizing that each target domain sample exhibits a unique domain shift, we design Domain Prompt Updating (DPU) strategy to optimize prompt parameters differently for each sample, facilitating efficient adaptation to the target domain. Extensive experiments were conducted on widely-used TTA and continual TTA benchmarks, and our proposed method achieves state-of-the-art performance in both semantic segmentation and depth estimation tasks.
<div id='section'>Paperid: <span id='pid'>205, <a href='https://arxiv.org/pdf/2505.17434.pdf' target='_blank'>https://arxiv.org/pdf/2505.17434.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guanzhou Lan, Yuqi Yang, Anup Teejo Mathew, Feiping Nie, Rong Wang, Xuelong Li, Federico Renda, Bin Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.17434">Dynamic Manipulation of Deformable Objects in 3D: Simulation, Benchmark and Learning Strategy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Goal-conditioned dynamic manipulation is inherently challenging due to complex system dynamics and stringent task constraints, particularly in deformable object scenarios characterized by high degrees of freedom and underactuation. Prior methods often simplify the problem to low-speed or 2D settings, limiting their applicability to real-world 3D tasks. In this work, we explore 3D goal-conditioned rope manipulation as a representative challenge. To mitigate data scarcity, we introduce a novel simulation framework and benchmark grounded in reduced-order dynamics, which enables compact state representation and facilitates efficient policy learning. Building on this, we propose Dynamics Informed Diffusion Policy (DIDP), a framework that integrates imitation pretraining with physics-informed test-time adaptation. First, we design a diffusion policy that learns inverse dynamics within the reduced-order space, enabling imitation learning to move beyond naÃ¯ve data fitting and capture the underlying physical structure. Second, we propose a physics-informed test-time adaptation scheme that imposes kinematic boundary conditions and structured dynamics priors on the diffusion process, ensuring consistency and reliability in manipulation execution. Extensive experiments validate the proposed approach, demonstrating strong performance in terms of accuracy and robustness in the learned policy.
<div id='section'>Paperid: <span id='pid'>206, <a href='https://arxiv.org/pdf/2304.12764.pdf' target='_blank'>https://arxiv.org/pdf/2304.12764.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yi Su, Yixin Ji, Juntao Li, Hai Ye, Min Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.12764">Test-Time Adaptation with Perturbation Consistency Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Currently, pre-trained language models (PLMs) do not cope well with the distribution shift problem, resulting in models trained on the training set failing in real test scenarios. To address this problem, the test-time adaptation (TTA) shows great potential, which updates model parameters to suit the test data at the testing time. Existing TTA methods rely on well-designed auxiliary tasks or self-training strategies based on pseudo-label. However, these methods do not achieve good trade-offs regarding performance gains and computational costs. To obtain some insights into such a dilemma, we take two representative TTA methods, i.e., Tent and OIL, for exploration and find that stable prediction is the key to achieving a good balance. Accordingly, in this paper, we propose perturbation consistency learning (PCL), a simple test-time adaptation method to promote the model to make stable predictions for samples with distribution shifts. Extensive experiments on adversarial robustness and cross-lingual transferring demonstrate that our method can achieve higher or comparable performance with less inference time over strong PLM backbones and previous state-of-the-art TTA methods.
<div id='section'>Paperid: <span id='pid'>207, <a href='https://arxiv.org/pdf/2507.00951.pdf' target='_blank'>https://arxiv.org/pdf/2507.00951.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rizwan Qureshi, Ranjan Sapkota, Abbas Shah, Amgad Muneer, Anas Zafar, Ashmal Vayani, Maged Shoman, Abdelrahman B. M. Eldaly, Kai Zhang, Ferhat Sadak, Shaina Raza, Xinqi Fan, Ravid Shwartz-Ziv, Hong Yan, Vinjia Jain, Aman Chadha, Manoj Karkee, Jia Wu, Seyedali Mirjalili
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.00951">Thinking Beyond Tokens: From Brain-Inspired Intelligence to Cognitive Foundations for Artificial General Intelligence and its Societal Impact</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Can machines truly think, reason and act in domains like humans? This enduring question continues to shape the pursuit of Artificial General Intelligence (AGI). Despite the growing capabilities of models such as GPT-4.5, DeepSeek, Claude 3.5 Sonnet, Phi-4, and Grok 3, which exhibit multimodal fluency and partial reasoning, these systems remain fundamentally limited by their reliance on token-level prediction and lack of grounded agency. This paper offers a cross-disciplinary synthesis of AGI development, spanning artificial intelligence, cognitive neuroscience, psychology, generative models, and agent-based systems. We analyze the architectural and cognitive foundations of general intelligence, highlighting the role of modular reasoning, persistent memory, and multi-agent coordination. In particular, we emphasize the rise of Agentic RAG frameworks that combine retrieval, planning, and dynamic tool use to enable more adaptive behavior. We discuss generalization strategies, including information compression, test-time adaptation, and training-free methods, as critical pathways toward flexible, domain-agnostic intelligence. Vision-Language Models (VLMs) are reexamined not just as perception modules but as evolving interfaces for embodied understanding and collaborative task completion. We also argue that true intelligence arises not from scale alone but from the integration of memory and reasoning: an orchestration of modular, interactive, and self-improving components where compression enables adaptive behavior. Drawing on advances in neurosymbolic systems, reinforcement learning, and cognitive scaffolding, we explore how recent architectures begin to bridge the gap between statistical learning and goal-directed cognition. Finally, we identify key scientific, technical, and ethical challenges on the path to AGI.
<div id='section'>Paperid: <span id='pid'>208, <a href='https://arxiv.org/pdf/2503.02221.pdf' target='_blank'>https://arxiv.org/pdf/2503.02221.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yusheng Zhao, Junyu Luo, Xiao Luo, Jinsheng Huang, Jingyang Yuan, Zhiping Xiao, Ming Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.02221">Attention Bootstrapping for Multi-Modal Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation aims to adapt a well-trained model to potential distribution shifts at test time using only unlabeled test data, without access to the original training data. While previous efforts mainly focus on a single modality, test-time distribution shift in the multi-modal setting is more complex and calls for new solutions. This paper tackles the problem of multi-modal test-time adaptation by proposing a novel method named Attention Bootstrapping with Principal Entropy Minimization (ABPEM). We observe that test-time distribution shift causes misalignment across modalities, leading to a large gap between intra-modality discrepancies (measured by self-attention) and inter-modality discrepancies (measured by cross-attention). We name this the attention gap. This attention gap widens with more severe distribution shifts, hindering effective modality fusion. To mitigate this attention gap and encourage better modality fusion, we propose attention bootstrapping that promotes cross-attention with the guidance of self-attention. Moreover, to reduce the gradient noise in the commonly-used entropy minimization, we adopt principal entropy minimization, a refinement of entropy minimization that reduces gradient noise by focusing on the principal parts of entropy, excluding less reliable gradient information. Extensive experiments on the benchmarks validate the effectiveness of the proposed ABPEM in comparison with competing baselines.
<div id='section'>Paperid: <span id='pid'>209, <a href='https://arxiv.org/pdf/2409.13095.pdf' target='_blank'>https://arxiv.org/pdf/2409.13095.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhonghao Shi, Xuan Shi, Anfeng Xu, Tiantian Feng, Harshvardhan Srivastava, Shrikanth Narayanan, Maja J. MatariÄ
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.13095">Examining Test-Time Adaptation for Personalized Child Speech Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automatic speech recognition (ASR) models often experience performance degradation due to data domain shifts introduced at test time, a challenge that is further amplified for child speakers. Test-time adaptation (TTA) methods have shown great potential in bridging this domain gap. However, the use of TTA to adapt ASR models to the individual differences in each child's speech has not yet been systematically studied. In this work, we investigate the effectiveness of two widely used TTA methods-SUTA, SGEM-in adapting off-the-shelf ASR models and their fine-tuned versions for child speech recognition, with the goal of enabling continuous, unsupervised adaptation at test time. Our findings show that TTA significantly improves the performance of both off-the-shelf and fine-tuned ASR models, both on average and across individual child speakers, compared to unadapted baselines. However, while TTA helps adapt to individual variability, it may still be limited with non-linguistic child speech.
<div id='section'>Paperid: <span id='pid'>210, <a href='https://arxiv.org/pdf/2505.17459.pdf' target='_blank'>https://arxiv.org/pdf/2505.17459.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingwen Cheng, Ruikun Li, Huandong Wang, Yong Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.17459">Sparse Diffusion Autoencoder for Test-time Adapting Prediction of Complex Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting the behavior of complex systems is critical in many scientific and engineering domains, and hinges on the model's ability to capture their underlying dynamics. Existing methods encode the intrinsic dynamics of high-dimensional observations through latent representations and predict autoregressively. However, these latent representations lose the inherent spatial structure of spatiotemporal dynamics, leading to the predictor's inability to effectively model spatial interactions and neglect emerging dynamics during long-term prediction. In this work, we propose SparseDiff, introducing a test-time adaptation strategy to dynamically update the encoding scheme to accommodate emergent spatiotemporal structures during the long-term evolution of the system. Specifically, we first design a codebook-based sparse encoder, which coarsens the continuous spatial domain into a sparse graph topology. Then, we employ a graph neural ordinary differential equation to model the dynamics and guide a diffusion decoder for reconstruction. SparseDiff autoregressively predicts the spatiotemporal evolution and adjust the sparse topological structure to adapt to emergent spatiotemporal patterns by adaptive re-encoding. Extensive evaluations on representative systems demonstrate that SparseDiff achieves an average prediction error reduction of 49.99\% compared to baselines, requiring only 1\% of the spatial resolution.
<div id='section'>Paperid: <span id='pid'>211, <a href='https://arxiv.org/pdf/2405.19682.pdf' target='_blank'>https://arxiv.org/pdf/2405.19682.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongbin Lin, Yifan Zhang, Shuaicheng Niu, Shuguang Cui, Zhen Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.19682">Fully Test-Time Adaptation for Monocular 3D Object Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Monocular 3D object detection (Mono 3Det) aims to identify 3D objects from a single RGB image. However, existing methods often assume training and test data follow the same distribution, which may not hold in real-world test scenarios. To address the out-of-distribution (OOD) problems, we explore a new adaptation paradigm for Mono 3Det, termed Fully Test-time Adaptation. It aims to adapt a well-trained model to unlabeled test data by handling potential data distribution shifts at test time without access to training data and test labels. However, applying this paradigm in Mono 3Det poses significant challenges due to OOD test data causing a remarkable decline in object detection scores. This decline conflicts with the pre-defined score thresholds of existing detection methods, leading to severe object omissions (i.e., rare positive detections and many false negatives). Consequently, the limited positive detection and plenty of noisy predictions cause test-time adaptation to fail in Mono 3Det. To handle this problem, we propose a novel Monocular Test-Time Adaptation (MonoTTA) method, based on two new strategies. 1) Reliability-driven adaptation: we empirically find that high-score objects are still reliable and the optimization of high-score objects can enhance confidence across all detections. Thus, we devise a self-adaptive strategy to identify reliable objects for model adaptation, which discovers potential objects and alleviates omissions. 2) Noise-guard adaptation: since high-score objects may be scarce, we develop a negative regularization term to exploit the numerous low-score objects via negative learning, preventing overfitting to noise and trivial solutions. Experimental results show that MonoTTA brings significant performance gains for Mono 3Det models in OOD test scenarios, approximately 190% gains by average on KITTI and 198% gains on nuScenes.
<div id='section'>Paperid: <span id='pid'>212, <a href='https://arxiv.org/pdf/2508.03388.pdf' target='_blank'>https://arxiv.org/pdf/2508.03388.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yizhe Xiong, Zihan Zhou, Yiwen Liang, Hui Chen, Zijia Lin, Tianxiang Hao, Fan Zhang, Jungong Han, Guiguang Ding
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.03388">Neutralizing Token Aggregation via Information Augmentation for Efficient Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-Time Adaptation (TTA) has emerged as an effective solution for adapting Vision Transformers (ViT) to distribution shifts without additional training data. However, existing TTA methods often incur substantial computational overhead, limiting their applicability in resource-constrained real-world scenarios. To reduce inference cost, plug-and-play token aggregation methods merge redundant tokens in ViTs to reduce total processed tokens. Albeit efficient, it suffers from significant performance degradation when directly integrated with existing TTA methods. We formalize this problem as Efficient Test-Time Adaptation (ETTA), seeking to preserve the adaptation capability of TTA while reducing inference latency. In this paper, we first provide a theoretical analysis from a novel mutual information perspective, showing that token aggregation inherently leads to information loss, which cannot be fully mitigated by conventional norm-tuning-based TTA methods. Guided by this insight, we propose to \textbf{N}eutralize Token \textbf{A}ggregation \textbf{v}ia \textbf{I}nformation \textbf{A}ugmentation (\textbf{NAVIA}). Specifically, we directly augment the [CLS] token embedding and incorporate adaptive biases into the [CLS] token in shallow layers of ViTs. We theoretically demonstrate that these augmentations, when optimized via entropy minimization, recover the information lost due to token aggregation. Extensive experiments across various out-of-distribution benchmarks demonstrate that NAVIA significantly outperforms state-of-the-art methods by over 2.5\%, while achieving an inference latency reduction of more than 20\%, effectively addressing the ETTA challenge.
<div id='section'>Paperid: <span id='pid'>213, <a href='https://arxiv.org/pdf/2501.01472.pdf' target='_blank'>https://arxiv.org/pdf/2501.01472.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Peiliang Gong, Mohamed Ragab, Min Wu, Zhenghua Chen, Yongyi Su, Xiaoli Li, Daoqiang Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.01472">Augmented Contrastive Clustering with Uncertainty-Aware Prototyping for Time Series Test Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation aims to adapt pre-trained deep neural networks using solely online unlabelled test data during inference. Although TTA has shown promise in visual applications, its potential in time series contexts remains largely unexplored. Existing TTA methods, originally designed for visual tasks, may not effectively handle the complex temporal dynamics of real-world time series data, resulting in suboptimal adaptation performance. To address this gap, we propose Augmented Contrastive Clustering with Uncertainty-aware Prototyping (ACCUP), a straightforward yet effective TTA method for time series data. Initially, our approach employs augmentation ensemble on the time series data to capture diverse temporal information and variations, incorporating uncertainty-aware prototypes to distill essential characteristics. Additionally, we introduce an entropy comparison scheme to selectively acquire more confident predictions, enhancing the reliability of pseudo labels. Furthermore, we utilize augmented contrastive clustering to enhance feature discriminability and mitigate error accumulation from noisy pseudo labels, promoting cohesive clustering within the same class while facilitating clear separation between different classes. Extensive experiments conducted on three real-world time series datasets and an additional visual dataset demonstrate the effectiveness and generalization potential of the proposed method, advancing the underexplored realm of TTA for time series data.
<div id='section'>Paperid: <span id='pid'>214, <a href='https://arxiv.org/pdf/2502.02998.pdf' target='_blank'>https://arxiv.org/pdf/2502.02998.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fan Lyu, Hanyu Zhao, Ziqi Shi, Ye Liu, Fuyuan Hu, Zhang Zhang, Liang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.02998">Conformal Uncertainty Indicator for Continual Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual Test-Time Adaptation (CTTA) aims to adapt models to sequentially changing domains during testing, relying on pseudo-labels for self-adaptation. However, incorrect pseudo-labels can accumulate, leading to performance degradation. To address this, we propose a Conformal Uncertainty Indicator (CUI) for CTTA, leveraging Conformal Prediction (CP) to generate prediction sets that include the true label with a specified coverage probability. Since domain shifts can lower the coverage than expected, making CP unreliable, we dynamically compensate for the coverage by measuring both domain and data differences. Reliable pseudo-labels from CP are then selectively utilized to enhance adaptation. Experiments confirm that CUI effectively estimates uncertainty and improves adaptation performance across various existing CTTA methods.
<div id='section'>Paperid: <span id='pid'>215, <a href='https://arxiv.org/pdf/2406.02609.pdf' target='_blank'>https://arxiv.org/pdf/2406.02609.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiayao Tan, Fan Lyu, Chenggong Ni, Tingliang Feng, Fuyuan Hu, Zhang Zhang, Shaochuang Zhao, Liang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.02609">Less is More: Pseudo-Label Filtering for Continual Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual Test-Time Adaptation (CTTA) aims to adapt a pre-trained model to a sequence of target domains during the test phase without accessing the source data. To adapt to unlabeled data from unknown domains, existing methods rely on constructing pseudo-labels for all samples and updating the model through self-training. However, these pseudo-labels often involve noise, leading to insufficient adaptation. To improve the quality of pseudo-labels, we propose a pseudo-label selection method for CTTA, called Pseudo Labeling Filter (PLF). The key idea of PLF is to keep selecting appropriate thresholds for pseudo-labels and identify reliable ones for self-training. Specifically, we present three principles for setting thresholds during continuous domain learning, including initialization, growth and diversity. Based on these principles, we design Self-Adaptive Thresholding to filter pseudo-labels. Additionally, we introduce a Class Prior Alignment (CPA) method to encourage the model to make diverse predictions for unknown domain samples. Through extensive experiments, PLF outperforms current state-of-the-art methods, proving its effectiveness in CTTA.
<div id='section'>Paperid: <span id='pid'>216, <a href='https://arxiv.org/pdf/2405.14602.pdf' target='_blank'>https://arxiv.org/pdf/2405.14602.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziqi Shi, Fan Lyu, Ye Liu, Fanhua Shang, Fuyuan Hu, Wei Feng, Zhang Zhang, Liang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.14602">Controllable Continual Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual Test-Time Adaptation (CTTA) is an emerging and challenging task where a model trained in a source domain must adapt to continuously changing conditions during testing, without access to the original source data. CTTA is prone to error accumulation due to uncontrollable domain shifts, leading to blurred decision boundaries between categories. Existing CTTA methods primarily focus on suppressing domain shifts, which proves inadequate during the unsupervised test phase. In contrast, we introduce a novel approach that guides rather than suppresses these shifts. Specifically, we propose $\textbf{C}$ontrollable $\textbf{Co}$ntinual $\textbf{T}$est-$\textbf{T}$ime $\textbf{A}$daptation (C-CoTTA), which explicitly prevents any single category from encroaching on others, thereby mitigating the mutual influence between categories caused by uncontrollable shifts. Moreover, our method reduces the sensitivity of model to domain transformations, thereby minimizing the magnitude of category shifts. Extensive quantitative experiments demonstrate the effectiveness of our method, while qualitative analyses, such as t-SNE plots, confirm the theoretical validity of our approach.
<div id='section'>Paperid: <span id='pid'>217, <a href='https://arxiv.org/pdf/2402.08182.pdf' target='_blank'>https://arxiv.org/pdf/2402.08182.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fan Lyu, Kaile Du, Yuyang Li, Hanyu Zhao, Zhang Zhang, Guangcan Liu, Liang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.08182">Variational Continual Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The prior drift is crucial in Continual Test-Time Adaptation (CTTA) methods that only use unlabeled test data, as it can cause significant error propagation. In this paper, we introduce VCoTTA, a variational Bayesian approach to measure uncertainties in CTTA. At the source stage, we transform a pre-trained deterministic model into a Bayesian Neural Network (BNN) via a variational warm-up strategy, injecting uncertainties into the model. During the testing time, we employ a mean-teacher update strategy using variational inference for the student model and exponential moving average for the teacher model. Our novel approach updates the student model by combining priors from both the source and teacher models. The evidence lower bound is formulated as the cross-entropy between the student and teacher models, along with the Kullback-Leibler (KL) divergence of the prior mixture. Experimental results on three datasets demonstrate the method's effectiveness in mitigating prior drift within the CTTA framework.
<div id='section'>Paperid: <span id='pid'>218, <a href='https://arxiv.org/pdf/2311.16420.pdf' target='_blank'>https://arxiv.org/pdf/2311.16420.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>YiFan Zhang, Xue Wang, Tian Zhou, Kun Yuan, Zhang Zhang, Liang Wang, Rong Jin, Tieniu Tan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.16420">Model-free Test Time Adaptation for Out-Of-Distribution Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-distribution (OOD) detection is essential for the reliability of ML models. Most existing methods for OOD detection learn a fixed decision criterion from a given in-distribution dataset and apply it universally to decide if a data point is OOD. Recent work~\cite{fang2022is} shows that given only in-distribution data, it is impossible to reliably detect OOD data without extra assumptions. Motivated by the theoretical result and recent exploration of test-time adaptation methods, we propose a Non-Parametric Test Time \textbf{Ada}ptation framework for \textbf{O}ut-Of-\textbf{D}istribution \textbf{D}etection (\abbr). Unlike conventional methods, \abbr utilizes online test samples for model adaptation during testing, enhancing adaptability to changing data distributions. The framework incorporates detected OOD instances into decision-making, reducing false positive rates, particularly when ID and OOD distributions overlap significantly. We demonstrate the effectiveness of \abbr through comprehensive experiments on multiple OOD detection benchmarks, extensive empirical studies show that \abbr significantly improves the performance of OOD detection over state-of-the-art methods. Specifically, \abbr reduces the false positive rate (FPR95) by $23.23\%$ on the CIFAR-10 benchmarks and $38\%$ on the ImageNet-1k benchmarks compared to the advanced methods. Lastly, we theoretically verify the effectiveness of \abbr.
<div id='section'>Paperid: <span id='pid'>219, <a href='https://arxiv.org/pdf/2306.02544.pdf' target='_blank'>https://arxiv.org/pdf/2306.02544.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuhao Huang, Xin Yang, Xiaoqiong Huang, Xinrui Zhou, Haozhe Chi, Haoran Dou, Xindi Hu, Jian Wang, Xuedong Deng, Dong Ni
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.02544">Fourier Test-time Adaptation with Multi-level Consistency for Robust Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep classifiers may encounter significant performance degradation when processing unseen testing data from varying centers, vendors, and protocols. Ensuring the robustness of deep models against these domain shifts is crucial for their widespread clinical application. In this study, we propose a novel approach called Fourier Test-time Adaptation (FTTA), which employs a dual-adaptation design to integrate input and model tuning, thereby jointly improving the model robustness. The main idea of FTTA is to build a reliable multi-level consistency measurement of paired inputs for achieving self-correction of prediction. Our contribution is two-fold. First, we encourage consistency in global features and local attention maps between the two transformed images of the same input. Here, the transformation refers to Fourier-based input adaptation, which can transfer one unseen image into source style to reduce the domain gap. Furthermore, we leverage style-interpolated images to enhance the global and local features with learnable parameters, which can smooth the consistency measurement and accelerate convergence. Second, we introduce a regularization technique that utilizes style interpolation consistency in the frequency space to encourage self-consistency in the logit space of the model output. This regularization provides strong self-supervised signals for robustness enhancement. FTTA was extensively validated on three large classification datasets with different modalities and organs. Experimental results show that FTTA is general and outperforms other strong state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>220, <a href='https://arxiv.org/pdf/2510.02750.pdf' target='_blank'>https://arxiv.org/pdf/2510.02750.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lihua Zhou, Mao Ye, Shuaifeng Li, Nianxin Li, Jinlin Wu, Xiatian Zhu, Lei Deng, Hongbin Liu, Jiebo Luo, Zhen Lei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.02750">Bayesian Test-time Adaptation for Object Recognition and Detection with Vision-language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-language models (VLMs) such as CLIP and Grounding DINO have achieved remarkable success in object recognition and detection. However, their performance often degrades under real-world distribution shifts. Test-time adaptation (TTA) aims to mitigate this issue by adapting models during inference. Existing methods either rely on computationally expensive backpropagation, which hinders real-time deployment, or focus solely on likelihood adaptation, which overlooks the critical role of the prior. Our prior work, Bayesian Class Adaptation (BCA), addressed these shortcomings for object recognition by introducing a training-free framework that incorporates adaptive priors. Building upon this foundation, we now present Bayesian Class Adaptation plus (BCA+), a unified, training-free framework for TTA for both object recognition and detection. BCA+ introduces a dynamic cache that adaptively stores and updates class embeddings, spatial scales (for detection), and, crucially, adaptive class priors derived from historical predictions. We formulate adaptation as a Bayesian inference problem, where final predictions are generated by fusing the initial VLM output with a cache-based prediction. This cache-based prediction combines a dynamically updated likelihood (measuring feature and scale similarity) and a prior (reflecting the evolving class distribution). This dual-adaptation mechanism, coupled with uncertainty-guided fusion, enables BCA+ to correct both the model's semantic understanding and its contextual confidence. As a training-free method requiring no backpropagation, BCA+ is highly efficient. Extensive experiments demonstrate that BCA+ achieves state-of-the-art performance on both recognition and detection benchmarks.
<div id='section'>Paperid: <span id='pid'>221, <a href='https://arxiv.org/pdf/2510.02750.pdf' target='_blank'>https://arxiv.org/pdf/2510.02750.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lihua Zhou, Mao Ye, Shuaifeng Li, Nianxin Li, Jinlin Wu, Xiatian Zhu, Lei Deng, Hongbin Liu, Jiebo Luo, Zhen Lei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.02750">Bayesian Test-time Adaptation for Object Recognition and Detection with Vision-language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-language models (VLMs) such as CLIP and Grounding DINO have achieved remarkable success in object recognition and detection. However, their performance often degrades under real-world distribution shifts. Test-time adaptation (TTA) aims to mitigate this issue by adapting models during inference. Existing methods either rely on computationally expensive backpropagation, which hinders real-time deployment, or focus solely on likelihood adaptation, which overlooks the critical role of the prior. Our prior work, Bayesian Class Adaptation (BCA), addressed these shortcomings for object recognition by introducing a training-free framework that incorporates adaptive priors. Building upon this foundation, we now present Bayesian Class Adaptation plus (BCA+), a unified, training-free framework for TTA for both object recognition and detection. BCA+ introduces a dynamic cache that adaptively stores and updates class embeddings, spatial scales (for detection), and, crucially, adaptive class priors derived from historical predictions. We formulate adaptation as a Bayesian inference problem, where final predictions are generated by fusing the initial VLM output with a cache-based prediction. This cache-based prediction combines a dynamically updated likelihood (measuring feature and scale similarity) and a prior (reflecting the evolving class distribution). This dual-adaptation mechanism, coupled with uncertainty-guided fusion, enables BCA+ to correct both the model's semantic understanding and its contextual confidence. As a training-free method requiring no backpropagation, BCA+ is highly efficient. Extensive experiments demonstrate that BCA+ achieves state-of-the-art performance on both recognition and detection benchmarks.
<div id='section'>Paperid: <span id='pid'>222, <a href='https://arxiv.org/pdf/2510.10223.pdf' target='_blank'>https://arxiv.org/pdf/2510.10223.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yijie Xu, Huizai Yao, Zhiyu Guo, Weiyu Guo, Pengteng Li, Aiwei Liu, Xuming Hu, Hui Xiong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.10223">You only need 4 extra tokens: Synergistic Test-time Adaptation for LLMs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) are increasingly deployed in specialized domains such as finance, medicine, and agriculture, where they face significant distribution shifts from their training data. Domain-specific fine-tuning can mitigate this challenge but relies on high-quality labeled data that is expensive and slow to collect in expertise-limited settings. We study label-free test-time adaptation for language models and present SyTTA, an inference-time framework that adapts models on-the-fly without additional supervision. SyTTA couples two complementary uncertainty signals that arise under distribution shift: input-side perplexity, indicating mismatch with domain-specific terminology and patterns, and output-side predictive entropy, indicating diffuse and unstable token probabilities during generation. Across diverse model architectures and domain-specific benchmarks, SyTTA delivers consistent gains. Notably, on agricultural question answering, SyTTA improves Rouge-LSum by over 120% on Qwen-2.5-7B with only 4 extra tokens per query. These results show that effective test-time adaptation for language models is achievable without labeled examples, supporting deployment in label-scarce domains. The code will be made available upon acceptance.
<div id='section'>Paperid: <span id='pid'>223, <a href='https://arxiv.org/pdf/2412.09706.pdf' target='_blank'>https://arxiv.org/pdf/2412.09706.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chun-Mei Feng, Yuanyang He, Jian Zou, Salman Khan, Huan Xiong, Zhen Li, Wangmeng Zuo, Rick Siow Mong Goh, Yong Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.09706">Diffusion-Enhanced Test-time Adaptation with Text and Image Augmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing test-time prompt tuning (TPT) methods focus on single-modality data, primarily enhancing images and using confidence ratings to filter out inaccurate images. However, while image generation models can produce visually diverse images, single-modality data enhancement techniques still fail to capture the comprehensive knowledge provided by different modalities. Additionally, we note that the performance of TPT-based methods drops significantly when the number of augmented images is limited, which is not unusual given the computational expense of generative augmentation. To address these issues, we introduce IT3A, a novel test-time adaptation method that utilizes a pre-trained generative model for multi-modal augmentation of each test sample from unknown new domains. By combining augmented data from pre-trained vision and language models, we enhance the ability of the model to adapt to unknown new test data. Additionally, to ensure that key semantics are accurately retained when generating various visual and text enhancements, we employ cosine similarity filtering between the logits of the enhanced images and text with the original test data. This process allows us to filter out some spurious augmentation and inadequate combinations. To leverage the diverse enhancements provided by the generation model across different modals, we have replaced prompt tuning with an adapter for greater flexibility in utilizing text templates. Our experiments on the test datasets with distribution shifts and domain gaps show that in a zero-shot setting, IT3A outperforms state-of-the-art test-time prompt tuning methods with a 5.50% increase in accuracy.
<div id='section'>Paperid: <span id='pid'>224, <a href='https://arxiv.org/pdf/2411.17002.pdf' target='_blank'>https://arxiv.org/pdf/2411.17002.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shambhavi Mishra, Julio Silva-RodrÄ±guez, Ismail Ben Ayed, Marco Pedersoli, Jose Dolz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.17002">Words Matter: Leveraging Individual Text Embeddings for Code Generation in CLIP Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-language foundation models, such as CLIP, have shown unprecedented zero-shot performance across a wide range of tasks. Nevertheless, these models may be unreliable under distributional shifts, as their performance is significantly degraded. In this work, we explore how to efficiently leverage class text information to mitigate these distribution drifts encountered by large pre-trained vision-language models (VLMs) during test-time inference. In particular, we propose to generate pseudo-labels for the test-time samples by exploiting generic class text embeddings as fixed centroids of a label assignment problem, which is efficiently solved with Optimal Transport. Furthermore, the proposed adaptation method (CLIP-OT) integrates a multiple template knowledge distillation approach, which replicates multi-view contrastive learning strategies in unsupervised representation learning but without incurring additional computational complexity. Extensive experiments on multiple popular test-time adaptation benchmarks presenting diverse complexity empirically show the superiority of CLIP-OT, achieving performance gains of up to 7% over recent state-of-the-art methods, yet being computationally and memory efficient.
<div id='section'>Paperid: <span id='pid'>225, <a href='https://arxiv.org/pdf/2411.09289.pdf' target='_blank'>https://arxiv.org/pdf/2411.09289.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dilxat Muhtar, Yelong Shen, Yaming Yang, Xiaodong Liu, Yadong Lu, Jianfeng Liu, Yuefeng Zhan, Hao Sun, Weiwei Deng, Feng Sun, Xueliang Zhang, Jianfeng Gao, Weizhu Chen, Qi Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.09289">StreamAdapter: Efficient Test Time Adaptation from Contextual Streams</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In-context learning (ICL) allows large language models (LLMs) to adapt to new tasks directly from the given demonstrations without requiring gradient updates. While recent advances have expanded context windows to accommodate more demonstrations, this approach increases inference costs without necessarily improving performance. To mitigate these issues, We propose StreamAdapter, a novel approach that directly updates model parameters from context at test time, eliminating the need for explicit in-context demonstrations. StreamAdapter employs context mapping and weight absorption mechanisms to dynamically transform ICL demonstrations into parameter updates with minimal additional parameters. By reducing reliance on numerous in-context examples, StreamAdapter significantly reduce inference costs and allows for efficient inference with constant time complexity, regardless of demonstration count. Extensive experiments across diverse tasks and model architectures demonstrate that StreamAdapter achieves comparable or superior adaptation capability to ICL while requiring significantly fewer demonstrations. The superior task adaptation and context encoding capabilities of StreamAdapter on both language understanding and generation tasks provides a new perspective for adapting LLMs at test time using context, allowing for more efficient adaptation across scenarios and more cost-effective inference
<div id='section'>Paperid: <span id='pid'>226, <a href='https://arxiv.org/pdf/2507.11969.pdf' target='_blank'>https://arxiv.org/pdf/2507.11969.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhaohong Huang, Yuxin Zhang, Jingjing Xie, Fei Chao, Rongrong Ji
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.11969">GS-Bias: Global-Spatial Bias Learner for Single-Image Test-Time Adaptation of Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in test-time adaptation (TTA) for Vision-Language Models (VLMs) have garnered increasing attention, particularly through the use of multiple augmented views of a single image to boost zero-shot generalization. Unfortunately, existing methods fail to strike a satisfactory balance between performance and efficiency, either due to excessive overhead of tuning text prompts or unstable benefits from handcrafted, training-free visual feature enhancement. In this paper, we present Global-Spatial Bias Learner (GS-Bias), an efficient and effective TTA paradigm that incorporates two learnable biases during TTA, unfolded as the global bias and spatial bias. Particularly, the global bias captures the global semantic features of a test image by learning consistency across augmented views, while spatial bias learns the semantic coherence between regions in the image's spatial visual representation. It is worth highlighting that these two sets of biases are directly added to the logits outputed by the pretrained VLMs, which circumvent the full backpropagation through VLM that hinders the efficiency of existing TTA methods. This endows GS-Bias with extremely high efficiency while achieving state-of-the-art performance on 15 benchmark datasets. For example, it achieves a 2.23% improvement over TPT in cross-dataset generalization and a 2.72% improvement in domain generalization, while requiring only 6.5% of TPT's memory usage on ImageNet.
<div id='section'>Paperid: <span id='pid'>227, <a href='https://arxiv.org/pdf/2510.00078.pdf' target='_blank'>https://arxiv.org/pdf/2510.00078.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sicong Liu, Weiye Wu, Xiangrui Xu, Teng Li, Bowen Pang, Bin Guo, Zhiwen Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.00078">Adaptive and Resource-efficient Agentic AI Systems for Mobile and Embedded Devices: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Foundation models have reshaped AI by unifying fragmented architectures into scalable backbones with multimodal reasoning and contextual adaptation. In parallel, the long-standing notion of AI agents, defined by the sensing-decision-action loop, is entering a new paradigm: with FMs as their cognitive core, agents transcend rule-based behaviors to achieve autonomy, generalization, and self-reflection. This dual shift is reinforced by real-world demands such as autonomous driving, robotics, virtual assistants, and GUI agents, as well as ecosystem advances in embedded hardware, edge computing, mobile deployment platforms, and communication protocols that together enable large-scale deployment. Yet this convergence collides with reality: while applications demand long-term adaptability and real-time interaction, mobile and edge deployments remain constrained by memory, energy, bandwidth, and latency. This creates a fundamental tension between the growing complexity of FMs and the limited resources of deployment environments. This survey provides the first systematic characterization of adaptive, resource-efficient agentic AI systems. We summarize enabling techniques into elastic inference, test-time adaptation, dynamic multimodal integration, and agentic AI applications, and identify open challenges in balancing accuracy-latency-communication trade-offs and sustaining robustness under distribution shifts. We further highlight future opportunities in algorithm-system co-design, cognitive adaptation, and collaborative edge deployment. By mapping FM structures, cognition, and hardware resources, this work establishes a unified perspective toward scalable, adaptive, and resource-efficient agentic AI. We believe this survey can help readers to understand the connections between enabling technologies while promoting further discussions on the fusion of agentic intelligence and intelligent agents.
<div id='section'>Paperid: <span id='pid'>228, <a href='https://arxiv.org/pdf/2510.00078.pdf' target='_blank'>https://arxiv.org/pdf/2510.00078.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sicong Liu, Weiye Wu, Xiangrui Xu, Teng Li, Bowen Pang, Bin Guo, Zhiwen Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.00078">Adaptive and Resource-efficient Agentic AI Systems for Mobile and Embedded Devices: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Foundation models have reshaped AI by unifying fragmented architectures into scalable backbones with multimodal reasoning and contextual adaptation. In parallel, the long-standing notion of AI agents, defined by the sensing-decision-action loop, is entering a new paradigm: with FMs as their cognitive core, agents transcend rule-based behaviors to achieve autonomy, generalization, and self-reflection. This dual shift is reinforced by real-world demands such as autonomous driving, robotics, virtual assistants, and GUI agents, as well as ecosystem advances in embedded hardware, edge computing, mobile deployment platforms, and communication protocols that together enable large-scale deployment. Yet this convergence collides with reality: while applications demand long-term adaptability and real-time interaction, mobile and edge deployments remain constrained by memory, energy, bandwidth, and latency. This creates a fundamental tension between the growing complexity of FMs and the limited resources of deployment environments. This survey provides the first systematic characterization of adaptive, resource-efficient agentic AI systems. We summarize enabling techniques into elastic inference, test-time adaptation, dynamic multimodal integration, and agentic AI applications, and identify open challenges in balancing accuracy-latency-communication trade-offs and sustaining robustness under distribution shifts. We further highlight future opportunities in algorithm-system co-design, cognitive adaptation, and collaborative edge deployment. By mapping FM structures, cognition, and hardware resources, this work establishes a unified perspective toward scalable, adaptive, and resource-efficient agentic AI. We believe this survey can help readers to understand the connections between enabling technologies while promoting further discussions on the fusion of agentic intelligence and intelligent agents.
<div id='section'>Paperid: <span id='pid'>229, <a href='https://arxiv.org/pdf/2503.20354.pdf' target='_blank'>https://arxiv.org/pdf/2503.20354.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ke Ma, Jiaqi Tang, Bin Guo, Fan Dang, Sicong Liu, Zhui Zhu, Lei Wu, Cheng Fang, Ying-Cong Chen, Zhiwen Yu, Yunhao Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.20354">SURGEON: Memory-Adaptive Fully Test-Time Adaptation via Dynamic Activation Sparsity</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite the growing integration of deep models into mobile terminals, the accuracy of these models declines significantly due to various deployment interferences. Test-time adaptation (TTA) has emerged to improve the performance of deep models by adapting them to unlabeled target data online. Yet, the significant memory cost, particularly in resource-constrained terminals, impedes the effective deployment of most backward-propagation-based TTA methods. To tackle memory constraints, we introduce SURGEON, a method that substantially reduces memory cost while preserving comparable accuracy improvements during fully test-time adaptation (FTTA) without relying on specific network architectures or modifications to the original training procedure. Specifically, we propose a novel dynamic activation sparsity strategy that directly prunes activations at layer-specific dynamic ratios during adaptation, allowing for flexible control of learning ability and memory cost in a data-sensitive manner. Among this, two metrics, Gradient Importance and Layer Activation Memory, are considered to determine the layer-wise pruning ratios, reflecting accuracy contribution and memory efficiency, respectively. Experimentally, our method surpasses the baselines by not only reducing memory usage but also achieving superior accuracy, delivering SOTA performance across diverse datasets, architectures, and tasks.
<div id='section'>Paperid: <span id='pid'>230, <a href='https://arxiv.org/pdf/2411.18860.pdf' target='_blank'>https://arxiv.org/pdf/2411.18860.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dacheng Liao, Mengshi Qi, Liang Liu, Huadong Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.18860">Improving Batch Normalization with TTA for Robust Object Detection in Self-Driving</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In current open real-world autonomous driving scenarios, challenges such as sensor failure and extreme weather conditions hinder the generalization of most autonomous driving perception models to these unseen domain due to the domain shifts between the test and training data. As the parameter scale of autonomous driving perception models grows, traditional test-time adaptation (TTA) methods become unstable and often degrade model performance in most scenarios. To address these challenges, this paper proposes two new robust methods to improve the Batch Normalization with TTA for object detection in autonomous driving: (1) We introduce a LearnableBN layer based on Generalized-search Entropy Minimization (GSEM) method. Specifically, we modify the traditional BN layer by incorporating auxiliary learnable parameters, which enables the BN layer to dynamically update the statistics according to the different input data. (2) We propose a new semantic-consistency based dual-stage-adaptation strategy, which encourages the model to iteratively search for the optimal solution and eliminates unstable samples during the adaptation process. Extensive experiments on the NuScenes-C dataset shows that our method achieves a maximum improvement of about 8% using BEVFormer as the baseline model across six corruption types and three levels of severity. We will make our source code available soon.
<div id='section'>Paperid: <span id='pid'>231, <a href='https://arxiv.org/pdf/2410.08256.pdf' target='_blank'>https://arxiv.org/pdf/2410.08256.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cheng Fang, Sicong Liu, Zimu Zhou, Bin Guo, Jiaqi Tang, Ke Ma, Zhiwen Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.08256">AdaShadow: Responsive Test-time Model Adaptation in Non-stationary Mobile Environments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>On-device adapting to continual, unpredictable domain shifts is essential for mobile applications like autonomous driving and augmented reality to deliver seamless user experiences in evolving environments. Test-time adaptation (TTA) emerges as a promising solution by tuning model parameters with unlabeled live data immediately before prediction. However, TTA's unique forward-backward-reforward pipeline notably increases the latency over standard inference, undermining the responsiveness in time-sensitive mobile applications. This paper presents AdaShadow, a responsive test-time adaptation framework for non-stationary mobile data distribution and resource dynamics via selective updates of adaptation-critical layers. Although the tactic is recognized in generic on-device training, TTA's unsupervised and online context presents unique challenges in estimating layer importance and latency, as well as scheduling the optimal layer update plan. AdaShadow addresses these challenges with a backpropagation-free assessor to rapidly identify critical layers, a unit-based runtime predictor to account for resource dynamics in latency estimation, and an online scheduler for prompt layer update planning. Also, AdaShadow incorporates a memory I/O-aware computation reuse scheme to further reduce latency in the reforward pass. Results show that AdaShadow achieves the best accuracy-latency balance under continual shifts. At low memory and energy costs, Adashadow provides a 2x to 3.5x speedup (ms-level) over state-of-the-art TTA methods with comparable accuracy and a 14.8% to 25.4% accuracy boost over efficient supervised methods with similar latency.
<div id='section'>Paperid: <span id='pid'>232, <a href='https://arxiv.org/pdf/2409.03403.pdf' target='_blank'>https://arxiv.org/pdf/2409.03403.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lawrence Yunliang Chen, Chenfeng Xu, Karthik Dharmarajan, Muhammad Zubair Irshad, Richard Cheng, Kurt Keutzer, Masayoshi Tomizuka, Quan Vuong, Ken Goldberg
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.03403">RoVi-Aug: Robot and Viewpoint Augmentation for Cross-Embodiment Robot Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Scaling up robot learning requires large and diverse datasets, and how to efficiently reuse collected data and transfer policies to new embodiments remains an open question. Emerging research such as the Open-X Embodiment (OXE) project has shown promise in leveraging skills by combining datasets including different robots. However, imbalances in the distribution of robot types and camera angles in many datasets make policies prone to overfit. To mitigate this issue, we propose RoVi-Aug, which leverages state-of-the-art image-to-image generative models to augment robot data by synthesizing demonstrations with different robots and camera views. Through extensive physical experiments, we show that, by training on robot- and viewpoint-augmented data, RoVi-Aug can zero-shot deploy on an unseen robot with significantly different camera angles. Compared to test-time adaptation algorithms such as Mirage, RoVi-Aug requires no extra processing at test time, does not assume known camera angles, and allows policy fine-tuning. Moreover, by co-training on both the original and augmented robot datasets, RoVi-Aug can learn multi-robot and multi-task policies, enabling more efficient transfer between robots and skills and improving success rates by up to 30%. Project website: https://rovi-aug.github.io.
<div id='section'>Paperid: <span id='pid'>233, <a href='https://arxiv.org/pdf/2302.14611.pdf' target='_blank'>https://arxiv.org/pdf/2302.14611.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Debasmit Das, Shubhankar Borse, Hyojin Park, Kambiz Azarian, Hong Cai, Risheek Garrepalli, Fatih Porikli
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.14611">TransAdapt: A Transformative Framework for Online Test Time Adaptive Semantic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptive (TTA) semantic segmentation adapts a source pre-trained image semantic segmentation model to unlabeled batches of target domain test images, different from real-world, where samples arrive one-by-one in an online fashion. To tackle online settings, we propose TransAdapt, a framework that uses transformer and input transformations to improve segmentation performance. Specifically, we pre-train a transformer-based module on a segmentation network that transforms unsupervised segmentation output to a more reliable supervised output, without requiring test-time online training. To also facilitate test-time adaptation, we propose an unsupervised loss based on the transformed input that enforces the model to be invariant and equivariant to photometric and geometric perturbations, respectively. Overall, our framework produces higher quality segmentation masks with up to 17.6% and 2.8% mIOU improvement over no-adaptation and competitive baselines, respectively.
<div id='section'>Paperid: <span id='pid'>234, <a href='https://arxiv.org/pdf/2506.19022.pdf' target='_blank'>https://arxiv.org/pdf/2506.19022.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinlong Li, Dong Zhao, Qi Zang, Zequn Jie, Lin Ma, Nicu Sebe
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.19022">Orthogonal Projection Subspace to Aggregate Online Prior-knowledge for Continual Test-time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual Test Time Adaptation (CTTA) is a task that requires a source pre-trained model to continually adapt to new scenarios with changing target distributions. Existing CTTA methods primarily focus on mitigating the challenges of catastrophic forgetting and error accumulation. Though there have been emerging methods based on forgetting adaptation with parameter-efficient fine-tuning, they still struggle to balance competitive performance and efficient model adaptation, particularly in complex tasks like semantic segmentation. In this paper, to tackle the above issues, we propose a novel pipeline, Orthogonal Projection Subspace to aggregate online Prior-knowledge, dubbed OoPk. Specifically, we first project a tuning subspace orthogonally which allows the model to adapt to new domains while preserving the knowledge integrity of the pre-trained source model to alleviate catastrophic forgetting. Then, we elaborate an online prior-knowledge aggregation strategy that employs an aggressive yet efficient image masking strategy to mimic potential target dynamism, enhancing the student model's domain adaptability. This further gradually ameliorates the teacher model's knowledge, ensuring high-quality pseudo labels and reducing error accumulation. We demonstrate our method with extensive experiments that surpass previous CTTA methods and achieve competitive performances across various continual TTA benchmarks in semantic segmentation tasks.
<div id='section'>Paperid: <span id='pid'>235, <a href='https://arxiv.org/pdf/2502.09662.pdf' target='_blank'>https://arxiv.org/pdf/2502.09662.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Jiang, Cheng Jin, Huangjing Lin, Yanning Zhou, Xi Wang, Jiabo Ma, Li Ding, Jun Hou, Runsheng Liu, Zhizhong Chai, Luyang Luo, Huijuan Shi, Yinling Qian, Qiong Wang, Changzhong Li, Anjia Han, Ronald Cheong Kin Chan, Hao Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.09662">Generalizable Cervical Cancer Screening via Large-scale Pretraining and Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cervical cancer is a leading malignancy in female reproductive system. While AI-assisted cytology offers a cost-effective and non-invasive screening solution, current systems struggle with generalizability in complex clinical scenarios. To address this issue, we introduced Smart-CCS, a generalizable Cervical Cancer Screening paradigm based on pretraining and adaptation to create robust and generalizable screening systems. To develop and validate Smart-CCS, we first curated a large-scale, multi-center dataset named CCS-127K, which comprises a total of 127,471 cervical cytology whole-slide images collected from 48 medical centers. By leveraging large-scale self-supervised pretraining, our CCS models are equipped with strong generalization capability, potentially generalizing across diverse scenarios. Then, we incorporated test-time adaptation to specifically optimize the trained CCS model for complex clinical settings, which adapts and refines predictions, improving real-world applicability. We conducted large-scale system evaluation among various cohorts. In retrospective cohorts, Smart-CCS achieved an overall area under the curve (AUC) value of 0.965 and sensitivity of 0.913 for cancer screening on 11 internal test datasets. In external testing, system performance maintained high at 0.950 AUC across 6 independent test datasets. In prospective cohorts, our Smart-CCS achieved AUCs of 0.947, 0.924, and 0.986 in three prospective centers, respectively. Moreover, the system demonstrated superior sensitivity in diagnosing cervical cancer, confirming the accuracy of our cancer screening results by using histology findings for validation. Interpretability analysis with cell and slide predictions further indicated that the system's decision-making aligns with clinical practice. Smart-CCS represents a significant advancement in cancer screening across diverse clinical contexts.
<div id='section'>Paperid: <span id='pid'>236, <a href='https://arxiv.org/pdf/2412.20034.pdf' target='_blank'>https://arxiv.org/pdf/2412.20034.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yanshuo Wang, Xuesong Li, Jinguang Tong, Jie Hong, Jun Lan, Weiqiang Wang, Huijia Zhu, Haoxing Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.20034">Maintain Plasticity in Long-timescale Continual Test-time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual test-time domain adaptation (CTTA) aims to adjust pre-trained source models to perform well over time across non-stationary target environments. While previous methods have made considerable efforts to optimize the adaptation process, a crucial question remains: can the model adapt to continually-changing environments with preserved plasticity over a long time? The plasticity refers to the model's capability to adjust predictions in response to non-stationary environments continually. In this work, we explore plasticity, this essential but often overlooked aspect of continual adaptation to facilitate more sustained adaptation in the long run. First, we observe that most CTTA methods experience a steady and consistent decline in plasticity during the long-timescale continual adaptation phase. Moreover, we find that the loss of plasticity is strongly associated with the change in label flip. Based on this correlation, we propose a simple yet effective policy, Adaptive Shrink-Restore (ASR), towards preserving the model's plasticity. In particular, ASR does the weight re-initialization by the adaptive intervals. The adaptive interval is determined based on the change in label flipping. Our method is validated on extensive CTTA benchmarks, achieving excellent performance.
<div id='section'>Paperid: <span id='pid'>237, <a href='https://arxiv.org/pdf/2411.15173.pdf' target='_blank'>https://arxiv.org/pdf/2411.15173.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zixian Su, Jingwei Guo, Xi Yang, Qiufeng Wang, Kaizhu Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.15173">Un-mixing Test-time Adaptation under Heterogeneous Data Streams</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deploying deep models in real-world scenarios remains challenging due to significant performance drops under distribution shifts between training and deployment environments. Test-Time Adaptation (TTA) has recently emerged as a promising solution, enabling on-the-fly model adaptation without access to source data. However, its effectiveness degrades significantly in the presence of complex, mixed distribution shifts - common in practical settings - where multiple latent domains coexist. Adapting under such intrinsic heterogeneity, especially in unlabeled and online conditions, remains an open and underexplored challenge. In this paper, we study TTA under mixed distribution shifts and move beyond conventional homogeneous adaptation paradigms. By revisiting TTA from a frequency-domain perspective, we observe that distribution heterogeneity often manifests in Fourier space - for instance, high-frequency components tend to carry domain-specific variations. This motivates us to perform domain-aware separation using high-frequency texture cues, making diverse shift patterns more tractable. To this end, we propose FreDA, a novel Frequency-based Decentralized Adaptation framework that decomposes globally heterogeneous data into locally homogeneous components in the frequency domain. It further employs decentralized learning and augmentation strategies to robustly adapt under complex, evolving shifts. Extensive experiments across various environments (corrupted, natural, and medical) demonstrate the superiority of our proposed framework over the state-of-the-arts.
<div id='section'>Paperid: <span id='pid'>238, <a href='https://arxiv.org/pdf/2405.03000.pdf' target='_blank'>https://arxiv.org/pdf/2405.03000.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenqi Shi, Ran Xu, Yuchen Zhuang, Yue Yu, Haotian Sun, Hang Wu, Carl Yang, May D. Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.03000">MedAdapter: Efficient Test-Time Adaptation of Large Language Models towards Medical Reasoning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite their improved capabilities in generation and reasoning, adapting large language models (LLMs) to the biomedical domain remains challenging due to their immense size and corporate privacy. In this work, we propose MedAdapter, a unified post-hoc adapter for test-time adaptation of LLMs towards biomedical applications. Instead of fine-tuning the entire LLM, MedAdapter effectively adapts the original model by fine-tuning only a small BERT-sized adapter to rank candidate solutions generated by LLMs. Experiments demonstrate that MedAdapter effectively adapts both white-box and black-box LLMs in biomedical reasoning, achieving average performance improvements of 25.48% and 11.31%, respectively, without requiring extensive computational resources or sharing data with third parties. MedAdapter also yields superior performance when combined with train-time adaptation, highlighting a flexible and complementary solution to existing adaptation methods. Faced with the challenges of balancing model performance, computational resources, and data privacy, MedAdapter provides an efficient, privacy-preserving, cost-effective, and transparent solution for adapting LLMs to the biomedical domain.
<div id='section'>Paperid: <span id='pid'>239, <a href='https://arxiv.org/pdf/2404.17930.pdf' target='_blank'>https://arxiv.org/pdf/2404.17930.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>BenoÃ®t GÃ©rin, AnaÃ¯s Halin, Anthony Cioppa, Maxim Henry, Bernard Ghanem, BenoÃ®t Macq, Christophe De Vleeschouwer, Marc Van Droogenbroeck
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.17930">Multi-Stream Cellular Test-Time Adaptation of Real-Time Models Evolving in Dynamic Environments</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the era of the Internet of Things (IoT), objects connect through a dynamic network, empowered by technologies like 5G, enabling real-time data sharing. However, smart objects, notably autonomous vehicles, face challenges in critical local computations due to limited resources. Lightweight AI models offer a solution but struggle with diverse data distributions. To address this limitation, we propose a novel Multi-Stream Cellular Test-Time Adaptation (MSC-TTA) setup where models adapt on the fly to a dynamic environment divided into cells. Then, we propose a real-time adaptive student-teacher method that leverages the multiple streams available in each cell to quickly adapt to changing data distributions. We validate our methodology in the context of autonomous vehicles navigating across cells defined based on location and weather conditions. To facilitate future benchmarking, we release a new multi-stream large-scale synthetic semantic segmentation dataset, called DADE, and show that our multi-stream approach outperforms a single-stream baseline. We believe that our work will open research opportunities in the IoT and 5G eras, offering solutions for real-time model adaptation.
<div id='section'>Paperid: <span id='pid'>240, <a href='https://arxiv.org/pdf/2404.13571.pdf' target='_blank'>https://arxiv.org/pdf/2404.13571.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaxin Zhang, Yiqi Wang, Xihong Yang, Siwei Wang, Yu Feng, Yu Shi, Ruicaho Ren, En Zhu, Xinwang Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.13571">Test-Time Training on Graphs with Large Language Models (LLMs)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph Neural Networks have demonstrated great success in various fields of multimedia. However, the distribution shift between the training and test data challenges the effectiveness of GNNs. To mitigate this challenge, Test-Time Training (TTT) has been proposed as a promising approach. Traditional TTT methods require a demanding unsupervised training strategy to capture the information from test to benefit the main task. Inspired by the great annotation ability of Large Language Models (LLMs) on Text-Attributed Graphs (TAGs), we propose to enhance the test-time training on graphs with LLMs as annotators. In this paper, we design a novel Test-Time Training pipeline, LLMTTT, which conducts the test-time adaptation under the annotations by LLMs on a carefully-selected node set. Specifically, LLMTTT introduces a hybrid active node selection strategy that considers not only node diversity and representativeness, but also prediction signals from the pre-trained model. Given annotations from LLMs, a two-stage training strategy is designed to tailor the test-time model with the limited and noisy labels. A theoretical analysis ensures the validity of our method and extensive experiments demonstrate that the proposed LLMTTT can achieve a significant performance improvement compared to existing Out-of-Distribution (OOD) generalization methods.
<div id='section'>Paperid: <span id='pid'>241, <a href='https://arxiv.org/pdf/2506.02453.pdf' target='_blank'>https://arxiv.org/pdf/2506.02453.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kunyu Wang, Xueyang Fu, Yuanfei Bao, Chengjie Ge, Chengzhi Cao, Wei Zhai, Zheng-Jun Zha
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.02453">PAID: Pairwise Angular-Invariant Decomposition for Continual Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual Test-Time Adaptation (CTTA) aims to online adapt a pre-trained model to changing environments during inference. Most existing methods focus on exploiting target data, while overlooking another crucial source of information, the pre-trained weights, which encode underutilized domain-invariant priors. This paper takes the geometric attributes of pre-trained weights as a starting point, systematically analyzing three key components: magnitude, absolute angle, and pairwise angular structure. We find that the pairwise angular structure remains stable across diverse corrupted domains and encodes domain-invariant semantic information, suggesting it should be preserved during adaptation. Based on this insight, we propose PAID (Pairwise Angular-Invariant Decomposition), a prior-driven CTTA method that decomposes weight into magnitude and direction, and introduces a learnable orthogonal matrix via Householder reflections to globally rotate direction while preserving the pairwise angular structure. During adaptation, only the magnitudes and the orthogonal matrices are updated. PAID achieves consistent improvements over recent SOTA methods on four widely used CTTA benchmarks, demonstrating that preserving pairwise angular structure offers a simple yet effective principle for CTTA.
<div id='section'>Paperid: <span id='pid'>242, <a href='https://arxiv.org/pdf/2407.06310.pdf' target='_blank'>https://arxiv.org/pdf/2407.06310.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mengzhe Geng, Xurong Xie, Jiajun Deng, Zengrui Jin, Guinan Li, Tianzi Wang, Shujie Hu, Zhaoqing Li, Helen Meng, Xunying Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.06310">Homogeneous Speaker Features for On-the-Fly Dysarthric and Elderly Speaker Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The application of data-intensive automatic speech recognition (ASR) technologies to dysarthric and elderly adult speech is confronted by their mismatch against healthy and nonaged voices, data scarcity and large speaker-level variability. To this end, this paper proposes two novel data-efficient methods to learn homogeneous dysarthric and elderly speaker-level features for rapid, on-the-fly test-time adaptation of DNN/TDNN and Conformer ASR models. These include: 1) speaker-level variance-regularized spectral basis embedding (VR-SBE) features that exploit a special regularization term to enforce homogeneity of speaker features in adaptation; and 2) feature-based learning hidden unit contributions (f-LHUC) transforms that are conditioned on VR-SBE features. Experiments are conducted on four tasks across two languages: the English UASpeech and TORGO dysarthric speech datasets, the English DementiaBank Pitt and Cantonese JCCOCC MoCA elderly speech corpora. The proposed on-the-fly speaker adaptation techniques consistently outperform baseline iVector and xVector adaptation by statistically significant word or character error rate reductions up to 5.32% absolute (18.57% relative) and batch-mode LHUC speaker adaptation by 2.24% absolute (9.20% relative), while operating with real-time factors speeding up to 33.6 times against xVectors during adaptation. The efficacy of the proposed adaptation techniques is demonstrated in a comparison against current ASR technologies including SSL pre-trained systems on UASpeech, where our best system produces a state-of-the-art WER of 23.33%. Analyses show VR-SBE features and f-LHUC transforms are insensitive to speaker-level data quantity in testtime adaptation. T-SNE visualization reveals they have stronger speaker-level homogeneity than baseline iVectors, xVectors and batch-mode LHUC transforms.
<div id='section'>Paperid: <span id='pid'>243, <a href='https://arxiv.org/pdf/2306.14608.pdf' target='_blank'>https://arxiv.org/pdf/2306.14608.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiajun Deng, Guinan Li, Xurong Xie, Zengrui Jin, Mingyu Cui, Tianzi Wang, Shujie Hu, Mengzhe Geng, Xunying Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.14608">Factorised Speaker-environment Adaptive Training of Conformer Speech Recognition Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Rich sources of variability in natural speech present significant challenges to current data intensive speech recognition technologies. To model both speaker and environment level diversity, this paper proposes a novel Bayesian factorised speaker-environment adaptive training and test time adaptation approach for Conformer ASR models. Speaker and environment level characteristics are separately modeled using compact hidden output transforms, which are then linearly or hierarchically combined to represent any speaker-environment combination. Bayesian learning is further utilized to model the adaptation parameter uncertainty. Experiments on the 300-hr WHAM noise corrupted Switchboard data suggest that factorised adaptation consistently outperforms the baseline and speaker label only adapted Conformers by up to 3.1% absolute (10.4% relative) word error rate reductions. Further analysis shows the proposed method offers potential for rapid adaption to unseen speaker-environment conditions.
<div id='section'>Paperid: <span id='pid'>244, <a href='https://arxiv.org/pdf/2508.14437.pdf' target='_blank'>https://arxiv.org/pdf/2508.14437.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gabriel Tjio, Jie Zhang, Xulei Yang, Yun Xing, Nhat Chung, Xiaofeng Cao, Ivor W. Tsang, Chee Keong Kwoh, Qing Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.14437">FOCUS: Frequency-Optimized Conditioning of DiffUSion Models for mitigating catastrophic forgetting during Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation enables models to adapt to evolving domains. However, balancing the tradeoff between preserving knowledge and adapting to domain shifts remains challenging for model adaptation methods, since adapting to domain shifts can induce forgetting of task-relevant knowledge. To address this problem, we propose FOCUS, a novel frequency-based conditioning approach within a diffusion-driven input-adaptation framework. Utilising learned, spatially adaptive frequency priors, our approach conditions the reverse steps during diffusion-driven denoising to preserve task-relevant semantic information for dense prediction.
  FOCUS leverages a trained, lightweight, Y-shaped Frequency Prediction Network (Y-FPN) that disentangles high and low frequency information from noisy images. This minimizes the computational costs involved in implementing our approach in a diffusion-driven framework. We train Y-FPN with FrequencyMix, a novel data augmentation method that perturbs the images across diverse frequency bands, which improves the robustness of our approach to diverse corruptions.
  We demonstrate the effectiveness of FOCUS for semantic segmentation and monocular depth estimation across 15 corruption types and three datasets, achieving state-of-the-art averaged performance. In addition to improving standalone performance, FOCUS complements existing model adaptation methods since we can derive pseudo labels from FOCUS-denoised images for additional supervision. Even under limited, intermittent supervision with the pseudo labels derived from the FOCUS denoised images, we show that FOCUS mitigates catastrophic forgetting for recent model adaptation methods.
<div id='section'>Paperid: <span id='pid'>245, <a href='https://arxiv.org/pdf/2505.17931.pdf' target='_blank'>https://arxiv.org/pdf/2505.17931.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xingjian Li, Qifeng Wu, Colleen Que, Yiran Ding, Adithya S. Ubaradka, Jianhua Xing, Tianyang Wang, Min Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.17931">AutoMiSeg: Automatic Medical Image Segmentation via Test-Time Adaptation of Foundation Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Medical image segmentation is vital for clinical diagnosis, yet current deep learning methods often demand extensive expert effort, i.e., either through annotating large training datasets or providing prompts at inference time for each new case. This paper introduces a zero-shot and automatic segmentation pipeline that combines off-the-shelf vision-language and segmentation foundation models. Given a medical image and a task definition (e.g., "segment the optic disc in an eye fundus image"), our method uses a grounding model to generate an initial bounding box, followed by a visual prompt boosting module that enhance the prompts, which are then processed by a promptable segmentation model to produce the final mask. To address the challenges of domain gap and result verification, we introduce a test-time adaptation framework featuring a set of learnable adaptors that align the medical inputs with foundation model representations. Its hyperparameters are optimized via Bayesian Optimization, guided by a proxy validation model without requiring ground-truth labels. Our pipeline offers an annotation-efficient and scalable solution for zero-shot medical image segmentation across diverse tasks. Our pipeline is evaluated on seven diverse medical imaging datasets and shows promising results. By proper decomposition and test-time adaptation, our fully automatic pipeline performs competitively with weakly-prompted interactive foundation models.
<div id='section'>Paperid: <span id='pid'>246, <a href='https://arxiv.org/pdf/2505.17931.pdf' target='_blank'>https://arxiv.org/pdf/2505.17931.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xingjian Li, Qifeng Wu, Adithya S. Ubaradka, Yiran Ding, Colleen Que, Runmin Jiang, Jianhua Xing, Tianyang Wang, Min Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.17931">AutoMiSeg: Automatic Medical Image Segmentation via Test-Time Adaptation of Foundation Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Medical image segmentation is vital for clinical diagnosis, yet current deep learning methods often demand extensive expert effort, i.e., either through annotating large training datasets or providing prompts at inference time for each new case. This paper introduces a zero-shot and automatic segmentation pipeline that combines off-the-shelf vision-language and segmentation foundation models. Given a medical image and a task definition (e.g., "segment the optic disc in an eye fundus image"), our method uses a grounding model to generate an initial bounding box, followed by a visual prompt boosting module that enhance the prompts, which are then processed by a promptable segmentation model to produce the final mask. To address the challenges of domain gap and result verification, we introduce a test-time adaptation framework featuring a set of learnable adaptors that align the medical inputs with foundation model representations. Its hyperparameters are optimized via Bayesian Optimization, guided by a proxy validation model without requiring ground-truth labels. Our pipeline offers an annotation-efficient and scalable solution for zero-shot medical image segmentation across diverse tasks. Our pipeline is evaluated on seven diverse medical imaging datasets and shows promising results. By proper decomposition and test-time adaptation, our fully automatic pipeline not only substantially surpasses the previously best-performing method, yielding a 69\% relative improvement in accuracy (Dice Score from 42.53 to 71.81), but also performs competitively with weakly-prompted interactive foundation models.
<div id='section'>Paperid: <span id='pid'>247, <a href='https://arxiv.org/pdf/2505.17931.pdf' target='_blank'>https://arxiv.org/pdf/2505.17931.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xingjian Li, Qifeng Wu, Adithya S. Ubaradka, Yiran Ding, Colleen Que, Runmin Jiang, Jianhua Xing, Tianyang Wang, Min Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.17931">AutoMiSeg: Automatic Medical Image Segmentation via Test-Time Adaptation of Foundation Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Medical image segmentation is vital for clinical diagnosis, yet current deep learning methods often demand extensive expert effort, i.e., either through annotating large training datasets or providing prompts at inference time for each new case. This paper introduces a zero-shot and automatic segmentation pipeline that combines off-the-shelf vision-language and segmentation foundation models. Given a medical image and a task definition (e.g., "segment the optic disc in an eye fundus image"), our method uses a grounding model to generate an initial bounding box, followed by a visual prompt boosting module that enhance the prompts, which are then processed by a promptable segmentation model to produce the final mask. To address the challenges of domain gap and result verification, we introduce a test-time adaptation framework featuring a set of learnable adaptors that align the medical inputs with foundation model representations. Its hyperparameters are optimized via Bayesian Optimization, guided by a proxy validation model without requiring ground-truth labels. Our pipeline offers an annotation-efficient and scalable solution for zero-shot medical image segmentation across diverse tasks. Our pipeline is evaluated on seven diverse medical imaging datasets and shows promising results. By proper decomposition and test-time adaptation, our fully automatic pipeline not only substantially surpasses the previously best-performing method, yielding a 69\% relative improvement in accuracy (Dice Score from 42.53 to 71.81), but also performs competitively with weakly-prompted interactive foundation models.
<div id='section'>Paperid: <span id='pid'>248, <a href='https://arxiv.org/pdf/2505.11883.pdf' target='_blank'>https://arxiv.org/pdf/2505.11883.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zihuan Qiu, Yi Xu, Chiyuan He, Fanman Meng, Linfeng Xu, Qingbo Wu, Hongliang Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11883">MINGLE: Mixtures of Null-Space Gated Low-Rank Experts for Test-Time Continual Model Merging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual model merging integrates independently fine-tuned models sequentially without access to original training data, providing a scalable and efficient solution to continual learning. However, current methods still face critical challenges, notably parameter interference among tasks and limited adaptability to evolving test distributions. The former causes catastrophic forgetting of integrated tasks, while the latter hinders effective adaptation to new tasks. To address these, we propose MINGLE, a novel framework for test-time continual model merging, which leverages test-time adaptation using a small set of unlabeled test samples from the current task to dynamically guide the merging process. MINGLE employs a mixture-of-experts architecture composed of parameter-efficient, low-rank experts, enabling efficient adaptation and improving robustness to distribution shifts. To mitigate catastrophic forgetting, we propose Null-Space Constrained Gating, which restricts gating updates to subspaces orthogonal to prior task representations. This suppresses activations on old task inputs and preserves model behavior on past tasks. To further balance stability and adaptability, we design an Adaptive Relaxation Strategy, which dynamically adjusts the constraint strength based on interference signals captured during test-time adaptation. Extensive experiments on standard continual merging benchmarks demonstrate that MINGLE achieves robust generalization, reduces forgetting significantly, and consistently surpasses previous state-of-the-art methods by 7-9\% on average across diverse task orders.
<div id='section'>Paperid: <span id='pid'>249, <a href='https://arxiv.org/pdf/2303.14333.pdf' target='_blank'>https://arxiv.org/pdf/2303.14333.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luca Zancato, Alessandro Achille, Tian Yu Liu, Matthew Trager, Pramuditha Perera, Stefano Soatto
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.14333">Train/Test-Time Adaptation with Retrieval</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce Train/Test-Time Adaptation with Retrieval (${\rm T^3AR}$), a method to adapt models both at train and test time by means of a retrieval module and a searchable pool of external samples. Before inference, ${\rm T^3AR}$ adapts a given model to the downstream task using refined pseudo-labels and a self-supervised contrastive objective function whose noise distribution leverages retrieved real samples to improve feature adaptation on the target data manifold. The retrieval of real images is key to ${\rm T^3AR}$ since it does not rely solely on synthetic data augmentations to compensate for the lack of adaptation data, as typically done by other adaptation algorithms. Furthermore, thanks to the retrieval module, our method gives the user or service provider the possibility to improve model adaptation on the downstream task by incorporating further relevant data or to fully remove samples that may no longer be available due to changes in user preference after deployment. First, we show that ${\rm T^3AR}$ can be used at training time to improve downstream fine-grained classification over standard fine-tuning baselines, and the fewer the adaptation data the higher the relative improvement (up to 13%). Second, we apply ${\rm T^3AR}$ for test-time adaptation and show that exploiting a pool of external images at test-time leads to more robust representations over existing methods on DomainNet-126 and VISDA-C, especially when few adaptation data are available (up to 8%).
<div id='section'>Paperid: <span id='pid'>250, <a href='https://arxiv.org/pdf/2505.16524.pdf' target='_blank'>https://arxiv.org/pdf/2505.16524.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Huitong Yang, Zhuoxiao Chen, Fengyi Zhang, Zi Huang, Yadan Luo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.16524">CodeMerge: Codebook-Guided Model Merging for Robust Test-Time Adaptation in Autonomous Driving</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Maintaining robust 3D perception under dynamic and unpredictable test-time conditions remains a critical challenge for autonomous driving systems. Existing test-time adaptation (TTA) methods often fail in high-variance tasks like 3D object detection due to unstable optimization and sharp minima. While recent model merging strategies based on linear mode connectivity (LMC) offer improved stability by interpolating between fine-tuned checkpoints, they are computationally expensive, requiring repeated checkpoint access and multiple forward passes. In this paper, we introduce CodeMerge, a lightweight and scalable model merging framework that bypasses these limitations by operating in a compact latent space. Instead of loading full models, CodeMerge represents each checkpoint with a low-dimensional fingerprint derived from the source model's penultimate features and constructs a key-value codebook. We compute merging coefficients using ridge leverage scores on these fingerprints, enabling efficient model composition without compromising adaptation quality. Our method achieves strong performance across challenging benchmarks, improving end-to-end 3D detection 14.9% NDS on nuScenes-C and LiDAR-based detection by over 7.6% mAP on nuScenes-to-KITTI, while benefiting downstream tasks such as online mapping, motion prediction and planning even without training. Code and pretrained models are released in the supplementary material.
<div id='section'>Paperid: <span id='pid'>251, <a href='https://arxiv.org/pdf/2505.11350.pdf' target='_blank'>https://arxiv.org/pdf/2505.11350.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Derek Ming Siang Tan, Shailesh, Boyang Liu, Alok Raj, Qi Xuan Ang, Weiheng Dai, Tanishq Duhan, Jimmy Chiun, Yuhong Cao, Florian Shkurti, Guillaume Sartoretti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11350">Search-TTA: A Multimodal Test-Time Adaptation Framework for Visual Search in the Wild</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To perform outdoor autonomous visual navigation and search, a robot may leverage satellite imagery as a prior map. This can help inform high-level search and exploration strategies, even when such images lack sufficient resolution to allow for visual recognition of targets. However, there are limited training datasets of satellite images with annotated targets that are not directly visible. Furthermore, approaches which leverage large Vision Language Models (VLMs) for generalization may yield inaccurate outputs due to hallucination, leading to inefficient search. To address these challenges, we introduce Search-TTA, a multimodal test-time adaptation framework with a flexible plug-and-play interface compatible with various input modalities (e.g. image, text, sound) and planning methods. First, we pretrain a satellite image encoder to align with CLIP's visual encoder to output probability distributions of target presence used for visual search. Second, our framework dynamically refines CLIP's predictions during search using a test-time adaptation mechanism. Through a novel feedback loop inspired by Spatial Poisson Point Processes, uncertainty-weighted gradient updates are used to correct potentially inaccurate predictions and improve search performance. To train and evaluate Search-TTA, we curate AVS-Bench, a visual search dataset based on internet-scale ecological data that contains up to 380k training and 8k validation images (in- and out-domain). We find that Search-TTA improves planner performance by up to 30.0%, particularly in cases with poor initial CLIP predictions due to limited training data. It also performs comparably with significantly larger VLMs, and achieves zero-shot generalization to unseen modalities. Finally, we deploy Search-TTA on a real UAV via hardware-in-the-loop testing, by simulating its operation within a large-scale simulation that provides onboard sensing.
<div id='section'>Paperid: <span id='pid'>252, <a href='https://arxiv.org/pdf/2505.11350.pdf' target='_blank'>https://arxiv.org/pdf/2505.11350.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Derek Ming Siang Tan, Shailesh, Boyang Liu, Alok Raj, Qi Xuan Ang, Weiheng Dai, Tanishq Duhan, Jimmy Chiun, Yuhong Cao, Florian Shkurti, Guillaume Sartoretti
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11350">Search-TTA: A Multimodal Test-Time Adaptation Framework for Visual Search in the Wild</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>To perform outdoor autonomous visual navigation and search, a robot may leverage satellite imagery as a prior map. This can help inform high-level search and exploration strategies, even when such images lack sufficient resolution to allow for visual recognition of targets. However, there are limited training datasets of satellite images with annotated targets that are not directly visible. Furthermore, approaches which leverage large Vision Language Models (VLMs) for generalization may yield inaccurate outputs due to hallucination, leading to inefficient search. To address these challenges, we introduce Search-TTA, a multimodal test-time adaptation framework with a flexible plug-and-play interface compatible with various input modalities (e.g. image, text, sound) and planning methods. First, we pretrain a satellite image encoder to align with CLIP's visual encoder to output probability distributions of target presence used for visual search. Second, our framework dynamically refines CLIP's predictions during search using a test-time adaptation mechanism. Through a novel feedback loop inspired by Spatial Poisson Point Processes, uncertainty-weighted gradient updates are used to correct potentially inaccurate predictions and improve search performance. To train and evaluate Search-TTA, we curate AVS-Bench, a visual search dataset based on internet-scale ecological data that contains up to 380k training and 8k validation images (in- and out-domain). We find that Search-TTA improves planner performance by up to 30.0%, particularly in cases with poor initial CLIP predictions due to limited training data. It also performs comparably with significantly larger VLMs, and achieves zero-shot generalization to unseen modalities. Finally, we deploy Search-TTA on a real UAV via hardware-in-the-loop testing, by simulating its operation within a large-scale simulation that provides onboard sensing.
<div id='section'>Paperid: <span id='pid'>253, <a href='https://arxiv.org/pdf/2410.14729.pdf' target='_blank'>https://arxiv.org/pdf/2410.14729.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zixin Wang, Dong Gong, Sen Wang, Zi Huang, Yadan Luo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.14729">Is Less More? Exploring Token Condensation as Training-free Test-time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Contrastive Language-Image Pretraining (CLIP) excels at learning generalizable image representations but often falls short in zero-shot inference on certain downstream datasets. Test-time adaptation (TTA) mitigates this issue by adjusting components like normalization layers or context prompts, yet it typically requires large batch sizes and extensive augmentations, leading to high computational costs. This raises a key question: Can VLMs' performance drop in specific test cases be mitigated through efficient, training-free approaches? To explore the solution, we investigate token condensation (TC) techniques, originally designed to enhance vision transformer efficiency by refining token usage during inference. We observe that informative tokens improve visual-text alignment in VLMs like CLIP on unseen datasets. However, existing TC methods often fail to maintain in-distribution performance when reducing tokens, prompting us to ask: How can we transform TC into an effective ``free-lunch'' adaptation strategy for VLMs? To address this, we propose Token Condensation as Adaptation (TCA), a training-free adaptation method that takes a step beyond standard TC. Rather than passively discarding tokens, TCA condenses token representation by introducing reservoir-based domain anchor tokens for information-preserving token reduction and logits correction. TCA achieves up to a 21.4% performance improvement over the strongest baseline on cross-dataset benchmark and the CIFAR-100-Corrupted dataset while reducing GFLOPs by 12.2% to 48.9%, with minimal hyperparameter dependency on both CLIP and SigLIP series.
<div id='section'>Paperid: <span id='pid'>254, <a href='https://arxiv.org/pdf/2406.13891.pdf' target='_blank'>https://arxiv.org/pdf/2406.13891.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhuoxiao Chen, Zixin Wang, Yadan Luo, Sen Wang, Zi Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.13891">DPO: Dual-Perturbation Optimization for Test-time Adaptation in 3D Object Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>LiDAR-based 3D object detection has seen impressive advances in recent times. However, deploying trained 3D detectors in the real world often yields unsatisfactory performance when the distribution of the test data significantly deviates from the training data due to different weather conditions, object sizes, \textit{etc}. A key factor in this performance degradation is the diminished generalizability of pre-trained models, which creates a sharp loss landscape during training. Such sharpness, when encountered during testing, can precipitate significant performance declines, even with minor data variations. To address the aforementioned challenges, we propose \textbf{dual-perturbation optimization (DPO)} for \textbf{\underline{T}est-\underline{t}ime \underline{A}daptation in \underline{3}D \underline{O}bject \underline{D}etection (TTA-3OD)}. We minimize the sharpness to cultivate a flat loss landscape to ensure model resiliency to minor data variations, thereby enhancing the generalization of the adaptation process. To fully capture the inherent variability of the test point clouds, we further introduce adversarial perturbation to the input BEV features to better simulate the noisy test environment. As the dual perturbation strategy relies on trustworthy supervision signals, we utilize a reliable Hungarian matcher to filter out pseudo-labels sensitive to perturbations. Additionally, we introduce early Hungarian cutoff to avoid error accumulation from incorrect pseudo-labels by halting the adaptation process. Extensive experiments across three types of transfer tasks demonstrate that the proposed DPO significantly surpasses previous state-of-the-art approaches, specifically on Waymo $\rightarrow$ KITTI, outperforming the most competitive baseline by 57.72\% in $\text{AP}_\text{3D}$ and reaching 91\% of the fully supervised upper bound.
<div id='section'>Paperid: <span id='pid'>255, <a href='https://arxiv.org/pdf/2410.07695.pdf' target='_blank'>https://arxiv.org/pdf/2410.07695.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Leyi Zhu, Weihuang Liu, Xinyi Chen, Zimeng Li, Xuhang Chen, Zhen Wang, Chi-Man Pun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.07695">Test-Time Intensity Consistency Adaptation for Shadow Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Shadow detection is crucial for accurate scene understanding in computer vision, yet it is challenged by the diverse appearances of shadows caused by variations in illumination, object geometry, and scene context. Deep learning models often struggle to generalize to real-world images due to the limited size and diversity of training datasets. To address this, we introduce TICA, a novel framework that leverages light-intensity information during test-time adaptation to enhance shadow detection accuracy. TICA exploits the inherent inconsistencies in light intensity across shadow regions to guide the model toward a more consistent prediction. A basic encoder-decoder model is initially trained on a labeled dataset for shadow detection. Then, during the testing phase, the network is adjusted for each test sample by enforcing consistent intensity predictions between two augmented input image versions. This consistency training specifically targets both foreground and background intersection regions to identify shadow regions within images accurately for robust adaptation. Extensive evaluations on the ISTD and SBU shadow detection datasets reveal that TICA significantly demonstrates that TICA outperforms existing state-of-the-art methods, achieving superior results in balanced error rate (BER).
<div id='section'>Paperid: <span id='pid'>256, <a href='https://arxiv.org/pdf/2407.06450.pdf' target='_blank'>https://arxiv.org/pdf/2407.06450.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Elena Camuffo, Umberto Michieli, Simone Milani, Jijoong Moon, Mete Ozay
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.06450">Enhanced Model Robustness to Input Corruptions by Per-corruption Adaptation of Normalization Statistics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Developing a reliable vision system is a fundamental challenge for robotic technologies (e.g., indoor service robots and outdoor autonomous robots) which can ensure reliable navigation even in challenging environments such as adverse weather conditions (e.g., fog, rain), poor lighting conditions (e.g., over/under exposure), or sensor degradation (e.g., blurring, noise), and can guarantee high performance in safety-critical functions. Current solutions proposed to improve model robustness usually rely on generic data augmentation techniques or employ costly test-time adaptation methods. In addition, most approaches focus on addressing a single vision task (typically, image recognition) utilising synthetic data. In this paper, we introduce Per-corruption Adaptation of Normalization statistics (PAN) to enhance the model robustness of vision systems. Our approach entails three key components: (i) a corruption type identification module, (ii) dynamic adjustment of normalization layer statistics based on identified corruption type, and (iii) real-time update of these statistics according to input data. PAN can integrate seamlessly with any convolutional model for enhanced accuracy in several robot vision tasks. In our experiments, PAN obtains robust performance improvement on challenging real-world corrupted image datasets (e.g., OpenLoris, ExDark, ACDC), where most of the current solutions tend to fail. Moreover, PAN outperforms the baseline models by 20-30% on synthetic benchmarks in object recognition tasks.
<div id='section'>Paperid: <span id='pid'>257, <a href='https://arxiv.org/pdf/2306.14479.pdf' target='_blank'>https://arxiv.org/pdf/2306.14479.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinxin Liu, Hongyin Zhang, Zifeng Zhuang, Yachen Kang, Donglin Wang, Bin Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.14479">Design from Policies: Conservative Test-Time Adaptation for Offline Policy Optimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we decouple the iterative bi-level offline RL (value estimation and policy extraction) from the offline training phase, forming a non-iterative bi-level paradigm and avoiding the iterative error propagation over two levels. Specifically, this non-iterative paradigm allows us to conduct inner-level optimization (value estimation) in training, while performing outer-level optimization (policy extraction) in testing. Naturally, such a paradigm raises three core questions that are not fully answered by prior non-iterative offline RL counterparts like reward-conditioned policy: (q1) What information should we transfer from the inner-level to the outer-level? (q2) What should we pay attention to when exploiting the transferred information for safe/confident outer-level optimization? (q3) What are the benefits of concurrently conducting outer-level optimization during testing? Motivated by model-based optimization (MBO), we propose DROP (design from policies), which fully answers the above questions. Specifically, in the inner-level, DROP decomposes offline data into multiple subsets, and learns an MBO score model (a1). To keep safe exploitation to the score model in the outer-level, we explicitly learn a behavior embedding and introduce a conservative regularization (a2). During testing, we show that DROP permits deployment adaptation, enabling an adaptive inference across states (a3). Empirically, we evaluate DROP on various tasks, showing that DROP gains comparable or better performance compared to prior methods.
<div id='section'>Paperid: <span id='pid'>258, <a href='https://arxiv.org/pdf/2503.09248.pdf' target='_blank'>https://arxiv.org/pdf/2503.09248.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lihua Zhou, Mao Ye, Shuaifeng Li, Nianxin Li, Xiatian Zhu, Lei Deng, Hongbin Liu, Zhen Lei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.09248">Bayesian Test-Time Adaptation for Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation with pre-trained vision-language models, such as CLIP, aims to adapt the model to new, potentially out-of-distribution test data. Existing methods calculate the similarity between visual embedding and learnable class embeddings, which are initialized by text embeddings, for zero-shot image classification. In this work, we first analyze this process based on Bayes theorem, and observe that the core factors influencing the final prediction are the likelihood and the prior. However, existing methods essentially focus on adapting class embeddings to adapt likelihood, but they often ignore the importance of prior. To address this gap, we propose a novel approach, \textbf{B}ayesian \textbf{C}lass \textbf{A}daptation (BCA), which in addition to continuously updating class embeddings to adapt likelihood, also uses the posterior of incoming samples to continuously update the prior for each class embedding. This dual updating mechanism allows the model to better adapt to distribution shifts and achieve higher prediction accuracy. Our method not only surpasses existing approaches in terms of performance metrics but also maintains superior inference rates and memory usage, making it highly efficient and practical for real-world applications.
<div id='section'>Paperid: <span id='pid'>259, <a href='https://arxiv.org/pdf/2411.00632.pdf' target='_blank'>https://arxiv.org/pdf/2411.00632.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jincen Jiang, Qianyu Zhou, Yuhang Li, Xinkui Zhao, Meili Wang, Lizhuang Ma, Jian Chang, Jian Jun Zhang, Xuequan Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.00632">PCoTTA: Continual Test-Time Adaptation for Multi-Task Point Cloud Understanding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we present PCoTTA, an innovative, pioneering framework for Continual Test-Time Adaptation (CoTTA) in multi-task point cloud understanding, enhancing the model's transferability towards the continually changing target domain. We introduce a multi-task setting for PCoTTA, which is practical and realistic, handling multiple tasks within one unified model during the continual adaptation. Our PCoTTA involves three key components: automatic prototype mixture (APM), Gaussian Splatted feature shifting (GSFS), and contrastive prototype repulsion (CPR). Firstly, APM is designed to automatically mix the source prototypes with the learnable prototypes with a similarity balancing factor, avoiding catastrophic forgetting. Then, GSFS dynamically shifts the testing sample toward the source domain, mitigating error accumulation in an online manner. In addition, CPR is proposed to pull the nearest learnable prototype close to the testing feature and push it away from other prototypes, making each prototype distinguishable during the adaptation. Experimental comparisons lead to a new benchmark, demonstrating PCoTTA's superiority in boosting the model's transferability towards the continually changing target domain.
<div id='section'>Paperid: <span id='pid'>260, <a href='https://arxiv.org/pdf/2408.09494.pdf' target='_blank'>https://arxiv.org/pdf/2408.09494.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiran Song, Qianyu Zhou, Lizhuang Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.09494">Source-Free Test-Time Adaptation For Online Surface-Defect Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Surface defect detection is significant in industrial production. However, detecting defects with varying textures and anomaly classes during the test time is challenging. This arises due to the differences in data distributions between source and target domains. Collecting and annotating new data from the target domain and retraining the model is time-consuming and costly. In this paper, we propose a novel test-time adaptation surface-defect detection approach that adapts pre-trained models to new domains and classes during inference. Our approach involves two core ideas. Firstly, we introduce a supervisor to filter samples and select only those with high confidence to update the model. This ensures that the model is not excessively biased by incorrect data. Secondly, we propose the augmented mean prediction to generate robust pseudo labels and a dynamically-balancing loss to facilitate the model in effectively integrating classification and segmentation results to improve surface-defect detection accuracy. Our approach is real-time and does not require additional offline retraining. Experiments demonstrate it outperforms state-of-the-art techniques.
<div id='section'>Paperid: <span id='pid'>261, <a href='https://arxiv.org/pdf/2308.08505.pdf' target='_blank'>https://arxiv.org/pdf/2308.08505.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianshuo Cong, Xinlei He, Yun Shen, Yang Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.08505">Test-Time Poisoning Attacks Against Test-Time Adaptation Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deploying machine learning (ML) models in the wild is challenging as it suffers from distribution shifts, where the model trained on an original domain cannot generalize well to unforeseen diverse transfer domains. To address this challenge, several test-time adaptation (TTA) methods have been proposed to improve the generalization ability of the target pre-trained models under test data to cope with the shifted distribution. The success of TTA can be credited to the continuous fine-tuning of the target model according to the distributional hint from the test samples during test time. Despite being powerful, it also opens a new attack surface, i.e., test-time poisoning attacks, which are substantially different from previous poisoning attacks that occur during the training time of ML models (i.e., adversaries cannot intervene in the training process). In this paper, we perform the first test-time poisoning attack against four mainstream TTA methods, including TTT, DUA, TENT, and RPL. Concretely, we generate poisoned samples based on the surrogate models and feed them to the target TTA models. Experimental results show that the TTA methods are generally vulnerable to test-time poisoning attacks. For instance, the adversary can feed as few as 10 poisoned samples to degrade the performance of the target model from 76.20% to 41.83%. Our results demonstrate that TTA algorithms lacking a rigorous security assessment are unsuitable for deployment in real-life scenarios. As such, we advocate for the integration of defenses against test-time poisoning attacks into the design of TTA methods.
<div id='section'>Paperid: <span id='pid'>262, <a href='https://arxiv.org/pdf/2407.04396.pdf' target='_blank'>https://arxiv.org/pdf/2407.04396.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qian Zeng, Le Zhang, Yipeng Liu, Ce Zhu, Fan Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.04396">Graph-Guided Test-Time Adaptation for Glaucoma Diagnosis using Fundus Photography</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Glaucoma is a leading cause of irreversible blindness worldwide. While deep learning approaches using fundus images have largely improved early diagnosis of glaucoma, variations in images from different devices and locations (known as domain shifts) challenge the use of pre-trained models in real-world settings. To address this, we propose a novel Graph-guided Test-Time Adaptation (GTTA) framework to generalize glaucoma diagnosis models to unseen test environments. GTTA integrates the topological information of fundus images into the model training, enhancing the model's transferability and reducing the risk of learning spurious correlation. During inference, GTTA introduces a novel test-time training objective to make the source-trained classifier progressively adapt to target patterns with reliable class conditional estimation and consistency regularization. Experiments on cross-domain glaucoma diagnosis benchmarks demonstrate the superiority of the overall framework and individual components under different backbone networks.
<div id='section'>Paperid: <span id='pid'>263, <a href='https://arxiv.org/pdf/2406.11309.pdf' target='_blank'>https://arxiv.org/pdf/2406.11309.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuefeng Hu, Ke Zhang, Min Sun, Albert Chen, Cheng-Hao Kuo, Ram Nevatia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.11309">BaFTA: Backprop-Free Test-Time Adaptation For Zero-Shot Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large-scale pretrained vision-language models like CLIP have demonstrated remarkable zero-shot image classification capabilities across diverse domains. To enhance CLIP's performance while preserving the zero-shot paradigm, various test-time prompt tuning methods have been introduced to refine class embeddings through unsupervised learning objectives during inference. However, these methods often encounter challenges in selecting appropriate learning rates to prevent collapsed training in the absence of validation data during test-time adaptation. In this study, we propose a novel backpropagation-free algorithm BaFTA for test-time adaptation of vision-language models. Instead of fine-tuning text prompts to refine class embeddings, our approach directly estimates class centroids using online clustering within a projected embedding space that aligns text and visual embeddings. We dynamically aggregate predictions from both estimated and original class embeddings, as well as from distinct augmented views, by assessing the reliability of each prediction using RÃ©nyi Entropy. Through extensive experiments, we demonstrate that BaFTA consistently outperforms state-of-the-art test-time adaptation methods in both effectiveness and efficiency.
<div id='section'>Paperid: <span id='pid'>264, <a href='https://arxiv.org/pdf/2404.00095.pdf' target='_blank'>https://arxiv.org/pdf/2404.00095.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yun-Yun Tsai, Fu-Chen Chen, Albert Y. C. Chen, Junfeng Yang, Che-Chun Su, Min Sun, Cheng-Hao Kuo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.00095">GDA: Generalized Diffusion for Robust Test-time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning models struggle with generalization when encountering out-of-distribution (OOD) samples with unexpected distribution shifts. For vision tasks, recent studies have shown that test-time adaptation employing diffusion models can achieve state-of-the-art accuracy improvements on OOD samples by generating new samples that align with the model's domain without the need to modify the model's weights. Unfortunately, those studies have primarily focused on pixel-level corruptions, thereby lacking the generalization to adapt to a broader range of OOD types. We introduce Generalized Diffusion Adaptation (GDA), a novel diffusion-based test-time adaptation method robust against diverse OOD types. Specifically, GDA iteratively guides the diffusion by applying a marginal entropy loss derived from the model, in conjunction with style and content preservation losses during the reverse sampling process. In other words, GDA considers the model's output behavior with the semantic information of the samples as a whole, which can reduce ambiguity in downstream tasks during the generation process. Evaluation across various popular model architectures and OOD benchmarks shows that GDA consistently outperforms prior work on diffusion-driven adaptation. Notably, it achieves the highest classification accuracy improvements, ranging from 4.4\% to 5.02\% on ImageNet-C and 2.5\% to 7.4\% on Rendition, Sketch, and Stylized benchmarks. This performance highlights GDA's generalization to a broader range of OOD benchmarks.
<div id='section'>Paperid: <span id='pid'>265, <a href='https://arxiv.org/pdf/2510.04243.pdf' target='_blank'>https://arxiv.org/pdf/2510.04243.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jincan Lou, Jingkun Chen, Haoquan Li, Hang Li, Wenjian Huang, Weihua Chen, Fan Wang, Jianguo Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.04243">The best performance in the CARE 2025 -- Liver Task (LiSeg-Contrast): Contrast-Aware Semi-Supervised Segmentation with Domain Generalization and Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate liver segmentation from contrast-enhanced MRI is essential for diagnosis, treatment planning, and disease monitoring. However, it remains challenging due to limited annotated data, heterogeneous enhancement protocols, and significant domain shifts across scanners and institutions. Traditional image-to-image translation frameworks have made great progress in domain generalization, but their application is not straightforward. For example, Pix2Pix requires image registration, and cycle-GAN cannot be integrated seamlessly into segmentation pipelines. Meanwhile, these methods are originally used to deal with cross-modality scenarios, and often introduce structural distortions and suffer from unstable training, which may pose drawbacks in our single-modality scenario. To address these challenges, we propose CoSSeg-TTA, a compact segmentation framework for the GED4 (Gd-EOB-DTPA enhanced hepatobiliary phase MRI) modality built upon nnU-Netv2 and enhanced with a semi-supervised mean teacher scheme to exploit large amounts of unlabeled volumes. A domain adaptation module, incorporating a randomized histogram-based style appearance transfer function and a trainable contrast-aware network, enriches domain diversity and mitigates cross-center variability. Furthermore, a continual test-time adaptation strategy is employed to improve robustness during inference. Extensive experiments demonstrate that our framework consistently outperforms the nnU-Netv2 baseline, achieving superior Dice score and Hausdorff Distance while exhibiting strong generalization to unseen domains under low-annotation conditions.
<div id='section'>Paperid: <span id='pid'>266, <a href='https://arxiv.org/pdf/2510.04243.pdf' target='_blank'>https://arxiv.org/pdf/2510.04243.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jincan Lou, Jingkun Chen, Haoquan Li, Hang Li, Wenjian Huang, Weihua Chen, Fan Wang, Jianguo Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.04243">The best performance in the CARE 2025 -- Liver Task (LiSeg-Contrast): Contrast-Aware Semi-Supervised Segmentation with Domain Generalization and Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate liver segmentation from contrast-enhanced MRI is essential for diagnosis, treatment planning, and disease monitoring. However, it remains challenging due to limited annotated data, heterogeneous enhancement protocols, and significant domain shifts across scanners and institutions. Traditional image-to-image translation frameworks have made great progress in domain generalization, but their application is not straightforward. For example, Pix2Pix requires image registration, and cycle-GAN cannot be integrated seamlessly into segmentation pipelines. Meanwhile, these methods are originally used to deal with cross-modality scenarios, and often introduce structural distortions and suffer from unstable training, which may pose drawbacks in our single-modality scenario. To address these challenges, we propose CoSSeg-TTA, a compact segmentation framework for the GED4 (Gd-EOB-DTPA enhanced hepatobiliary phase MRI) modality built upon nnU-Netv2 and enhanced with a semi-supervised mean teacher scheme to exploit large amounts of unlabeled volumes. A domain adaptation module, incorporating a randomized histogram-based style appearance transfer function and a trainable contrast-aware network, enriches domain diversity and mitigates cross-center variability. Furthermore, a continual test-time adaptation strategy is employed to improve robustness during inference. Extensive experiments demonstrate that our framework consistently outperforms the nnU-Netv2 baseline, achieving superior Dice score and Hausdorff Distance while exhibiting strong generalization to unseen domains under low-annotation conditions.
<div id='section'>Paperid: <span id='pid'>267, <a href='https://arxiv.org/pdf/2510.04243.pdf' target='_blank'>https://arxiv.org/pdf/2510.04243.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jincan Lou, Jingkun Chen, Haoquan Li, Hang Li, Wenjian Huang, Weihua Chen, Fan Wang, Jianguo Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.04243">The 1st Solution for CARE Liver Task Challenge 2025: Contrast-Aware Semi-Supervised Segmentation with Domain Generalization and Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate liver segmentation from contrast-enhanced MRI is essential for diagnosis, treatment planning, and disease monitoring. However, it remains challenging due to limited annotated data, heterogeneous enhancement protocols, and significant domain shifts across scanners and institutions. Traditional image-to-image translation frameworks have made great progress in domain generalization, but their application is not straightforward. For example, Pix2Pix requires image registration, and cycle-GAN cannot be integrated seamlessly into segmentation pipelines. Meanwhile, these methods are originally used to deal with cross-modality scenarios, and often introduce structural distortions and suffer from unstable training, which may pose drawbacks in our single-modality scenario. To address these challenges, we propose CoSSeg-TTA, a compact segmentation framework for the GED4 (Gd-EOB-DTPA enhanced hepatobiliary phase MRI) modality built upon nnU-Netv2 and enhanced with a semi-supervised mean teacher scheme to exploit large amounts of unlabeled volumes. A domain adaptation module, incorporating a randomized histogram-based style appearance transfer function and a trainable contrast-aware network, enriches domain diversity and mitigates cross-center variability. Furthermore, a continual test-time adaptation strategy is employed to improve robustness during inference. Extensive experiments demonstrate that our framework consistently outperforms the nnU-Netv2 baseline, achieving superior Dice score and Hausdorff Distance while exhibiting strong generalization to unseen domains under low-annotation conditions.
<div id='section'>Paperid: <span id='pid'>268, <a href='https://arxiv.org/pdf/2410.15624.pdf' target='_blank'>https://arxiv.org/pdf/2410.15624.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haobin Li, Peng Hu, Qianjun Zhang, Xi Peng, Xiting Liu, Mouxing Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.15624">Test-time Adaptation for Cross-modal Retrieval with Query Shift</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The success of most existing cross-modal retrieval methods heavily relies on the assumption that the given queries follow the same distribution of the source domain. However, such an assumption is easily violated in real-world scenarios due to the complexity and diversity of queries, thus leading to the query shift problem. Specifically, query shift refers to the online query stream originating from the domain that follows a different distribution with the source one. In this paper, we observe that query shift would not only diminish the uniformity (namely, within-modality scatter) of the query modality but also amplify the gap between query and gallery modalities. Based on the observations, we propose a novel method dubbed Test-time adaptation for Cross-modal Retrieval (TCR). In brief, TCR employs a novel module to refine the query predictions (namely, retrieval results of the query) and a joint objective to prevent query shift from disturbing the common space, thus achieving online adaptation for the cross-modal retrieval models with query shift. Expensive experiments demonstrate the effectiveness of the proposed TCR against query shift. The code will be released upon acceptance.
<div id='section'>Paperid: <span id='pid'>269, <a href='https://arxiv.org/pdf/2507.21858.pdf' target='_blank'>https://arxiv.org/pdf/2507.21858.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianhui Wang, Yinda Chen, Yangfan He, Xinyuan Song, Yi Xin, Dapeng Zhang, Zhongwei Wan, Bin Li, Rongchao Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.21858">Low-Cost Test-Time Adaptation for Robust Video Editing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Video editing is a critical component of content creation that transforms raw footage into coherent works aligned with specific visual and narrative objectives. Existing approaches face two major challenges: temporal inconsistencies due to failure in capturing complex motion patterns, and overfitting to simple prompts arising from limitations in UNet backbone architectures. While learning-based methods can enhance editing quality, they typically demand substantial computational resources and are constrained by the scarcity of high-quality annotated data. In this paper, we present Vid-TTA, a lightweight test-time adaptation framework that personalizes optimization for each test video during inference through self-supervised auxiliary tasks. Our approach incorporates a motion-aware frame reconstruction mechanism that identifies and preserves crucial movement regions, alongside a prompt perturbation and reconstruction strategy that strengthens model robustness to diverse textual descriptions. These innovations are orchestrated by a meta-learning driven dynamic loss balancing mechanism that adaptively adjusts the optimization process based on video characteristics. Extensive experiments demonstrate that Vid-TTA significantly improves video temporal consistency and mitigates prompt overfitting while maintaining low computational overhead, offering a plug-and-play performance boost for existing video editing models.
<div id='section'>Paperid: <span id='pid'>270, <a href='https://arxiv.org/pdf/2507.00502.pdf' target='_blank'>https://arxiv.org/pdf/2507.00502.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>JianChao Zhao, Chenhao Ding, Songlin Dong, Yuhang He, Yihong Gong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.00502">ExPaMoE: An Expandable Parallel Mixture of Experts for Continual Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual Test-Time Adaptation (CTTA) aims to enable models to adapt on-the-fly to a stream of unlabeled data under evolving distribution shifts. However, existing CTTA methods typically rely on shared model parameters across all domains, making them vulnerable to feature entanglement and catastrophic forgetting in the presence of large or non-stationary domain shifts. To address this limitation, we propose ExPaMoE, a novel framework based on an Expandable Parallel Mixture-of-Experts architecture. ExPaMoE decouples domain-general and domain-specific knowledge via a dual-branch expert design with token-guided feature separation, and dynamically expands its expert pool based on a Spectral-Aware Online Domain Discriminator (SODD) that detects distribution changes in real-time using frequency-domain cues. Extensive experiments demonstrate the superiority of ExPaMoE across diverse CTTA scenarios. We evaluate our method on standard benchmarks including CIFAR-10C, CIFAR-100C, ImageNet-C, and Cityscapes-to-ACDC for semantic segmentation. Additionally, we introduce ImageNet++, a large-scale and realistic CTTA benchmark built from multiple ImageNet-derived datasets, to better reflect long-term adaptation under complex domain evolution. ExPaMoE consistently outperforms prior arts, showing strong robustness, scalability, and resistance to forgetting.
<div id='section'>Paperid: <span id='pid'>271, <a href='https://arxiv.org/pdf/2507.00462.pdf' target='_blank'>https://arxiv.org/pdf/2507.00462.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jizhou Han, Chenhao Ding, SongLin Dong, Yuhang He, Xinyuan Gao, Yihong Gong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.00462">Unleashing the Potential of All Test Samples: Mean-Shift Guided Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Visual-language models (VLMs) like CLIP exhibit strong generalization but struggle with distribution shifts at test time. Existing training-free test-time adaptation (TTA) methods operate strictly within CLIP's original feature space, relying on high-confidence samples while overlooking the potential of low-confidence ones. We propose MS-TTA, a training-free approach that enhances feature representations beyond CLIP's space using a single-step k-nearest neighbors (kNN) Mean-Shift. By refining all test samples, MS-TTA improves feature compactness and class separability, leading to more stable adaptation. Additionally, a cache of refined embeddings further enhances inference by providing Mean Shift enhanced logits. Extensive evaluations on OOD and cross-dataset benchmarks demonstrate that MS-TTA consistently outperforms state-of-the-art training-free TTA methods, achieving robust adaptation without requiring additional training.
<div id='section'>Paperid: <span id='pid'>272, <a href='https://arxiv.org/pdf/2502.19946.pdf' target='_blank'>https://arxiv.org/pdf/2502.19946.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenhao Ding, Xinyuan Gao, Songlin Dong, Yuhang He, Qiang Wang, Xiang Song, Alex Kot, Yihong Gong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.19946">Space Rotation with Basis Transformation for Training-free Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the development of visual-language models (VLM) in downstream task applications, test-time adaptation methods based on VLM have attracted increasing attention for their ability to address changes distribution in test-time. Although prior approaches have achieved some progress, they typically either demand substantial computational resources or are constrained by the limitations of the original feature space, rendering them less effective for test-time adaptation tasks. To address these challenges, we propose a training-free feature space rotation with basis transformation for test-time adaptation. By leveraging the inherent distinctions among classes, we reconstruct the original feature space and map it to a new representation, thereby enhancing the clarity of class differences and providing more effective guidance for the model during testing. Additionally, to better capture relevant information from various classes, we maintain a dynamic queue to store representative samples. Experimental results across multiple benchmarks demonstrate that our method outperforms state-of-the-art techniques in terms of both performance and efficiency.
<div id='section'>Paperid: <span id='pid'>273, <a href='https://arxiv.org/pdf/2410.13472.pdf' target='_blank'>https://arxiv.org/pdf/2410.13472.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziyang Chen, Yiwen Ye, Yongsheng Pan, Jingfeng Zhang, Yanning Zhang, Yong Xia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.13472">Day-Night Adaptation: An Innovative Source-free Adaptation Framework for Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Distribution shifts widely exist in medical images acquired from different medical centres, hindering the deployment of semantic segmentation models trained on one centre (source domain) to another (target domain). While unsupervised domain adaptation has shown significant promise in mitigating these shifts, it poses privacy risks due to sharing data between centres. To facilitate adaptation while preserving data privacy, source-free domain adaptation (SFDA) and test-time adaptation (TTA) have emerged as effective paradigms, relying solely on target domain data. However, SFDA requires a pre-collected target domain dataset before deployment. TTA insufficiently exploit the potential value of test data, as it processes the test data only once. Considering that most medical centres operate during the day and remain inactive at night in clinical practice, we propose a novel adaptation framework called Day-Night Adaptation (DyNA) with above insights, which performs adaptation through day-night cycles without requiring access to source data. During the day, a low-frequency prompt is trained to adapt the frozen model to each test sample. We construct a memory bank for prompt initialization and develop a warm-up mechanism to enhance prompt training. During the night, we reuse test data collected from the day and introduce a global student model to bridge the knowledge between teacher and student models, facilitating model fine-tuning while ensuring training stability. Extensive experiments demonstrate that our DyNA outperforms existing TTA and SFDA methods on two benchmark medical image segmentation tasks. Code will be available after the paper is published.
<div id='section'>Paperid: <span id='pid'>274, <a href='https://arxiv.org/pdf/2406.11548.pdf' target='_blank'>https://arxiv.org/pdf/2406.11548.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chuyan Xiong, Chengyu Shen, Xiaoqi Li, Kaichen Zhou, Jeremy Liu, Ruiping Wang, Hao Dong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.11548">AIC MLLM: Autonomous Interactive Correction MLLM for Robust Robotic Manipulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The ability to reflect on and correct failures is crucial for robotic systems to interact stably with real-life objects.Observing the generalization and reasoning capabilities of Multimodal Large Language Models (MLLMs), previous approaches have aimed to utilize these models to enhance robotic systems accordingly.However, these methods typically focus on high-level planning corrections using an additional MLLM, with limited utilization of failed samples to correct low-level contact poses which is particularly prone to occur during articulated object manipulation.To address this gap, we propose an Autonomous Interactive Correction (AIC) MLLM, which makes use of previous low-level interaction experiences to correct SE(3) pose predictions for articulated object. Specifically, AIC MLLM is initially fine-tuned to acquire both pose prediction and feedback prompt comprehension abilities.We design two types of prompt instructions for interactions with objects: 1) visual masks to highlight unmovable parts for position correction, and 2) textual descriptions to indicate potential directions for rotation correction. During inference, a Feedback Information Extraction module is introduced to recognize the failure cause, allowing AIC MLLM to adaptively correct the pose prediction using the corresponding prompts.To further enhance manipulation stability, we devise a Test Time Adaptation strategy that enables AIC MLLM to better adapt to the current scene configuration.Finally, extensive experiments are conducted in both simulated and real-world environments to evaluate the proposed method. The results demonstrate that our AIC MLLM can efficiently correct failure samples by leveraging interaction experience prompts.Our project website is https://sites.google.com/view/aic-mllm.
<div id='section'>Paperid: <span id='pid'>275, <a href='https://arxiv.org/pdf/2312.16217.pdf' target='_blank'>https://arxiv.org/pdf/2312.16217.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaoqi Li, Mingxu Zhang, Yiran Geng, Haoran Geng, Yuxing Long, Yan Shen, Renrui Zhang, Jiaming Liu, Hao Dong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.16217">ManipLLM: Embodied Multimodal Large Language Model for Object-Centric Robotic Manipulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Robot manipulation relies on accurately predicting contact points and end-effector directions to ensure successful operation. However, learning-based robot manipulation, trained on a limited category within a simulator, often struggles to achieve generalizability, especially when confronted with extensive categories. Therefore, we introduce an innovative approach for robot manipulation that leverages the robust reasoning capabilities of Multimodal Large Language Models (MLLMs) to enhance the stability and generalization of manipulation. By fine-tuning the injected adapters, we preserve the inherent common sense and reasoning ability of the MLLMs while equipping them with the ability for manipulation. The fundamental insight lies in the introduced fine-tuning paradigm, encompassing object category understanding, affordance prior reasoning, and object-centric pose prediction to stimulate the reasoning ability of MLLM in manipulation. During inference, our approach utilizes an RGB image and text prompt to predict the end effector's pose in chain of thoughts. After the initial contact is established, an active impedance adaptation policy is introduced to plan the upcoming waypoints in a closed-loop manner. Moreover, in real world, we design a test-time adaptation (TTA) strategy for manipulation to enable the model better adapt to the current real-world scene configuration. Experiments in simulator and real-world show the promising performance of ManipLLM. More details and demonstrations can be found at https://sites.google.com/view/manipllm.
<div id='section'>Paperid: <span id='pid'>276, <a href='https://arxiv.org/pdf/2507.03458.pdf' target='_blank'>https://arxiv.org/pdf/2507.03458.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Leyan Xue, Zongbo Han, Guangyu Wang, Qinghua Hu, Mingyue Cheng, Changqing Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.03458">Helping CLIP See Both the Forest and the Trees: A Decomposition and Description Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-Language Models (VLMs) like CLIP achieve cross-modal semantic alignment through contrastive learning, exhibiting robust zero-shot generalization. Traditional prompt engineering, however, predominantly relies on coarse-grained category labels, neglecting fine-grained local semantics. Existing approaches assume that VLMs inherently recognize localized visual details and attempt to enhance classification by augmenting text prompts with attribute descriptors generated by large language models. However, our systematic experiments reveal critical limitations: CLIP's strong bias toward global image patterns hinders its ability to process localized visual descriptors. To address this fundamental constraint, we propose a simple, effective, and plug-and-play solution that enables CLIP to ``See Both the Forest and the Trees." Specifically, we employ stochastic multi-crop augmentation to activate CLIP's latent capacity for localized feature analysis. By cropping only partial regions, the approach effectively constrains the model's receptive field and recalibrates its attention mechanism, thereby mitigating its inherent bias. We evaluate the proposed method under zero-shot, few-shot, and test-time adaptation settings, and extensive experiments demonstrate that D&D achieves promising performance.
<div id='section'>Paperid: <span id='pid'>277, <a href='https://arxiv.org/pdf/2505.14600.pdf' target='_blank'>https://arxiv.org/pdf/2505.14600.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Xiao, Tianyi Peng, Yanghao Zhou, Rohan Kumar Das
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.14600">AdaKWS: Towards Robust Keyword Spotting with Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Spoken keyword spotting (KWS) aims to identify keywords in audio for wide applications, especially on edge devices. Current small-footprint KWS systems focus on efficient model designs. However, their inference performance can decline in unseen environments or noisy backgrounds. Test-time adaptation (TTA) helps models adapt to test samples without needing the original training data. In this study, we present AdaKWS, the first TTA method for robust KWS to the best of our knowledge. Specifically, 1) We initially optimize the model's confidence by selecting reliable samples based on prediction entropy minimization and adjusting the normalization statistics in each batch. 2) We introduce pseudo-keyword consistency (PKC) to identify critical, reliable features without overfitting to noise. Our experiments show that AdaKWS outperforms other methods across various conditions, including Gaussian noise and real-scenario noises. The code will be released in due course.
<div id='section'>Paperid: <span id='pid'>278, <a href='https://arxiv.org/pdf/2410.22373.pdf' target='_blank'>https://arxiv.org/pdf/2410.22373.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yufei Zhang, Yicheng Xu, Hongxin Wei, Zhiping Lin, Xiaofeng Zou, Cen Chen, Huiping Zhuang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.22373">Analytic Continual Test-Time Adaptation for Multi-Modality Corruption</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-Time Adaptation (TTA) enables pre-trained models to bridge the gap between source and target datasets using unlabeled test data, addressing domain shifts caused by corruptions like weather changes, noise, or sensor malfunctions in test time. Multi-Modal Continual Test-Time Adaptation (MM-CTTA), as an extension of standard TTA, further allows models to handle multi-modal inputs and adapt to continuously evolving target domains. However, MM-CTTA faces critical challenges such as catastrophic forgetting and reliability bias, which are rarely addressed effectively under multi-modal corruption scenarios. In this paper, we propose a novel approach, Multi-modality Dynamic Analytic Adapter (MDAA), to tackle MM-CTTA tasks. MDAA introduces analytic learning,a closed-form training technique,through Analytic Classifiers (ACs) to mitigate catastrophic forgetting. Furthermore, we design the Dynamic Late Fusion Mechanism (DLFM) to dynamically select and integrate reliable information from different modalities. Extensive experiments show that MDAA achieves state-of-the-art performance across the proposed tasks.
<div id='section'>Paperid: <span id='pid'>279, <a href='https://arxiv.org/pdf/2410.03306.pdf' target='_blank'>https://arxiv.org/pdf/2410.03306.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sameer Ambekar, Julia A. Schnabel, Cosmin I. Bercea
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.03306">Selective Test-Time Adaptation for Unsupervised Anomaly Detection using Neural Implicit Representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning models in medical imaging often encounter challenges when adapting to new clinical settings unseen during training. Test-time adaptation offers a promising approach to optimize models for these unseen domains, yet its application in anomaly detection (AD) remains largely unexplored. AD aims to efficiently identify deviations from normative distributions; however, full adaptation, including pathological shifts, may inadvertently learn the anomalies it intends to detect. We introduce a novel concept of selective test-time adaptation that utilizes the inherent characteristics of deep pre-trained features to adapt selectively in a zero-shot manner to any test image from an unseen domain. This approach employs a model-agnostic, lightweight multi-layer perceptron for neural implicit representations, enabling the adaptation of outputs from any reconstruction-based AD method without altering the source-trained model. Rigorous validation in brain AD demonstrated that our strategy substantially enhances detection accuracy for multiple conditions and different target distributions. Specifically, our method improves the detection rates by up to 78% for enlarged ventricles and 24% for edemas.
<div id='section'>Paperid: <span id='pid'>280, <a href='https://arxiv.org/pdf/2403.00376.pdf' target='_blank'>https://arxiv.org/pdf/2403.00376.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Huan Ma, Yan Zhu, Changqing Zhang, Peilin Zhao, Baoyuan Wu, Long-Kai Huang, Qinghua Hu, Bingzhe Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.00376">Spurious Feature Eraser: Stabilizing Test-Time Adaptation for Vision-Language Foundation Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-language foundation models have exhibited remarkable success across a multitude of downstream tasks due to their scalability on extensive image-text paired data. However, these models also display significant limitations when applied to downstream tasks, such as fine-grained image classification, as a result of ``decision shortcuts'' that hinder their generalization capabilities. In this work, we find that the CLIP model possesses a rich set of features, encompassing both \textit{desired invariant causal features} and \textit{undesired decision shortcuts}. Moreover, the underperformance of CLIP on downstream tasks originates from its inability to effectively utilize pre-trained features in accordance with specific task requirements. To address this challenge, we propose a simple yet effective method, Spurious Feature Eraser (SEraser), to alleviate the decision shortcuts by erasing the spurious features. Specifically, we introduce a test-time prompt tuning paradigm that optimizes a learnable prompt, thereby compelling the model to exploit invariant features while disregarding decision shortcuts during the inference phase. The proposed method effectively alleviates excessive dependence on potentially misleading spurious information. We conduct comparative analysis of the proposed method against various approaches which validates the significant superiority.
<div id='section'>Paperid: <span id='pid'>281, <a href='https://arxiv.org/pdf/2401.14619.pdf' target='_blank'>https://arxiv.org/pdf/2401.14619.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xingzhi Zhou, Zhiliang Tian, Ka Chun Cheung, Simon See, Nevin L. Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.14619">Resilient Practical Test-Time Adaptation: Soft Batch Normalization Alignment and Entropy-driven Memory Bank</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time domain adaptation effectively adjusts the source domain model to accommodate unseen domain shifts in a target domain during inference. However, the model performance can be significantly impaired by continuous distribution changes in the target domain and non-independent and identically distributed (non-i.i.d.) test samples often encountered in practical scenarios. While existing memory bank methodologies use memory to store samples and mitigate non-i.i.d. effects, they do not inherently prevent potential model degradation. To address this issue, we propose a resilient practical test-time adaptation (ResiTTA) method focused on parameter resilience and data quality. Specifically, we develop a resilient batch normalization with estimation on normalization statistics and soft alignments to mitigate overfitting and model degradation. We use an entropy-driven memory bank that accounts for timeliness, the persistence of over-confident samples, and sample uncertainty for high-quality data in adaptation. Our framework periodically adapts the source domain model using a teacher-student model through a self-training loss on the memory samples, incorporating soft alignment losses on batch normalization. We empirically validate ResiTTA across various benchmark datasets, demonstrating state-of-the-art performance.
<div id='section'>Paperid: <span id='pid'>282, <a href='https://arxiv.org/pdf/2509.22813.pdf' target='_blank'>https://arxiv.org/pdf/2509.22813.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sahar Dastani, Ali Bahri, Gustavo Adolfo Vargas Hakim, Moslem Yazdanpanah, Mehrdad Noori, David Osowiechi, Samuel Barbeau, Ismail Ben Ayed, Herve Lombaert, Christian Desrosiers
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.22813">TRUST: Test-Time Refinement using Uncertainty-Guided SSM Traverses</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>State Space Models (SSMs) have emerged as efficient alternatives to Vision Transformers (ViTs), with VMamba standing out as a pioneering architecture designed for vision tasks. However, their generalization performance degrades significantly under distribution shifts. To address this limitation, we propose TRUST (Test-Time Refinement using Uncertainty-Guided SSM Traverses), a novel test-time adaptation (TTA) method that leverages diverse traversal permutations to generate multiple causal perspectives of the input image. Model predictions serve as pseudo-labels to guide updates of the Mamba-specific parameters, and the adapted weights are averaged to integrate the learned information across traversal scans. Altogether, TRUST is the first approach that explicitly leverages the unique architectural properties of SSMs for adaptation. Experiments on seven benchmarks show that TRUST consistently improves robustness and outperforms existing TTA methods.
<div id='section'>Paperid: <span id='pid'>283, <a href='https://arxiv.org/pdf/2509.22813.pdf' target='_blank'>https://arxiv.org/pdf/2509.22813.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sahar Dastani, Ali Bahri, Gustavo Adolfo Vargas Hakim, Moslem Yazdanpanah, Mehrdad Noori, David Osowiechi, Samuel Barbeau, Ismail Ben Ayed, Herve Lombaert, Christian Desrosiers
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.22813">TRUST: Test-Time Refinement using Uncertainty-Guided SSM Traverses</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>State Space Models (SSMs) have emerged as efficient alternatives to Vision Transformers (ViTs), with VMamba standing out as a pioneering architecture designed for vision tasks. However, their generalization performance degrades significantly under distribution shifts. To address this limitation, we propose TRUST (Test-Time Refinement using Uncertainty-Guided SSM Traverses), a novel test-time adaptation (TTA) method that leverages diverse traversal permutations to generate multiple causal perspectives of the input image. Model predictions serve as pseudo-labels to guide updates of the Mamba-specific parameters, and the adapted weights are averaged to integrate the learned information across traversal scans. Altogether, TRUST is the first approach that explicitly leverages the unique architectural properties of SSMs for adaptation. Experiments on seven benchmarks show that TRUST consistently improves robustness and outperforms existing TTA methods.
<div id='section'>Paperid: <span id='pid'>284, <a href='https://arxiv.org/pdf/2507.03657.pdf' target='_blank'>https://arxiv.org/pdf/2507.03657.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xingyu Zhu, Shuo Wang, Beier Zhu, Miaoge Li, Yunfan Li, Junfeng Fang, Zhicai Wang, Dongsheng Wang, Hanwang Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.03657">Dynamic Multimodal Prototype Learning in Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the increasing attention to pre-trained vision-language models (VLMs), \eg, CLIP, substantial efforts have been devoted to many downstream tasks, especially in test-time adaptation (TTA). However, previous works focus on learning prototypes only in the textual modality while overlooking the ambiguous semantics in class names. These ambiguities lead to textual prototypes that are insufficient to capture visual concepts, resulting in limited performance. To address this issue, we introduce \textbf{ProtoMM}, a training-free framework that constructs multimodal prototypes to adapt VLMs during the test time. By viewing the prototype as a discrete distribution over the textual descriptions and visual particles, ProtoMM has the ability to combine the multimodal features for comprehensive prototype learning. More importantly, the visual particles are dynamically updated as the testing stream flows. This allows our multimodal prototypes to continually learn from the data, enhancing their generalizability in unseen scenarios. In addition, we quantify the importance of the prototypes and test images by formulating their semantic distance as an optimal transport problem. Extensive experiments on 15 zero-shot benchmarks demonstrate the effectiveness of our method, achieving a 1.03\% average accuracy improvement over state-of-the-art methods on ImageNet and its variant datasets.
<div id='section'>Paperid: <span id='pid'>285, <a href='https://arxiv.org/pdf/2506.11121.pdf' target='_blank'>https://arxiv.org/pdf/2506.11121.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wei-Ping Huang, Guan-Ting Lin, Hung-yi Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.11121">SUTA-LM: Bridging Test-Time Adaptation and Language Model Rescoring for Robust ASR</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite progress in end-to-end ASR, real-world domain mismatches still cause performance drops, which Test-Time Adaptation (TTA) aims to mitigate by adjusting models during inference. Recent work explores combining TTA with external language models, using techniques like beam search rescoring or generative error correction. In this work, we identify a previously overlooked challenge: TTA can interfere with language model rescoring, revealing the nontrivial nature of effectively combining the two methods. Based on this insight, we propose SUTA-LM, a simple yet effective extension of SUTA, an entropy-minimization-based TTA approach, with language model rescoring. SUTA-LM first applies a controlled adaptation process guided by an auto-step selection mechanism leveraging both acoustic and linguistic information, followed by language model rescoring to refine the outputs. Experiments on 18 diverse ASR datasets show that SUTA-LM achieves robust results across a wide range of domains.
<div id='section'>Paperid: <span id='pid'>286, <a href='https://arxiv.org/pdf/2505.21844.pdf' target='_blank'>https://arxiv.org/pdf/2505.21844.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mehrdad Noori, David Osowiechi, Gustavo Adolfo Vargas Hakim, Ali Bahri, Moslem Yazdanpanah, Sahar Dastani, Farzad Beizaee, Ismail Ben Ayed, Christian Desrosiers
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.21844">Test-Time Adaptation of Vision-Language Models for Open-Vocabulary Semantic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, test-time adaptation has attracted wide interest in the context of vision-language models for image classification. However, to the best of our knowledge, the problem is completely overlooked in dense prediction tasks such as Open-Vocabulary Semantic Segmentation (OVSS). In response, we propose a novel TTA method tailored to adapting VLMs for segmentation during test time. Unlike TTA methods for image classification, our Multi-Level and Multi-Prompt (MLMP) entropy minimization integrates features from intermediate vision-encoder layers and is performed with different text-prompt templates at both the global CLS token and local pixel-wise levels. Our approach could be used as plug-and-play for any segmentation network, does not require additional training data or labels, and remains effective even with a single test sample. Furthermore, we introduce a comprehensive OVSS TTA benchmark suite, which integrates a rigorous evaluation protocol, seven segmentation datasets, and 15 common corruptions, with a total of 82 distinct test scenarios, establishing a standardized and comprehensive testbed for future TTA research in open-vocabulary segmentation. Our experiments on this suite demonstrate that our segmentation-tailored method consistently delivers significant gains over direct adoption of TTA classification baselines.
<div id='section'>Paperid: <span id='pid'>287, <a href='https://arxiv.org/pdf/2412.09899.pdf' target='_blank'>https://arxiv.org/pdf/2412.09899.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junrui Xiao, Zhikai Li, Lianwei Yang, Yiduo Mei, Qingyi Gu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.09899">TTAQ: Towards Stable Post-training Quantization in Continuous Domain Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Post-training quantization (PTQ) reduces excessive hardware cost by quantizing full-precision models into lower bit representations on a tiny calibration set, without retraining. Despite the remarkable progress made through recent efforts, traditional PTQ methods typically encounter failure in dynamic and ever-changing real-world scenarios, involving unpredictable data streams and continual domain shifts, which poses greater challenges. In this paper, we propose a novel and stable quantization process for test-time adaptation (TTA), dubbed TTAQ, to address the performance degradation of traditional PTQ in dynamically evolving test domains. To tackle domain shifts in quantizer, TTAQ proposes the Perturbation Error Mitigation (PEM) and Perturbation Consistency Reconstruction (PCR). Specifically, PEM analyzes the error propagation and devises a weight regularization scheme to mitigate the impact of input perturbations. On the other hand, PCR introduces consistency learning to ensure that quantized models provide stable predictions for same sample. Furthermore, we introduce Adaptive Balanced Loss (ABL) to adjust the logits by taking advantage of the frequency and complexity of the class, which can effectively address the class imbalance caused by unpredictable data streams during optimization. Extensive experiments are conducted on multiple datasets with generic TTA methods, proving that TTAQ can outperform existing baselines and encouragingly improve the accuracy of low bit PTQ models in continually changing test domains. For instance, TTAQ decreases the mean error of 2-bit models on ImageNet-C dataset by an impressive 10.1\%.
<div id='section'>Paperid: <span id='pid'>288, <a href='https://arxiv.org/pdf/2411.01116.pdf' target='_blank'>https://arxiv.org/pdf/2411.01116.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ali Bahri, Moslem Yazdanpanah, Mehrdad Noori, Sahar Dastani, Milad Cheraghalikhani, David Osowiech, Farzad Beizaee, Gustavo adolfo. vargas-hakim, Ismail Ben Ayed, Christian Desrosiers
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.01116">Test-Time Adaptation in Point Clouds: Leveraging Sampling Variation with Weight Averaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-Time Adaptation (TTA) addresses distribution shifts during testing by adapting a pretrained model without access to source data. In this work, we propose a novel TTA approach for 3D point cloud classification, combining sampling variation with weight averaging. Our method leverages Farthest Point Sampling (FPS) and K-Nearest Neighbors (KNN) to create multiple point cloud representations, adapting the model for each variation using the TENT algorithm. The final model parameters are obtained by averaging the adapted weights, leading to improved robustness against distribution shifts. Extensive experiments on ModelNet40-C, ShapeNet-C, and ScanObjectNN-C datasets, with different backbones (Point-MAE, PointNet, DGCNN), demonstrate that our approach consistently outperforms existing methods while maintaining minimal resource overhead. The proposed method effectively enhances model generalization and stability in challenging real-world conditions.
<div id='section'>Paperid: <span id='pid'>289, <a href='https://arxiv.org/pdf/2406.11064.pdf' target='_blank'>https://arxiv.org/pdf/2406.11064.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guan-Ting Lin, Wei-Ping Huang, Hung-yi Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.11064">Continual Test-time Adaptation for End-to-end Speech Recognition on Noisy Speech</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep Learning-based end-to-end Automatic Speech Recognition (ASR) has made significant strides but still struggles with performance on out-of-domain samples due to domain shifts in real-world scenarios. Test-Time Adaptation (TTA) methods address this issue by adapting models using test samples at inference time. However, current ASR TTA methods have largely focused on non-continual TTA, which limits cross-sample knowledge learning compared to continual TTA. In this work, we first propose a Fast-slow TTA framework for ASR that leverages the advantage of continual and non-continual TTA. Following this framework, we introduce Dynamic SUTA (DSUTA), an entropy-minimization-based continual TTA method for ASR. To enhance DSUTA robustness for time-varying data, we design a dynamic reset strategy to automatically detect domain shifts and reset the model, making it more effective at handling multi-domain data. Our method demonstrates superior performance on various noisy ASR datasets, outperforming both non-continual and continual TTA baselines while maintaining robustness to domain changes without requiring domain boundary information.
<div id='section'>Paperid: <span id='pid'>290, <a href='https://arxiv.org/pdf/2403.10911.pdf' target='_blank'>https://arxiv.org/pdf/2403.10911.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yeongtak Oh, Jonghyun Lee, Jooyoung Choi, Dahuin Jung, Uiwon Hwang, Sungroh Yoon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.10911">Efficient Diffusion-Driven Corruption Editor for Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) addresses the unforeseen distribution shifts occurring during test time. In TTA, performance, memory consumption, and time consumption are crucial considerations. A recent diffusion-based TTA approach for restoring corrupted images involves image-level updates. However, using pixel space diffusion significantly increases resource requirements compared to conventional model updating TTA approaches, revealing limitations as a TTA method. To address this, we propose a novel TTA method that leverages an image editing model based on a latent diffusion model (LDM) and fine-tunes it using our newly introduced corruption modeling scheme. This scheme enhances the robustness of the diffusion model against distribution shifts by creating (clean, corrupted) image pairs and fine-tuning the model to edit corrupted images into clean ones. Moreover, we introduce a distilled variant to accelerate the model for corruption editing using only 4 network function evaluations (NFEs). We extensively validated our method across various architectures and datasets including image and video domains. Our model achieves the best performance with a 100 times faster runtime than that of a diffusion-based baseline. Furthermore, it is three times faster than the previous model updating TTA method that utilizes data augmentation, making an image-level updating approach more feasible.
<div id='section'>Paperid: <span id='pid'>291, <a href='https://arxiv.org/pdf/2402.03312.pdf' target='_blank'>https://arxiv.org/pdf/2402.03312.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyoungseob Park, Anjali Gupta, Alex Wong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.03312">Test-Time Adaptation for Depth Completion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>It is common to observe performance degradation when transferring models trained on some (source) datasets to target testing data due to a domain gap between them. Existing methods for bridging this gap, such as domain adaptation (DA), may require the source data on which the model was trained (often not available), while others, i.e., source-free DA, require many passes through the testing data. We propose an online test-time adaptation method for depth completion, the task of inferring a dense depth map from a single image and associated sparse depth map, that closes the performance gap in a single pass. We first present a study on how the domain shift in each data modality affects model performance. Based on our observations that the sparse depth modality exhibits a much smaller covariate shift than the image, we design an embedding module trained in the source domain that preserves a mapping from features encoding only sparse depth to those encoding image and sparse depth. During test time, sparse depth features are projected using this map as a proxy for source domain features and are used as guidance to train a set of auxiliary parameters (i.e., adaptation layer) to align image and sparse depth features from the target test domain to that of the source domain. We evaluate our method on indoor and outdoor scenarios and show that it improves over baselines by an average of 21.1%.
<div id='section'>Paperid: <span id='pid'>292, <a href='https://arxiv.org/pdf/2310.19177.pdf' target='_blank'>https://arxiv.org/pdf/2310.19177.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Noah Thomas McDermott, Junfeng Yang, Chengzhi Mao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.19177">Robustifying Language Models with Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large-scale language models achieved state-of-the-art performance over a number of language tasks. However, they fail on adversarial language examples, which are sentences optimized to fool the language models but with similar semantic meanings for humans. While prior work focuses on making the language model robust at training time, retraining for robustness is often unrealistic for large-scale foundation models. Instead, we propose to make the language models robust at test time. By dynamically adapting the input sentence with predictions from masked words, we show that we can reverse many language adversarial attacks. Since our approach does not require any training, it works for novel tasks at test time and can adapt to novel adversarial corruptions. Visualizations and empirical results on two popular sentence classification datasets demonstrate that our method can repair adversarial language attacks over 65% o
<div id='section'>Paperid: <span id='pid'>293, <a href='https://arxiv.org/pdf/2310.12345.pdf' target='_blank'>https://arxiv.org/pdf/2310.12345.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gustavo A. Vargas Hakim, David Osowiechi, Mehrdad Noori, Milad Cheraghalikhani, Ismail Ben Ayed, Christian Desrosiers
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.12345">ClusT3: Information Invariant Test-Time Training</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep Learning models have shown remarkable performance in a broad range of vision tasks. However, they are often vulnerable against domain shifts at test-time. Test-time training (TTT) methods have been developed in an attempt to mitigate these vulnerabilities, where a secondary task is solved at training time simultaneously with the main task, to be later used as an self-supervised proxy task at test-time. In this work, we propose a novel unsupervised TTT technique based on the maximization of Mutual Information between multi-scale feature maps and a discrete latent representation, which can be integrated to the standard training as an auxiliary clustering task. Experimental results demonstrate competitive classification performance on different popular test-time adaptation benchmarks.
<div id='section'>Paperid: <span id='pid'>294, <a href='https://arxiv.org/pdf/2303.00198.pdf' target='_blank'>https://arxiv.org/pdf/2303.00198.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yun-Yun Tsai, Chengzhi Mao, Junfeng Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.00198">Convolutional Visual Prompt for Robust Visual Perception</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision models are often vulnerable to out-of-distribution (OOD) samples without adapting. While visual prompts offer a lightweight method of input-space adaptation for large-scale vision models, they rely on a high-dimensional additive vector and labeled data. This leads to overfitting when adapting models in a self-supervised test-time setting without labels. We introduce convolutional visual prompts (CVP) for label-free test-time adaptation for robust visual perception. The structured nature of CVP demands fewer trainable parameters, less than 1\% compared to standard visual prompts, combating overfitting. Extensive experiments and analysis on a wide variety of OOD visual perception tasks show that our approach is effective, improving robustness by up to 5.87% over several large-scale models.
<div id='section'>Paperid: <span id='pid'>295, <a href='https://arxiv.org/pdf/2507.07908.pdf' target='_blank'>https://arxiv.org/pdf/2507.07908.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiao Yang, Jiyao Wang, Yuxuan Fan, Can Liu, Houcheng Su, Weichen Guo, Zitong Yu, Dengbo He, Kaishun Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.07908">Not Only Consistency: Enhance Test-Time Adaptation with Spatio-temporal Inconsistency for Remote Physiological Measurement</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Remote physiological measurement (RPM) has emerged as a promising non-invasive method for monitoring physiological signals using the non-contact device. Although various domain adaptation and generalization methods were proposed to promote the adaptability of deep-based RPM models in unseen deployment environments, considerations in aspects such as privacy concerns and real-time adaptation restrict their application in real-world deployment. Thus, we aim to propose a novel fully Test-Time Adaptation (TTA) strategy tailored for RPM tasks in this work. Specifically, based on prior knowledge in physiology and our observations, we noticed not only there is spatio-temporal consistency in the frequency domain of BVP signals, but also that inconsistency in the time domain was significant. Given this, by leveraging both consistency and inconsistency priors, we introduce an innovative expert knowledge-based self-supervised \textbf{C}onsistency-\textbf{i}n\textbf{C}onsistency-\textbf{i}ntegration (\textbf{CiCi}) framework to enhances model adaptation during inference. Besides, our approach further incorporates a gradient dynamic control mechanism to mitigate potential conflicts between priors, ensuring stable adaptation across instances. Through extensive experiments on five diverse datasets under the TTA protocol, our method consistently outperforms existing techniques, presenting state-of-the-art performance in real-time self-supervised adaptation without accessing source data. The code will be released later.
<div id='section'>Paperid: <span id='pid'>296, <a href='https://arxiv.org/pdf/2412.17306.pdf' target='_blank'>https://arxiv.org/pdf/2412.17306.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gongyu Chen, Haomin Zhang, Chaofan Ding, Zihao Chen, Xinhan Di
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.17306">Multiple Consistency-guided Test-Time Adaptation for Contrastive Audio-Language Models with Unlabeled Audio</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>One fascinating aspect of pre-trained Audio-Language Models (ALMs) learning is their impressive zero-shot generalization capability and test-time adaptation (TTA) methods aiming to improve domain performance without annotations. However, previous test time adaptation (TTA) methods for ALMs in zero-shot classification tend to be stuck in incorrect model predictions. In order to further boost the performance, we propose multiple guidance on prompt learning without annotated labels. First, guidance of consistency on both context tokens and domain tokens of ALMs is set. Second, guidance of both consistency across multiple augmented views of each single test sample and contrastive learning across different test samples is set. Third, we propose a corresponding end-end learning framework for the proposed test-time adaptation method without annotated labels. We extensively evaluate our approach on 12 downstream tasks across domains, our proposed adaptation method leads to 4.41% (max 7.50%) average zero-shot performance improvement in comparison with the state-of-the-art models.
<div id='section'>Paperid: <span id='pid'>297, <a href='https://arxiv.org/pdf/2404.05426.pdf' target='_blank'>https://arxiv.org/pdf/2404.05426.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Benedetta Liberatori, Alessandro Conti, Paolo Rota, Yiming Wang, Elisa Ricci
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.05426">Test-Time Zero-Shot Temporal Action Localization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Zero-Shot Temporal Action Localization (ZS-TAL) seeks to identify and locate actions in untrimmed videos unseen during training. Existing ZS-TAL methods involve fine-tuning a model on a large amount of annotated training data. While effective, training-based ZS-TAL approaches assume the availability of labeled data for supervised learning, which can be impractical in some applications. Furthermore, the training process naturally induces a domain bias into the learned model, which may adversely affect the model's generalization ability to arbitrary videos. These considerations prompt us to approach the ZS-TAL problem from a radically novel perspective, relaxing the requirement for training data. To this aim, we introduce a novel method that performs Test-Time adaptation for Temporal Action Localization (T3AL). In a nutshell, T3AL adapts a pre-trained Vision and Language Model (VLM). T3AL operates in three steps. First, a video-level pseudo-label of the action category is computed by aggregating information from the entire video. Then, action localization is performed adopting a novel procedure inspired by self-supervised learning. Finally, frame-level textual descriptions extracted with a state-of-the-art captioning model are employed for refining the action region proposals. We validate the effectiveness of T3AL by conducting experiments on the THUMOS14 and the ActivityNet-v1.3 datasets. Our results demonstrate that T3AL significantly outperforms zero-shot baselines based on state-of-the-art VLMs, confirming the benefit of a test-time adaptation approach.
<div id='section'>Paperid: <span id='pid'>298, <a href='https://arxiv.org/pdf/2403.07684.pdf' target='_blank'>https://arxiv.org/pdf/2403.07684.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yijun Yang, Hongtao Wu, Angelica I. Aviles-Rivero, Yulun Zhang, Jing Qin, Lei Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.07684">Genuine Knowledge from Practice: Diffusion Test-Time Adaptation for Video Adverse Weather Removal</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Real-world vision tasks frequently suffer from the appearance of unexpected adverse weather conditions, including rain, haze, snow, and raindrops. In the last decade, convolutional neural networks and vision transformers have yielded outstanding results in single-weather video removal. However, due to the absence of appropriate adaptation, most of them fail to generalize to other weather conditions. Although ViWS-Net is proposed to remove adverse weather conditions in videos with a single set of pre-trained weights, it is seriously blinded by seen weather at train-time and degenerates when coming to unseen weather during test-time. In this work, we introduce test-time adaptation into adverse weather removal in videos, and propose the first framework that integrates test-time adaptation into the iterative diffusion reverse process. Specifically, we devise a diffusion-based network with a novel temporal noise model to efficiently explore frame-correlated information in degraded video clips at training stage. During inference stage, we introduce a proxy task named Diffusion Tubelet Self-Calibration to learn the primer distribution of test video stream and optimize the model by approximating the temporal noise model for online adaptation. Experimental results, on benchmark datasets, demonstrate that our Test-Time Adaptation method with Diffusion-based network(Diff-TTA) outperforms state-of-the-art methods in terms of restoring videos degraded by seen weather conditions. Its generalizable capability is also validated with unseen weather conditions in both synthesized and real-world videos.
<div id='section'>Paperid: <span id='pid'>299, <a href='https://arxiv.org/pdf/2509.03956.pdf' target='_blank'>https://arxiv.org/pdf/2509.03956.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Minjong Yoo, Jinwoo Jang, Sihyung Yoon, Honguk Woo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.03956">World Model Implanting for Test-time Adaptation of Embodied Agents</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In embodied AI, a persistent challenge is enabling agents to robustly adapt to novel domains without requiring extensive data collection or retraining. To address this, we present a world model implanting framework (WorMI) that combines the reasoning capabilities of large language models (LLMs) with independently learned, domain-specific world models through test-time composition. By allowing seamless implantation and removal of the world models, the embodied agent's policy achieves and maintains cross-domain adaptability. In the WorMI framework, we employ a prototype-based world model retrieval approach, utilizing efficient trajectory-based abstract representation matching, to incorporate relevant models into test-time composition. We also develop a world-wise compound attention method that not only integrates the knowledge from the retrieved world models but also aligns their intermediate representations with the reasoning model's representation within the agent's policy. This framework design effectively fuses domain-specific knowledge from multiple world models, ensuring robust adaptation to unseen domains. We evaluate our WorMI on the VirtualHome and ALFWorld benchmarks, demonstrating superior zero-shot and few-shot performance compared to several LLM-based approaches across a range of unseen domains. These results highlight the frameworks potential for scalable, real-world deployment in embodied agent scenarios where adaptability and data efficiency are essential.
<div id='section'>Paperid: <span id='pid'>300, <a href='https://arxiv.org/pdf/2509.03956.pdf' target='_blank'>https://arxiv.org/pdf/2509.03956.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Minjong Yoo, Jinwoo Jang, Sihyung Yoon, Honguk Woo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.03956">World Model Implanting for Test-time Adaptation of Embodied Agents</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In embodied AI, a persistent challenge is enabling agents to robustly adapt to novel domains without requiring extensive data collection or retraining. To address this, we present a world model implanting framework (WorMI) that combines the reasoning capabilities of large language models (LLMs) with independently learned, domain-specific world models through test-time composition. By allowing seamless implantation and removal of the world models, the embodied agent's policy achieves and maintains cross-domain adaptability. In the WorMI framework, we employ a prototype-based world model retrieval approach, utilizing efficient trajectory-based abstract representation matching, to incorporate relevant models into test-time composition. We also develop a world-wise compound attention method that not only integrates the knowledge from the retrieved world models but also aligns their intermediate representations with the reasoning model's representation within the agent's policy. This framework design effectively fuses domain-specific knowledge from multiple world models, ensuring robust adaptation to unseen domains. We evaluate our WorMI on the VirtualHome and ALFWorld benchmarks, demonstrating superior zero-shot and few-shot performance compared to several LLM-based approaches across a range of unseen domains. These results highlight the frameworks potential for scalable, real-world deployment in embodied agent scenarios where adaptability and data efficiency are essential.
<div id='section'>Paperid: <span id='pid'>301, <a href='https://arxiv.org/pdf/2507.12880.pdf' target='_blank'>https://arxiv.org/pdf/2507.12880.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenting Zhu, Chaozhuo Li, Qingpo Yang, Xi Zhang, Philip S. Yu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.12880">T3MAL: Test-Time Fast Adaptation for Robust Multi-Scale Information Diffusion Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Information diffusion prediction (IDP) is a pivotal task for understanding how information propagates among users. Most existing methods commonly adhere to a conventional training-test paradigm, where models are pretrained on training data and then directly applied to test samples. However, the success of this paradigm hinges on the assumption that the data are independently and identically distributed, which often fails in practical social networks due to the inherent uncertainty and variability of user behavior. In the paper, we address the novel challenge of distribution shifts within IDP tasks and propose a robust test-time training (TTT)-based framework for multi-scale diffusion prediction, named T3MAL. The core idea is to flexibly adapt a trained model to accommodate the distribution of each test instance before making predictions via a self-supervised auxiliary task. Specifically, T3MAL introduces a BYOL-inspired self-supervised auxiliary network that shares a common feature extraction backbone with the primary diffusion prediction network to guide instance-specific adaptation during testing. Furthermore, T3MAL enables fast and accurate test-time adaptation by incorporating a novel meta-auxiliary learning scheme and a lightweight adaptor, which together provide better weight initialization for TTT and mitigate catastrophic forgetting. Extensive experiments on three public datasets demonstrate that T3MAL outperforms various state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>302, <a href='https://arxiv.org/pdf/2506.07078.pdf' target='_blank'>https://arxiv.org/pdf/2506.07078.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiaheng Dong, Hong Jia, Soumyajit Chatterjee, Abhirup Ghosh, James Bailey, Ting Dang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.07078">E-BATS: Efficient Backpropagation-Free Test-Time Adaptation for Speech Foundation Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Speech Foundation Models encounter significant performance degradation when deployed in real-world scenarios involving acoustic domain shifts, such as background noise and speaker accents. Test-time adaptation (TTA) has recently emerged as a viable strategy to address such domain shifts at inference time without requiring access to source data or labels. However, existing TTA approaches, particularly those relying on backpropagation, are memory-intensive, limiting their applicability in speech tasks and resource-constrained settings. Although backpropagation-free methods offer improved efficiency, existing ones exhibit poor accuracy. This is because they are predominantly developed for vision tasks, which fundamentally differ from speech task formulations, noise characteristics, and model architecture, posing unique transferability challenges. In this paper, we introduce E-BATS, the first Efficient BAckpropagation-free TTA framework designed explicitly for speech foundation models. E-BATS achieves a balance between adaptation effectiveness and memory efficiency through three key components: (i) lightweight prompt adaptation for a forward-pass-based feature alignment, (ii) a multi-scale loss to capture both global (utterance-level) and local distribution shifts (token-level) and (iii) a test-time exponential moving average mechanism for stable adaptation across utterances. Experiments conducted on four noisy speech datasets spanning sixteen acoustic conditions demonstrate consistent improvements, with 4.1%-13.5% accuracy gains over backpropagation-free baselines and 2.0-6.4 times GPU memory savings compared to backpropagation-based methods. By enabling scalable and robust adaptation under acoustic variability, this work paves the way for developing more efficient adaptation approaches for practical speech processing systems in real-world environments.
<div id='section'>Paperid: <span id='pid'>303, <a href='https://arxiv.org/pdf/2410.12191.pdf' target='_blank'>https://arxiv.org/pdf/2410.12191.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kecheng Chen, Pingping Zhang, Tiexin Qin, Shiqi Wang, Hong Yan, Haoliang Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.12191">Test-time adaptation for image compression with distribution regularization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current test- or compression-time adaptation image compression (TTA-IC) approaches, which leverage both latent and decoder refinements as a two-step adaptation scheme, have potentially enhanced the rate-distortion (R-D) performance of learned image compression models on cross-domain compression tasks, \textit{e.g.,} from natural to screen content images. However, compared with the emergence of various decoder refinement variants, the latent refinement, as an inseparable ingredient, is barely tailored to cross-domain scenarios. To this end, we aim to develop an advanced latent refinement method by extending the effective hybrid latent refinement (HLR) method, which is designed for \textit{in-domain} inference improvement but shows noticeable degradation of the rate cost in \textit{cross-domain} tasks. Specifically, we first provide theoretical analyses, in a cue of marginalization approximation from in- to cross-domain scenarios, to uncover that the vanilla HLR suffers from an underlying mismatch between refined Gaussian conditional and hyperprior distributions, leading to deteriorated joint probability approximation of marginal distribution with increased rate consumption. To remedy this issue, we introduce a simple Bayesian approximation-endowed \textit{distribution regularization} to encourage learning a better joint probability approximation in a plug-and-play manner. Extensive experiments on six in- and cross-domain datasets demonstrate that our proposed method not only improves the R-D performance compared with other latent refinement counterparts, but also can be flexibly integrated into existing TTA-IC methods with incremental benefits.
<div id='section'>Paperid: <span id='pid'>304, <a href='https://arxiv.org/pdf/2409.19375.pdf' target='_blank'>https://arxiv.org/pdf/2409.19375.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zongbo Han, Jialong Yang, Guangyu Wang, Junfan Li, Qianli Xu, Mike Zheng Shou, Changqing Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.19375">DOTA: Distributional Test-Time Adaptation of Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-language foundation models (VLMs), such as CLIP, exhibit remarkable performance across a wide range of tasks. However, deploying these models can be unreliable when significant distribution gaps exist between training and test data, while fine-tuning for diverse scenarios is often costly. Cache-based test-time adapters offer an efficient alternative by storing representative test samples to guide subsequent classifications. Yet, these methods typically employ naive cache management with limited capacity, leading to severe catastrophic forgetting when samples are inevitably dropped during updates. In this paper, we propose DOTA (DistributiOnal Test-time Adaptation), a simple yet effective method addressing this limitation. Crucially, instead of merely memorizing individual test samples, DOTA continuously estimates the underlying distribution of the test data stream. Test-time posterior probabilities are then computed using these dynamically estimated distributions via Bayes' theorem for adaptation. This distribution-centric approach enables the model to continually learn and adapt to the deployment environment. Extensive experiments validate that DOTA significantly mitigates forgetting and achieves state-of-the-art performance compared to existing methods.
<div id='section'>Paperid: <span id='pid'>305, <a href='https://arxiv.org/pdf/2409.19375.pdf' target='_blank'>https://arxiv.org/pdf/2409.19375.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zongbo Han, Jialong Yang, Guangyu Wang, Junfan Li, Qianli Xu, Mike Zheng Shou, Changqing Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.19375">DOTA: Distributional Test-Time Adaptation of Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-language foundation models (VLMs), such as CLIP, exhibit remarkable performance across a wide range of tasks. However, deploying these models can be unreliable when significant distribution gaps exist between training and test data, while fine-tuning for diverse scenarios is often costly. Cache-based test-time adapters offer an efficient alternative by storing representative test samples to guide subsequent classifications. Yet, these methods typically employ naive cache management with limited capacity, leading to severe catastrophic forgetting when samples are inevitably dropped during updates. In this paper, we propose DOTA (DistributiOnal Test-time Adaptation), a simple yet effective method addressing this limitation. Crucially, instead of merely memorizing individual test samples, DOTA continuously estimates the underlying distribution of the test data stream. Test-time posterior probabilities are then computed using these dynamically estimated distributions via Bayes' theorem for adaptation. This distribution-centric approach enables the model to continually learn and adapt to the deployment environment. Extensive experiments validate that DOTA significantly mitigates forgetting and achieves state-of-the-art performance compared to existing methods.
<div id='section'>Paperid: <span id='pid'>306, <a href='https://arxiv.org/pdf/2408.16265.pdf' target='_blank'>https://arxiv.org/pdf/2408.16265.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yu Liang, Shilei Cao, Xiucheng Zhang, Juepeng Zheng, Jianxi Huang, Haohuan Fu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.16265">Low Saturation Confidence Distribution-based Test-Time Adaptation for Cross-Domain Remote Sensing Image Classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Unsupervised Domain Adaptation (UDA) has emerged as a powerful technique for addressing the distribution shift across various Remote Sensing (RS) applications. However, most UDA approaches require access to source data, which may be infeasible due to data privacy or transmission constraints. Source-free Domain Adaptation addresses the absence of source data but usually demands a large amount of target domain data beforehand, hindering rapid adaptation and restricting their applicability in broader scenarios. In practical cross-domain RS image classification, achieving a balance between adaptation speed and accuracy is crucial. Therefore, we propose Low Saturation Confidence Distribution Test-Time Adaptation (LSCD-TTA), marketing the first attempt to explore Test-Time Adaptation for cross-domain RS image classification without requiring source or target training data. LSCD-TTA adapts a source-trained model on the fly using only the target test data encountered during inference, enabling immediate and efficient adaptation while maintaining high accuracy. Specifically, LSCD-TTA incorporates three optimization strategies tailored to the distribution characteristics of RS images. Firstly, weak-confidence softmax-entropy loss emphasizes categories that are more difficult to classify to address unbalanced class distribution. Secondly, balanced-categories softmax-entropy loss softens and balances the predicted probabilities to tackle the category diversity. Finally, low saturation distribution loss utilizes soft log-likelihood ratios to reduce the impact of low-confidence samples in the later stages of adaptation. By effectively combining these losses, LSCD-TTA enables rapid and accurate adaptation to the target domain for RS image classification.
<div id='section'>Paperid: <span id='pid'>307, <a href='https://arxiv.org/pdf/2303.17937.pdf' target='_blank'>https://arxiv.org/pdf/2303.17937.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yijin Chen, Xun Xu, Yongyi Su, Kui Jia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.17937">STFAR: Improving Object Detection Robustness at Test-Time by Self-Training with Feature Alignment Regularization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Domain adaptation helps generalizing object detection models to target domain data with distribution shift. It is often achieved by adapting with access to the whole target domain data. In a more realistic scenario, target distribution is often unpredictable until inference stage. This motivates us to explore adapting an object detection model at test-time, a.k.a. test-time adaptation (TTA). In this work, we approach test-time adaptive object detection (TTAOD) from two perspective. First, we adopt a self-training paradigm to generate pseudo labeled objects with an exponential moving average model. The pseudo labels are further used to supervise adapting source domain model. As self-training is prone to incorrect pseudo labels, we further incorporate aligning feature distributions at two output levels as regularizations to self-training. To validate the performance on TTAOD, we create benchmarks based on three standard object detection datasets and adapt generic TTA methods to object detection task. Extensive evaluations suggest our proposed method sets the state-of-the-art on test-time adaptive object detection task.
<div id='section'>Paperid: <span id='pid'>308, <a href='https://arxiv.org/pdf/2303.16730.pdf' target='_blank'>https://arxiv.org/pdf/2303.16730.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Taeyeop Lee, Jonathan Tremblay, Valts Blukis, Bowen Wen, Byeong-Uk Lee, Inkyu Shin, Stan Birchfield, In So Kweon, Kuk-Jin Yoon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.16730">TTA-COPE: Test-Time Adaptation for Category-Level Object Pose Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation methods have been gaining attention recently as a practical solution for addressing source-to-target domain gaps by gradually updating the model without requiring labels on the target data. In this paper, we propose a method of test-time adaptation for category-level object pose estimation called TTA-COPE. We design a pose ensemble approach with a self-training loss using pose-aware confidence. Unlike previous unsupervised domain adaptation methods for category-level object pose estimation, our approach processes the test data in a sequential, online manner, and it does not require access to the source domain at runtime. Extensive experimental results demonstrate that the proposed pose ensemble and the self-training loss improve category-level object pose performance during test time under both semi-supervised and unsupervised settings. Project page: https://taeyeop.com/ttacope
<div id='section'>Paperid: <span id='pid'>309, <a href='https://arxiv.org/pdf/2509.02182.pdf' target='_blank'>https://arxiv.org/pdf/2509.02182.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shyma Alhuwaider, Motasem Alfarra, Juan C. Perez, Merey Ramazanova, Bernard Ghanem
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.02182">ADVMEM: Adversarial Memory Initialization for Realistic Test-Time Adaptation via Tracklet-Based Benchmarking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a novel tracklet-based dataset for benchmarking test-time adaptation (TTA) methods. The aim of this dataset is to mimic the intricate challenges encountered in real-world environments such as images captured by hand-held cameras, self-driving cars, etc. The current benchmarks for TTA focus on how models face distribution shifts, when deployed, and on violations to the customary independent-and-identically-distributed (i.i.d.) assumption in machine learning. Yet, these benchmarks fail to faithfully represent realistic scenarios that naturally display temporal dependencies, such as how consecutive frames from a video stream likely show the same object across time. We address this shortcoming of current datasets by proposing a novel TTA benchmark we call the "Inherent Temporal Dependencies" (ITD) dataset. We ensure the instances in ITD naturally embody temporal dependencies by collecting them from tracklets-sequences of object-centric images we compile from the bounding boxes of an object-tracking dataset. We use ITD to conduct a thorough experimental analysis of current TTA methods, and shed light on the limitations of these methods when faced with the challenges of temporal dependencies. Moreover, we build upon these insights and propose a novel adversarial memory initialization strategy to improve memory-based TTA methods. We find this strategy substantially boosts the performance of various methods on our challenging benchmark.
<div id='section'>Paperid: <span id='pid'>310, <a href='https://arxiv.org/pdf/2509.02182.pdf' target='_blank'>https://arxiv.org/pdf/2509.02182.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shyma Alhuwaider, Motasem Alfarra, Juan C. Perez, Merey Ramazanova, Bernard Ghanem
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.02182">ADVMEM: Adversarial Memory Initialization for Realistic Test-Time Adaptation via Tracklet-Based Benchmarking</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce a novel tracklet-based dataset for benchmarking test-time adaptation (TTA) methods. The aim of this dataset is to mimic the intricate challenges encountered in real-world environments such as images captured by hand-held cameras, self-driving cars, etc. The current benchmarks for TTA focus on how models face distribution shifts, when deployed, and on violations to the customary independent-and-identically-distributed (i.i.d.) assumption in machine learning. Yet, these benchmarks fail to faithfully represent realistic scenarios that naturally display temporal dependencies, such as how consecutive frames from a video stream likely show the same object across time. We address this shortcoming of current datasets by proposing a novel TTA benchmark we call the "Inherent Temporal Dependencies" (ITD) dataset. We ensure the instances in ITD naturally embody temporal dependencies by collecting them from tracklets-sequences of object-centric images we compile from the bounding boxes of an object-tracking dataset. We use ITD to conduct a thorough experimental analysis of current TTA methods, and shed light on the limitations of these methods when faced with the challenges of temporal dependencies. Moreover, we build upon these insights and propose a novel adversarial memory initialization strategy to improve memory-based TTA methods. We find this strategy substantially boosts the performance of various methods on our challenging benchmark.
<div id='section'>Paperid: <span id='pid'>311, <a href='https://arxiv.org/pdf/2507.18225.pdf' target='_blank'>https://arxiv.org/pdf/2507.18225.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xin Wei, Qin Yang, Yijie Fang, Mingrui Zhu, Nannan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.18225">3D Test-time Adaptation via Graph Spectral Driven Point Shift</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While test-time adaptation (TTA) methods effectively address domain shifts by dynamically adapting pre-trained models to target domain data during online inference, their application to 3D point clouds is hindered by their irregular and unordered structure. Current 3D TTA methods often rely on computationally expensive spatial-domain optimizations and may require additional training data. In contrast, we propose Graph Spectral Domain Test-Time Adaptation (GSDTTA), a novel approach for 3D point cloud classification that shifts adaptation to the graph spectral domain, enabling more efficient adaptation by capturing global structural properties with fewer parameters. Point clouds in target domain are represented as outlier-aware graphs and transformed into graph spectral domain by Graph Fourier Transform (GFT). For efficiency, adaptation is performed by optimizing only the lowest 10% of frequency components, which capture the majority of the point cloud's energy. An inverse GFT (IGFT) is then applied to reconstruct the adapted point cloud with the graph spectral-driven point shift. This process is enhanced by an eigenmap-guided self-training strategy that iteratively refines both the spectral adjustments and the model parameters. Experimental results and ablation studies on benchmark datasets demonstrate the effectiveness of GSDTTA, outperforming existing TTA methods for 3D point cloud classification.
<div id='section'>Paperid: <span id='pid'>312, <a href='https://arxiv.org/pdf/2507.14312.pdf' target='_blank'>https://arxiv.org/pdf/2507.14312.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marc Lafon, Gustavo Adolfo Vargas Hakim, ClÃ©ment Rambour, Christian Desrosier, Nicolas Thome
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.14312">CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-language models (VLMs) like CLIP exhibit strong zero-shot capabilities but often fail to generalize under distribution shifts. Test-time adaptation (TTA) allows models to update at inference time without labeled data, typically via entropy minimization. However, this objective is fundamentally misaligned with the contrastive image-text training of VLMs, limiting adaptation performance and introducing failure modes such as pseudo-label drift and class collapse. We propose CLIPTTA, a new gradient-based TTA method for vision-language models that leverages a soft contrastive loss aligned with CLIP's pre-training objective. We provide a theoretical analysis of CLIPTTA's gradients, showing how its batch-aware design mitigates the risk of collapse. We further extend CLIPTTA to the open-set setting, where both in-distribution (ID) and out-of-distribution (OOD) samples are encountered, using an Outlier Contrastive Exposure (OCE) loss to improve OOD detection. Evaluated on 75 datasets spanning diverse distribution shifts, CLIPTTA consistently outperforms entropy-based objectives and is highly competitive with state-of-the-art TTA methods, outperforming them on a large number of datasets and exhibiting more stable performance across diverse shifts.
<div id='section'>Paperid: <span id='pid'>313, <a href='https://arxiv.org/pdf/2507.14312.pdf' target='_blank'>https://arxiv.org/pdf/2507.14312.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marc Lafon, Gustavo Adolfo Vargas Hakim, ClÃ©ment Rambour, Christian Desrosier, Nicolas Thome
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.14312">CLIPTTA: Robust Contrastive Vision-Language Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-language models (VLMs) like CLIP exhibit strong zero-shot capabilities but often fail to generalize under distribution shifts. Test-time adaptation (TTA) allows models to update at inference time without labeled data, typically via entropy minimization. However, this objective is fundamentally misaligned with the contrastive image-text training of VLMs, limiting adaptation performance and introducing failure modes such as pseudo-label drift and class collapse. We propose CLIPTTA, a new gradient-based TTA method for vision-language models that leverages a soft contrastive loss aligned with CLIP's pre-training objective. We provide a theoretical analysis of CLIPTTA's gradients, showing how its batch-aware design mitigates the risk of collapse. We further extend CLIPTTA to the open-set setting, where both in-distribution (ID) and out-of-distribution (OOD) samples are encountered, using an Outlier Contrastive Exposure (OCE) loss to improve OOD detection. Evaluated on 75 datasets spanning diverse distribution shifts, CLIPTTA consistently outperforms entropy-based objectives and is highly competitive with state-of-the-art TTA methods, outperforming them on a large number of datasets and exhibiting more stable performance across diverse shifts.
<div id='section'>Paperid: <span id='pid'>314, <a href='https://arxiv.org/pdf/2501.09052.pdf' target='_blank'>https://arxiv.org/pdf/2501.09052.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuang Cui, Yi Li, Jiangmeng Li, Xiongxin Tang, Bing Su, Fanjiang Xu, Hui Xiong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.09052">Continual Test-Time Adaptation for Single Image Defocus Deblurring via Causal Siamese Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Single image defocus deblurring (SIDD) aims to restore an all-in-focus image from a defocused one. Distribution shifts in defocused images generally lead to performance degradation of existing methods during out-of-distribution inferences. In this work, we gauge the intrinsic reason behind the performance degradation, which is identified as the heterogeneity of lens-specific point spread functions. Empirical evidence supports this finding, motivating us to employ a continual test-time adaptation (CTTA) paradigm for SIDD. However, traditional CTTA methods, which primarily rely on entropy minimization, cannot sufficiently explore task-dependent information for pixel-level regression tasks like SIDD. To address this issue, we propose a novel Siamese networks-based continual test-time adaptation framework, which adapts source models to continuously changing target domains only requiring unlabeled target data in an online manner. To further mitigate semantically erroneous textures introduced by source SIDD models under severe degradation, we revisit the learning paradigm through a structural causal model and propose Causal Siamese networks (CauSiam). Our method leverages large-scale pre-trained vision-language models to derive discriminative universal semantic priors and integrates these priors into Siamese networks, ensuring causal identifiability between blurry inputs and restored images. Extensive experiments demonstrate that CauSiam effectively improves the generalization performance of existing SIDD methods in continuously changing domains.
<div id='section'>Paperid: <span id='pid'>315, <a href='https://arxiv.org/pdf/2406.12456.pdf' target='_blank'>https://arxiv.org/pdf/2406.12456.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yi Zhang, Yidong Zhao, Lu Huang, Liming Xia, Qian Tao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.12456">Deep-learning-based groupwise registration for motion correction of cardiac $T_1$ mapping</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quantitative $T_1$ mapping by MRI is an increasingly important tool for clinical assessment of cardiovascular diseases. The cardiac $T_1$ map is derived by fitting a known signal model to a series of baseline images, while the quality of this map can be deteriorated by involuntary respiratory and cardiac motion. To correct motion, a template image is often needed to register all baseline images, but the choice of template is nontrivial, leading to inconsistent performance sensitive to image contrast. In this work, we propose a novel deep-learning-based groupwise registration framework, which omits the need for a template, and registers all baseline images simultaneously. We design two groupwise losses for this registration framework: the first is a linear principal component analysis (PCA) loss that enforces alignment of baseline images irrespective of the intensity variation, and the second is an auxiliary relaxometry loss that enforces adherence of intensity profile to the signal model. We extensively evaluated our method, termed ``PCA-Relax'', and other baseline methods on an in-house cardiac MRI dataset including both pre- and post-contrast $T_1$ sequences. All methods were evaluated under three distinct training-and-evaluation strategies, namely, standard, one-shot, and test-time-adaptation. The proposed PCA-Relax showed further improved performance of registration and mapping over well-established baselines. The proposed groupwise framework is generic and can be adapted to applications involving multiple images.
<div id='section'>Paperid: <span id='pid'>316, <a href='https://arxiv.org/pdf/2404.15161.pdf' target='_blank'>https://arxiv.org/pdf/2404.15161.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Merey Ramazanova, Alejandro Pardo, Bernard Ghanem, Motasem Alfarra
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.15161">Test-Time Adaptation for Combating Missing Modalities in Egocentric Videos</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding videos that contain multiple modalities is crucial, especially in egocentric videos, where combining various sensory inputs significantly improves tasks like action recognition and moment localization. However, real-world applications often face challenges with incomplete modalities due to privacy concerns, efficiency needs, or hardware issues. Current methods, while effective, often necessitate retraining the model entirely to handle missing modalities, making them computationally intensive, particularly with large training datasets. In this study, we propose a novel approach to address this issue at test time without requiring retraining. We frame the problem as a test-time adaptation task, where the model adjusts to the available unlabeled data at test time. Our method, MiDl~(Mutual information with self-Distillation), encourages the model to be insensitive to the specific modality source present during testing by minimizing the mutual information between the prediction and the available modality. Additionally, we incorporate self-distillation to maintain the model's original performance when both modalities are available. MiDl represents the first self-supervised, online solution for handling missing modalities exclusively at test time. Through experiments with various pretrained models and datasets, MiDl demonstrates substantial performance improvement without the need for retraining.
<div id='section'>Paperid: <span id='pid'>317, <a href='https://arxiv.org/pdf/2310.13533.pdf' target='_blank'>https://arxiv.org/pdf/2310.13533.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Damian SÃ³jka, Yuyang Liu, Dipam Goswami, Sebastian Cygert, BartÅomiej Twardowski, Joost van de Weijer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.13533">Technical Report for ICCV 2023 Visual Continual Learning Challenge: Continuous Test-time Adaptation for Semantic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The goal of the challenge is to develop a test-time adaptation (TTA) method, which could adapt the model to gradually changing domains in video sequences for semantic segmentation task. It is based on a synthetic driving video dataset - SHIFT. The source model is trained on images taken during daytime in clear weather. Domain changes at test-time are mainly caused by varying weather conditions and times of day. The TTA methods are evaluated in each image sequence (video) separately, meaning the model is reset to the source model state before the next sequence. Images come one by one and a prediction has to be made at the arrival of each frame. Each sequence is composed of 401 images and starts with the source domain, then gradually drifts to a different one (changing weather or time of day) until the middle of the sequence. In the second half of the sequence, the domain gradually shifts back to the source one. Ground truth data is available only for the validation split of the SHIFT dataset, in which there are only six sequences that start and end with the source domain. We conduct an analysis specifically on those sequences. Ground truth data for test split, on which the developed TTA methods are evaluated for leader board ranking, are not publicly available.
  The proposed solution secured a 3rd place in a challenge and received an innovation award. Contrary to the solutions that scored better, we did not use any external pretrained models or specialized data augmentations, to keep the solutions as general as possible. We have focused on analyzing the distributional shift and developing a method that could adapt to changing data dynamics and generalize across different scenarios.
<div id='section'>Paperid: <span id='pid'>318, <a href='https://arxiv.org/pdf/2304.04795.pdf' target='_blank'>https://arxiv.org/pdf/2304.04795.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Motasem Alfarra, Hani Itani, Alejandro Pardo, Shyma Alhuwaider, Merey Ramazanova, Juan C. PÃ©rez, Zhipeng Cai, Matthias MÃ¼ller, Bernard Ghanem
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.04795">Evaluation of Test-Time Adaptation Under Computational Time Constraints</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes a novel online evaluation protocol for Test Time Adaptation (TTA) methods, which penalizes slower methods by providing them with fewer samples for adaptation. TTA methods leverage unlabeled data at test time to adapt to distribution shifts. Although many effective methods have been proposed, their impressive performance usually comes at the cost of significantly increased computation budgets. Current evaluation protocols overlook the effect of this extra computation cost, affecting their real-world applicability. To address this issue, we propose a more realistic evaluation protocol for TTA methods, where data is received in an online fashion from a constant-speed data stream, thereby accounting for the method's adaptation speed. We apply our proposed protocol to benchmark several TTA methods on multiple datasets and scenarios. Extensive experiments show that, when accounting for inference speed, simple and fast approaches can outperform more sophisticated but slower methods. For example, SHOT from 2020, outperforms the state-of-the-art method SAR from 2023 in this setting. Our results reveal the importance of developing practical TTA methods that are both accurate and efficient.
<div id='section'>Paperid: <span id='pid'>319, <a href='https://arxiv.org/pdf/2301.12576.pdf' target='_blank'>https://arxiv.org/pdf/2301.12576.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tong Wu, Feiran Jia, Xiangyu Qi, Jiachen T. Wang, Vikash Sehwag, Saeed Mahloujifar, Prateek Mittal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.12576">Uncovering Adversarial Risks of Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, test-time adaptation (TTA) has been proposed as a promising solution for addressing distribution shifts. It allows a base model to adapt to an unforeseen distribution during inference by leveraging the information from the batch of (unlabeled) test data. However, we uncover a novel security vulnerability of TTA based on the insight that predictions on benign samples can be impacted by malicious samples in the same batch. To exploit this vulnerability, we propose Distribution Invading Attack (DIA), which injects a small fraction of malicious data into the test batch. DIA causes models using TTA to misclassify benign and unperturbed test data, providing an entirely new capability for adversaries that is infeasible in canonical machine learning pipelines. Through comprehensive evaluations, we demonstrate the high effectiveness of our attack on multiple benchmarks across six TTA methods. In response, we investigate two countermeasures to robustify the existing insecure TTA implementations, following the principle of "security by design". Together, we hope our findings can make the community aware of the utility-security tradeoffs in deploying TTA and provide valuable insights for developing robust TTA approaches.
<div id='section'>Paperid: <span id='pid'>320, <a href='https://arxiv.org/pdf/2509.25495.pdf' target='_blank'>https://arxiv.org/pdf/2509.25495.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiacheng Shi, Hongfei Du, Y. Alicia Hong, Ye Gao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.25495">EMO-TTA: Improving Test-Time Adaptation of Audio-Language Models for Speech Emotion Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Speech emotion recognition (SER) with audio-language models (ALMs) remains vulnerable to distribution shifts at test time, leading to performance degradation in out-of-domain scenarios. Test-time adaptation (TTA) provides a promising solution but often relies on gradient-based updates or prompt tuning, limiting flexibility and practicality. We propose Emo-TTA, a lightweight, training-free adaptation framework that incrementally updates class-conditional statistics via an Expectation-Maximization procedure for explicit test-time distribution estimation, using ALM predictions as priors. Emo-TTA operates on individual test samples without modifying model weights. Experiments on six out-of-domain SER benchmarks show consistent accuracy improvements over prior TTA baselines, demonstrating the effectiveness of statistical adaptation in aligning model predictions with evolving test distributions.
<div id='section'>Paperid: <span id='pid'>321, <a href='https://arxiv.org/pdf/2509.25495.pdf' target='_blank'>https://arxiv.org/pdf/2509.25495.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiacheng Shi, Hongfei Du, Y. Alicia Hong, Ye Gao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.25495">EMO-TTA: Improving Test-Time Adaptation of Audio-Language Models for Speech Emotion Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Speech emotion recognition (SER) with audio-language models (ALMs) remains vulnerable to distribution shifts at test time, leading to performance degradation in out-of-domain scenarios. Test-time adaptation (TTA) provides a promising solution but often relies on gradient-based updates or prompt tuning, limiting flexibility and practicality. We propose Emo-TTA, a lightweight, training-free adaptation framework that incrementally updates class-conditional statistics via an Expectation-Maximization procedure for explicit test-time distribution estimation, using ALM predictions as priors. Emo-TTA operates on individual test samples without modifying model weights. Experiments on six out-of-domain SER benchmarks show consistent accuracy improvements over prior TTA baselines, demonstrating the effectiveness of statistical adaptation in aligning model predictions with evolving test distributions.
<div id='section'>Paperid: <span id='pid'>322, <a href='https://arxiv.org/pdf/2509.25495.pdf' target='_blank'>https://arxiv.org/pdf/2509.25495.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiacheng Shi, Hongfei Du, Y. Alicia Hong, Ye Gao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.25495">EMO-TTA: Improving Test-Time Adaptation of Audio-Language Models for Speech Emotion Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Speech emotion recognition (SER) with audio-language models (ALMs) remains vulnerable to distribution shifts at test time, leading to performance degradation in out-of-domain scenarios. Test-time adaptation (TTA) provides a promising solution but often relies on gradient-based updates or prompt tuning, limiting flexibility and practicality. We propose Emo-TTA, a lightweight, training-free adaptation framework that incrementally updates class-conditional statistics via an Expectation-Maximization procedure for explicit test-time distribution estimation, using ALM predictions as priors. Emo-TTA operates on individual test samples without modifying model weights. Experiments on six out-of-domain SER benchmarks show consistent accuracy improvements over prior TTA baselines, demonstrating the effectiveness of statistical adaptation in aligning model predictions with evolving test distributions.
<div id='section'>Paperid: <span id='pid'>323, <a href='https://arxiv.org/pdf/2509.25495.pdf' target='_blank'>https://arxiv.org/pdf/2509.25495.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiacheng Shi, Hongfei Du, Y. Alicia Hong, Ye Gao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.25495">EMO-TTA: Improving Test-Time Adaptation of Audio-Language Models for Speech Emotion Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Speech emotion recognition (SER) with audio-language models (ALMs) remains vulnerable to distribution shifts at test time, leading to performance degradation in out-of-domain scenarios. Test-time adaptation (TTA) provides a promising solution but often relies on gradient-based updates or prompt tuning, limiting flexibility and practicality. We propose Emo-TTA, a lightweight, training-free adaptation framework that incrementally updates class-conditional statistics via an Expectation-Maximization procedure for explicit test-time distribution estimation, using ALM predictions as priors. Emo-TTA operates on individual test samples without modifying model weights. Experiments on six out-of-domain SER benchmarks show consistent accuracy improvements over prior TTA baselines, demonstrating the effectiveness of statistical adaptation in aligning model predictions with evolving test distributions.
<div id='section'>Paperid: <span id='pid'>324, <a href='https://arxiv.org/pdf/2508.17417.pdf' target='_blank'>https://arxiv.org/pdf/2508.17417.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaojie Yin, Qilong Wang, Qinghua Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.17417">Constrained Prompt Enhancement for Improving Zero-Shot Generalization of Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-language models (VLMs) pre-trained on web-scale data exhibit promising zero-shot generalization but often suffer from semantic misalignment due to domain gaps between pre-training and downstream tasks. Existing approaches primarily focus on text prompting with class-specific descriptions and visual-text adaptation via aligning cropped image regions with textual descriptions. However, they still face the issues of incomplete textual prompts and noisy visual prompts. In this paper, we propose a novel constrained prompt enhancement (CPE) method to improve visual-textual alignment by constructing comprehensive textual prompts and compact visual prompts from the semantic perspective. Specifically, our approach consists of two key components: Topology-Guided Synonymous Semantic Generation (TGSSG) and Category-Agnostic Discriminative Region Selection (CADRS). Textually, to address the issue of incomplete semantic expression in textual prompts, our TGSSG first generates synonymous semantic set for each category via large language models, and constructs comprehensive textual prompts based on semantic ambiguity entropy and persistent homology analysis. Visually, to mitigate the irrelevant visual noise introduced by random cropping, our CADRS identifies discriminative regions with activation maps outputted by a pre-trained vision model, effectively filtering out noisy regions and generating compact visual prompts. Given the comprehensive set of textual prompts and compact set of visual prompts, we introduce two set-to-set matching strategies based on test-time adaptation (TTA) and optimal transport (OT) to achieve effective visual-textual alignment, and so improve zero-shot generalization of VLMs.
<div id='section'>Paperid: <span id='pid'>325, <a href='https://arxiv.org/pdf/2501.13795.pdf' target='_blank'>https://arxiv.org/pdf/2501.13795.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chaolei Han, Hongsong Wang, Jidong Kuang, Lei Zhang, Jie Gui
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.13795">Training-Free Zero-Shot Temporal Action Detection with Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing zero-shot temporal action detection (ZSTAD) methods predominantly use fully supervised or unsupervised strategies to recognize unseen activities. However, these training-based methods are prone to domain shifts and require high computational costs, which hinder their practical applicability in real-world scenarios. In this paper, unlike previous works, we propose a training-Free Zero-shot temporal Action Detection (FreeZAD) method, leveraging existing vision-language (ViL) models to directly classify and localize unseen activities within untrimmed videos without any additional fine-tuning or adaptation. We mitigate the need for explicit temporal modeling and reliance on pseudo-label quality by designing the LOGarithmic decay weighted Outer-Inner-Contrastive Score (LogOIC) and frequency-based Actionness Calibration. Furthermore, we introduce a test-time adaptation (TTA) strategy using Prototype-Centric Sampling (PCS) to expand FreeZAD, enabling ViL models to adapt more effectively for ZSTAD. Extensive experiments on the THUMOS14 and ActivityNet-1.3 datasets demonstrate that our training-free method outperforms state-of-the-art unsupervised methods while requiring only 1/13 of the runtime. When equipped with TTA, the enhanced method further narrows the gap with fully supervised methods.
<div id='section'>Paperid: <span id='pid'>326, <a href='https://arxiv.org/pdf/2412.07228.pdf' target='_blank'>https://arxiv.org/pdf/2412.07228.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Siyang Li, Ziwei Wang, Hanbin Luo, Lieyun Ding, Dongrui Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.07228">T-TIME: Test-Time Information Maximization Ensemble for Plug-and-Play BCIs</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Objective: An electroencephalogram (EEG)-based brain-computer interface (BCI) enables direct communication between the human brain and a computer. Due to individual differences and non-stationarity of EEG signals, such BCIs usually require a subject-specific calibration session before each use, which is time-consuming and user-unfriendly. Transfer learning (TL) has been proposed to shorten or eliminate this calibration, but existing TL approaches mainly consider offline settings, where all unlabeled EEG trials from the new user are available. Methods: This paper proposes Test-Time Information Maximization Ensemble (T-TIME) to accommodate the most challenging online TL scenario, where unlabeled EEG data from the new user arrive in a stream, and immediate classification is performed. T-TIME initializes multiple classifiers from the aligned source data. When an unlabeled test EEG trial arrives, T-TIME first predicts its labels using ensemble learning, and then updates each classifier by conditional entropy minimization and adaptive marginal distribution regularization. Our code is publicized. Results: Extensive experiments on three public motor imagery based BCI datasets demonstrated that T-TIME outperformed about 20 classical and state-of-the-art TL approaches. Significance: To our knowledge, this is the first work on test time adaptation for calibration-free EEG-based BCIs, making plug-and-play BCIs possible.
<div id='section'>Paperid: <span id='pid'>327, <a href='https://arxiv.org/pdf/2408.05769.pdf' target='_blank'>https://arxiv.org/pdf/2408.05769.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Eunseop Yoon, Hee Suk Yoon, John Harvill, Mark Hasegawa-Johnson, Chang D. Yoo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.05769">LI-TTA: Language Informed Test-Time Adaptation for Automatic Speech Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-Time Adaptation (TTA) has emerged as a crucial solution to the domain shift challenge, wherein the target environment diverges from the original training environment. A prime exemplification is TTA for Automatic Speech Recognition (ASR), which enhances model performance by leveraging output prediction entropy minimization as a self-supervision signal. However, a key limitation of this self-supervision lies in its primary focus on acoustic features, with minimal attention to the linguistic properties of the input. To address this gap, we propose Language Informed Test-Time Adaptation (LI-TTA), which incorporates linguistic insights during TTA for ASR. LI-TTA integrates corrections from an external language model to merge linguistic with acoustic information by minimizing the CTC loss from the correction alongside the standard TTA loss. With extensive experiments, we show that LI-TTA effectively improves the performance of TTA for ASR in various distribution shift situations.
<div id='section'>Paperid: <span id='pid'>328, <a href='https://arxiv.org/pdf/2407.14231.pdf' target='_blank'>https://arxiv.org/pdf/2407.14231.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sebastian Cygert, Damian SÃ³jka, Tomasz TrzciÅski, BartÅomiej Twardowski
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.14231">Realistic Evaluation of Test-Time Adaptation Algorithms: Unsupervised Hyperparameter Selection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-Time Adaptation (TTA) has recently emerged as a promising strategy for tackling the problem of machine learning model robustness under distribution shifts by adapting the model during inference without access to any labels. Because of task difficulty, hyperparameters strongly influence the effectiveness of adaptation. However, the literature has provided little exploration into optimal hyperparameter selection. In this work, we tackle this problem by evaluating existing TTA methods using surrogate-based hp-selection strategies (which do not assume access to the test labels) to obtain a more realistic evaluation of their performance. We show that some of the recent state-of-the-art methods exhibit inferior performance compared to the previous algorithms when using our more realistic evaluation setup. Further, we show that forgetting is still a problem in TTA as the only method that is robust to hp-selection resets the model to the initial state at every step. We analyze different types of unsupervised selection strategies, and while they work reasonably well in most scenarios, the only strategies that work consistently well use some kind of supervision (either by a limited number of annotated test samples or by using pretraining data). Our findings underscore the need for further research with more rigorous benchmarking by explicitly stating model selection strategies, to facilitate which we open-source our code.
<div id='section'>Paperid: <span id='pid'>329, <a href='https://arxiv.org/pdf/2402.08712.pdf' target='_blank'>https://arxiv.org/pdf/2402.08712.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daeun Lee, Jaehong Yoon, Sung Ju Hwang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.08712">BECoTTA: Input-dependent Online Blending of Experts for Continual Test-time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual Test Time Adaptation (CTTA) is required to adapt efficiently to continuous unseen domains while retaining previously learned knowledge. However, despite the progress of CTTA, it is still challenging to deploy the model with improved forgetting-adaptation trade-offs and efficiency. In addition, current CTTA scenarios assume only the disjoint situation, even though real-world domains are seamlessly changed. To address these challenges, this paper proposes BECoTTA, an input-dependent and efficient modular framework for CTTA. We propose Mixture-of Domain Low-rank Experts (MoDE) that contains two core components: (i) Domain-Adaptive Routing, which helps to selectively capture the domain adaptive knowledge with multiple domain routers, and (ii) Domain-Expert Synergy Loss to maximize the dependency between each domain and expert. We validate that our method outperforms multiple CTTA scenarios, including disjoint and gradual domain shits, while only requiring ~98% fewer trainable parameters. We also provide analyses of our method, including the construction of experts, the effect of domain-adaptive experts, and visualizations.
<div id='section'>Paperid: <span id='pid'>330, <a href='https://arxiv.org/pdf/2312.04813.pdf' target='_blank'>https://arxiv.org/pdf/2312.04813.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haoran Fan, Qi Fan, Maurice Pagnucco, Yang Song
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.04813">DARNet: Bridging Domain Gaps in Cross-Domain Few-Shot Segmentation with Dynamic Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Few-shot segmentation (FSS) aims to segment novel classes in a query image by using only a small number of supporting images from base classes. However, in cross-domain few-shot segmentation (CD-FSS), leveraging features from label-rich domains for resource-constrained domains poses challenges due to domain discrepancies. This work presents a Dynamically Adaptive Refine (DARNet) method that aims to balance generalization and specificity for CD-FSS. Our method includes the Channel Statistics Disruption (CSD) strategy, which perturbs feature channel statistics in the source domain, bolstering generalization to unknown target domains. Moreover, recognizing the variability across target domains, an Adaptive Refine Self-Matching (ARSM) method is also proposed to adjust the matching threshold and dynamically refine the prediction result with the self-matching method, enhancing accuracy. We also present a Test-Time Adaptation (TTA) method to refine the model's adaptability to diverse feature distributions. Our approach demonstrates superior performance against state-of-the-art methods in CD-FSS tasks.
<div id='section'>Paperid: <span id='pid'>331, <a href='https://arxiv.org/pdf/2509.14420.pdf' target='_blank'>https://arxiv.org/pdf/2509.14420.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhicheng Lin, Xiaolin Wu, Xi Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.14420">Class-invariant Test-Time Augmentation for Domain Generalization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep models often suffer significant performance degradation under distribution shifts. Domain generalization (DG) seeks to mitigate this challenge by enabling models to generalize to unseen domains. Most prior approaches rely on multi-domain training or computationally intensive test-time adaptation. In contrast, we propose a complementary strategy: lightweight test-time augmentation. Specifically, we develop a novel Class-Invariant Test-Time Augmentation (CI-TTA) technique. The idea is to generate multiple variants of each input image through elastic and grid deformations that nevertheless belong to the same class as the original input. Their predictions are aggregated through a confidence-guided filtering scheme that remove unreliable outputs, ensuring the final decision relies on consistent and trustworthy cues. Extensive Experiments on PACS and Office-Home datasets demonstrate consistent gains across different DG algorithms and backbones, highlighting the effectiveness and generality of our approach.
<div id='section'>Paperid: <span id='pid'>332, <a href='https://arxiv.org/pdf/2509.14420.pdf' target='_blank'>https://arxiv.org/pdf/2509.14420.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhicheng Lin, Xiaolin Wu, Xi Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.14420">Class-invariant Test-Time Augmentation for Domain Generalization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep models often suffer significant performance degradation under distribution shifts. Domain generalization (DG) seeks to mitigate this challenge by enabling models to generalize to unseen domains. Most prior approaches rely on multi-domain training or computationally intensive test-time adaptation. In contrast, we propose a complementary strategy: lightweight test-time augmentation. Specifically, we develop a novel Class-Invariant Test-Time Augmentation (CI-TTA) technique. The idea is to generate multiple variants of each input image through elastic and grid deformations that nevertheless belong to the same class as the original input. Their predictions are aggregated through a confidence-guided filtering scheme that remove unreliable outputs, ensuring the final decision relies on consistent and trustworthy cues. Extensive Experiments on PACS and Office-Home datasets demonstrate consistent gains across different DG algorithms and backbones, highlighting the effectiveness and generality of our approach.
<div id='section'>Paperid: <span id='pid'>333, <a href='https://arxiv.org/pdf/2509.14420.pdf' target='_blank'>https://arxiv.org/pdf/2509.14420.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhicheng Lin, Xiaolin Wu, Xi Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.14420">Class-Invariant Test-Time Augmentation for Domain Generalization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep models often suffer significant performance degradation under distribution shifts. Domain generalization (DG) seeks to mitigate this challenge by enabling models to generalize to unseen domains. Most prior approaches rely on multi-domain training or computationally intensive test-time adaptation. In contrast, we propose a complementary strategy: lightweight test-time augmentation. Specifically, we develop a novel Class-Invariant Test-Time Augmentation (CI-TTA) technique. The idea is to generate multiple variants of each input image through elastic and grid deformations that nevertheless belong to the same class as the original input. Their predictions are aggregated through a confidence-guided filtering scheme that remove unreliable outputs, ensuring the final decision relies on consistent and trustworthy cues. Extensive Experiments on PACS and Office-Home datasets demonstrate consistent gains across different DG algorithms and backbones, highlighting the effectiveness and generality of our approach.
<div id='section'>Paperid: <span id='pid'>334, <a href='https://arxiv.org/pdf/2509.04977.pdf' target='_blank'>https://arxiv.org/pdf/2509.04977.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuaicheng Niu, Guohao Chen, Deyu Chen, Yifan Zhang, Jiaxiang Wu, Zhiquan Wen, Yaofo Chen, Peilin Zhao, Chunyan Miao, Mingkui Tan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.04977">Adapt in the Wild: Test-Time Entropy Minimization with Sharpness and Feature Regularization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) may fail to improve or even harm the model performance when test data have: 1) mixed distribution shifts, 2) small batch sizes, 3) online imbalanced label distribution shifts. This is often a key obstacle preventing existing TTA methods from being deployed in the real world. In this paper, we investigate the unstable reasons and find that the batch norm layer is a crucial factor hindering TTA stability. Conversely, TTA can perform more stably with batch-agnostic norm layers, i.e., group or layer norm. However, we observe that TTA with group and layer norms does not always succeed and still suffers many failure cases, i.e., the model collapses into trivial solutions by assigning the same class label for all samples. By digging into this, we find that, during the collapse process: 1) the model gradients often undergo an initial explosion followed by rapid degradation, suggesting that certain noisy test samples with large gradients may disrupt adaptation; and 2) the model representations tend to exhibit high correlations and classification bias. To address this, we first propose a sharpness-aware and reliable entropy minimization method, called SAR, for stabilizing TTA from two aspects: 1) remove partial noisy samples with large gradients, 2) encourage model weights to go to a flat minimum so that the model is robust to the remaining noisy samples. Based on SAR, we further introduce SAR^2 to prevent representation collapse with two regularizers: 1) a redundancy regularizer to reduce inter-dimensional correlations among centroid-invariant features; and 2) an inequity regularizer to maximize the prediction entropy of a prototype centroid, thereby penalizing biased representations toward any specific class. Promising results demonstrate that our methods perform more stably over prior methods and are computationally efficient under the above wild test scenarios.
<div id='section'>Paperid: <span id='pid'>335, <a href='https://arxiv.org/pdf/2509.04977.pdf' target='_blank'>https://arxiv.org/pdf/2509.04977.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuaicheng Niu, Guohao Chen, Deyu Chen, Yifan Zhang, Jiaxiang Wu, Zhiquan Wen, Yaofo Chen, Peilin Zhao, Chunyan Miao, Mingkui Tan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.04977">Adapt in the Wild: Test-Time Entropy Minimization with Sharpness and Feature Regularization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) may fail to improve or even harm the model performance when test data have: 1) mixed distribution shifts, 2) small batch sizes, 3) online imbalanced label distribution shifts. This is often a key obstacle preventing existing TTA methods from being deployed in the real world. In this paper, we investigate the unstable reasons and find that the batch norm layer is a crucial factor hindering TTA stability. Conversely, TTA can perform more stably with batch-agnostic norm layers, i.e., group or layer norm. However, we observe that TTA with group and layer norms does not always succeed and still suffers many failure cases, i.e., the model collapses into trivial solutions by assigning the same class label for all samples. By digging into this, we find that, during the collapse process: 1) the model gradients often undergo an initial explosion followed by rapid degradation, suggesting that certain noisy test samples with large gradients may disrupt adaptation; and 2) the model representations tend to exhibit high correlations and classification bias. To address this, we first propose a sharpness-aware and reliable entropy minimization method, called SAR, for stabilizing TTA from two aspects: 1) remove partial noisy samples with large gradients, 2) encourage model weights to go to a flat minimum so that the model is robust to the remaining noisy samples. Based on SAR, we further introduce SAR^2 to prevent representation collapse with two regularizers: 1) a redundancy regularizer to reduce inter-dimensional correlations among centroid-invariant features; and 2) an inequity regularizer to maximize the prediction entropy of a prototype centroid, thereby penalizing biased representations toward any specific class. Promising results demonstrate that our methods perform more stably over prior methods and are computationally efficient under the above wild test scenarios.
<div id='section'>Paperid: <span id='pid'>336, <a href='https://arxiv.org/pdf/2508.12690.pdf' target='_blank'>https://arxiv.org/pdf/2508.12690.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dongjae Jeon, Taeheon Kim, Seongwon Cho, Minhyuk Seo, Jonghyun Choi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.12690">TTA-DAME: Test-Time Adaptation with Domain Augmentation and Model Ensemble for Dynamic Driving Conditions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time Adaptation (TTA) poses a challenge, requiring models to dynamically adapt and perform optimally on shifting target domains. This task is particularly emphasized in real-world driving scenes, where weather domain shifts occur frequently. To address such dynamic changes, our proposed method, TTA-DAME, leverages source domain data augmentation into target domains. Additionally, we introduce a domain discriminator and a specialized domain detector to mitigate drastic domain shifts, especially from daytime to nighttime conditions. To further improve adaptability, we train multiple detectors and consolidate their predictions through Non-Maximum Suppression (NMS). Our empirical validation demonstrates the effectiveness of our method, showing significant performance enhancements on the SHIFT Benchmark.
<div id='section'>Paperid: <span id='pid'>337, <a href='https://arxiv.org/pdf/2506.06782.pdf' target='_blank'>https://arxiv.org/pdf/2506.06782.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qinting Jiang, Chuyang Ye, Dongyan Wei, Bingli Wang, Yuan Xue, Jingyan Jiang, Zhi Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.06782">Feature-Based Instance Neighbor Discovery: Advanced Stable Test-Time Adaptation in Dynamic World</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite progress, deep neural networks still suffer performance declines under distribution shifts between training and test domains, leading to a substantial decrease in Quality of Experience (QoE) for applications. Existing test-time adaptation (TTA) methods are challenged by dynamic, multiple test distributions within batches. We observe that feature distributions across different domains inherently cluster into distinct groups with varying means and variances. This divergence reveals a critical limitation of previous global normalization strategies in TTA, which inevitably distort the original data characteristics. Based on this insight, we propose Feature-based Instance Neighbor Discovery (FIND), which comprises three key components: Layer-wise Feature Disentanglement (LFD), Feature Aware Batch Normalization (FABN) and Selective FABN (S-FABN). LFD stably captures features with similar distributions at each layer by constructing graph structures. While FABN optimally combines source statistics with test-time distribution specific statistics for robust feature representation. Finally, S-FABN determines which layers require feature partitioning and which can remain unified, thereby enhancing inference efficiency. Extensive experiments demonstrate that FIND significantly outperforms existing methods, achieving a 30\% accuracy improvement in dynamic scenarios while maintaining computational efficiency.
<div id='section'>Paperid: <span id='pid'>338, <a href='https://arxiv.org/pdf/2506.02671.pdf' target='_blank'>https://arxiv.org/pdf/2506.02671.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiao Chen, Jiazhen Huang, Qinting Jiang, Fanding Huang, Xianghua Fu, Jingyan Jiang, Zhi Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.02671">Small Aid, Big Leap: Efficient Test-Time Adaptation for Vision-Language Models with AdaptNet</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) has emerged as a critical technique for enhancing the generalization capability of vision-language models (VLMs) during inference. However, existing approaches often incur substantial computational costs and exhibit poor scalability, primarily due to sample-wise adaptation granularity and reliance on costly auxiliary designs such as data augmentation. To address these limitations, we introduce SAIL (Small Aid, Big Leap), a novel adapter-based TTA framework that leverages a lightweight, learnable AdaptNet to enable efficient and scalable model adaptation. As SAIL's core, a frozen pre-trained VLM collaborates with AdaptNet through a confidence-based interpolation weight, generating robust predictions during inference. These predictions serve as self-supervised targets to align AdaptNet's outputs through efficient batch-wise processing, dramatically reducing computational costs without modifying the VLM or requiring memory caches. To mitigate catastrophic forgetting during continual adaptation, we propose a gradient-aware reset strategy driven by a gradient drift indicator (GDI), which dynamically detects domain transitions and strategically resets AdaptNet for stable adaptation. Extensive experiments across diverse benchmarks on two scenarios demonstrate that SAIL achieves state-of-the-art performance while maintaining low computational costs. These results highlight SAIL's effectiveness, efficiency and scalability for real-world deployment. The code will be released upon acceptance.
<div id='section'>Paperid: <span id='pid'>339, <a href='https://arxiv.org/pdf/2505.16166.pdf' target='_blank'>https://arxiv.org/pdf/2505.16166.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuhao Xue, Zhifei Zhang, Xinyang Jiang, Yifei Shen, Junyao Gao, Wentao Gu, Jiale Zhao, Miaojing Shi, Cairong Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.16166">TRAIL: Transferable Robust Adversarial Images via Latent diffusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Adversarial attacks exploiting unrestricted natural perturbations present severe security risks to deep learning systems, yet their transferability across models remains limited due to distribution mismatches between generated adversarial features and real-world data. While recent works utilize pre-trained diffusion models as adversarial priors, they still encounter challenges due to the distribution shift between the distribution of ideal adversarial samples and the natural image distribution learned by the diffusion model. To address the challenge, we propose Transferable Robust Adversarial Images via Latent Diffusion (TRAIL), a test-time adaptation framework that enables the model to generate images from a distribution of images with adversarial features and closely resembles the target images. To mitigate the distribution shift, during attacks, TRAIL updates the diffusion U-Net's weights by combining adversarial objectives (to mislead victim models) and perceptual constraints (to preserve image realism). The adapted model then generates adversarial samples through iterative noise injection and denoising guided by these objectives. Experiments demonstrate that TRAIL significantly outperforms state-of-the-art methods in cross-model attack transferability, validating that distribution-aligned adversarial feature synthesis is critical for practical black-box attacks.
<div id='section'>Paperid: <span id='pid'>340, <a href='https://arxiv.org/pdf/2503.23388.pdf' target='_blank'>https://arxiv.org/pdf/2503.23388.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fanding Huang, Jingyan Jiang, Qinting Jiang, Hebei Li, Faisal Nadeem Khan, Zhi Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.23388">COSMIC: Clique-Oriented Semantic Multi-space Integration for Robust CLIP Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent vision-language models (VLMs) face significant challenges in test-time adaptation to novel domains. While cache-based methods show promise by leveraging historical information, they struggle with both caching unreliable feature-label pairs and indiscriminately using single-class information during querying, significantly compromising adaptation accuracy. To address these limitations, we propose COSMIC (Clique-Oriented Semantic Multi-space Integration for CLIP), a robust test-time adaptation framework that enhances adaptability through multi-granular, cross-modal semantic caching and graph-based querying mechanisms. Our framework introduces two key innovations: Dual Semantics Graph (DSG) and Clique Guided Hyper-class (CGH). The Dual Semantics Graph constructs complementary semantic spaces by incorporating textual features, coarse-grained CLIP features, and fine-grained DINOv2 features to capture rich semantic relationships. Building upon these dual graphs, the Clique Guided Hyper-class component leverages structured class relationships to enhance prediction robustness through correlated class selection. Extensive experiments demonstrate COSMIC's superior performance across multiple benchmarks, achieving significant improvements over state-of-the-art methods: 15.81% gain on out-of-distribution tasks and 5.33% on cross-domain generation with CLIP RN-50. Code is available at github.com/hf618/COSMIC.
<div id='section'>Paperid: <span id='pid'>341, <a href='https://arxiv.org/pdf/2503.08099.pdf' target='_blank'>https://arxiv.org/pdf/2503.08099.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Runxi Cheng, Feng Xiong, Yongxian Wei, Wanyun Zhu, Chun Yuan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.08099">Whoever Started the Interference Should End It: Guiding Data-Free Model Merging via Task Vectors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Model merging seeks to integrate task-specific expert models into a unified architecture while preserving multi-task generalization capabilities, yet parameter interference between constituent models frequently induces performance degradation. Although prior work has explored many merging strategies, resolving interference without additional data for retraining or test-time computation remains challenging. In this paper, we theoretically demonstrate that the task vectors of the linear layer constitute an approximate linear subspace for its corresponding input. Therefore, we can minimize interference under the guidance of task vectors. Based on this insight, we propose \textbf{WUDI-Merging} (\textbf{W}hoever started the interference sho\textbf{U}ld en\textbf{D} \textbf{I}t), a simple yet effective model merging method that eliminates interference without any additional data or rescaling coefficients. Comprehensive empirical evaluations across vision and language benchmarks demonstrate our method's superiority, achieving state-of-the-art performance in data-free model merging scenarios (average 10.9\% improvement versus baseline methods) while even outperforming mainstream test-time adaptation approaches by 3.3\%, and only very few computing resources are required. The code will be publicly available soon.
<div id='section'>Paperid: <span id='pid'>342, <a href='https://arxiv.org/pdf/2410.10442.pdf' target='_blank'>https://arxiv.org/pdf/2410.10442.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yushun Tang, Shuoshuo Chen, Jiyuan Jia, Yi Zhang, Zhihai He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.10442">Domain-Conditioned Transformer for Fully Test-time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fully test-time adaptation aims to adapt a network model online based on sequential analysis of input samples during the inference stage. We observe that, when applying a transformer network model into a new domain, the self-attention profiles of image samples in the target domain deviate significantly from those in the source domain, which results in large performance degradation during domain changes. To address this important issue, we propose a new structure for the self-attention modules in the transformer. Specifically, we incorporate three domain-conditioning vectors, called domain conditioners, into the query, key, and value components of the self-attention module. We learn a network to generate these three domain conditioners from the class token at each transformer network layer. We find that, during fully online test-time adaptation, these domain conditioners at each transform network layer are able to gradually remove the impact of domain shift and largely recover the original self-attention profile. Our extensive experimental results demonstrate that the proposed domain-conditioned transformer significantly improves the online fully test-time domain adaptation performance and outperforms existing state-of-the-art methods by large margins.
<div id='section'>Paperid: <span id='pid'>343, <a href='https://arxiv.org/pdf/2407.09498.pdf' target='_blank'>https://arxiv.org/pdf/2407.09498.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yunbei Zhang, Akshay Mehra, Jihun Hamm
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.09498">OT-VP: Optimal Transport-guided Visual Prompting for Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision Transformers (ViTs) have demonstrated remarkable capabilities in learning representations, but their performance is compromised when applied to unseen domains. Previous methods either engage in prompt learning during the training phase or modify model parameters at test time through entropy minimization. The former often overlooks unlabeled target data, while the latter doesn't fully address domain shifts. In this work, our approach, Optimal Transport-guided Test-Time Visual Prompting (OT-VP), handles these problems by leveraging prompt learning at test time to align the target and source domains without accessing the training process or altering pre-trained model parameters. This method involves learning a universal visual prompt for the target domain by optimizing the Optimal Transport distance.OT-VP, with only four learned prompt tokens, exceeds state-of-the-art performance across three stylistic datasets-PACS, VLCS, OfficeHome, and one corrupted dataset ImageNet-C. Additionally, OT-VP operates efficiently, both in terms of memory and computation, and is adaptable for extension to online settings.
<div id='section'>Paperid: <span id='pid'>344, <a href='https://arxiv.org/pdf/2406.19341.pdf' target='_blank'>https://arxiv.org/pdf/2406.19341.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yushun Tang, Shuoshuo Chen, Zhehan Kan, Yi Zhang, Qinghai Guo, Zhihai He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.19341">Learning Visual Conditioning Tokens to Correct Domain Shift for Fully Test-time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fully test-time adaptation aims to adapt the network model based on sequential analysis of input samples during the inference stage to address the cross-domain performance degradation problem of deep neural networks. This work is based on the following interesting finding: in transformer-based image classification, the class token at the first transformer encoder layer can be learned to capture the domain-specific characteristics of target samples during test-time adaptation. This learned token, when combined with input image patch embeddings, is able to gradually remove the domain-specific information from the feature representations of input samples during the transformer encoding process, thereby significantly improving the test-time adaptation performance of the source model across different domains. We refer to this class token as visual conditioning token (VCT). To successfully learn the VCT, we propose a bi-level learning approach to capture the long-term variations of domain-specific characteristics while accommodating local variations of instance-specific characteristics. Experimental results on the benchmark datasets demonstrate that our proposed bi-level visual conditioning token learning method is able to achieve significantly improved test-time adaptation performance by up to 1.9%.
<div id='section'>Paperid: <span id='pid'>345, <a href='https://arxiv.org/pdf/2406.10737.pdf' target='_blank'>https://arxiv.org/pdf/2406.10737.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yunbei Zhang, Akshay Mehra, Shuaicheng Niu, Jihun Hamm
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.10737">DPCore: Dynamic Prompt Coreset for Continual Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual Test-Time Adaptation (CTTA) seeks to adapt source pre-trained models to continually changing, unseen target domains. While existing CTTA methods assume structured domain changes with uniform durations, real-world environments often exhibit dynamic patterns where domains recur with varying frequencies and durations. Current approaches, which adapt the same parameters across different domains, struggle in such dynamic conditions-they face convergence issues with brief domain exposures, risk forgetting previously learned knowledge, or misapplying it to irrelevant domains. To remedy this, we propose DPCore, a method designed for robust performance across diverse domain change patterns while ensuring computational efficiency. DPCore integrates three key components: Visual Prompt Adaptation for efficient domain alignment, a Prompt Coreset for knowledge preservation, and a Dynamic Update mechanism that intelligently adjusts existing prompts for similar domains while creating new ones for substantially different domains. Extensive experiments on four benchmarks demonstrate that DPCore consistently outperforms various CTTA methods, achieving state-of-the-art performance in both structured and dynamic settings while reducing trainable parameters by 99% and computation time by 64% compared to previous approaches.
<div id='section'>Paperid: <span id='pid'>346, <a href='https://arxiv.org/pdf/2406.07430.pdf' target='_blank'>https://arxiv.org/pdf/2406.07430.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yimeng Gu, Mengqi Zhang, Ignacio Castro, Shu Wu, Gareth Tyson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.07430">Learning Domain-Invariant Features for Out-of-Context News Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Out-of-context news is a common type of misinformation on online media platforms. This involves posting a caption, alongside a mismatched news image. Existing out-of-context news detection models only consider the scenario where pre-labeled data is available for each domain, failing to address the out-of-context news detection on unlabeled domains (e.g. news topics or agencies). In this work, we therefore focus on domain adaptive out-of-context news detection. In order to effectively adapt the detection model to unlabeled news topics or agencies, we propose ConDA-TTA (Contrastive Domain Adaptation with Test-Time Adaptation) which applies contrastive learning and maximum mean discrepancy (MMD) to learn domain-invariant features. In addition, we leverage test-time target domain statistics to further assist domain adaptation. Experimental results show that our approach outperforms baselines in most domain adaptation settings on two public datasets, by as much as 2.93% in F1 and 2.08% in accuracy.
<div id='section'>Paperid: <span id='pid'>347, <a href='https://arxiv.org/pdf/2406.05413.pdf' target='_blank'>https://arxiv.org/pdf/2406.05413.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qinting Jiang, Chuyang Ye, Dongyan Wei, Yuan Xue, Jingyan Jiang, Zhi Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.05413">Discover Your Neighbors: Advanced Stable Test-Time Adaptation in Dynamic World</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite progress, deep neural networks still suffer performance declines under distribution shifts between training and test domains, leading to a substantial decrease in Quality of Experience (QoE) for multimedia applications. Existing test-time adaptation (TTA) methods are challenged by dynamic, multiple test distributions within batches. This work provides a new perspective on analyzing batch normalization techniques through class-related and class-irrelevant features, our observations reveal combining source and test batch normalization statistics robustly characterizes target distributions. However, test statistics must have high similarity. We thus propose Discover Your Neighbours (DYN), the first backward-free approach specialized for dynamic TTA. The core innovation is identifying similar samples via instance normalization statistics and clustering into groups which provides consistent class-irrelevant representations. Specifically, Our DYN consists of layer-wise instance statistics clustering (LISC) and cluster-aware batch normalization (CABN). In LISC, we perform layer-wise clustering of approximate feature samples at each BN layer by calculating the cosine similarity of instance normalization statistics across the batch. CABN then aggregates SBN and TCN statistics to collaboratively characterize the target distribution, enabling more robust representations. Experimental results validate DYN's robustness and effectiveness, demonstrating maintained performance under dynamic data stream patterns.
<div id='section'>Paperid: <span id='pid'>348, <a href='https://arxiv.org/pdf/2403.11491.pdf' target='_blank'>https://arxiv.org/pdf/2403.11491.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingkui Tan, Guohao Chen, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Peilin Zhao, Shuaicheng Niu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.11491">Uncertainty-Calibrated Test-Time Model Adaptation without Forgetting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) seeks to tackle potential distribution shifts between training and test data by adapting a given model w.r.t. any test sample. Although recent TTA has shown promising performance, we still face two key challenges: 1) prior methods perform backpropagation for each test sample, resulting in unbearable optimization costs to many applications; 2) while existing TTA can significantly improve the test performance on out-of-distribution data, they often suffer from severe performance degradation on in-distribution data after TTA (known as forgetting). To this end, we have proposed an Efficient Anti-Forgetting Test-Time Adaptation (EATA) method which develops an active sample selection criterion to identify reliable and non-redundant samples for test-time entropy minimization. To alleviate forgetting, EATA introduces a Fisher regularizer estimated from test samples to constrain important model parameters from drastic changes. However, in EATA, the adopted entropy loss consistently assigns higher confidence to predictions even for samples that are underlying uncertain, leading to overconfident predictions. To tackle this, we further propose EATA with Calibration (EATA-C) to separately exploit the reducible model uncertainty and the inherent data uncertainty for calibrated TTA. Specifically, we measure the model uncertainty by the divergence between predictions from the full network and its sub-networks, on which we propose a divergence loss to encourage consistent predictions instead of overconfident ones. To further recalibrate prediction confidence, we utilize the disagreement among predicted labels as an indicator of the data uncertainty, and then devise a min-max entropy regularizer to selectively increase and decrease prediction confidence for different samples. Experiments on image classification and semantic segmentation verify the effectiveness of our methods.
<div id='section'>Paperid: <span id='pid'>349, <a href='https://arxiv.org/pdf/2402.18920.pdf' target='_blank'>https://arxiv.org/pdf/2402.18920.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dongliang Cao, Marvin Eisenberger, Nafie El Amrani, Daniel Cremers, Florian Bernard
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.18920">Spectral Meets Spatial: Harmonising 3D Shape Matching and Interpolation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Although 3D shape matching and interpolation are highly interrelated, they are often studied separately and applied sequentially to relate different 3D shapes, thus resulting in sub-optimal performance. In this work we present a unified framework to predict both point-wise correspondences and shape interpolation between 3D shapes. To this end, we combine the deep functional map framework with classical surface deformation models to map shapes in both spectral and spatial domains. On the one hand, by incorporating spatial maps, our method obtains more accurate and smooth point-wise correspondences compared to previous functional map methods for shape matching. On the other hand, by introducing spectral maps, our method gets rid of commonly used but computationally expensive geodesic distance constraints that are only valid for near-isometric shape deformations. Furthermore, we propose a novel test-time adaptation scheme to capture both pose-dominant and shape-dominant deformations. Using different challenging datasets, we demonstrate that our method outperforms previous state-of-the-art methods for both shape matching and interpolation, even compared to supervised approaches.
<div id='section'>Paperid: <span id='pid'>350, <a href='https://arxiv.org/pdf/2308.08810.pdf' target='_blank'>https://arxiv.org/pdf/2308.08810.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sunghyun Park, Seunghan Yang, Jaegul Choo, Sungrack Yun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.08810">Label Shift Adapter for Test-Time Adaptation under Covariate and Label Shifts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) aims to adapt a pre-trained model to the target domain in a batch-by-batch manner during inference. While label distributions often exhibit imbalances in real-world scenarios, most previous TTA approaches typically assume that both source and target domain datasets have balanced label distribution. Due to the fact that certain classes appear more frequently in certain domains (e.g., buildings in cities, trees in forests), it is natural that the label distribution shifts as the domain changes. However, we discover that the majority of existing TTA methods fail to address the coexistence of covariate and label shifts. To tackle this challenge, we propose a novel label shift adapter that can be incorporated into existing TTA approaches to deal with label shifts during the TTA process effectively. Specifically, we estimate the label distribution of the target domain to feed it into the label shift adapter. Subsequently, the label shift adapter produces optimal parameters for the target label distribution. By predicting only the parameters for a part of the pre-trained source model, our approach is computationally efficient and can be easily applied, regardless of the model architectures. Through extensive experiments, we demonstrate that integrating our strategy with TTA approaches leads to substantial performance improvements under the joint presence of label and covariate shifts.
<div id='section'>Paperid: <span id='pid'>351, <a href='https://arxiv.org/pdf/2303.09870.pdf' target='_blank'>https://arxiv.org/pdf/2303.09870.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Devavrat Tomar, Guillaume Vray, Behzad Bozorgtabar, Jean-Philippe Thiran
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.09870">TeSLA: Test-Time Self-Learning With Automatic Adversarial Augmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Most recent test-time adaptation methods focus on only classification tasks, use specialized network architectures, destroy model calibration or rely on lightweight information from the source domain. To tackle these issues, this paper proposes a novel Test-time Self-Learning method with automatic Adversarial augmentation dubbed TeSLA for adapting a pre-trained source model to the unlabeled streaming test data. In contrast to conventional self-learning methods based on cross-entropy, we introduce a new test-time loss function through an implicitly tight connection with the mutual information and online knowledge distillation. Furthermore, we propose a learnable efficient adversarial augmentation module that further enhances online knowledge distillation by simulating high entropy augmented images. Our method achieves state-of-the-art classification and segmentation results on several benchmarks and types of domain shifts, particularly on challenging measurement shifts of medical images. TeSLA also benefits from several desirable properties compared to competing methods in terms of calibration, uncertainty metrics, insensitivity to model architectures, and source training strategies, all supported by extensive ablations. Our code and models are available on GitHub.
<div id='section'>Paperid: <span id='pid'>352, <a href='https://arxiv.org/pdf/2303.00914.pdf' target='_blank'>https://arxiv.org/pdf/2303.00914.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yushun Tang, Ce Zhang, Heng Xu, Shuoshuo Chen, Jie Cheng, Luziwei Leng, Qinghai Guo, Zhihai He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.00914">Neuro-Modulated Hebbian Learning for Fully Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fully test-time adaptation aims to adapt the network model based on sequential analysis of input samples during the inference stage to address the cross-domain performance degradation problem of deep neural networks. We take inspiration from the biological plausibility learning where the neuron responses are tuned based on a local synapse-change procedure and activated by competitive lateral inhibition rules. Based on these feed-forward learning rules, we design a soft Hebbian learning process which provides an unsupervised and effective mechanism for online adaptation. We observe that the performance of this feed-forward Hebbian learning for fully test-time adaptation can be significantly improved by incorporating a feedback neuro-modulation layer. It is able to fine-tune the neuron responses based on the external feedback generated by the error back-propagation from the top inference layers. This leads to our proposed neuro-modulated Hebbian learning (NHL) method for fully test-time adaptation. With the unsupervised feed-forward soft Hebbian learning being combined with a learned neuro-modulator to capture feedback from external responses, the source model can be effectively adapted during the testing process. Experimental results on benchmark datasets demonstrate that our proposed method can significantly improve the adaptation performance of network models and outperforms existing state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>353, <a href='https://arxiv.org/pdf/2211.01315.pdf' target='_blank'>https://arxiv.org/pdf/2211.01315.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shawqi Al-Maliki, Faissal El Bouanani, Mohamed Abdallah, Junaid Qadir, Ala Al-Fuqaha
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.01315">Addressing Data Distribution Shifts in Online Machine Learning Powered Smart City Applications Using Augmented Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data distribution shift is a common problem in machine learning-powered smart city applications where the test data differs from the training data. Augmenting smart city applications with online machine learning models can handle this issue at test time, albeit with high cost and unreliable performance. To overcome this limitation, we propose to endow test-time adaptation with a systematic active fine-tuning (SAF) layer that is characterized by three key aspects: a continuity aspect that adapts to ever-present data distribution shifts; intelligence aspect that recognizes the importance of fine-tuning as a distribution-shift-aware process that occurs at the appropriate time to address the recently detected data distribution shifts; and cost-effectiveness aspect that involves budgeted human-machine collaboration to make relabeling cost-effective and practical for diverse smart city applications. Our empirical results show that our proposed approach outperforms the traditional test-time adaptation by a factor of two.
<div id='section'>Paperid: <span id='pid'>354, <a href='https://arxiv.org/pdf/2203.11194.pdf' target='_blank'>https://arxiv.org/pdf/2203.11194.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mihir Prabhudesai, Anirudh Goyal, Sujoy Paul, Sjoerd van Steenkiste, Mehdi S. M. Sajjadi, Gaurav Aggarwal, Thomas Kipf, Deepak Pathak, Katerina Fragkiadaki
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2203.11194">Test-time Adaptation with Slot-Centric Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current visual detectors, though impressive within their training distribution, often fail to parse out-of-distribution scenes into their constituent entities. Recent test-time adaptation methods use auxiliary self-supervised losses to adapt the network parameters to each test example independently and have shown promising results towards generalization outside the training distribution for the task of image classification. In our work, we find evidence that these losses are insufficient for the task of scene decomposition, without also considering architectural inductive biases. Recent slot-centric generative models attempt to decompose scenes into entities in a self-supervised manner by reconstructing pixels. Drawing upon these two lines of work, we propose Slot-TTA, a semi-supervised slot-centric scene decomposition model that at test time is adapted per scene through gradient descent on reconstruction or cross-view synthesis objectives. We evaluate Slot-TTA across multiple input modalities, images or 3D point clouds, and show substantial out-of-distribution performance improvements against state-of-the-art supervised feed-forward detectors, and alternative test-time adaptation methods.
<div id='section'>Paperid: <span id='pid'>355, <a href='https://arxiv.org/pdf/2510.11068.pdf' target='_blank'>https://arxiv.org/pdf/2510.11068.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinyu Luo, Jie Liu, Kecheng Chen, Junyi Yang, Bo Ding, Arindam Basu, Haoliang Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.11068">Efficient Edge Test-Time Adaptation via Latent Feature Coordinate Correction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Edge devices face significant challenges due to limited computational resources and distribution shifts, making efficient and adaptable machine learning essential. Existing test-time adaptation (TTA) methods often rely on gradient-based optimization or batch processing, which are inherently unsuitable for resource-constrained edge scenarios due to their reliance on backpropagation and high computational demands. Gradient-free alternatives address these issues but often suffer from limited learning capacity, lack flexibility, or impose architectural constraints. To overcome these limitations, we propose a novel single-instance TTA method tailored for edge devices (TED), which employs forward-only coordinate optimization in the principal subspace of latent using the covariance matrix adaptation evolution strategy (CMA-ES). By updating a compact low-dimensional vector, TED not only enhances output confidence but also aligns the latent representation closer to the source latent distribution within the latent principal subspace. This is achieved without backpropagation, keeping the model parameters frozen, and enabling efficient, forgetting-free adaptation with minimal memory and computational overhead. Experiments on image classification and keyword spotting tasks across the ImageNet and Google Speech Commands series datasets demonstrate that TED achieves state-of-the-art performance while $\textit{reducing computational complexity by up to 63 times}$, offering a practical and scalable solution for real-world edge applications. Furthermore, we successfully $\textit{deployed TED on the ZYNQ-7020 platform}$, demonstrating its feasibility and effectiveness for resource-constrained edge devices in real-world deployments.
<div id='section'>Paperid: <span id='pid'>356, <a href='https://arxiv.org/pdf/2508.20516.pdf' target='_blank'>https://arxiv.org/pdf/2508.20516.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenting Yin, Han Sun, Xinru Meng, Ningzhong Liu, Huiyu Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.20516">DCFS: Continual Test-Time Adaptation via Dual Consistency of Feature and Sample</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual test-time adaptation aims to continuously adapt a pre-trained model to a stream of target domain data without accessing source data. Without access to source domain data, the model focuses solely on the feature characteristics of the target data. Relying exclusively on these features can lead to confusion and introduce learning biases. Currently, many existing methods generate pseudo-labels via model predictions. However, the quality of pseudo-labels cannot be guaranteed and the problem of error accumulation must be solved. To address these challenges, we propose DCFS, a novel CTTA framework that introduces dual-path feature consistency and confidence-aware sample learning. This framework disentangles the whole feature representation of the target data into semantic-related feature and domain-related feature using dual classifiers to learn distinct feature representations. By maintaining consistency between the sub-features and the whole feature, the model can comprehensively capture data features from multiple perspectives. Additionally, to ensure that the whole feature information of the target domain samples is not overlooked, we set a adaptive threshold and calculate a confidence score for each sample to carry out loss weighted self-supervised learning, effectively reducing the noise of pseudo-labels and alleviating the problem of error accumulation. The efficacy of our proposed method is validated through extensive experimentation across various datasets, including CIFAR10-C, CIFAR100-C, and ImageNet-C, demonstrating consistent performance in continual test-time adaptation scenarios.
<div id='section'>Paperid: <span id='pid'>357, <a href='https://arxiv.org/pdf/2505.18734.pdf' target='_blank'>https://arxiv.org/pdf/2505.18734.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Eunjin Roh, Yigitcan Kaya, Christopher Kruegel, Giovanni Vigna, Sanghyun Hong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.18734">MADCAT: Combating Malware Detection Under Concept Drift with Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present MADCAT, a self-supervised approach designed to address the concept drift problem in malware detection. MADCAT employs an encoder-decoder architecture and works by test-time training of the encoder on a small, balanced subset of the test-time data using a self-supervised objective. During test-time training, the model learns features that are useful for detecting both previously seen (old) data and newly arriving samples. We demonstrate the effectiveness of MADCAT in continuous Android malware detection settings. MADCAT consistently outperforms baseline methods in detection performance at test time. We also show the synergy between MADCAT and prior approaches in addressing concept drift in malware detection
<div id='section'>Paperid: <span id='pid'>358, <a href='https://arxiv.org/pdf/2504.02008.pdf' target='_blank'>https://arxiv.org/pdf/2504.02008.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kecheng Chen, Xinyu Luo, Tiexin Qin, Jie Liu, Hui Liu, Victor Ho Fun Lee, Hong Yan, Haoliang Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.02008">Test-time Adaptation for Foundation Medical Segmentation Model without Parametric Updates</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Foundation medical segmentation models, with MedSAM being the most popular, have achieved promising performance across organs and lesions. However, MedSAM still suffers from compromised performance on specific lesions with intricate structures and appearance, as well as bounding box prompt-induced perturbations. Although current test-time adaptation (TTA) methods for medical image segmentation may tackle this issue, partial (e.g., batch normalization) or whole parametric updates restrict their effectiveness due to limited update signals or catastrophic forgetting in large models. Meanwhile, these approaches ignore the computational complexity during adaptation, which is particularly significant for modern foundation models. To this end, our theoretical analyses reveal that directly refining image embeddings is feasible to approach the same goal as parametric updates under the MedSAM architecture, which enables us to realize high computational efficiency and segmentation performance without the risk of catastrophic forgetting. Under this framework, we propose to encourage maximizing factorized conditional probabilities of the posterior prediction probability using a proposed distribution-approximated latent conditional random field loss combined with an entropy minimization loss. Experiments show that we achieve about 3\% Dice score improvements across three datasets while reducing computational complexity by over 7 times.
<div id='section'>Paperid: <span id='pid'>359, <a href='https://arxiv.org/pdf/2501.00818.pdf' target='_blank'>https://arxiv.org/pdf/2501.00818.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinru Meng, Han Sun, Jiamei Liu, Ningzhong Liu, Huiyu Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.00818">SPARNet: Continual Test-Time Adaptation via Sample Partitioning Strategy and Anti-Forgetting Regularization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time Adaptation (TTA) aims to improve model performance when the model encounters domain changes after deployment. The standard TTA mainly considers the case where the target domain is static, while the continual TTA needs to undergo a sequence of domain changes. This encounters a significant challenge as the model needs to adapt for the long-term and is unaware of when the domain changes occur. The quality of pseudo-labels is hard to guarantee. Noisy pseudo-labels produced by simple self-training methods can cause error accumulation and catastrophic forgetting. In this work, we propose a new framework named SPARNet which consists of two parts, sample partitioning strategy and anti-forgetting regularization. The sample partition strategy divides samples into two groups, namely reliable samples and unreliable samples. According to the characteristics of each group of samples, we choose different strategies to deal with different groups of samples. This ensures that reliable samples contribute more to the model. At the same time, the negative impacts of unreliable samples are eliminated by the mean teacher's consistency learning. Finally, we introduce a regularization term to alleviate the catastrophic forgetting problem, which can limit important parameters from excessive changes. This term enables long-term adaptation of parameters in the network. The effectiveness of our method is demonstrated in continual TTA scenario by conducting a large number of experiments on CIFAR10-C, CIFAR100-C and ImageNet-C.
<div id='section'>Paperid: <span id='pid'>360, <a href='https://arxiv.org/pdf/2412.07980.pdf' target='_blank'>https://arxiv.org/pdf/2412.07980.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mingxi Lei, Chunwei Ma, Meng Ding, Yufan Zhou, Ziyun Huang, Jinhui Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.07980">TTVD: Towards a Geometric Framework for Test-Time Adaptation Based on Voronoi Diagram</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning models often struggle with generalization when deploying on real-world data, due to the common distributional shift to the training data. Test-time adaptation (TTA) is an emerging scheme used at inference time to address this issue. In TTA, models are adapted online at the same time when making predictions to test data. Neighbor-based approaches have gained attention recently, where prototype embeddings provide location information to alleviate the feature shift between training and testing data. However, due to their inherit limitation of simplicity, they often struggle to learn useful patterns and encounter performance degradation. To confront this challenge, we study the TTA problem from a geometric point of view. We first reveal that the underlying structure of neighbor-based methods aligns with the Voronoi Diagram, a classical computational geometry model for space partitioning. Building on this observation, we propose the Test-Time adjustment by Voronoi Diagram guidance (TTVD), a novel framework that leverages the benefits of this geometric property. Specifically, we explore two key structures: 1) Cluster-induced Voronoi Diagram (CIVD): This integrates the joint contribution of self-supervision and entropy-based methods to provide richer information. 2) Power Diagram (PD): A generalized version of the Voronoi Diagram that refines partitions by assigning weights to each Voronoi cell. Our experiments under rigid, peer-reviewed settings on CIFAR-10-C, CIFAR-100-C, ImageNet-C, and ImageNet-R shows that TTVD achieves remarkable improvements compared to state-of-the-art methods. Moreover, extensive experimental results also explore the effects of batch size and class imbalance, which are two scenarios commonly encountered in real-world applications. These analyses further validate the robustness and adaptability of our proposed framework.
<div id='section'>Paperid: <span id='pid'>361, <a href='https://arxiv.org/pdf/2407.12697.pdf' target='_blank'>https://arxiv.org/pdf/2407.12697.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mahdi Gilany, Mohamed Harmanani, Paul Wilson, Minh Nguyen Nhat To, Amoon Jamzad, Fahimeh Fooladgar, Brian Wodlinger, Purang Abolmaesumi, Parvin Mousavi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.12697">Calibrated Diverse Ensemble Entropy Minimization for Robust Test-Time Adaptation in Prostate Cancer Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>High resolution micro-ultrasound has demonstrated promise in real-time prostate cancer detection, with deep learning becoming a prominent tool for learning complex tissue properties reflected on ultrasound. However, a significant roadblock to real-world deployment remains, which prior works often overlook: model performance suffers when applied to data from different clinical centers due to variations in data distribution. This distribution shift significantly impacts the model's robustness, posing major challenge to clinical deployment. Domain adaptation and specifically its test-time adaption (TTA) variant offer a promising solution to address this challenge. In a setting designed to reflect real-world conditions, we compare existing methods to state-of-the-art TTA approaches adopted for cancer detection, demonstrating the lack of robustness to distribution shifts in the former. We then propose Diverse Ensemble Entropy Minimization (DEnEM), questioning the effectiveness of current TTA methods on ultrasound data. We show that these methods, although outperforming baselines, are suboptimal due to relying on neural networks output probabilities, which could be uncalibrated, or relying on data augmentation, which is not straightforward to define on ultrasound data. Our results show a significant improvement of $5\%$ to $7\%$ in AUROC over the existing methods and $3\%$ to $5\%$ over TTA methods, demonstrating the advantage of DEnEM in addressing distribution shift.
  \keywords{Ultrasound Imaging \and Prostate Cancer \and Computer-aided Diagnosis \and Distribution Shift Robustness \and Test-time Adaptation.}
<div id='section'>Paperid: <span id='pid'>362, <a href='https://arxiv.org/pdf/2405.07046.pdf' target='_blank'>https://arxiv.org/pdf/2405.07046.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yunchuan Ma, Laiyun Qing, Guorong Li, Yuankai Qi, Amin Beheshti, Quan Z. Sheng, Qingming Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.07046">RETTA: Retrieval-Enhanced Test-Time Adaptation for Zero-Shot Video Captioning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite the significant progress of fully-supervised video captioning, zero-shot methods remain much less explored. In this paper, we propose a novel zero-shot video captioning framework named Retrieval-Enhanced Test-Time Adaptation (RETTA), which takes advantage of existing pretrained large-scale vision and language models to directly generate captions with test-time adaptation. Specifically, we bridge video and text using four key models: a general video-text retrieval model XCLIP, a general image-text matching model CLIP, a text alignment model AnglE, and a text generation model GPT-2, due to their source-code availability. The main challenge is how to enable the text generation model to be sufficiently aware of the content in a given video so as to generate corresponding captions. To address this problem, we propose using learnable tokens as a communication medium among these four frozen models GPT-2, XCLIP, CLIP, and AnglE. Different from the conventional way that trains these tokens with training data, we propose to learn these tokens with soft targets of the inference data under several carefully crafted loss functions, which enable the tokens to absorb video information catered for GPT-2. This procedure can be efficiently done in just a few iterations (we use 16 iterations in the experiments) and does not require ground truth data. Extensive experimental results on three widely used datasets, MSR-VTT, MSVD, and VATEX, show absolute 5.1%-32.4% improvements in terms of the main metric CIDEr compared to several state-of-the-art zero-shot video captioning methods.
<div id='section'>Paperid: <span id='pid'>363, <a href='https://arxiv.org/pdf/2404.17275.pdf' target='_blank'>https://arxiv.org/pdf/2404.17275.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiang Gu, Xi Yu, Yan Yang, Jian Sun, Zongben Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.17275">Adversarial Reweighting with $Î±$-Power Maximization for Domain Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The practical Domain Adaptation (DA) tasks, e.g., Partial DA (PDA), open-set DA, universal DA, and test-time adaptation, have gained increasing attention in the machine learning community. In this paper, we propose a novel approach, dubbed Adversarial Reweighting with $Î±$-Power Maximization (ARPM), for PDA where the source domain contains private classes absent in target domain. In ARPM, we propose a novel adversarial reweighting model that adversarially learns to reweight source domain data to identify source-private class samples by assigning smaller weights to them, for mitigating potential negative transfer. Based on the adversarial reweighting, we train the transferable recognition model on the reweighted source distribution to be able to classify common class data. To reduce the prediction uncertainty of the recognition model on the target domain for PDA, we present an $Î±$-power maximization mechanism in ARPM, which enriches the family of losses for reducing the prediction uncertainty for PDA. Extensive experimental results on five PDA benchmarks, i.e., Office-31, Office-Home, VisDA-2017, ImageNet-Caltech, and DomainNet, show that our method is superior to recent PDA methods. Ablation studies also confirm the effectiveness of components in our approach. To theoretically analyze our method, we deduce an upper bound of target domain expected error for PDA, which is approximately minimized in our approach. We further extend ARPM to open-set DA, universal DA, and test time adaptation, and verify the usefulness through experiments.
<div id='section'>Paperid: <span id='pid'>364, <a href='https://arxiv.org/pdf/2402.09004.pdf' target='_blank'>https://arxiv.org/pdf/2402.09004.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Juhyeon Shin, Jonghyun Lee, Saehyung Lee, Minjun Park, Dongjun Lee, Uiwon Hwang, Sungroh Yoon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.09004">Gradient Alignment with Prototype Feature for Fully Test-time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In context of Test-time Adaptation(TTA), we propose a regularizer, dubbed Gradient Alignment with Prototype feature (GAP), which alleviates the inappropriate guidance from entropy minimization loss from misclassified pseudo label. We developed a gradient alignment loss to precisely manage the adaptation process, ensuring that changes made for some data don't negatively impact the model's performance on other data. We introduce a prototype feature of a class as a proxy measure of the negative impact. To make GAP regularizer feasible under the TTA constraints, where model can only access test data without labels, we tailored its formula in two ways: approximating prototype features with weight vectors of the classifier, calculating gradient without back-propagation. We demonstrate GAP significantly improves TTA methods across various datasets, which proves its versatility and effectiveness.
<div id='section'>Paperid: <span id='pid'>365, <a href='https://arxiv.org/pdf/2311.04991.pdf' target='_blank'>https://arxiv.org/pdf/2311.04991.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fahim Faisal Niloy, Sk Miraj Ahmed, Dripta S. Raychaudhuri, Samet Oymak, Amit K. Roy-Chowdhury
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.04991">Effective Restoration of Source Knowledge in Continual Test Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditional test-time adaptation (TTA) methods face significant challenges in adapting to dynamic environments characterized by continuously changing long-term target distributions. These challenges primarily stem from two factors: catastrophic forgetting of previously learned valuable source knowledge and gradual error accumulation caused by miscalibrated pseudo labels. To address these issues, this paper introduces an unsupervised domain change detection method that is capable of identifying domain shifts in dynamic environments and subsequently resets the model parameters to the original source pre-trained values. By restoring the knowledge from the source, it effectively corrects the negative consequences arising from the gradual deterioration of model parameters caused by ongoing shifts in the domain. Our method involves progressive estimation of global batch-norm statistics specific to each domain, while keeping track of changes in the statistics triggered by domain shifts. Importantly, our method is agnostic to the specific adaptation technique employed and thus, can be incorporated to existing TTA methods to enhance their performance in dynamic environments. We perform extensive experiments on benchmark datasets to demonstrate the superior performance of our method compared to state-of-the-art adaptation methods.
<div id='section'>Paperid: <span id='pid'>366, <a href='https://arxiv.org/pdf/2307.04470.pdf' target='_blank'>https://arxiv.org/pdf/2307.04470.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yexin Liu, Weiming Zhang, Guoyang Zhao, Jinjing Zhu, Athanasios Vasilakos, Lin Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.04470">Test-Time Adaptation for Nighttime Color-Thermal Semantic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The ability to scene understanding in adverse visual conditions, e.g., nighttime, has sparked active research for RGB-Thermal (RGB-T) semantic segmentation. However, it is essentially hampered by two critical problems: 1) the day-night gap of RGB images is larger than that of thermal images, and 2) the class-wise performance of RGB images at night is not consistently higher or lower than that of thermal images. we propose the first test-time adaptation (TTA) framework, dubbed Night-TTA, to address the problems for nighttime RGBT semantic segmentation without access to the source (daytime) data during adaptation. Our method enjoys three key technical parts. Firstly, as one modality (e.g., RGB) suffers from a larger domain gap than that of the other (e.g., thermal), Imaging Heterogeneity Refinement (IHR) employs an interaction branch on the basis of RGB and thermal branches to prevent cross-modal discrepancy and performance degradation. Then, Class Aware Refinement (CAR) is introduced to obtain reliable ensemble logits based on pixel-level distribution aggregation of the three branches. In addition, we also design a specific learning scheme for our TTA framework, which enables the ensemble logits and three student logits to collaboratively learn to improve the quality of predictions during the testing phase of our Night TTA. Extensive experiments show that our method achieves state-of-the-art (SoTA) performance with a 13.07% boost in mIoU.
<div id='section'>Paperid: <span id='pid'>367, <a href='https://arxiv.org/pdf/2302.12400.pdf' target='_blank'>https://arxiv.org/pdf/2302.12400.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Zhiquan Wen, Yaofo Chen, Peilin Zhao, Mingkui Tan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.12400">Towards Stable Test-Time Adaptation in Dynamic Wild World</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) has shown to be effective at tackling distribution shifts between training and testing data by adapting a given model on test samples. However, the online model updating of TTA may be unstable and this is often a key obstacle preventing existing TTA methods from being deployed in the real world. Specifically, TTA may fail to improve or even harm the model performance when test data have: 1) mixed distribution shifts, 2) small batch sizes, and 3) online imbalanced label distribution shifts, which are quite common in practice. In this paper, we investigate the unstable reasons and find that the batch norm layer is a crucial factor hindering TTA stability. Conversely, TTA can perform more stably with batch-agnostic norm layers, \ie, group or layer norm. However, we observe that TTA with group and layer norms does not always succeed and still suffers many failure cases. By digging into the failure cases, we find that certain noisy test samples with large gradients may disturb the model adaption and result in collapsed trivial solutions, \ie, assigning the same class label for all samples. To address the above collapse issue, we propose a sharpness-aware and reliable entropy minimization method, called SAR, for further stabilizing TTA from two aspects: 1) remove partial noisy samples with large gradients, 2) encourage model weights to go to a flat minimum so that the model is robust to the remaining noisy samples. Promising results demonstrate that SAR performs more stably over prior methods and is computationally efficient under the above wild test scenarios.
<div id='section'>Paperid: <span id='pid'>368, <a href='https://arxiv.org/pdf/2508.12643.pdf' target='_blank'>https://arxiv.org/pdf/2508.12643.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pinci Yang, Peisong Wen, Ke Ma, Qianqian Xu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.12643">Learn Faster and Remember More: Balancing Exploration and Exploitation for Continual Test-time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual Test-Time Adaptation (CTTA) aims to adapt a source pre-trained model to continually changing target domains during inference. As a fundamental principle, an ideal CTTA method should rapidly adapt to new domains (exploration) while retaining and exploiting knowledge from previously encountered domains to handle similar domains in the future. Despite significant advances, balancing exploration and exploitation in CTTA is still challenging: 1) Existing methods focus on adjusting predictions based on deep-layer outputs of neural networks. However, domain shifts typically affect shallow features, which are inefficient to be adjusted from deep predictions, leading to dilatory exploration; 2) A single model inevitably forgets knowledge of previous domains during the exploration, making it incapable of exploiting historical knowledge to handle similar future domains. To address these challenges, this paper proposes a mean teacher framework that strikes an appropriate Balance between Exploration and Exploitation (BEE) during the CTTA process. For the former challenge, we introduce a Multi-level Consistency Regularization (MCR) loss that aligns the intermediate features of the student and teacher models, accelerating adaptation to the current domain. For the latter challenge, we employ a Complementary Anchor Replay (CAR) mechanism to reuse historical checkpoints (anchors), recovering complementary knowledge for diverse domains. Experiments show that our method significantly outperforms state-of-the-art methods on several benchmarks, demonstrating its effectiveness for CTTA tasks.
<div id='section'>Paperid: <span id='pid'>369, <a href='https://arxiv.org/pdf/2508.09223.pdf' target='_blank'>https://arxiv.org/pdf/2508.09223.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sameer Ambekar, Daniel M. Lang, Julia A. Schnabel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.09223">Hierarchical Adaptive networks with Task vectors for Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation allows pretrained models to adjust to incoming data streams, addressing distribution shifts between source and target domains. However, standard methods rely on single-dimensional linear classification layers, which often fail to handle diverse and complex shifts. We propose Hierarchical Adaptive Networks with Task Vectors (Hi-Vec), which leverages multiple layers of increasing size for dynamic test-time adaptation. By decomposing the encoder's representation space into such hierarchically organized layers, Hi-Vec, in a plug-and-play manner, allows existing methods to adapt to shifts of varying complexity. Our contributions are threefold: First, we propose dynamic layer selection for automatic identification of the optimal layer for adaptation to each test batch. Second, we propose a mechanism that merges weights from the dynamic layer to other layers, ensuring all layers receive target information. Third, we propose linear layer agreement that acts as a gating function, preventing erroneous fine-tuning by adaptation on noisy batches. We rigorously evaluate the performance of Hi-Vec in challenging scenarios and on multiple target datasets, proving its strong capability to advance state-of-the-art methods. Our results show that Hi-Vec improves robustness, addresses uncertainty, and handles limited batch sizes and increased outlier rates.
<div id='section'>Paperid: <span id='pid'>370, <a href='https://arxiv.org/pdf/2506.01381.pdf' target='_blank'>https://arxiv.org/pdf/2506.01381.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yilong Lai, Jialong Wu, Zhenglin Wang, Deyu Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.01381">AdaRewriter: Unleashing the Power of Prompting-based Conversational Query Reformulation via Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Prompting-based conversational query reformulation has emerged as a powerful approach for conversational search, refining ambiguous user queries into standalone search queries. Best-of-N reformulation over the generated candidates via prompting shows impressive potential scaling capability. However, both the previous tuning methods (training time) and adaptation approaches (test time) can not fully unleash their benefits. In this paper, we propose AdaRewriter, a novel framework for query reformulation using an outcome-supervised reward model via test-time adaptation. By training a lightweight reward model with contrastive ranking loss, AdaRewriter selects the most promising reformulation during inference. Notably, it can operate effectively in black-box systems, including commercial LLM APIs. Experiments on five conversational search datasets show that AdaRewriter significantly outperforms the existing methods across most settings, demonstrating the potential of test-time adaptation for conversational query reformulation.
<div id='section'>Paperid: <span id='pid'>371, <a href='https://arxiv.org/pdf/2505.18337.pdf' target='_blank'>https://arxiv.org/pdf/2505.18337.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rajarshi Bhattacharya, Shakeeb Murtaza, Christian Desrosiers, Jose Dolz, Maguelonne Heritier, Eric Granger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.18337">DART$^3$: Leveraging Distance for Test Time Adaptation in Person Re-Identification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Person re-identification (ReID) models are known to suffer from camera bias, where learned representations cluster according to camera viewpoints rather than identity, leading to significant performance degradation under (inter-camera) domain shifts in real-world surveillance systems when new cameras are added to camera networks. State-of-the-art test-time adaptation (TTA) methods, largely designed for classification tasks, rely on classification entropy-based objectives that fail to generalize well to ReID, thus making them unsuitable for tackling camera bias. In this paper, we introduce DART$^3$, a TTA framework specifically designed to mitigate camera-induced domain shifts in person ReID. DART$^3$ (Distance-Aware Retrieval Tuning at Test Time) leverages a distance-based objective that aligns better with image retrieval tasks like ReID by exploiting the correlation between nearest-neighbor distance and prediction error. Unlike prior ReID-specific domain adaptation methods, DART$^3$ requires no source data, architectural modifications, or retraining, and can be deployed in both fully black-box and hybrid settings. Empirical evaluations on multiple ReID benchmarks indicate that DART$^3$ and DART$^3$ LITE, a lightweight alternative to the approach, consistently outperforms state-of-the-art TTA baselines, making for a viable option to online learning to mitigate the adverse effects of camera bias.
<div id='section'>Paperid: <span id='pid'>372, <a href='https://arxiv.org/pdf/2505.13643.pdf' target='_blank'>https://arxiv.org/pdf/2505.13643.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rakibul Hasan Rajib, Md Akil Raihan Iftee, Mir Sazzat Hossain, A. K. M. Mahbubur Rahman, Sajib Mistry, M Ashraful Amin, Amin Ahsan Ali
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.13643">FedCTTA: A Collaborative Approach to Continual Test-Time Adaptation in Federated Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Federated Learning (FL) enables collaborative model training across distributed clients without sharing raw data, making it ideal for privacy-sensitive applications. However, FL models often suffer performance degradation due to distribution shifts between training and deployment. Test-Time Adaptation (TTA) offers a promising solution by allowing models to adapt using only test samples. However, existing TTA methods in FL face challenges such as computational overhead, privacy risks from feature sharing, and scalability concerns due to memory constraints. To address these limitations, we propose Federated Continual Test-Time Adaptation (FedCTTA), a privacy-preserving and computationally efficient framework for federated adaptation. Unlike prior methods that rely on sharing local feature statistics, FedCTTA avoids direct feature exchange by leveraging similarity-aware aggregation based on model output distributions over randomly generated noise samples. This approach ensures adaptive knowledge sharing while preserving data privacy. Furthermore, FedCTTA minimizes the entropy at each client for continual adaptation, enhancing the model's confidence in evolving target distributions. Our method eliminates the need for server-side training during adaptation and maintains a constant memory footprint, making it scalable even as the number of clients or training rounds increases. Extensive experiments show that FedCTTA surpasses existing methods across diverse temporal and spatial heterogeneity scenarios.
<div id='section'>Paperid: <span id='pid'>373, <a href='https://arxiv.org/pdf/2504.15323.pdf' target='_blank'>https://arxiv.org/pdf/2504.15323.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Donggyun Kim, Chanwoo Kim, Seunghoon Hong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.15323">HyperFlow: Gradient-Free Emulation of Few-Shot Fine-Tuning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While test-time fine-tuning is beneficial in few-shot learning, the need for multiple backpropagation steps can be prohibitively expensive in real-time or low-resource scenarios. To address this limitation, we propose an approach that emulates gradient descent without computing gradients, enabling efficient test-time adaptation. Specifically, we formulate gradient descent as an Euler discretization of an ordinary differential equation (ODE) and train an auxiliary network to predict the task-conditional drift using only the few-shot support set. The adaptation then reduces to a simple numerical integration (e.g., via the Euler method), which requires only a few forward passes of the auxiliary network -- no gradients or forward passes of the target model are needed. In experiments on cross-domain few-shot classification using the Meta-Dataset and CDFSL benchmarks, our method significantly improves out-of-domain performance over the non-fine-tuned baseline while incurring only 6\% of the memory cost and 0.02\% of the computation time of standard fine-tuning, thus establishing a practical middle ground between direct transfer and fully fine-tuned approaches.
<div id='section'>Paperid: <span id='pid'>374, <a href='https://arxiv.org/pdf/2501.01127.pdf' target='_blank'>https://arxiv.org/pdf/2501.01127.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sihan Wang, Shangqi Gao, Fuping Wu, Xiahai Zhuang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.01127">InDeed: Interpretable image deep decomposition with guaranteed generalizability</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Image decomposition aims to analyze an image into elementary components, which is essential for numerous downstream tasks and also by nature provides certain interpretability to the analysis. Deep learning can be powerful for such tasks, but surprisingly their combination with a focus on interpretability and generalizability is rarely explored. In this work, we introduce a novel framework for interpretable deep image decomposition, combining hierarchical Bayesian modeling and deep learning to create an architecture-modularized and model-generalizable deep neural network (DNN). The proposed framework includes three steps: (1) hierarchical Bayesian modeling of image decomposition, (2) transforming the inference problem into optimization tasks, and (3) deep inference via a modularized Bayesian DNN. We further establish a theoretical connection between the loss function and the generalization error bound, which inspires a new test-time adaptation approach for out-of-distribution scenarios. We instantiated the application using two downstream tasks, \textit{i.e.}, image denoising, and unsupervised anomaly detection, and the results demonstrated improved generalizability as well as interpretability of our methods. The source code will be released upon the acceptance of this paper.
<div id='section'>Paperid: <span id='pid'>375, <a href='https://arxiv.org/pdf/2412.01052.pdf' target='_blank'>https://arxiv.org/pdf/2412.01052.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingnan Shi, Rajat Talak, Harry Zhang, David Jin, Luca Carlone
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.01052">CRISP: Object Pose and Shape Estimation with Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider the problem of estimating object pose and shape from an RGB-D image. Our first contribution is to introduce CRISP, a category-agnostic object pose and shape estimation pipeline. The pipeline implements an encoder-decoder model for shape estimation. It uses FiLM-conditioning for implicit shape reconstruction and a DPT-based network for estimating pose-normalized points for pose estimation. As a second contribution, we propose an optimization-based pose and shape corrector that can correct estimation errors caused by a domain gap. Observing that the shape decoder is well behaved in the convex hull of known shapes, we approximate the shape decoder with an active shape model, and show that this reduces the shape correction problem to a constrained linear least squares problem, which can be solved efficiently by an interior point algorithm. Third, we introduce a self-training pipeline to perform self-supervised domain adaptation of CRISP. The self-training is based on a correct-and-certify approach, which leverages the corrector to generate pseudo-labels at test time, and uses them to self-train CRISP. We demonstrate CRISP (and the self-training) on YCBV, SPE3R, and NOCS datasets. CRISP shows high performance on all the datasets. Moreover, our self-training is capable of bridging a large domain gap. Finally, CRISP also shows an ability to generalize to unseen objects. Code and pre-trained models will be available on https://web.mit.edu/sparklab/research/crisp_object_pose_shape/.
<div id='section'>Paperid: <span id='pid'>376, <a href='https://arxiv.org/pdf/2409.06240.pdf' target='_blank'>https://arxiv.org/pdf/2409.06240.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohsi Jawaid, Rajat Talak, Yasir Latif, Luca Carlone, Tat-Jun Chin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.06240">Test-Time Certifiable Self-Supervision to Bridge the Sim2Real Gap in Event-Based Satellite Pose Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning plays a critical role in vision-based satellite pose estimation. However, the scarcity of real data from the space environment means that deep models need to be trained using synthetic data, which raises the Sim2Real domain gap problem. A major cause of the Sim2Real gap are novel lighting conditions encountered during test time. Event sensors have been shown to provide some robustness against lighting variations in vision-based pose estimation. However, challenging lighting conditions due to strong directional light can still cause undesirable effects in the output of commercial off-the-shelf event sensors, such as noisy/spurious events and inhomogeneous event densities on the object. Such effects are non-trivial to simulate in software, thus leading to Sim2Real gap in the event domain. To close the Sim2Real gap in event-based satellite pose estimation, the paper proposes a test-time self-supervision scheme with a certifier module. Self-supervision is enabled by an optimisation routine that aligns a dense point cloud of the predicted satellite pose with the event data to attempt to rectify the inaccurately estimated pose. The certifier attempts to verify the corrected pose, and only certified test-time inputs are backpropagated via implicit differentiation to refine the predicted landmarks, thus improving the pose estimates and closing the Sim2Real gap. Results show that the our method outperforms established test-time adaptation schemes.
<div id='section'>Paperid: <span id='pid'>377, <a href='https://arxiv.org/pdf/2407.02880.pdf' target='_blank'>https://arxiv.org/pdf/2407.02880.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Frederic Z. Zhang, Paul Albert, Cristian Rodriguez-Opazo, Anton van den Hengel, Ehsan Abbasnejad
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.02880">Knowledge Composition using Task Vectors with Learned Anisotropic Scaling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pre-trained models produce strong generic representations that can be adapted via fine-tuning. The learned weight difference relative to the pre-trained model, known as a task vector, characterises the direction and stride of fine-tuning. The significance of task vectors is such that simple arithmetic operations on them can be used to combine diverse representations from different domains. This paper builds on these properties of task vectors and aims to answer (1) whether components of task vectors, particularly parameter blocks, exhibit similar characteristics, and (2) how such blocks can be used to enhance knowledge composition and transfer. To this end, we introduce aTLAS, an algorithm that linearly combines parameter blocks with different learned coefficients, resulting in anisotropic scaling at the task vector level. We show that such linear combinations explicitly exploit the low intrinsic dimensionality of pre-trained models, with only a few coefficients being the learnable parameters. Furthermore, composition of parameter blocks leverages the already learned representations, thereby reducing the dependency on large amounts of data. We demonstrate the effectiveness of our method in task arithmetic, few-shot recognition and test-time adaptation, with supervised or unsupervised objectives. In particular, we show that (1) learned anisotropic scaling allows task vectors to be more disentangled, causing less interference in composition; (2) task vector composition excels with scarce or no labeled data and is less prone to domain shift, thus leading to better generalisability; (3) mixing the most informative parameter blocks across different task vectors prior to training can reduce the memory footprint and improve the flexibility of knowledge transfer. Moreover, we show the potential of aTLAS as a PEFT method, particularly with less data, and demonstrate its scalibility.
<div id='section'>Paperid: <span id='pid'>378, <a href='https://arxiv.org/pdf/2311.09533.pdf' target='_blank'>https://arxiv.org/pdf/2311.09533.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xi Ye, Ruoxi Sun, Sercan Ã. Arik, Tomas Pfister
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.09533">Effective Large Language Model Adaptation for Improved Grounding and Citation Generation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large language models (LLMs) have achieved remarkable advancements in natural language understanding and generation. However, one major issue towards their widespread deployment in the real world is that they can generate "hallucinated" answers that are not factual. Towards this end, this paper focuses on improving LLMs by grounding their responses in retrieved passages and by providing citations. We propose a new framework, AGREE, Adaptation for GRounding EnhancEment, that improves the grounding from a holistic perspective. Our framework tunes LLMs to selfground the claims in their responses and provide accurate citations to retrieved documents. This tuning on top of the pre-trained LLMs requires well-grounded responses (with citations) for paired queries, for which we introduce a method that can automatically construct such data from unlabeled queries. The selfgrounding capability of tuned LLMs further grants them a test-time adaptation (TTA) capability that can actively retrieve passages to support the claims that have not been grounded, which iteratively improves the responses of LLMs. Across five datasets and two LLMs, our results show that the proposed tuningbased AGREE framework generates superior grounded responses with more accurate citations compared to prompting-based approaches and post-hoc citing-based approaches
<div id='section'>Paperid: <span id='pid'>379, <a href='https://arxiv.org/pdf/2310.08986.pdf' target='_blank'>https://arxiv.org/pdf/2310.08986.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenyu Lin, Yusheng He, Zhengqing Zang, Chenwei Tang, Tao Wang, Jiancheng Lv
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.08986">VCL Challenges 2023 at ICCV 2023 Technical Report: Bi-level Adaptation Method for Test-time Adaptive Object Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This report outlines our team's participation in VCL Challenges B Continual Test_time Adaptation, focusing on the technical details of our approach. Our primary focus is Testtime Adaptation using bi_level adaptations, encompassing image_level and detector_level adaptations. At the image level, we employ adjustable parameterbased image filters, while at the detector level, we leverage adjustable parameterbased mean teacher modules. Ultimately, through the utilization of these bi_level adaptations, we have achieved a remarkable 38.3% mAP on the target domain of the test set within VCL Challenges B. It is worth noting that the minimal drop in mAP, is mearly 4.2%, and the overall performance is 32.5% mAP.
<div id='section'>Paperid: <span id='pid'>380, <a href='https://arxiv.org/pdf/2307.00676.pdf' target='_blank'>https://arxiv.org/pdf/2307.00676.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingjie Guo, Weitong Zhang, Matthew Sinclair, Daniel Rueckert, Chen Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.00676">Pay Attention to the Atlas: Atlas-Guided Test-Time Adaptation Method for Robust 3D Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Convolutional neural networks (CNNs) often suffer from poor performance when tested on target data that differs from the training (source) data distribution, particularly in medical imaging applications where variations in imaging protocols across different clinical sites and scanners lead to different imaging appearances. However, re-accessing source training data for unsupervised domain adaptation or labeling additional test data for model fine-tuning can be difficult due to privacy issues and high labeling costs, respectively. To solve this problem, we propose a novel atlas-guided test-time adaptation (TTA) method for robust 3D medical image segmentation, called AdaAtlas. AdaAtlas only takes one single unlabeled test sample as input and adapts the segmentation network by minimizing an atlas-based loss. Specifically, the network is adapted so that its prediction after registration is aligned with the learned atlas in the atlas space, which helps to reduce anatomical segmentation errors at test time. In addition, different from most existing TTA methods which restrict the adaptation to batch normalization blocks in the segmentation network only, we further exploit the use of channel and spatial attention blocks for improved adaptability at test time. Extensive experiments on multiple datasets from different sites show that AdaAtlas with attention blocks adapted (AdaAtlas-Attention) achieves superior performance improvements, greatly outperforming other competitive TTA methods.
<div id='section'>Paperid: <span id='pid'>381, <a href='https://arxiv.org/pdf/2505.05375.pdf' target='_blank'>https://arxiv.org/pdf/2505.05375.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kejie Zhao, Wenjia Hua, Aiersi Tuerhong, Luziwei Leng, Yuxin Ma, Qinghai Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.05375">Threshold Modulation for Online Test-Time Adaptation of Spiking Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, spiking neural networks (SNNs), deployed on neuromorphic chips, provide highly efficient solutions on edge devices in different scenarios. However, their ability to adapt to distribution shifts after deployment has become a crucial challenge. Online test-time adaptation (OTTA) offers a promising solution by enabling models to dynamically adjust to new data distributions without requiring source data or labeled target samples. Nevertheless, existing OTTA methods are largely designed for traditional artificial neural networks and are not well-suited for SNNs. To address this gap, we propose a low-power, neuromorphic chip-friendly online test-time adaptation framework, aiming to enhance model generalization under distribution shifts. The proposed approach is called Threshold Modulation (TM), which dynamically adjusts the firing threshold through neuronal dynamics-inspired normalization, being more compatible with neuromorphic hardware. Experimental results on benchmark datasets demonstrate the effectiveness of this method in improving the robustness of SNNs against distribution shifts while maintaining low computational cost. The proposed method offers a practical solution for online test-time adaptation of SNNs, providing inspiration for the design of future neuromorphic chips. The demo code is available at github.com/NneurotransmitterR/TM-OTTA-SNN.
<div id='section'>Paperid: <span id='pid'>382, <a href='https://arxiv.org/pdf/2504.08010.pdf' target='_blank'>https://arxiv.org/pdf/2504.08010.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuaicheng Niu, Guohao Chen, Peilin Zhao, Tianyi Wang, Pengcheng Wu, Zhiqi Shen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.08010">Self-Bootstrapping for Versatile Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we seek to develop a versatile test-time adaptation (TTA) objective for a variety of tasks - classification and regression across image-, object-, and pixel-level predictions. We achieve this through a self-bootstrapping scheme that optimizes prediction consistency between the test image (as target) and its deteriorated view. The key challenge lies in devising effective augmentations/deteriorations that: i) preserve the image's geometric information, e.g., object sizes and locations, which is crucial for TTA on object/pixel-level tasks, and ii) provide sufficient learning signals for TTA. To this end, we analyze how common distribution shifts affect the image's information power across spatial frequencies in the Fourier domain, and reveal that low-frequency components carry high power and masking these components supplies more learning signals, while masking high-frequency components can not. In light of this, we randomly mask the low-frequency amplitude of an image in its Fourier domain for augmentation. Meanwhile, we also augment the image with noise injection to compensate for missing learning signals at high frequencies, by enhancing the information power there. Experiments show that, either independently or as a plug-and-play module, our method achieves superior results across classification, segmentation, and 3D monocular detection tasks with both transformer and CNN models.
<div id='section'>Paperid: <span id='pid'>383, <a href='https://arxiv.org/pdf/2503.11194.pdf' target='_blank'>https://arxiv.org/pdf/2503.11194.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiuxia Lin, Kerui Gu, Linlin Yang, Angela Yao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.11194">Online Test-time Adaptation for 3D Human Pose Estimation: A Practical Perspective with Estimated 2D Poses</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Online test-time adaptation for 3D human pose estimation is used for video streams that differ from training data. Ground truth 2D poses are used for adaptation, but only estimated 2D poses are available in practice. This paper addresses adapting models to streaming videos with estimated 2D poses. Comparing adaptations reveals the challenge of limiting estimation errors while preserving accurate pose information. To this end, we propose adaptive aggregation, a two-stage optimization, and local augmentation for handling varying levels of estimated pose error. First, we perform adaptive aggregation across videos to initialize the model state with labeled representative samples. Within each video, we use a two-stage optimization to benefit from 2D fitting while minimizing the impact of erroneous updates. Second, we employ local augmentation, using adjacent confident samples to update the model before adapting to the current non-confident sample. Our method surpasses state-of-the-art by a large margin, advancing adaptation towards more practical settings of using estimated 2D poses.
<div id='section'>Paperid: <span id='pid'>384, <a href='https://arxiv.org/pdf/2502.18334.pdf' target='_blank'>https://arxiv.org/pdf/2502.18334.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hans Hao-Hsun Hsu, Shikun Liu, Han Zhao, Pan Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.18334">Structural Alignment Improves Graph Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Graph-based learning excels at capturing interaction patterns in diverse domains like recommendation, fraud detection, and particle physics. However, its performance often degrades under distribution shifts, especially those altering network connectivity. Current methods to address these shifts typically require retraining with the source dataset, which is often infeasible due to computational or privacy limitations. We introduce Test-Time Structural Alignment (TSA), a novel algorithm for Graph Test-Time Adaptation (GTTA) that aligns graph structures during inference without accessing the source data. Grounded in a theoretical understanding of graph data distribution shifts, TSA employs three synergistic strategies: uncertainty-aware neighborhood weighting to accommodate neighbor label distribution shifts, adaptive balancing of self-node and aggregated neighborhood representations based on their signal-to-noise ratio, and decision boundary refinement to correct residual label and feature shifts. Extensive experiments on synthetic and real-world datasets demonstrate TSA's consistent outperformance of both non-graph TTA methods and state-of-the-art GTTA baselines.
<div id='section'>Paperid: <span id='pid'>385, <a href='https://arxiv.org/pdf/2407.10784.pdf' target='_blank'>https://arxiv.org/pdf/2407.10784.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Changhun Kim, Taewon Kim, Seungyeon Woo, June Yong Yang, Eunho Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.10784">AdapTable: Test-Time Adaptation for Tabular Data via Shift-Aware Uncertainty Calibrator and Label Distribution Handler</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In real-world scenarios, tabular data often suffer from distribution shifts that threaten the performance of machine learning models. Despite its prevalence and importance, handling distribution shifts in the tabular domain remains underexplored due to the inherent challenges within the tabular data itself. In this sense, test-time adaptation (TTA) offers a promising solution by adapting models to target data without accessing source data, crucial for privacy-sensitive tabular domains. However, existing TTA methods either 1) overlook the nature of tabular distribution shifts, often involving label distribution shifts, or 2) impose architectural constraints on the model, leading to a lack of applicability. To this end, we propose AdapTable, a novel TTA framework for tabular data. AdapTable operates in two stages: 1) calibrating model predictions using a shift-aware uncertainty calibrator, and 2) adjusting these predictions to match the target label distribution with a label distribution handler. We validate the effectiveness of AdapTable through theoretical analysis and extensive experiments on various distribution shift scenarios. Our results demonstrate AdapTable's ability to handle various real-world distribution shifts, achieving up to a 16% improvement on the HELOC dataset.
<div id='section'>Paperid: <span id='pid'>386, <a href='https://arxiv.org/pdf/2404.01650.pdf' target='_blank'>https://arxiv.org/pdf/2404.01650.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuaicheng Niu, Chunyan Miao, Guohao Chen, Pengcheng Wu, Peilin Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.01650">Test-Time Model Adaptation with Only Forward Passes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation has proven effective in adapting a given trained model to unseen test samples with potential distribution shifts. However, in real-world scenarios, models are usually deployed on resource-limited devices, e.g., FPGAs, and are often quantized and hard-coded with non-modifiable parameters for acceleration. In light of this, existing methods are often infeasible since they heavily depend on computation-intensive backpropagation for model updating that may be not supported. To address this, we propose a test-time Forward-Optimization Adaptation (FOA) method. In FOA, we seek to solely learn a newly added prompt (as model's input) via a derivative-free covariance matrix adaptation evolution strategy. To make this strategy work stably under our online unsupervised setting, we devise a novel fitness function by measuring test-training statistic discrepancy and model prediction entropy. Moreover, we design an activation shifting scheme that directly tunes the model activations for shifted test samples, making them align with the source training domain, thereby further enhancing adaptation performance. Without using any backpropagation and altering model weights, FOA runs on quantized 8-bit ViT outperforms gradient-based TENT on full-precision 32-bit ViT, while achieving an up to 24-fold memory reduction on ImageNet-C.
<div id='section'>Paperid: <span id='pid'>387, <a href='https://arxiv.org/pdf/2401.08703.pdf' target='_blank'>https://arxiv.org/pdf/2401.08703.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guowei Wang, Changxing Ding, Wentao Tan, Mingkui Tan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.08703">Decoupled Prototype Learning for Reliable Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) is a task that continually adapts a pre-trained source model to the target domain during inference. One popular approach involves fine-tuning model with cross-entropy loss according to estimated pseudo-labels. However, its performance is significantly affected by noisy pseudo-labels. This study reveals that minimizing the classification error of each sample causes the cross-entropy loss's vulnerability to label noise. To address this issue, we propose a novel Decoupled Prototype Learning (DPL) method that features prototype-centric loss computation. First, we decouple the optimization of class prototypes. For each class prototype, we reduce its distance with positive samples and enlarge its distance with negative samples in a contrastive manner. This strategy prevents the model from overfitting to noisy pseudo-labels. Second, we propose a memory-based strategy to enhance DPL's robustness for the small batch sizes often encountered in TTA. We update each class's pseudo-feature from a memory in a momentum manner and insert an additional DPL loss. Finally, we introduce a consistency regularization-based approach to leverage samples with unconfident pseudo-labels. This approach transfers feature styles of samples with unconfident pseudo-labels to those with confident pseudo-labels. Thus, more reliable samples for TTA are created. The experimental results demonstrate that our methods achieve state-of-the-art performance on domain generalization benchmarks, and reliably improve the performance of self-training-based methods on image corruption benchmarks. The code will be released.
<div id='section'>Paperid: <span id='pid'>388, <a href='https://arxiv.org/pdf/2309.02150.pdf' target='_blank'>https://arxiv.org/pdf/2309.02150.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Andrew Du, Anh-Dzung Doan, Yee Wei Law, Tat-Jun Chin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.02150">Domain Adaptation for Satellite-Borne Hyperspectral Cloud Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The advent of satellite-borne machine learning hardware accelerators has enabled the on-board processing of payload data using machine learning techniques such as convolutional neural networks (CNN). A notable example is using a CNN to detect the presence of clouds in hyperspectral data captured on Earth observation (EO) missions, whereby only clear sky data is downlinked to conserve bandwidth. However, prior to deployment, new missions that employ new sensors will not have enough representative datasets to train a CNN model, while a model trained solely on data from previous missions will underperform when deployed to process the data on the new missions. This underperformance stems from the domain gap, i.e., differences in the underlying distributions of the data generated by the different sensors in previous and future missions. In this paper, we address the domain gap problem in the context of on-board hyperspectral cloud detection. Our main contributions lie in formulating new domain adaptation tasks that are motivated by a concrete EO mission, developing a novel algorithm for bandwidth-efficient supervised domain adaptation, and demonstrating test-time adaptation algorithms on space deployable neural network accelerators. Our contributions enable minimal data transmission to be invoked (e.g., only 1% of the weights in ResNet50) to achieve domain adaptation, thereby allowing more sophisticated CNN models to be deployed and updated on satellites without being hampered by domain gap and bandwidth limitations.
<div id='section'>Paperid: <span id='pid'>389, <a href='https://arxiv.org/pdf/2308.06879.pdf' target='_blank'>https://arxiv.org/pdf/2308.06879.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jungsoo Lee, Debasmit Das, Jaegul Choo, Sungha Choi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.06879">Towards Open-Set Test-Time Adaptation Utilizing the Wisdom of Crowds in Entropy Minimization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) methods, which generally rely on the model's predictions (e.g., entropy minimization) to adapt the source pretrained model to the unlabeled target domain, suffer from noisy signals originating from 1) incorrect or 2) open-set predictions. Long-term stable adaptation is hampered by such noisy signals, so training models without such error accumulation is crucial for practical TTA. To address these issues, including open-set TTA, we propose a simple yet effective sample selection method inspired by the following crucial empirical finding. While entropy minimization compels the model to increase the probability of its predicted label (i.e., confidence values), we found that noisy samples rather show decreased confidence values. To be more specific, entropy minimization attempts to raise the confidence values of an individual sample's prediction, but individual confidence values may rise or fall due to the influence of signals from numerous other predictions (i.e., wisdom of crowds). Due to this fact, noisy signals misaligned with such 'wisdom of crowds', generally found in the correct signals, fail to raise the individual confidence values of wrong samples, despite attempts to increase them. Based on such findings, we filter out the samples whose confidence values are lower in the adapted model than in the original model, as they are likely to be noisy. Our method is widely applicable to existing TTA methods and improves their long-term adaptation performance in both image classification (e.g., 49.4% reduced error rates with TENT) and semantic segmentation (e.g., 11.7% gain in mIoU with TENT).
<div id='section'>Paperid: <span id='pid'>390, <a href='https://arxiv.org/pdf/2303.01904.pdf' target='_blank'>https://arxiv.org/pdf/2303.01904.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junha Song, Jungsoo Lee, In So Kweon, Sungha Choi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.01904">EcoTTA: Memory-Efficient Continual Test-time Adaptation via Self-distilled Regularization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a simple yet effective approach that improves continual test-time adaptation (TTA) in a memory-efficient manner. TTA may primarily be conducted on edge devices with limited memory, so reducing memory is crucial but has been overlooked in previous TTA studies. In addition, long-term adaptation often leads to catastrophic forgetting and error accumulation, which hinders applying TTA in real-world deployments. Our approach consists of two components to address these issues. First, we present lightweight meta networks that can adapt the frozen original networks to the target domain. This novel architecture minimizes memory consumption by decreasing the size of intermediate activations required for backpropagation. Second, our novel self-distilled regularization controls the output of the meta networks not to deviate significantly from the output of the frozen original networks, thereby preserving well-trained knowledge from the source domain. Without additional memory, this regularization prevents error accumulation and catastrophic forgetting, resulting in stable performance even in long-term test-time adaptation. We demonstrate that our simple yet effective strategy outperforms other state-of-the-art methods on various benchmarks for image classification and semantic segmentation tasks. Notably, our proposed method with ResNet-50 and WideResNet-40 takes 86% and 80% less memory than the recent state-of-the-art method, CoTTA.
<div id='section'>Paperid: <span id='pid'>391, <a href='https://arxiv.org/pdf/2302.04618.pdf' target='_blank'>https://arxiv.org/pdf/2302.04618.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hai Ye, Yuyang Ding, Juntao Li, Hwee Tou Ng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.04618">Robust Question Answering against Distribution Shifts with Test-Time Adaptation: An Empirical Study</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A deployed question answering (QA) model can easily fail when the test data has a distribution shift compared to the training data. Robustness tuning (RT) methods have been widely studied to enhance model robustness against distribution shifts before model deployment. However, can we improve a model after deployment? To answer this question, we evaluate test-time adaptation (TTA) to improve a model after deployment. We first introduce COLDQA, a unified evaluation benchmark for robust QA against text corruption and changes in language and domain. We then evaluate previous TTA methods on COLDQA and compare them to RT methods. We also propose a novel TTA method called online imitation learning (OIL). Through extensive experiments, we find that TTA is comparable to RT methods, and applying TTA after RT can significantly boost the performance on COLDQA. Our proposed OIL improves TTA to be more robust to variation in hyper-parameters and test distributions over time.
<div id='section'>Paperid: <span id='pid'>392, <a href='https://arxiv.org/pdf/2207.04913.pdf' target='_blank'>https://arxiv.org/pdf/2207.04913.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingge Wang, Liyan Xie, Yao Xie, Shao-Lun Huang, Yang Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.04913">Generalizing to Unseen Domains with Wasserstein Distributional Robustness under Limited Source Knowledge</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Domain generalization aims at learning a universal model that performs well on unseen target domains, incorporating knowledge from multiple source domains. In this research, we consider the scenario where different domain shifts occur among conditional distributions of different classes across domains. When labeled samples in the source domains are limited, existing approaches are not sufficiently robust. To address this problem, we propose a novel domain generalization framework called {Wasserstein Distributionally Robust Domain Generalization} (WDRDG), inspired by the concept of distributionally robust optimization. We encourage robustness over conditional distributions within class-specific Wasserstein uncertainty sets and optimize the worst-case performance of a classifier over these uncertainty sets. We further develop a test-time adaptation module leveraging optimal transport to quantify the relationship between the unseen target domain and source domains to make adaptive inference for target data. Experiments on the Rotated MNIST, PACS and the VLCS datasets demonstrate that our method could effectively balance the robustness and discriminability in challenging generalization scenarios.
<div id='section'>Paperid: <span id='pid'>393, <a href='https://arxiv.org/pdf/2510.10365.pdf' target='_blank'>https://arxiv.org/pdf/2510.10365.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Linlian Jiang, Rui Ma, Li Gu, Ziqiang Wang, Xinxin Zuo, Yang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.10365">PointMAC: Meta-Learned Adaptation for Robust Test-Time Point Cloud Completion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Point cloud completion is essential for robust 3D perception in safety-critical applications such as robotics and augmented reality. However, existing models perform static inference and rely heavily on inductive biases learned during training, limiting their ability to adapt to novel structural patterns and sensor-induced distortions at test time. To address this limitation, we propose PointMAC, a meta-learned framework for robust test-time adaptation in point cloud completion. It enables sample-specific refinement without requiring additional supervision. Our method optimizes the completion model under two self-supervised auxiliary objectives that simulate structural and sensor-level incompleteness. A meta-auxiliary learning strategy based on Model-Agnostic Meta-Learning (MAML) ensures that adaptation driven by auxiliary objectives is consistently aligned with the primary completion task. During inference, we adapt the shared encoder on-the-fly by optimizing auxiliary losses, with the decoder kept fixed. To further stabilize adaptation, we introduce Adaptive $λ$-Calibration, a meta-learned mechanism for balancing gradients between primary and auxiliary objectives. Extensive experiments on synthetic, simulated, and real-world datasets demonstrate that PointMAC achieves state-of-the-art results by refining each sample individually to produce high-quality completions. To the best of our knowledge, this is the first work to apply meta-auxiliary test-time adaptation to point cloud completion.
<div id='section'>Paperid: <span id='pid'>394, <a href='https://arxiv.org/pdf/2510.07239.pdf' target='_blank'>https://arxiv.org/pdf/2510.07239.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christos Ziakas, Nicholas Loo, Nishita Jain, Alessandra Russo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.07239">Red-Bandit: Test-Time Adaptation for LLM Red-Teaming via Bandit-Guided LoRA Experts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automated red-teaming has emerged as a scalable approach for auditing Large Language Models (LLMs) prior to deployment, yet existing approaches lack mechanisms to efficiently adapt to model-specific vulnerabilities at inference. We introduce Red-Bandit, a red-teaming framework that adapts online to identify and exploit model failure modes under distinct attack styles (e.g., manipulation, slang). Red-Bandit post-trains a set of parameter-efficient LoRA experts, each specialized for a particular attack style, using reinforcement learning that rewards the generation of unsafe prompts via a rule-based safety model. At inference, a multi-armed bandit policy dynamically selects among these attack-style experts based on the target model's response safety, balancing exploration and exploitation. Red-Bandit achieves state-of-the-art results on AdvBench under sufficient exploration (ASR@10), while producing more human-readable prompts (lower perplexity). Moreover, Red-Bandit's bandit policy serves as a diagnostic tool for uncovering model-specific vulnerabilities by indicating which attack styles most effectively elicit unsafe behaviors.
<div id='section'>Paperid: <span id='pid'>395, <a href='https://arxiv.org/pdf/2510.07239.pdf' target='_blank'>https://arxiv.org/pdf/2510.07239.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christos Ziakas, Nicholas Loo, Nishita Jain, Alessandra Russo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.07239">Red-Bandit: Test-Time Adaptation for LLM Red-Teaming via Bandit-Guided LoRA Experts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automated red-teaming has emerged as a scalable approach for auditing Large Language Models (LLMs) prior to deployment, yet existing approaches lack mechanisms to efficiently adapt to model-specific vulnerabilities at inference. We introduce Red-Bandit, a red-teaming framework that adapts online to identify and exploit model failure modes under distinct attack styles (e.g., manipulation, slang). Red-Bandit post-trains a set of parameter-efficient LoRA experts, each specialized for a particular attack style, using reinforcement learning that rewards the generation of unsafe prompts via a rule-based safety model. At inference, a multi-armed bandit policy dynamically selects among these attack-style experts based on the target model's response safety, balancing exploration and exploitation. Red-Bandit achieves state-of-the-art results on AdvBench under sufficient exploration (ASR@10), while producing more human-readable prompts (lower perplexity). Moreover, Red-Bandit's bandit policy serves as a diagnostic tool for uncovering model-specific vulnerabilities by indicating which attack styles most effectively elicit unsafe behaviors.
<div id='section'>Paperid: <span id='pid'>396, <a href='https://arxiv.org/pdf/2510.03839.pdf' target='_blank'>https://arxiv.org/pdf/2510.03839.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Behraj Khan, Tahir Qasim Syed
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.03839">Technical note on Sequential Test-Time Adaptation via Martingale-Driven Fisher Prompting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a theoretical framework for M-FISHER, a method for sequential distribution shift detection and stable adaptation in streaming data. For detection, we construct an exponential martingale from non-conformity scores and apply Ville's inequality to obtain time-uniform guarantees on false alarm control, ensuring statistical validity at any stopping time. Under sustained shifts, we further bound the expected detection delay as $\mathcal{O}(\log(1/δ)/Γ)$, where $Γ$ reflects the post-shift information gain, thereby linking detection efficiency to distributional divergence. For adaptation, we show that Fisher-preconditioned updates of prompt parameters implement natural gradient descent on the distributional manifold, yielding locally optimal updates that minimize KL divergence while preserving stability and parameterization invariance. Together, these results establish M-FISHER as a principled approach for robust, anytime-valid detection and geometrically stable adaptation in sequential decision-making under covariate shift.
<div id='section'>Paperid: <span id='pid'>397, <a href='https://arxiv.org/pdf/2510.03839.pdf' target='_blank'>https://arxiv.org/pdf/2510.03839.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Behraj Khan, Tahir Qasim Syed
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.03839">Technical note on Sequential Test-Time Adaptation via Martingale-Driven Fisher Prompting</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a theoretical framework for M-FISHER, a method for sequential distribution shift detection and stable adaptation in streaming data. For detection, we construct an exponential martingale from non-conformity scores and apply Ville's inequality to obtain time-uniform guarantees on false alarm control, ensuring statistical validity at any stopping time. Under sustained shifts, we further bound the expected detection delay as $\mathcal{O}(\log(1/δ)/Γ)$, where $Γ$ reflects the post-shift information gain, thereby linking detection efficiency to distributional divergence. For adaptation, we show that Fisher-preconditioned updates of prompt parameters implement natural gradient descent on the distributional manifold, yielding locally optimal updates that minimize KL divergence while preserving stability and parameterization invariance. Together, these results establish M-FISHER as a principled approach for robust, anytime-valid detection and geometrically stable adaptation in sequential decision-making under covariate shift.
<div id='section'>Paperid: <span id='pid'>398, <a href='https://arxiv.org/pdf/2508.20488.pdf' target='_blank'>https://arxiv.org/pdf/2508.20488.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zixuan Hu, Dongxiao Li, Xinzhu Ma, Shixiang Tang, Xiaotong Li, Wenhan Yang, Ling-Yu Duan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.20488">Adaptive Dual Uncertainty Optimization: Boosting Monocular 3D Object Detection under Test-Time Shifts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Accurate monocular 3D object detection (M3OD) is pivotal for safety-critical applications like autonomous driving, yet its reliability deteriorates significantly under real-world domain shifts caused by environmental or sensor variations. To address these shifts, Test-Time Adaptation (TTA) methods have emerged, enabling models to adapt to target distributions during inference. While prior TTA approaches recognize the positive correlation between low uncertainty and high generalization ability, they fail to address the dual uncertainty inherent to M3OD: semantic uncertainty (ambiguous class predictions) and geometric uncertainty (unstable spatial localization). To bridge this gap, we propose Dual Uncertainty Optimization (DUO), the first TTA framework designed to jointly minimize both uncertainties for robust M3OD. Through a convex optimization lens, we introduce an innovative convex structure of the focal loss and further derive a novel unsupervised version, enabling label-agnostic uncertainty weighting and balanced learning for high-uncertainty objects. In parallel, we design a semantic-aware normal field constraint that preserves geometric coherence in regions with clear semantic cues, reducing uncertainty from the unstable 3D representation. This dual-branch mechanism forms a complementary loop: enhanced spatial perception improves semantic classification, and robust semantic predictions further refine spatial understanding. Extensive experiments demonstrate the superiority of DUO over existing methods across various datasets and domain shift types.
<div id='section'>Paperid: <span id='pid'>399, <a href='https://arxiv.org/pdf/2508.06266.pdf' target='_blank'>https://arxiv.org/pdf/2508.06266.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zezeng Li, Rui Yang, Ruochen Chen, ZhongXuan Luo, Liming Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.06266">ADPro: a Test-time Adaptive Diffusion Policy for Robot Manipulation via Manifold and Initial Noise Constraints</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion policies have recently emerged as a powerful class of visuomotor controllers for robot manipulation, offering stable training and expressive multi-modal action modeling. However, existing approaches typically treat action generation as an unconstrained denoising process, ignoring valuable a priori knowledge about geometry and control structure. In this work, we propose the Adaptive Diffusion Policy (ADP), a test-time adaptation method that introduces two key inductive biases into the diffusion. First, we embed a geometric manifold constraint that aligns denoising updates with task-relevant subspaces, leveraging the fact that the relative pose between the end-effector and target scene provides a natural gradient direction, and guiding denoising along the geodesic path of the manipulation manifold. Then, to reduce unnecessary exploration and accelerate convergence, we propose an analytically guided initialization: rather than sampling from an uninformative prior, we compute a rough registration between the gripper and target scenes to propose a structured initial noisy action. ADP is compatible with pre-trained diffusion policies and requires no retraining, enabling test-time adaptation that tailors the policy to specific tasks, thereby enhancing generalization across novel tasks and environments. Experiments on RLBench, CALVIN, and real-world dataset show that ADPro, an implementation of ADP, improves success rates, generalization, and sampling efficiency, achieving up to 25% faster execution and 9% points over strong diffusion baselines.
<div id='section'>Paperid: <span id='pid'>400, <a href='https://arxiv.org/pdf/2508.06266.pdf' target='_blank'>https://arxiv.org/pdf/2508.06266.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zezeng Li, Rui Yang, Ruochen Chen, ZhongXuan Luo, Liming Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.06266">ADPro: a Test-time Adaptive Diffusion Policy via Manifold-constrained Denoising and Task-aware Initialization for Robotic Manipulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion policies have recently emerged as a powerful class of visuomotor controllers for robot manipulation, offering stable training and expressive multi-modal action modeling. However, existing approaches typically treat action generation as an unconstrained denoising process, ignoring valuable a priori knowledge about geometry and control structure. In this work, we propose the Adaptive Diffusion Policy (ADP), a test-time adaptation method that introduces two key inductive biases into the diffusion. First, we embed a geometric manifold constraint that aligns denoising updates with task-relevant subspaces, leveraging the fact that the relative pose between the end-effector and target scene provides a natural gradient direction, and guiding denoising along the geodesic path of the manipulation manifold. Then, to reduce unnecessary exploration and accelerate convergence, we propose an analytically guided initialization: rather than sampling from an uninformative prior, we compute a rough registration between the gripper and target scenes to propose a structured initial noisy action. ADP is compatible with pre-trained diffusion policies and requires no retraining, enabling test-time adaptation that tailors the policy to specific tasks, thereby enhancing generalization across novel tasks and environments. Experiments on RLBench, CALVIN, and real-world datasets show that ADPro, an implementation of ADP, improves success rates, generalization, and sampling efficiency, achieving up to 25% faster execution and 9% points over strong diffusion baselines.
<div id='section'>Paperid: <span id='pid'>401, <a href='https://arxiv.org/pdf/2508.06266.pdf' target='_blank'>https://arxiv.org/pdf/2508.06266.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zezeng Li, Rui Yang, Ruochen Chen, ZhongXuan Luo, Liming Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.06266">ADPro: a Test-time Adaptive Diffusion Policy via Manifold-constrained Denoising and Task-aware Initialization for Robotic Manipulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion policies have recently emerged as a powerful class of visuomotor controllers for robot manipulation, offering stable training and expressive multi-modal action modeling. However, existing approaches typically treat action generation as an unconstrained denoising process, ignoring valuable a priori knowledge about geometry and control structure. In this work, we propose the Adaptive Diffusion Policy (ADP), a test-time adaptation method that introduces two key inductive biases into the diffusion. First, we embed a geometric manifold constraint that aligns denoising updates with task-relevant subspaces, leveraging the fact that the relative pose between the end-effector and target scene provides a natural gradient direction, and guiding denoising along the geodesic path of the manipulation manifold. Then, to reduce unnecessary exploration and accelerate convergence, we propose an analytically guided initialization: rather than sampling from an uninformative prior, we compute a rough registration between the gripper and target scenes to propose a structured initial noisy action. ADP is compatible with pre-trained diffusion policies and requires no retraining, enabling test-time adaptation that tailors the policy to specific tasks, thereby enhancing generalization across novel tasks and environments. Experiments on RLBench, CALVIN, and real-world datasets show that ADPro, an implementation of ADP, improves success rates, generalization, and sampling efficiency, achieving up to 25% faster execution and 9% points over strong diffusion baselines.
<div id='section'>Paperid: <span id='pid'>402, <a href='https://arxiv.org/pdf/2508.06266.pdf' target='_blank'>https://arxiv.org/pdf/2508.06266.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zezeng Li, Rui Yang, Ruochen Chen, ZhongXuan Luo, Liming Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.06266">ADPro: a Test-time Adaptive Diffusion Policy via Manifold-constrained Denoising and Task-aware Initialization for Robotic Manipulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion policies have recently emerged as a powerful class of visuomotor controllers for robot manipulation, offering stable training and expressive multi-modal action modeling. However, existing approaches typically treat action generation as an unconstrained denoising process, ignoring valuable a priori knowledge about geometry and control structure. In this work, we propose the Adaptive Diffusion Policy (ADP), a test-time adaptation method that introduces two key inductive biases into the diffusion. First, we embed a geometric manifold constraint that aligns denoising updates with task-relevant subspaces, leveraging the fact that the relative pose between the end-effector and target scene provides a natural gradient direction, and guiding denoising along the geodesic path of the manipulation manifold. Then, to reduce unnecessary exploration and accelerate convergence, we propose an analytically guided initialization: rather than sampling from an uninformative prior, we compute a rough registration between the gripper and target scenes to propose a structured initial noisy action. ADP is compatible with pre-trained diffusion policies and requires no retraining, enabling test-time adaptation that tailors the policy to specific tasks, thereby enhancing generalization across novel tasks and environments. Experiments on RLBench, CALVIN, and real-world datasets show that ADPro, an implementation of ADP, improves success rates, generalization, and sampling efficiency, achieving up to 25% faster execution and 9% points over strong diffusion baselines.
<div id='section'>Paperid: <span id='pid'>403, <a href='https://arxiv.org/pdf/2508.06266.pdf' target='_blank'>https://arxiv.org/pdf/2508.06266.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zezeng Li, Rui Yang, Ruochen Chen, ZhongXuan Luo, Liming Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.06266">ADPro: a Test-time Adaptive Diffusion Policy via Manifold-constrained Denoising and Task-aware Initialization for Robotic Manipulation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion policies have recently emerged as a powerful class of visuomotor controllers for robot manipulation, offering stable training and expressive multi-modal action modeling. However, existing approaches typically treat action generation as an unconstrained denoising process, ignoring valuable a priori knowledge about geometry and control structure. In this work, we propose the Adaptive Diffusion Policy (ADP), a test-time adaptation method that introduces two key inductive biases into the diffusion. First, we embed a geometric manifold constraint that aligns denoising updates with task-relevant subspaces, leveraging the fact that the relative pose between the end-effector and target scene provides a natural gradient direction, and guiding denoising along the geodesic path of the manipulation manifold. Then, to reduce unnecessary exploration and accelerate convergence, we propose an analytically guided initialization: rather than sampling from an uninformative prior, we compute a rough registration between the gripper and target scenes to propose a structured initial noisy action. ADP is compatible with pre-trained diffusion policies and requires no retraining, enabling test-time adaptation that tailors the policy to specific tasks, thereby enhancing generalization across novel tasks and environments. Experiments on RLBench, CALVIN, and real-world datasets show that ADPro, an implementation of ADP, improves success rates, generalization, and sampling efficiency, achieving up to 25% faster execution and 9% points over strong diffusion baselines.
<div id='section'>Paperid: <span id='pid'>404, <a href='https://arxiv.org/pdf/2506.10085.pdf' target='_blank'>https://arxiv.org/pdf/2506.10085.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christos Ziakas, Alessandra Russo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.10085">Test-Time Adaptation for Generalizable Task Progress Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a test-time adaptation method that enables a progress estimation model to adapt online to the visual and temporal context of test trajectories by optimizing a learned self-supervised objective. To this end, we introduce a gradient-based meta-learning strategy to train the model on expert visual trajectories and their natural language task descriptions, such that test-time adaptation improves progress estimation relying on semantic content over temporal order. Our test-time adaptation method generalizes from a single training environment to diverse out-of-distribution tasks, environments, and embodiments, outperforming the state-of-the-art in-context learning approach using autoregressive vision-language models.
<div id='section'>Paperid: <span id='pid'>405, <a href='https://arxiv.org/pdf/2506.10085.pdf' target='_blank'>https://arxiv.org/pdf/2506.10085.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christos Ziakas, Alessandra Russo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.10085">VITA: Zero-Shot Value Functions via Test-Time Adaptation of Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-Language Models (VLMs) show promise as zero-shot goal-conditioned value functions, but their frozen pre-trained representations limit generalization and temporal reasoning. We introduce VITA, a zero-shot value function learning method that enhances both capabilities via test-time adaptation. At inference, a lightweight adaptation module is updated via a gradient step on a meta-learned self-supervised loss, such that each test-time update improves value estimation. By updating sequentially over a trajectory, VITA encodes history into its parameters, addressing the temporal reasoning limitations. To mitigate shortcut learning, we propose a dissimilarity-based sampling strategy that selects semantically diverse segments of the trajectory during training. In real-world robotic manipulation tasks, VITA generalizes from a single training environment to diverse out-of-distribution tasks, environments, and embodiments, outperforming the state-of-the-art zero-shot method using autoregressive VLMs. Furthermore, we demonstrate that VITA's zero-shot value estimates can be utilized for reward shaping in offline reinforcement learning, resulting in multi-task policies on the Meta-World benchmark that exceed the performance of those trained with the simulation's fuzzy-logic dense rewards.
<div id='section'>Paperid: <span id='pid'>406, <a href='https://arxiv.org/pdf/2506.10085.pdf' target='_blank'>https://arxiv.org/pdf/2506.10085.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christos Ziakas, Alessandra Russo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.10085">VITA: Zero-Shot Value Functions via Test-Time Adaptation of Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-Language Models (VLMs) show promise as zero-shot goal-conditioned value functions, but their frozen pre-trained representations limit generalization and temporal reasoning. We introduce VITA, a zero-shot value function learning method that enhances both capabilities via test-time adaptation. At inference, a lightweight adaptation module is updated via a gradient step on a meta-learned self-supervised loss, such that each test-time update improves value estimation. By updating sequentially over a trajectory, VITA encodes history into its parameters, addressing the temporal reasoning limitations. To mitigate shortcut learning, we propose a dissimilarity-based sampling strategy that selects semantically diverse segments of the trajectory during training. In real-world robotic manipulation tasks, VITA generalizes from a single training environment to diverse out-of-distribution tasks, environments, and embodiments, outperforming the state-of-the-art zero-shot method using autoregressive VLMs. Furthermore, we demonstrate that VITA's zero-shot value estimates can be utilized for reward shaping in offline reinforcement learning, resulting in multi-task policies on the Meta-World benchmark that exceed the performance of those trained with the simulation's fuzzy-logic dense rewards.
<div id='section'>Paperid: <span id='pid'>407, <a href='https://arxiv.org/pdf/2506.10085.pdf' target='_blank'>https://arxiv.org/pdf/2506.10085.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christos Ziakas, Alessandra Russo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.10085">VITA: Zero-Shot Value Functions via Test-Time Adaptation of Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-Language Models (VLMs) show promise as zero-shot goal-conditioned value functions, but their frozen pre-trained representations limit generalization and temporal reasoning. We introduce VITA, a zero-shot value function learning method that enhances both capabilities via test-time adaptation. At inference, a lightweight adaptation module is updated via a gradient step on a meta-learned self-supervised loss, such that each test-time update improves value estimation. By updating sequentially over a trajectory, VITA encodes history into its parameters, addressing the temporal reasoning limitations. To mitigate shortcut learning, we propose a dissimilarity-based sampling strategy that selects semantically diverse segments of the trajectory during training. In real-world robotic manipulation tasks, VITA generalizes from a single training environment to diverse out-of-distribution tasks, environments, and embodiments, outperforming the state-of-the-art zero-shot method using autoregressive VLMs. Furthermore, we demonstrate that VITA's zero-shot value estimates can be utilized for reward shaping in offline reinforcement learning, resulting in multi-task policies on the Meta-World benchmark that exceed the performance of those trained with the simulation's fuzzy-logic dense rewards.
<div id='section'>Paperid: <span id='pid'>408, <a href='https://arxiv.org/pdf/2506.10085.pdf' target='_blank'>https://arxiv.org/pdf/2506.10085.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christos Ziakas, Alessandra Russo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.10085">VITA: Zero-Shot Value Functions via Test-Time Adaptation of Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-Language Models (VLMs) show promise as zero-shot goal-conditioned value functions, but their frozen pre-trained representations limit generalization and temporal reasoning. We introduce VITA, a zero-shot value function learning method that enhances both capabilities via test-time adaptation. At inference, a lightweight adaptation module is updated via a gradient step on a meta-learned self-supervised loss, such that each test-time update improves value estimation. By updating sequentially over a trajectory, VITA encodes history into its parameters, addressing the temporal reasoning limitations. To mitigate shortcut learning, we propose a dissimilarity-based sampling strategy that selects semantically diverse segments of the trajectory during training. In real-world robotic manipulation tasks, VITA generalizes from a single training environment to diverse out-of-distribution tasks, environments, and embodiments, outperforming the state-of-the-art zero-shot method using autoregressive VLMs. Furthermore, we demonstrate that VITA's zero-shot value estimates can be utilized for reward shaping in offline reinforcement learning, resulting in multi-task policies on the Meta-World benchmark that exceed the performance of those trained with the simulation's fuzzy-logic dense rewards.
<div id='section'>Paperid: <span id='pid'>409, <a href='https://arxiv.org/pdf/2506.10085.pdf' target='_blank'>https://arxiv.org/pdf/2506.10085.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Christos Ziakas, Alessandra Russo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.10085">VITA: Zero-Shot Value Functions via Test-Time Adaptation of Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-Language Models (VLMs) show promise as zero-shot goal-conditioned value functions, but their frozen pre-trained representations limit generalization and temporal reasoning. We introduce VITA, a zero-shot value function learning method that enhances both capabilities via test-time adaptation. At inference, a lightweight adaptation module is updated via a gradient step on a meta-learned self-supervised loss, such that each test-time update improves value estimation. By updating sequentially over a trajectory, VITA encodes history into its parameters, addressing the temporal reasoning limitations. To mitigate shortcut learning, we propose a dissimilarity-based sampling strategy that selects semantically diverse segments of the trajectory during training. In real-world robotic manipulation tasks, VITA generalizes from a single training environment to diverse out-of-distribution tasks, environments, and embodiments, outperforming the state-of-the-art zero-shot method using autoregressive VLMs. Furthermore, we demonstrate that VITA's zero-shot value estimates can be utilized for reward shaping in offline reinforcement learning, resulting in multi-task policies on the Meta-World benchmark that exceed the performance of those trained with the simulation's fuzzy-logic dense rewards.
<div id='section'>Paperid: <span id='pid'>410, <a href='https://arxiv.org/pdf/2505.20704.pdf' target='_blank'>https://arxiv.org/pdf/2505.20704.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zixuan Hu, Yichun Hu, Xiaotong Li, Shixiang Tang, Ling-Yu Duan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.20704">Beyond Entropy: Region Confidence Proxy for Wild Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Wild Test-Time Adaptation (WTTA) is proposed to adapt a source model to unseen domains under extreme data scarcity and multiple shifts. Previous approaches mainly focused on sample selection strategies, while overlooking the fundamental problem on underlying optimization. Initially, we critically analyze the widely-adopted entropy minimization framework in WTTA and uncover its significant limitations in noisy optimization dynamics that substantially hinder adaptation efficiency. Through our analysis, we identify region confidence as a superior alternative to traditional entropy, however, its direct optimization remains computationally prohibitive for real-time applications. In this paper, we introduce a novel region-integrated method ReCAP that bypasses the lengthy process. Specifically, we propose a probabilistic region modeling scheme that flexibly captures semantic changes in embedding space. Subsequently, we develop a finite-to-infinite asymptotic approximation that transforms the intractable region confidence into a tractable and upper-bounded proxy. These innovations significantly unlock the overlooked potential dynamics in local region in a concise solution. Our extensive experiments demonstrate the consistent superiority of ReCAP over existing methods across various datasets and wild scenarios.
<div id='section'>Paperid: <span id='pid'>411, <a href='https://arxiv.org/pdf/2505.04087.pdf' target='_blank'>https://arxiv.org/pdf/2505.04087.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zixuan Hu, Yichun Hu, Ling-Yu Duan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.04087">SEVA: Leveraging Single-Step Ensemble of Vicinal Augmentations for Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-Time adaptation (TTA) aims to enhance model robustness against distribution shifts through rapid model adaptation during inference. While existing TTA methods often rely on entropy-based unsupervised training and achieve promising results, the common practice of a single round of entropy training is typically unable to adequately utilize reliable samples, hindering adaptation efficiency. In this paper, we discover augmentation strategies can effectively unleash the potential of reliable samples, but the rapidly growing computational cost impedes their real-time application. To address this limitation, we propose a novel TTA approach named Single-step Ensemble of Vicinal Augmentations (SEVA), which can take advantage of data augmentations without increasing the computational burden. Specifically, instead of explicitly utilizing the augmentation strategy to generate new data, SEVA develops a theoretical framework to explore the impacts of multiple augmentations on model adaptation and proposes to optimize an upper bound of the entropy loss to integrate the effects of multiple rounds of augmentation training into a single step. Furthermore, we discover and verify that using the upper bound as the loss is more conducive to the selection mechanism, as it can effectively filter out harmful samples that confuse the model. Combining these two key advantages, the proposed efficient loss and a complementary selection strategy can simultaneously boost the potential of reliable samples and meet the stringent time requirements of TTA. The comprehensive experiments on various network architectures across challenging testing scenarios demonstrate impressive performances and the broad adaptability of SEVA. The code will be publicly available.
<div id='section'>Paperid: <span id='pid'>412, <a href='https://arxiv.org/pdf/2410.04201.pdf' target='_blank'>https://arxiv.org/pdf/2410.04201.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nikita Durasov, Assaf Shocher, Doruk Oner, Gal Chechik, Alexei A. Efros, Pascal Fua
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.04201">IT$^3$: Idempotent Test-Time Training</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning models often struggle when deployed in real-world settings due to distribution shifts between training and test data. While existing approaches like domain adaptation and test-time training (TTT) offer partial solutions, they typically require additional data or domain-specific auxiliary tasks. We present Idempotent Test-Time Training (IT$^3$), a novel approach that enables on-the-fly adaptation to distribution shifts using only the current test instance, without any auxiliary task design. Our key insight is that enforcing idempotence -- where repeated applications of a function yield the same result -- can effectively replace domain-specific auxiliary tasks used in previous TTT methods. We theoretically connect idempotence to prediction confidence and demonstrate that minimizing the distance between successive applications of our model during inference leads to improved out-of-distribution performance. Extensive experiments across diverse domains (including image classification, aerodynamics prediction, and aerial segmentation) and architectures (MLPs, CNNs, GNNs) show that IT$^3$ consistently outperforms existing approaches while being simpler and more widely applicable. Our results suggest that idempotence provides a universal principle for test-time adaptation that generalizes across domains and architectures.
<div id='section'>Paperid: <span id='pid'>413, <a href='https://arxiv.org/pdf/2410.03263.pdf' target='_blank'>https://arxiv.org/pdf/2410.03263.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kazuki Adachi, Shin'ya Yamaguchi, Atsutoshi Kumagai, Tomoki Hamagami
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.03263">Test-time Adaptation for Regression by Subspace Alignment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper investigates test-time adaptation (TTA) for regression, where a regression model pre-trained in a source domain is adapted to an unknown target distribution with unlabeled target data. Although regression is one of the fundamental tasks in machine learning, most of the existing TTA methods have classification-specific designs, which assume that models output class-categorical predictions, whereas regression models typically output only single scalar values. To enable TTA for regression, we adopt a feature alignment approach, which aligns the feature distributions between the source and target domains to mitigate the domain gap. However, we found that naive feature alignment employed in existing TTA methods for classification is ineffective or even worse for regression because the features are distributed in a small subspace and many of the raw feature dimensions have little significance to the output. For an effective feature alignment in TTA for regression, we propose Significant-subspace Alignment (SSA). SSA consists of two components: subspace detection and dimension weighting. Subspace detection finds the feature subspace that is representative and significant to the output. Then, the feature alignment is performed in the subspace during TTA. Meanwhile, dimension weighting raises the importance of the dimensions of the feature subspace that have greater significance to the output. We experimentally show that SSA outperforms various baselines on real-world datasets.
<div id='section'>Paperid: <span id='pid'>414, <a href='https://arxiv.org/pdf/2409.17316.pdf' target='_blank'>https://arxiv.org/pdf/2409.17316.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haodong Li, Hao Lu, Ying-Cong Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.17316">Bi-TTA: Bidirectional Test-Time Adapter for Remote Physiological Measurement</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Remote photoplethysmography (rPPG) is gaining prominence for its non-invasive approach to monitoring physiological signals using only cameras. Despite its promise, the adaptability of rPPG models to new, unseen domains is hindered due to the environmental sensitivity of physiological signals. To address this, we pioneer the Test-Time Adaptation (TTA) in rPPG, enabling the adaptation of pre-trained models to the target domain during inference, sidestepping the need for annotations or source data due to privacy considerations. Particularly, utilizing only the user's face video stream as the accessible target domain data, the rPPG model is adjusted by tuning on each single instance it encounters. However, 1) TTA algorithms are designed predominantly for classification tasks, ill-suited in regression tasks such as rPPG due to inadequate supervision. 2) Tuning pre-trained models in a single-instance manner introduces variability and instability, posing challenges to effectively filtering domain-relevant from domain-irrelevant features while simultaneously preserving the learned information. To overcome these challenges, we present Bi-TTA, a novel expert knowledge-based Bidirectional Test-Time Adapter framework. Specifically, leveraging two expert-knowledge priors for providing self-supervision, our Bi-TTA primarily comprises two modules: a prospective adaptation (PA) module using sharpness-aware minimization to eliminate domain-irrelevant noise, enhancing the stability and efficacy during the adaptation process, and a retrospective stabilization (RS) module to dynamically reinforce crucial learned model parameters, averting performance degradation caused by overfitting or catastrophic forgetting. To this end, we established a large-scale benchmark for rPPG tasks under TTA protocol. The experimental results demonstrate the significant superiority of our approach over the state-of-the-art.
<div id='section'>Paperid: <span id='pid'>415, <a href='https://arxiv.org/pdf/2407.12128.pdf' target='_blank'>https://arxiv.org/pdf/2407.12128.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ziqiang Wang, Zhixiang Chi, Yanan Wu, Li Gu, Zhi Liu, Konstantinos Plataniotis, Yang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.12128">Distribution Alignment for Fully Test-Time Adaptation with Dynamic Online Data Streams</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Given a model trained on source data, Test-Time Adaptation (TTA) enables adaptation and inference in test data streams with domain shifts from the source. Current methods predominantly optimize the model for each incoming test data batch using self-training loss. While these methods yield commendable results in ideal test data streams, where batches are independently and identically sampled from the target distribution, they falter under more practical test data streams that are not independent and identically distributed (non-i.i.d.). The data batches in a non-i.i.d. stream display prominent label shifts relative to each other. It leads to conflicting optimization objectives among batches during the TTA process. Given the inherent risks of adapting the source model to unpredictable test-time distributions, we reverse the adaptation process and propose a novel Distribution Alignment loss for TTA. This loss guides the distributions of test-time features back towards the source distributions, which ensures compatibility with the well-trained source model and eliminates the pitfalls associated with conflicting optimization objectives. Moreover, we devise a domain shift detection mechanism to extend the success of our proposed TTA method in the continual domain shift scenarios. Our extensive experiments validate the logic and efficacy of our method. On six benchmark datasets, we surpass existing methods in non-i.i.d. scenarios and maintain competitive performance under the ideal i.i.d. assumption.
<div id='section'>Paperid: <span id='pid'>416, <a href='https://arxiv.org/pdf/2405.08270.pdf' target='_blank'>https://arxiv.org/pdf/2405.08270.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shishuai Hu, Zehui Liao, Zeyou Liu, Yong Xia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.08270">Towards Clinician-Preferred Segmentation: Leveraging Human-in-the-Loop for Test Time Adaptation in Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep learning-based medical image segmentation models often face performance degradation when deployed across various medical centers, largely due to the discrepancies in data distribution. Test Time Adaptation (TTA) methods, which adapt pre-trained models to test data, have been employed to mitigate such discrepancies. However, existing TTA methods primarily focus on manipulating Batch Normalization (BN) layers or employing prompt and adversarial learning, which may not effectively rectify the inconsistencies arising from divergent data distributions. In this paper, we propose a novel Human-in-the-loop TTA (HiTTA) framework that stands out in two significant ways. First, it capitalizes on the largely overlooked potential of clinician-corrected predictions, integrating these corrections into the TTA process to steer the model towards predictions that coincide more closely with clinical annotation preferences. Second, our framework conceives a divergence loss, designed specifically to diminish the prediction divergence instigated by domain disparities, through the careful calibration of BN parameters. Our HiTTA is distinguished by its dual-faceted capability to acclimatize to the distribution of test data whilst ensuring the model's predictions align with clinical expectations, thereby enhancing its relevance in a medical context. Extensive experiments on a public dataset underscore the superiority of our HiTTA over existing TTA methods, emphasizing the advantages of integrating human feedback and our divergence loss in enhancing the model's performance and adaptability across diverse medical centers.
<div id='section'>Paperid: <span id='pid'>417, <a href='https://arxiv.org/pdf/2403.17423.pdf' target='_blank'>https://arxiv.org/pdf/2403.17423.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shohei Enomoto, Naoya Hasegawa, Kazuki Adachi, Taku Sasaki, Shin'ya Yamaguchi, Satoshi Suzuki, Takeharu Eda
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.17423">Test-time Adaptation Meets Image Enhancement: Improving Accuracy via Uncertainty-aware Logit Switching</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks have achieved remarkable success in a variety of computer vision applications. However, there is a problem of degrading accuracy when the data distribution shifts between training and testing. As a solution of this problem, Test-time Adaptation~(TTA) has been well studied because of its practicality. Although TTA methods increase accuracy under distribution shift by updating the model at test time, using high-uncertainty predictions is known to degrade accuracy. Since the input image is the root of the distribution shift, we incorporate a new perspective on enhancing the input image into TTA methods to reduce the prediction's uncertainty. We hypothesize that enhancing the input image reduces prediction's uncertainty and increase the accuracy of TTA methods. On the basis of our hypothesis, we propose a novel method: Test-time Enhancer and Classifier Adaptation~(TECA). In TECA, the classification model is combined with the image enhancement model that transforms input images into recognition-friendly ones, and these models are updated by existing TTA methods. Furthermore, we found that the prediction from the enhanced image does not always have lower uncertainty than the prediction from the original image. Thus, we propose logit switching, which compares the uncertainty measure of these predictions and outputs the lower one. In our experiments, we evaluate TECA with various TTA methods and show that TECA reduces prediction's uncertainty and increases accuracy of TTA methods despite having no hyperparameters and little parameter overhead.
<div id='section'>Paperid: <span id='pid'>418, <a href='https://arxiv.org/pdf/2403.14114.pdf' target='_blank'>https://arxiv.org/pdf/2403.14114.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kazuki Adachi, Shohei Enomoto, Taku Sasaki, Shin'ya Yamaguchi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.14114">Test-time Similarity Modification for Person Re-identification toward Temporal Distribution Shift</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Person re-identification (re-id), which aims to retrieve images of the same person in a given image from a database, is one of the most practical image recognition applications. In the real world, however, the environments that the images are taken from change over time. This causes a distribution shift between training and testing and degrades the performance of re-id. To maintain re-id performance, models should continue adapting to the test environment's temporal changes. Test-time adaptation (TTA), which aims to adapt models to the test environment with only unlabeled test data, is a promising way to handle this problem because TTA can adapt models instantly in the test environment. However, the previous TTA methods are designed for classification and cannot be directly applied to re-id. This is because the set of people's identities in the dataset differs between training and testing in re-id, whereas the set of classes is fixed in the current TTA methods designed for classification. To improve re-id performance in changing test environments, we propose TEst-time similarity Modification for Person re-identification (TEMP), a novel TTA method for re-id. TEMP is the first fully TTA method for re-id, which does not require any modification to pre-training. Inspired by TTA methods that refine the prediction uncertainty in classification, we aim to refine the uncertainty in re-id. However, the uncertainty cannot be computed in the same way as classification in re-id since it is an open-set task, which does not share person labels between training and testing. Hence, we propose re-id entropy, an alternative uncertainty measure for re-id computed based on the similarity between the feature vectors. Experiments show that the re-id entropy can measure the uncertainty on re-id and TEMP improves the performance of re-id in online settings where the distribution changes over time.
<div id='section'>Paperid: <span id='pid'>419, <a href='https://arxiv.org/pdf/2312.08378.pdf' target='_blank'>https://arxiv.org/pdf/2312.08378.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Houcheng Su, Daixian Liu, Mengzhu Wang, Wei Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.08378">Singular Value Penalization and Semantic Data Augmentation for Fully Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fully test-time adaptation (FTTA) adapts a model that is trained on a source domain to a target domain during the testing phase, where the two domains follow different distributions and source data is unavailable during the training phase. Existing methods usually adopt entropy minimization to reduce the uncertainty of target prediction results, and improve the FTTA performance accordingly. However, they fail to ensure the diversity in target prediction results. Recent domain adaptation study has shown that maximizing the sum of singular values of prediction results can simultaneously enhance their confidence (discriminability) and diversity. However, during the training phase, larger singular values usually take up a dominant position in loss maximization. This results in the model being more inclined to enhance discriminability for easily distinguishable classes, and the improvement in diversity is insufficiently effective. Furthermore, the adaptation and prediction in FTTA only use data from the current batch, which may lead to the risk of overfitting. To address the aforementioned issues, we propose maximizing the sum of singular values while minimizing their variance. This enables the model's focus toward the smaller singular values, enhancing discriminability between more challenging classes and effectively increasing the diversity of prediction results. Moreover, we incorporate data from the previous batch to realize semantic data augmentation for the current batch, reducing the risk of overfitting. Extensive experiments on benchmark datasets show our proposed approach outperforms some compared state-of-the-art FTTA methods.
<div id='section'>Paperid: <span id='pid'>420, <a href='https://arxiv.org/pdf/2312.05274.pdf' target='_blank'>https://arxiv.org/pdf/2312.05274.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kaiyu Song, Hanjiang Lai, Yan Pan, Kun Yue, Jian Yin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.05274">Two Simple Principles for Diffusion-Based Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, diffusion-based test-time adaptations (TTA) have shown great advances, which leverage a diffusion model to map the images in the unknown test domain to the training domain. The unseen and diverse test domains make diffusion-based TTA an ill-posed problem. In this paper, we unravel two simple principles of the design tricks for diffusion-based methods. Intuitively, \textit{Principle 1} says semantic similarity preserving. We should preserve the semantic similarity between the original and generated test images. \textit{Principle 2} suggests minimal modifications. This principle enables the diffusion to map the test images to the training domain with minimal modifications of the test images. In particular, following the two principles, we propose our simple yet effective principle-guided diffusion-based test-time adaptation method (PDDA). Concretely, following Principle 1, we propose a semantic keeper, the method to preserve feature similarity, where the semantic keeper could filter the corruption introduced from the test domain, thus better preserving the semantics. Following Principle 2, we propose a modification keeper, where we introduce a regularization constraint into the generative process to minimize modifications to the test image. Meanwhile, there is a hidden conflict between the two principles. We further introduce the gradient-based view to unify the direction generated from two principles. Extensive experiments on CIFAR-10C, CIFAR-100C, ImageNet-W, and ImageNet-C with WideResNet-28-10, ResNet-50, Swin-T, and ConvNext-T demonstrate that PDDA significantly performs better than the complex state-of-the-art baselines. Specifically, PDDA achieves 2.4\% average accuracy improvements in ImageNet-C without any training process.
<div id='section'>Paperid: <span id='pid'>421, <a href='https://arxiv.org/pdf/2312.01835.pdf' target='_blank'>https://arxiv.org/pdf/2312.01835.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Longhui Yuan, Shuang Li, Zhuo He, Binhui Xie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.01835">Few Clicks Suffice: Active Test-Time Adaptation for Semantic Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) adapts the pre-trained models during inference using unlabeled test data and has received a lot of research attention due to its potential practical value. Unfortunately, without any label supervision, existing TTA methods rely heavily on heuristic or empirical studies. Where to update the model always falls into suboptimal or brings more computational resource consumption. Meanwhile, there is still a significant performance gap between the TTA approaches and their supervised counterparts. Motivated by active learning, in this work, we propose the active test-time adaptation for semantic segmentation setup. Specifically, we introduce the human-in-the-loop pattern during the testing phase, which queries very few labels to facilitate predictions and model updates in an online manner. To do so, we propose a simple but effective ATASeg framework, which consists of two parts, i.e., model adapter and label annotator. Extensive experiments demonstrate that ATASeg bridges the performance gap between TTA methods and their supervised counterparts with only extremely few annotations, even one click for labeling surpasses known SOTA TTA methods by 2.6% average mIoU on ACDC benchmark. Empirical results imply that progress in either the model adapter or the label annotator will bring improvements to the ATASeg framework, giving it large research and reality potential.
<div id='section'>Paperid: <span id='pid'>422, <a href='https://arxiv.org/pdf/2311.05858.pdf' target='_blank'>https://arxiv.org/pdf/2311.05858.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junyoung Park, Jin Kim, Hyeongjun Kwon, Ilhoon Yoon, Kwanghoon Sohn
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.05858">Layer-wise Auto-Weighting for Non-Stationary Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Given the inevitability of domain shifts during inference in real-world applications, test-time adaptation (TTA) is essential for model adaptation after deployment. However, the real-world scenario of continuously changing target distributions presents challenges including catastrophic forgetting and error accumulation. Existing TTA methods for non-stationary domain shifts, while effective, incur excessive computational load, making them impractical for on-device settings. In this paper, we introduce a layer-wise auto-weighting algorithm for continual and gradual TTA that autonomously identifies layers for preservation or concentrated adaptation. By leveraging the Fisher Information Matrix (FIM), we first design the learning weight to selectively focus on layers associated with log-likelihood changes while preserving unrelated ones. Then, we further propose an exponential min-max scaler to make certain layers nearly frozen while mitigating outliers. This minimizes forgetting and error accumulation, leading to efficient adaptation to non-stationary target distribution. Experiments on CIFAR-10C, CIFAR-100C, and ImageNet-C show our method outperforms conventional continual and gradual TTA approaches while significantly reducing computational load, highlighting the importance of FIM-based learning weight in adapting to continuously or gradually shifting target domains.
<div id='section'>Paperid: <span id='pid'>423, <a href='https://arxiv.org/pdf/2310.04941.pdf' target='_blank'>https://arxiv.org/pdf/2310.04941.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Eungyeup Kim, Mingjie Sun, Christina Baek, Aditi Raghunathan, J. Zico Kolter
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.04941">Test-Time Adaptation Induces Stronger Accuracy and Agreement-on-the-Line</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, Miller et al. (2021) and Baek et al. (2022) empirically demonstrated strong linear correlations between in-distribution (ID) versus out-of-distribution (OOD) accuracy and agreement. These trends, coined accuracy-on-the-line (ACL) and agreement-on-the-line (AGL), enable OOD model selection and performance estimation without labeled data. However, these phenomena also break for certain shifts, such as CIFAR10-C Gaussian Noise, posing a critical bottleneck. In this paper, we make a key finding that recent test-time adaptation (TTA) methods not only improve OOD performance, but drastically strengthen the ACL and AGL trends in models, even in shifts where models showed very weak correlations before. To analyze this, we revisit the theoretical conditions from Miller et al. (2021) that outline the types of distribution shifts needed for perfect ACL in linear models. Surprisingly, these conditions are satisfied after applying TTA to deep models in the penultimate feature embedding space. In particular, TTA causes the data distribution to collapse complex shifts into those can be expressed by a singular scaling variable in the feature space. Our results show that by combining TTA with AGL-based estimation methods, we can estimate the OOD performance of models with high precision for a broader set of distribution shifts. This lends us a simple system for selecting the best hyperparameters and adaptation strategy without any OOD labeled data.
<div id='section'>Paperid: <span id='pid'>424, <a href='https://arxiv.org/pdf/2310.04714.pdf' target='_blank'>https://arxiv.org/pdf/2310.04714.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuang Li, Longhui Yuan, Binhui Xie, Tao Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.04714">Generalized Robust Test-Time Adaptation in Continuous Dynamic Scenarios</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) adapts the pre-trained models to test distributions during the inference phase exclusively employing unlabeled test data streams, which holds great value for the deployment of models in real-world applications. Numerous studies have achieved promising performance on simplistic test streams, characterized by independently and uniformly sampled test data originating from a fixed target data distribution. However, these methods frequently prove ineffective in practical scenarios, where both continual covariate shift and continual label shift occur simultaneously, i.e., data and label distributions change concurrently and continually over time. In this study, a more challenging Practical Test-Time Adaptation (PTTA) setup is introduced, which takes into account the concurrent presence of continual covariate shift and continual label shift, and we propose a Generalized Robust Test-Time Adaptation (GRoTTA) method to effectively address the difficult problem. We start by steadily adapting the model through Robust Parameter Adaptation to make balanced predictions for test samples. To be specific, firstly, the effects of continual label shift are eliminated by enforcing the model to learn from a uniform label distribution and introducing recalibration of batch normalization to ensure stability. Secondly, the continual covariate shift is alleviated by employing a source knowledge regularization with the teacher-student model to update parameters. Considering the potential information in the test stream, we further refine the balanced predictions by Bias-Guided Output Adaptation, which exploits latent structure in the feature space and is adaptive to the imbalanced label distribution. Extensive experiments demonstrate GRoTTA outperforms the existing competitors by a large margin under PTTA setting, rendering it highly conducive for adoption in real-world applications.
<div id='section'>Paperid: <span id='pid'>425, <a href='https://arxiv.org/pdf/2309.14052.pdf' target='_blank'>https://arxiv.org/pdf/2309.14052.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Klara Janouskova, Tamir Shor, Chaim Baskin, Jiri Matas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.14052">Single Image Test-Time Adaptation for Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-Time Adaptation (TTA) methods improve the robustness of deep neural networks to domain shift on a variety of tasks such as image classification or segmentation. This work explores adapting segmentation models to a single unlabelled image with no other data available at test-time. In particular, this work focuses on adaptation by optimizing self-supervised losses at test-time. Multiple baselines based on different principles are evaluated under diverse conditions and a novel adversarial training is introduced for adaptation with mask refinement. Our additions to the baselines result in a 3.51 and 3.28 % increase over non-adapted baselines, without these improvements, the increase would be 1.7 and 2.16 % only.
<div id='section'>Paperid: <span id='pid'>426, <a href='https://arxiv.org/pdf/2309.07081.pdf' target='_blank'>https://arxiv.org/pdf/2309.07081.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Siyin Wang, Chao-Han Huck Yang, Ji Wu, Chao Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.07081">Can Whisper perform speech-based in-context learning?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper investigates the in-context learning abilities of the Whisper automatic speech recognition (ASR) models released by OpenAI. A novel speech-based in-context learning (SICL) approach is proposed for test-time adaptation, which can reduce the word error rates (WERs) with only a small number of labelled speech samples without gradient descent. Language-level adaptation experiments using Chinese dialects showed that when applying SICL to isolated word ASR, consistent and considerable relative WER reductions can be achieved using Whisper models of any size on two dialects, which is on average 32.3%. A k-nearest-neighbours-based in-context example selection technique can be applied to further improve the efficiency of SICL, which can increase the average relative WER reduction to 36.4%. The findings are verified using speaker adaptation or continuous speech recognition tasks, and both achieved considerable relative WER reductions. Detailed quantitative analyses are also provided to shed light on SICL's adaptability to phonological variances and dialect-specific lexical nuances.
<div id='section'>Paperid: <span id='pid'>427, <a href='https://arxiv.org/pdf/2309.03964.pdf' target='_blank'>https://arxiv.org/pdf/2309.03964.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Skyler Seto, Barry-John Theobald, Federico Danieli, Navdeep Jaitly, Dan Busbridge
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.03964">REALM: Robust Entropy Adaptive Loss Minimization for Improved Single-Sample Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fully-test-time adaptation (F-TTA) can mitigate performance loss due to distribution shifts between train and test data (1) without access to the training data, and (2) without knowledge of the model training procedure. In online F-TTA, a pre-trained model is adapted using a stream of test samples by minimizing a self-supervised objective, such as entropy minimization. However, models adapted with online using entropy minimization, are unstable especially in single sample settings, leading to degenerate solutions, and limiting the adoption of TTA inference strategies. Prior works identify noisy, or unreliable, samples as a cause of failure in online F-TTA. One solution is to ignore these samples, which can lead to bias in the update procedure, slow adaptation, and poor generalization. In this work, we present a general framework for improving robustness of F-TTA to these noisy samples, inspired by self-paced learning and robust loss functions. Our proposed approach, Robust Entropy Adaptive Loss Minimization (REALM), achieves better adaptation accuracy than previous approaches throughout the adaptation process on corruptions of CIFAR-10 and ImageNet-1K, demonstrating its effectiveness.
<div id='section'>Paperid: <span id='pid'>428, <a href='https://arxiv.org/pdf/2206.00205.pdf' target='_blank'>https://arxiv.org/pdf/2206.00205.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sanghun Jung, Jungsoo Lee, Nanhee Kim, Amirreza Shaban, Byron Boots, Jaegul Choo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.00205">CAFA: Class-Aware Feature Alignment for Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite recent advancements in deep learning, deep neural networks continue to suffer from performance degradation when applied to new data that differs from training data. Test-time adaptation (TTA) aims to address this challenge by adapting a model to unlabeled data at test time. TTA can be applied to pretrained networks without modifying their training procedures, enabling them to utilize a well-formed source distribution for adaptation. One possible approach is to align the representation space of test samples to the source distribution (\textit{i.e.,} feature alignment). However, performing feature alignment in TTA is especially challenging in that access to labeled source data is restricted during adaptation. That is, a model does not have a chance to learn test data in a class-discriminative manner, which was feasible in other adaptation tasks (\textit{e.g.,} unsupervised domain adaptation) via supervised losses on the source data. Based on this observation, we propose a simple yet effective feature alignment loss, termed as Class-Aware Feature Alignment (CAFA), which simultaneously 1) encourages a model to learn target representations in a class-discriminative manner and 2) effectively mitigates the distribution shifts at test time. Our method does not require any hyper-parameters or additional losses, which are required in previous approaches. We conduct extensive experiments on 6 different datasets and show our proposed method consistently outperforms existing baselines.
<div id='section'>Paperid: <span id='pid'>429, <a href='https://arxiv.org/pdf/2204.13263.pdf' target='_blank'>https://arxiv.org/pdf/2204.13263.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kazuki Adachi, Shin'ya Yamaguchi, Atsutoshi Kumagai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2204.13263">Covariance-aware Feature Alignment with Pre-computed Source Statistics for Test-time Adaptation to Multiple Image Corruptions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Real-world image recognition systems often face corrupted input images, which cause distribution shifts and degrade the performance of models. These systems often use a single prediction model in a central server and process images sent from various environments, such as cameras distributed in cities or cars. Such single models face images corrupted in heterogeneous ways in test time. Thus, they require to instantly adapt to the multiple corruptions during testing rather than being re-trained at a high cost. Test-time adaptation (TTA), which aims to adapt models without accessing the training dataset, is one of the settings that can address this problem. Existing TTA methods indeed work well on a single corruption. However, the adaptation ability is limited when multiple types of corruption occur, which is more realistic. We hypothesize this is because the distribution shift is more complicated, and the adaptation becomes more difficult in case of multiple corruptions. In fact, we experimentally found that a larger distribution gap remains after TTA. To address the distribution gap during testing, we propose a novel TTA method named Covariance-Aware Feature alignment (CAFe). We empirically show that CAFe outperforms prior TTA methods on image corruptions, including multiple types of corruptions.
<div id='section'>Paperid: <span id='pid'>430, <a href='https://arxiv.org/pdf/2507.08721.pdf' target='_blank'>https://arxiv.org/pdf/2507.08721.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mona Schirmer, Metod Jazbec, Christian A. Naesseth, Eric Nalisnick
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.08721">Monitoring Risks in Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Encountering shifted data at test time is a ubiquitous challenge when deploying predictive models. Test-time adaptation (TTA) methods address this issue by continuously adapting a deployed model using only unlabeled test data. While TTA can extend the model's lifespan, it is only a temporary solution. Eventually the model might degrade to the point that it must be taken offline and retrained. To detect such points of ultimate failure, we propose pairing TTA with risk monitoring frameworks that track predictive performance and raise alerts when predefined performance criteria are violated. Specifically, we extend existing monitoring tools based on sequential testing with confidence sequences to accommodate scenarios in which the model is updated at test time and no test labels are available to estimate the performance metrics of interest. Our extensions unlock the application of rigorous statistical risk monitoring to TTA, and we demonstrate the effectiveness of our proposed TTA monitoring framework across a representative set of datasets, distribution shift types, and TTA methods.
<div id='section'>Paperid: <span id='pid'>431, <a href='https://arxiv.org/pdf/2502.10724.pdf' target='_blank'>https://arxiv.org/pdf/2502.10724.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiuxia Lin, Rongyu Chen, Kerui Gu, Angela Yao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.10724">Semantics-aware Test-time Adaptation for 3D Human Pose Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work highlights a semantics misalignment in 3D human pose estimation. For the task of test-time adaptation, the misalignment manifests as overly smoothed and unguided predictions. The smoothing settles predictions towards some average pose. Furthermore, when there are occlusions or truncations, the adaptation becomes fully unguided. To this end, we pioneer the integration of a semantics-aware motion prior for the test-time adaptation of 3D pose estimation. We leverage video understanding and a well-structured motion-text space to adapt the model motion prediction to adhere to video semantics during test time. Additionally, we incorporate a missing 2D pose completion based on the motion-text similarity. The pose completion strengthens the motion prior's guidance for occlusions and truncations. Our method significantly improves state-of-the-art 3D human pose estimation TTA techniques, with more than 12% decrease in PA-MPJPE on 3DPW and 3DHP.
<div id='section'>Paperid: <span id='pid'>432, <a href='https://arxiv.org/pdf/2502.06828.pdf' target='_blank'>https://arxiv.org/pdf/2502.06828.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Martin Wimpff, Bruno Aristimunha, Sylvain Chevallier, Bin Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.06828">Fine-Tuning Strategies for Continual Online EEG Motor Imagery Decoding: Insights from a Large-Scale Longitudinal Study</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study investigates continual fine-tuning strategies for deep learning in online longitudinal electroencephalography (EEG) motor imagery (MI) decoding within a causal setting involving a large user group and multiple sessions per participant. We are the first to explore such strategies across a large user group, as longitudinal adaptation is typically studied in the single-subject setting with a single adaptation strategy, which limits the ability to generalize findings. First, we examine the impact of different fine-tuning approaches on decoder performance and stability. Building on this, we integrate online test-time adaptation (OTTA) to adapt the model during deployment, complementing the effects of prior fine-tuning. Our findings demonstrate that fine-tuning that successively builds on prior subject-specific information improves both performance and stability, while OTTA effectively adapts the model to evolving data distributions across consecutive sessions, enabling calibration-free operation. These results offer valuable insights and recommendations for future research in longitudinal online MI decoding and highlight the importance of combining domain adaptation strategies for improving BCI performance in real-world applications. Clinical Relevance: Our investigation enables more stable and efficient long-term motor imagery decoding, which is critical for neurorehabilitation and assistive technologies.
<div id='section'>Paperid: <span id='pid'>433, <a href='https://arxiv.org/pdf/2412.16901.pdf' target='_blank'>https://arxiv.org/pdf/2412.16901.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qi Deng, Shuaicheng Niu, Ronghao Zhang, Yaofo Chen, Runhao Zeng, Jian Chen, Xiping Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.16901">Learning to Generate Gradients for Test-Time Adaptation via Test-Time Training Layers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) aims to fine-tune a trained model online using unlabeled testing data to adapt to new environments or out-of-distribution data, demonstrating broad application potential in real-world scenarios. However, in this optimization process, unsupervised learning objectives like entropy minimization frequently encounter noisy learning signals. These signals produce unreliable gradients, which hinder the model ability to converge to an optimal solution quickly and introduce significant instability into the optimization process. In this paper, we seek to resolve these issues from the perspective of optimizer design. Unlike prior TTA using manually designed optimizers like SGD, we employ a learning-to-optimize approach to automatically learn an optimizer, called Meta Gradient Generator (MGG). Specifically, we aim for MGG to effectively utilize historical gradient information during the online optimization process to optimize the current model. To this end, in MGG, we design a lightweight and efficient sequence modeling layer -- gradient memory layer. It exploits a self-supervised reconstruction loss to compress historical gradient information into network parameters, thereby enabling better memorization ability over a long-term adaptation process. We only need a small number of unlabeled samples to pre-train MGG, and then the trained MGG can be deployed to process unseen samples. Promising results on ImageNet-C, R, Sketch, and A indicate that our method surpasses current state-of-the-art methods with fewer updates, less data, and significantly shorter adaptation iterations. Compared with a previous SOTA method SAR, we achieve 7.4% accuracy improvement and 4.2 times faster adaptation speed on ImageNet-C.
<div id='section'>Paperid: <span id='pid'>434, <a href='https://arxiv.org/pdf/2411.03687.pdf' target='_blank'>https://arxiv.org/pdf/2411.03687.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zehao Xiao, Cees G. M. Snoek
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.03687">Beyond Model Adaptation at Test Time: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Machine learning algorithms have achieved remarkable success across various disciplines, use cases and applications, under the prevailing assumption that training and test samples are drawn from the same distribution. Consequently, these algorithms struggle and become brittle even when samples in the test distribution start to deviate from the ones observed during training. Domain adaptation and domain generalization have been studied extensively as approaches to address distribution shifts across test and train domains, but each has its limitations. Test-time adaptation, a recently emerging learning paradigm, combines the benefits of domain adaptation and domain generalization by training models only on source data and adapting them to target data during test-time inference. In this survey, we provide a comprehensive and systematic review on test-time adaptation, covering more than 400 recent papers. We structure our review by categorizing existing methods into five distinct categories based on what component of the method is adjusted for test-time adaptation: the model, the inference, the normalization, the sample, or the prompt, providing detailed analysis of each. We further discuss the various preparation and adaptation settings for methods within these categories, offering deeper insights into the effective deployment for the evaluation of distribution shifts and their real-world application in understanding images, video and 3D, as well as modalities beyond vision. We close the survey with an outlook on emerging research opportunities for test-time adaptation.
<div id='section'>Paperid: <span id='pid'>435, <a href='https://arxiv.org/pdf/2408.08056.pdf' target='_blank'>https://arxiv.org/pdf/2408.08056.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chuyang Ye, Dongyan Wei, Zhendong Liu, Yuanyi Pang, Yixi Lin, Jiarong Liao, Qinting Jiang, Xianghua Fu, Qing Li, Jingyan Jiang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.08056">DATTA: Towards Diversity Adaptive Test-Time Adaptation in Dynamic Wild World</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) effectively addresses distribution shifts between training and testing data by adjusting models on test samples, which is crucial for improving model inference in real-world applications. However, traditional TTA methods typically follow a fixed pattern to address the dynamic data patterns (low-diversity or high-diversity patterns) often leading to performance degradation and consequently a decline in Quality of Experience (QoE). The primary issues we observed are:Different scenarios require different normalization methods (e.g., Instance Normalization is optimal in mixed domains but not in static domains). Model fine-tuning can potentially harm the model and waste time.Hence, it is crucial to design strategies for effectively measuring and managing distribution diversity to minimize its negative impact on model performance. Based on these observations, this paper proposes a new general method, named Diversity Adaptive Test-Time Adaptation (DATTA), aimed at improving QoE. DATTA dynamically selects the best batch normalization methods and fine-tuning strategies by leveraging the Diversity Score to differentiate between high and low diversity score batches. It features three key components: Diversity Discrimination (DD) to assess batch diversity, Diversity Adaptive Batch Normalization (DABN) to tailor normalization methods based on DD insights, and Diversity Adaptive Fine-Tuning (DAFT) to selectively fine-tune the model. Experimental results show that our method achieves up to a 21% increase in accuracy compared to state-of-the-art methodologies, indicating that our method maintains good model performance while demonstrating its robustness. Our code will be released soon.
<div id='section'>Paperid: <span id='pid'>436, <a href='https://arxiv.org/pdf/2407.13322.pdf' target='_blank'>https://arxiv.org/pdf/2407.13322.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pei-Kai Huang, Tzu-Hsien Chen, Ya-Ting Chan, Kuan-Wen Chen, Chiou-Ting Hsu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.13322">Fully Test-Time rPPG Estimation via Synthetic Signal-Guided Feature Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Many remote photoplethysmography (rPPG) estimation models have achieved promising performance in the training domain but often fail to accurately estimate physiological signals or heart rates (HR) in the target domains. Domain generalization (DG) or domain adaptation (DA) techniques are therefore adopted during the offline training stage to adapt the model to either unobserved or observed target domains by utilizing all available source domain data. However, in rPPG estimation problems, the adapted model usually encounters challenges in estimating target data with significant domain variation. In contrast, Test-Time Adaptation (TTA) enables the model to adaptively estimate rPPG signals in various unseen domains by online adapting to unlabeled target data without referring to any source data. In this paper, we first establish a new TTA-rPPG benchmark that encompasses various domain information and HR distributions to simulate the challenges encountered in real-world rPPG estimation. Next, we propose a novel synthetic signal-guided rPPG estimation framework to address the forgetting issue during the TTA stage and to enhance the adaptation capability of the pre-trained rPPG model. To this end, we develop a synthetic signal-guided feature learning method by synthesizing pseudo rPPG signals as pseudo ground truths to guide a conditional generator in generating latent rPPG features. In addition, we design an effective spectral-based entropy minimization technique to encourage the rPPG model to learn new target domain information. Both the generated rPPG features and synthesized rPPG signals prevent the rPPG model from overfitting to target data and forgetting previously acquired knowledge, while also broadly covering various heart rate (HR) distributions. Our extensive experiments on the TTA-rPPG benchmark show that the proposed method achieves superior performance.
<div id='section'>Paperid: <span id='pid'>437, <a href='https://arxiv.org/pdf/2403.19326.pdf' target='_blank'>https://arxiv.org/pdf/2403.19326.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyejin Park, Jeongyeon Hwang, Sunung Mun, Sangdon Park, Jungseul Ok
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.19326">MedBN: Robust Test-Time Adaptation against Malicious Test Samples</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) has emerged as a promising solution to address performance decay due to unforeseen distribution shifts between training and test data. While recent TTA methods excel in adapting to test data variations, such adaptability exposes a model to vulnerability against malicious examples, an aspect that has received limited attention. Previous studies have uncovered security vulnerabilities within TTA even when a small proportion of the test batch is maliciously manipulated. In response to the emerging threat, we propose median batch normalization (MedBN), leveraging the robustness of the median for statistics estimation within the batch normalization layer during test-time inference. Our method is algorithm-agnostic, thus allowing seamless integration with existing TTA frameworks. Our experimental results on benchmark datasets, including CIFAR10-C, CIFAR100-C and ImageNet-C, consistently demonstrate that MedBN outperforms existing approaches in maintaining robust performance across different attack scenarios, encompassing both instant and cumulative attacks. Through extensive experiments, we show that our approach sustains the performance even in the absence of attacks, achieving a practical balance between robustness and performance.
<div id='section'>Paperid: <span id='pid'>438, <a href='https://arxiv.org/pdf/2403.10650.pdf' target='_blank'>https://arxiv.org/pdf/2403.10650.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sarthak Kumar Maharana, Baoming Zhang, Yunhui Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.10650">PALM: Pushing Adaptive Learning Rate Mechanisms for Continual Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Real-world vision models in dynamic environments face rapid shifts in domain distributions, leading to decreased recognition performance. Using unlabeled test data, continuous test-time adaptation (CTTA) directly adjusts a pre-trained source discriminative model to these changing domains. A highly effective CTTA method involves applying layer-wise adaptive learning rates for selectively adapting pre-trained layers. However, it suffers from the poor estimation of domain shift and the inaccuracies arising from the pseudo-labels. This work aims to overcome these limitations by identifying layers for adaptation via quantifying model prediction uncertainty without relying on pseudo-labels. We utilize the magnitude of gradients as a metric, calculated by backpropagating the KL divergence between the softmax output and a uniform distribution, to select layers for further adaptation. Subsequently, for the parameters exclusively belonging to these selected layers, with the remaining ones frozen, we evaluate their sensitivity to approximate the domain shift and adjust their learning rates accordingly. We conduct extensive image classification experiments on CIFAR-10C, CIFAR-100C, and ImageNet-C, demonstrating the superior efficacy of our method compared to prior approaches.
<div id='section'>Paperid: <span id='pid'>439, <a href='https://arxiv.org/pdf/2402.01124.pdf' target='_blank'>https://arxiv.org/pdf/2402.01124.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Honglei Zhang, Zhiwei Li, Haoxuan Li, Xin Zhou, Jie Zhang, Yidong Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.01124">TransFR: Transferable Federated Recommendation with Adapter Tuning on Pre-trained Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Federated recommendations (FRs), facilitating multiple local clients to collectively learn a global model without disclosing user private data, have emerged as a prevalent on-device service. In conventional FRs, a dominant paradigm is to utilize discrete identities to represent clients and items, which are then mapped to domain-specific embeddings to participate in model training. Despite considerable performance, we reveal three inherent limitations that can not be ignored in federated settings, i.e., non-transferability across domains, ineffectiveness in cold-start settings, and potential privacy violations during federated training. To this end, we propose a transferable federated recommendation model, TransFR, which delicately incorporates the general capabilities empowered by pre-trained models and the personalized abilities by fine-tuning local private data. Specifically, it first learns domain-agnostic representations of items by exploiting pre-trained models with public textual corpora. To tailor for FR tasks, we further introduce efficient federated adapter-tuning and test-time adaptation mechanisms, which facilitate personalized local adapters for each client by fitting their private data distributions. We theoretically prove the advantages of incorporating adapter tuning in FRs regarding both effectiveness and privacy. Through extensive experiments, we show that our TransFR model surpasses several state-of-the-art FRs on transferability.
<div id='section'>Paperid: <span id='pid'>440, <a href='https://arxiv.org/pdf/2401.04130.pdf' target='_blank'>https://arxiv.org/pdf/2401.04130.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiangyu Chang, Sk Miraj Ahmed, Srikanth V. Krishnamurthy, Basak Guler, Ananthram Swami, Samet Oymak, Amit K. Roy-Chowdhury
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.04130">Plug-and-Play Transformer Modules for Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Parameter-efficient tuning (PET) methods such as LoRA, Adapter, and Visual Prompt Tuning (VPT) have found success in enabling adaptation to new domains by tuning small modules within a transformer model. However, the number of domains encountered during test time can be very large, and the data is usually unlabeled. Thus, adaptation to new domains is challenging; it is also impractical to generate customized tuned modules for each such domain. Toward addressing these challenges, this work introduces PLUTO: a Plug-and-pLay modUlar Test-time domain adaptatiOn strategy. We pre-train a large set of modules, each specialized for different source domains, effectively creating a ``module store''. Given a target domain with few-shot unlabeled data, we introduce an unsupervised test-time adaptation (TTA) method to (1) select a sparse subset of relevant modules from this store and (2) create a weighted combination of selected modules without tuning their weights. This plug-and-play nature enables us to harness multiple most-relevant source domains in a single inference call. Comprehensive evaluations demonstrate that PLUTO uniformly outperforms alternative TTA methods and that selecting $\leq$5 modules suffice to extract most of the benefit. At a high level, our method equips pre-trained transformers with the capability to dynamically adapt to new domains, motivating a new paradigm for efficient and scalable domain adaptation.
<div id='section'>Paperid: <span id='pid'>441, <a href='https://arxiv.org/pdf/2312.06712.pdf' target='_blank'>https://arxiv.org/pdf/2312.06712.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhipeng Bao, Yijun Li, Krishna Kumar Singh, Yu-Xiong Wang, Martial Hebert
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.06712">Separate-and-Enhance: Compositional Finetuning for Text2Image Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite recent significant strides achieved by diffusion-based Text-to-Image (T2I) models, current systems are still less capable of ensuring decent compositional generation aligned with text prompts, particularly for the multi-object generation. This work illuminates the fundamental reasons for such misalignment, pinpointing issues related to low attention activation scores and mask overlaps. While previous research efforts have individually tackled these issues, we assert that a holistic approach is paramount. Thus, we propose two novel objectives, the Separate loss and the Enhance loss, that reduce object mask overlaps and maximize attention scores, respectively. Our method diverges from conventional test-time-adaptation techniques, focusing on finetuning critical parameters, which enhances scalability and generalizability. Comprehensive evaluations demonstrate the superior performance of our model in terms of image realism, text-image alignment, and adaptability, notably outperforming prominent baselines. Ultimately, this research paves the way for T2I diffusion models with enhanced compositional capacities and broader applicability.
<div id='section'>Paperid: <span id='pid'>442, <a href='https://arxiv.org/pdf/2311.17056.pdf' target='_blank'>https://arxiv.org/pdf/2311.17056.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhaoying Pan, Daniel Geng, Andrew Owens
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.17056">Self-Supervised Motion Magnification by Backpropagating Through Optical Flow</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a simple, self-supervised method for magnifying subtle motions in video: given an input video and a magnification factor, we manipulate the video such that its new optical flow is scaled by the desired amount. To train our model, we propose a loss function that estimates the optical flow of the generated video and penalizes how far if deviates from the given magnification factor. Thus, training involves differentiating through a pretrained optical flow network. Since our model is self-supervised, we can further improve its performance through test-time adaptation, by finetuning it on the input video. It can also be easily extended to magnify the motions of only user-selected objects. Our approach avoids the need for synthetic magnification datasets that have been used to train prior learning-based approaches. Instead, it leverages the existing capabilities of off-the-shelf motion estimators. We demonstrate the effectiveness of our method through evaluations of both visual quality and quantitative metrics on a range of real-world and synthetic videos, and we show our method works for both supervised and unsupervised optical flow methods.
<div id='section'>Paperid: <span id='pid'>443, <a href='https://arxiv.org/pdf/2310.09505.pdf' target='_blank'>https://arxiv.org/pdf/2310.09505.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongfu Liu, Hengguan Huang, Ye Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.09505">Advancing Test-Time Adaptation in Wild Acoustic Test Settings</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Acoustic foundation models, fine-tuned for Automatic Speech Recognition (ASR), suffer from performance degradation in wild acoustic test settings when deployed in real-world scenarios. Stabilizing online Test-Time Adaptation (TTA) under these conditions remains an open and unexplored question. Existing wild vision TTA methods often fail to handle speech data effectively due to the unique characteristics of high-entropy speech frames, which are unreliably filtered out even when containing crucial semantic content. Furthermore, unlike static vision data, speech signals follow short-term consistency, requiring specialized adaptation strategies. In this work, we propose a novel wild acoustic TTA method tailored for ASR fine-tuned acoustic foundation models. Our method, Confidence-Enhanced Adaptation, performs frame-level adaptation using a confidence-aware weight scheme to avoid filtering out essential information in high-entropy frames. Additionally, we apply consistency regularization during test-time optimization to leverage the inherent short-term consistency of speech signals. Our experiments on both synthetic and real-world datasets demonstrate that our approach outperforms existing baselines under various wild acoustic test settings, including Gaussian noise, environmental sounds, accent variations, and sung speech.
<div id='section'>Paperid: <span id='pid'>444, <a href='https://arxiv.org/pdf/2306.06779.pdf' target='_blank'>https://arxiv.org/pdf/2306.06779.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hai Ye, Qizhe Xie, Hwee Tou Ng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.06779">Multi-Source Test-Time Adaptation as Dueling Bandits for Extractive Question Answering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we study multi-source test-time model adaptation from user feedback, where K distinct models are established for adaptation. To allow efficient adaptation, we cast the problem as a stochastic decision-making process, aiming to determine the best adapted model after adaptation. We discuss two frameworks: multi-armed bandit learning and multi-armed dueling bandits. Compared to multi-armed bandit learning, the dueling framework allows pairwise collaboration among K models, which is solved by a novel method named Co-UCB proposed in this work. Experiments on six datasets of extractive question answering (QA) show that the dueling framework using Co-UCB is more effective than other strong baselines for our studied problem.
<div id='section'>Paperid: <span id='pid'>445, <a href='https://arxiv.org/pdf/2212.08356.pdf' target='_blank'>https://arxiv.org/pdf/2212.08356.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junha Song, Kwanyong Park, InKyu Shin, Sanghyun Woo, Chaoning Zhang, In So Kweon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.08356">Test-time Adaptation in the Dynamic World with Compound Domain Knowledge Management</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Prior to the deployment of robotic systems, pre-training the deep-recognition models on all potential visual cases is infeasible in practice. Hence, test-time adaptation (TTA) allows the model to adapt itself to novel environments and improve its performance during test time (i.e., lifelong adaptation). Several works for TTA have shown promising adaptation performances in continuously changing environments. However, our investigation reveals that existing methods are vulnerable to dynamic distributional changes and often lead to overfitting of TTA models. To address this problem, this paper first presents a robust TTA framework with compound domain knowledge management. Our framework helps the TTA model to harvest the knowledge of multiple representative domains (i.e., compound domain) and conduct the TTA based on the compound domain knowledge. In addition, to prevent overfitting of the TTA model, we devise novel regularization which modulates the adaptation rates using domain-similarity between the source and the current target domain. With the synergy of the proposed framework and regularization, we achieve consistent performance improvements in diverse TTA scenarios, especially on dynamic domain shifts. We demonstrate the generality of proposals via extensive experiments including image classification on ImageNet-C and semantic segmentation on GTA5, C-driving, and corrupted Cityscapes datasets.
<div id='section'>Paperid: <span id='pid'>446, <a href='https://arxiv.org/pdf/2207.03442.pdf' target='_blank'>https://arxiv.org/pdf/2207.03442.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jin Gao, Jialing Zhang, Xihui Liu, Trevor Darrell, Evan Shelhamer, Dequan Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.03442">Back to the Source: Diffusion-Driven Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation harnesses test inputs to improve the accuracy of a model trained on source data when tested on shifted target data. Existing methods update the source model by (re-)training on each target domain. While effective, re-training is sensitive to the amount and order of the data and the hyperparameters for optimization. We instead update the target data, by projecting all test inputs toward the source domain with a generative diffusion model. Our diffusion-driven adaptation method, DDA, shares its models for classification and generation across all domains. Both models are trained on the source domain, then fixed during testing. We augment diffusion with image guidance and self-ensembling to automatically decide how much to adapt. Input adaptation by DDA is more robust than prior model adaptation approaches across a variety of corruptions, architectures, and data regimes on the ImageNet-C benchmark. With its input-wise updates, DDA succeeds where model adaptation degrades on too little data in small batches, dependent data in non-uniform order, or mixed data with multiple corruptions.
<div id='section'>Paperid: <span id='pid'>447, <a href='https://arxiv.org/pdf/2206.03271.pdf' target='_blank'>https://arxiv.org/pdf/2206.03271.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhao Mandi, Pieter Abbeel, Stephen James
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2206.03271">On the Effectiveness of Fine-tuning Versus Meta-reinforcement Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Intelligent agents should have the ability to leverage knowledge from previously learned tasks in order to learn new ones quickly and efficiently. Meta-learning approaches have emerged as a popular solution to achieve this. However, meta-reinforcement learning (meta-RL) algorithms have thus far been restricted to simple environments with narrow task distributions. Moreover, the paradigm of pretraining followed by fine-tuning to adapt to new tasks has emerged as a simple yet effective solution in supervised and self-supervised learning. This calls into question the benefits of meta-learning approaches also in reinforcement learning, which typically come at the cost of high complexity. We hence investigate meta-RL approaches in a variety of vision-based benchmarks, including Procgen, RLBench, and Atari, where evaluations are made on completely novel tasks. Our findings show that when meta-learning approaches are evaluated on different tasks (rather than different variations of the same task), multi-task pretraining with fine-tuning on new tasks performs equally as well, or better, than meta-pretraining with meta test-time adaptation. This is encouraging for future research, as multi-task pretraining tends to be simpler and computationally cheaper than meta-RL. From these findings, we advocate for evaluating future meta-RL methods on more challenging tasks and including multi-task pretraining with fine-tuning as a simple, yet strong baseline.
<div id='section'>Paperid: <span id='pid'>448, <a href='https://arxiv.org/pdf/2506.23104.pdf' target='_blank'>https://arxiv.org/pdf/2506.23104.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jihun Kim, Hoyong Kwon, Hyeokjun Kweon, Wooseong Jeong, Kuk-Jin Yoon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.23104">DC-TTA: Divide-and-Conquer Framework for Test-Time Adaptation of Interactive Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Interactive segmentation (IS) allows users to iteratively refine object boundaries with minimal cues, such as positive and negative clicks. While the Segment Anything Model (SAM) has garnered attention in the IS community for its promptable segmentation capabilities, it often struggles in specialized domains or when handling complex scenarios (e.g., camouflaged or multi-part objects). To overcome these challenges, we propose DC-TTA, a novel test-time adaptation (TTA) framework that adapts SAM on a per-sample basis by leveraging user interactions as supervision. Instead of forcing a single model to incorporate all user clicks at once, DC-TTA partitions the clicks into more coherent subsets, each processed independently via TTA with a separated model. This Divide-and-Conquer strategy reduces conflicts among diverse cues and enables more localized updates. Finally, we merge the adapted models to form a unified predictor that integrates the specialized knowledge from each subset. Experimental results across various benchmarks demonstrate that DC-TTA significantly outperforms SAM's zero-shot results and conventional TTA methods, effectively handling complex tasks such as camouflaged object segmentation with fewer interactions and improved accuracy.
<div id='section'>Paperid: <span id='pid'>449, <a href='https://arxiv.org/pdf/2504.04981.pdf' target='_blank'>https://arxiv.org/pdf/2504.04981.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sohyun Lee, Nayeong Kim, Juwon Kang, Seong Joon Oh, Suha Kwak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.04981">TestDG: Test-time Domain Generalization for Continual Test-time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper studies continual test-time adaptation (CTTA), the task of adapting a model to constantly changing unseen domains in testing while preserving previously learned knowledge. Existing CTTA methods mostly focus on adaptation to the current test domain only, overlooking generalization to arbitrary test domains a model may face in the future. To tackle this limitation, we present a novel online test-time domain generalization framework for CTTA, dubbed TestDG. TestDG aims to learn features invariant to both current and previous test domains on the fly during testing, improving the potential for effective generalization to future domains. To this end, we propose a new model architecture and a test-time adaptation strategy dedicated to learning domain-invariant features, along with a new data structure and optimization algorithm for effectively managing information from previous test domains. TestDG achieved state of the art on four public CTTA benchmarks. Moreover, it showed superior generalization to unseen test domains.
<div id='section'>Paperid: <span id='pid'>450, <a href='https://arxiv.org/pdf/2503.09394.pdf' target='_blank'>https://arxiv.org/pdf/2503.09394.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaozhen Qiao, Peng Huang, Jiakang Yuan, Xianda Guo, Bowen Ye, Chaocan Xue, Ye Zheng, Zhe Sun, Xuelong Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.09394">Bidirectional Prototype-Reward co-Evolution for Test-Time Adaptation of Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) is crucial in maintaining performance of Vision Language Models (VLMs) when facing distribution shifts, particularly when the source data or target labels are inaccessible. Existing TTA methods predominantly leverage the output probability distribution of CLIP for feature evaluation, resulting in biases under domain shifts, which cause misclassified features due to text priors or incorrect textual associations. To address these issues, we propose \underline{B}idirectional Prototype-Reward co-Evolution (BPRE), a novel VLMs framework with TTA that integrates feature quality assessment with prototype evolution via a synergistic feedback loop. First, the Multi-dimensional Quality-aware Reward Module (MQRM) is designed to evaluate feature quality and guide prototype refinement precisely. The continuous refinement of prototype quality via Prototype-Reward Interactive Evolution (PRIE) enhances the computation more robust. Through this bidirectional interaction, the precision of rewards and prototype evolution mutually reinforce each other, forming a self-evolving feedback cycle. Extensive experiments conducted on 15 diverse recognition datasets demonstrate that our model consistently achieves superior performance compared to other SOTA methods, and advances VLM generalization capabilities through emphasizing comprehensive feature evaluation.
<div id='section'>Paperid: <span id='pid'>451, <a href='https://arxiv.org/pdf/2409.09753.pdf' target='_blank'>https://arxiv.org/pdf/2409.09753.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shahriar Rifat, Jonathan Ashdown, Francesco Restuccia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.09753">DARDA: Domain-Aware Real-Time Dynamic Neural Network Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test Time Adaptation (TTA) has emerged as a practical solution to mitigate the performance degradation of Deep Neural Networks (DNNs) in the presence of corruption/ noise affecting inputs. Existing approaches in TTA continuously adapt the DNN, leading to excessive resource consumption and performance degradation due to accumulation of error stemming from lack of supervision. In this work, we propose Domain-Aware Real-Time Dynamic Adaptation (DARDA) to address such issues. Our key approach is to proactively learn latent representations of some corruption types, each one associated with a sub-network state tailored to correctly classify inputs affected by that corruption. After deployment, DARDA adapts the DNN to previously unseen corruptions in an unsupervised fashion by (i) estimating the latent representation of the ongoing corruption; (ii) selecting the sub-network whose associated corruption is the closest in the latent space to the ongoing corruption; and (iii) adapting DNN state, so that its representation matches the ongoing corruption. This way, DARDA is more resource efficient and can swiftly adapt to new distributions caused by different corruptions without requiring a large variety of input data. Through experiments with two popular mobile edge devices - Raspberry Pi and NVIDIA Jetson Nano - we show that DARDA reduces energy consumption and average cache memory footprint respectively by 1.74x and 2.64x with respect to the state of the art, while increasing the performance by 10.4%, 5.7% and 4.4% on CIFAR-10, CIFAR-100 and TinyImagenet.
<div id='section'>Paperid: <span id='pid'>452, <a href='https://arxiv.org/pdf/2408.11465.pdf' target='_blank'>https://arxiv.org/pdf/2408.11465.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kim Yu-Ji, Hyunwoo Ha, Kim Youwang, Jaeheung Surh, Hyowon Ha, Tae-Hyun Oh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.11465">MeTTA: Single-View to 3D Textured Mesh Reconstruction with Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Reconstructing 3D from a single view image is a long-standing challenge. One of the popular approaches to tackle this problem is learning-based methods, but dealing with the test cases unfamiliar with training data (Out-of-distribution; OoD) introduces an additional challenge. To adapt for unseen samples in test time, we propose MeTTA, a test-time adaptation (TTA) exploiting generative prior. We design joint optimization of 3D geometry, appearance, and pose to handle OoD cases with only a single view image. However, the alignment between the reference image and the 3D shape via the estimated viewpoint could be erroneous, which leads to ambiguity. To address this ambiguity, we carefully design learnable virtual cameras and their self-calibration. In our experiments, we demonstrate that MeTTA effectively deals with OoD scenarios at failure cases of existing learning-based 3D reconstruction models and enables obtaining a realistic appearance with physically based rendering (PBR) textures.
<div id='section'>Paperid: <span id='pid'>453, <a href='https://arxiv.org/pdf/2407.12492.pdf' target='_blank'>https://arxiv.org/pdf/2407.12492.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mona Schirmer, Dan Zhang, Eric Nalisnick
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.12492">Temporal Test-Time Adaptation with State-Space Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Distribution shifts between training and test data are inevitable over the lifecycle of a deployed model, leading to performance decay. Adapting a model on test samples can help mitigate this drop in performance. However, most test-time adaptation methods have focused on synthetic corruption shifts, leaving a variety of distribution shifts underexplored. In this paper, we focus on distribution shifts that evolve gradually over time, which are common in the wild but challenging for existing methods, as we show. To address this, we propose STAD, a probabilistic state-space model that adapts a deployed model to temporal distribution shifts by learning the time-varying dynamics in the last set of hidden features. Without requiring labels, our model infers time-evolving class prototypes that act as a dynamic classification head. Through experiments on real-world temporal distribution shifts, we show that our method excels in handling small batch sizes and label shift.
<div id='section'>Paperid: <span id='pid'>454, <a href='https://arxiv.org/pdf/2405.07171.pdf' target='_blank'>https://arxiv.org/pdf/2405.07171.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>WeiQin Chuah, Ruwan Tennakoon, Alireza Bab-Hadiashar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.07171">Enhanced Online Test-time Adaptation with Feature-Weight Cosine Alignment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Online Test-Time Adaptation (OTTA) has emerged as an effective strategy to handle distributional shifts, allowing on-the-fly adaptation of pre-trained models to new target domains during inference, without the need for source data. We uncovered that the widely studied entropy minimization (EM) method for OTTA, suffers from noisy gradients due to ambiguity near decision boundaries and incorrect low-entropy predictions. To overcome these limitations, this paper introduces a novel cosine alignment optimization approach with a dual-objective loss function that refines the precision of class predictions and adaptability to novel domains. Specifically, our method optimizes the cosine similarity between feature vectors and class weight vectors, enhancing the precision of class predictions and the model's adaptability to novel domains. Our method outperforms state-of-the-art techniques and sets a new benchmark in multiple datasets, including CIFAR-10-C, CIFAR-100-C, ImageNet-C, Office-Home, and DomainNet datasets, demonstrating high accuracy and robustness against diverse corruptions and domain shifts.
<div id='section'>Paperid: <span id='pid'>455, <a href='https://arxiv.org/pdf/2405.04782.pdf' target='_blank'>https://arxiv.org/pdf/2405.04782.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhaoxiang Zhang, Hanqiu Deng, Jinan Bao, Xingyu Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.04782">Dual-Image Enhanced CLIP for Zero-Shot Anomaly Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Image Anomaly Detection has been a challenging task in Computer Vision field. The advent of Vision-Language models, particularly the rise of CLIP-based frameworks, has opened new avenues for zero-shot anomaly detection. Recent studies have explored the use of CLIP by aligning images with normal and prompt descriptions. However, the exclusive dependence on textual guidance often falls short, highlighting the critical importance of additional visual references. In this work, we introduce a Dual-Image Enhanced CLIP approach, leveraging a joint vision-language scoring system. Our methods process pairs of images, utilizing each as a visual reference for the other, thereby enriching the inference process with visual context. This dual-image strategy markedly enhanced both anomaly classification and localization performances. Furthermore, we have strengthened our model with a test-time adaptation module that incorporates synthesized anomalies to refine localization capabilities. Our approach significantly exploits the potential of vision-language joint anomaly detection and demonstrates comparable performance with current SOTA methods across various datasets.
<div id='section'>Paperid: <span id='pid'>456, <a href='https://arxiv.org/pdf/2404.03784.pdf' target='_blank'>https://arxiv.org/pdf/2404.03784.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sabyasachi Sahoo, Mostafa ElAraby, Jonas Ngnawe, Yann Pequignot, Frederic Precioso, Christian Gagne
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.03784">A Layer Selection Approach to Test Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test Time Adaptation (TTA) addresses the problem of distribution shift by adapting a pretrained model to a new domain during inference. When faced with challenging shifts, most methods collapse and perform worse than the original pretrained model. In this paper, we find that not all layers are equally receptive to the adaptation, and the layers with the most misaligned gradients often cause performance degradation. To address this, we propose GALA, a novel layer selection criterion to identify the most beneficial updates to perform during test time adaptation. This criterion can also filter out unreliable samples with noisy gradients. Its simplicity allows seamless integration with existing TTA loss functions, thereby preventing degradation and focusing adaptation on the most trainable layers. This approach also helps to regularize adaptation to preserve the pretrained features, which are crucial for handling unseen domains. Through extensive experiments, we demonstrate that the proposed layer selection framework improves the performance of existing TTA approaches across multiple datasets, domain shifts, model architectures, and TTA losses.
<div id='section'>Paperid: <span id='pid'>457, <a href='https://arxiv.org/pdf/2403.01977.pdf' target='_blank'>https://arxiv.org/pdf/2403.01977.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Maytus Piriyajitakonkij, Mingfei Sun, Mengmi Zhang, Wei Pan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.01977">TTA-Nav: Test-time Adaptive Reconstruction for Point-Goal Navigation under Visual Corruptions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Robot navigation under visual corruption presents a formidable challenge. To address this, we propose a Test-time Adaptation (TTA) method, named as TTA-Nav, for point-goal navigation under visual corruptions. Our "plug-and-play" method incorporates a top-down decoder to a pre-trained navigation model. Firstly, the pre-trained navigation model gets a corrupted image and extracts features. Secondly, the top-down decoder produces the reconstruction given the high-level features extracted by the pre-trained model. Then, it feeds the reconstruction of a corrupted image back to the pre-trained model. Finally, the pre-trained model does forward pass again to output action. Despite being trained solely on clean images, the top-down decoder can reconstruct cleaner images from corrupted ones without the need for gradient-based adaptation. The pre-trained navigation model with our top-down decoder significantly enhances navigation performance across almost all visual corruptions in our benchmarks. Our method improves the success rate of point-goal navigation from the state-of-the-art result of 46% to 94% on the most severe corruption. This suggests its potential for broader application in robotic visual navigation. Project page: https://sites.google.com/view/tta-nav
<div id='section'>Paperid: <span id='pid'>458, <a href='https://arxiv.org/pdf/2402.04958.pdf' target='_blank'>https://arxiv.org/pdf/2402.04958.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pedro Vianna, Muawiz Chaudhary, Paria Mehrbod, An Tang, Guy Cloutier, Guy Wolf, Michael Eickenberg, Eugene Belilovsky
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.04958">Channel-Selective Normalization for Label-Shift Robust Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks have useful applications in many different tasks, however their performance can be severely affected by changes in the data distribution. For example, in the biomedical field, their performance can be affected by changes in the data (different machines, populations) between training and test datasets. To ensure robustness and generalization to real-world scenarios, test-time adaptation has been recently studied as an approach to adjust models to a new data distribution during inference. Test-time batch normalization is a simple and popular method that achieved compelling performance on domain shift benchmarks. It is implemented by recalculating batch normalization statistics on test batches. Prior work has focused on analysis with test data that has the same label distribution as the training data. However, in many practical applications this technique is vulnerable to label distribution shifts, sometimes producing catastrophic failure. This presents a risk in applying test time adaptation methods in deployment. We propose to tackle this challenge by only selectively adapting channels in a deep network, minimizing drastic adaptation that is sensitive to label shifts. Our selection scheme is based on two principles that we empirically motivate: (1) later layers of networks are more sensitive to label shift (2) individual features can be sensitive to specific classes. We apply the proposed technique to three classification tasks, including CIFAR10-C, Imagenet-C, and diagnosis of fatty liver, where we explore both covariate and label distribution shifts. We find that our method allows to bring the benefits of TTA while significantly reducing the risk of failure common in other methods, while being robust to choice in hyperparameters.
<div id='section'>Paperid: <span id='pid'>459, <a href='https://arxiv.org/pdf/2401.17728.pdf' target='_blank'>https://arxiv.org/pdf/2401.17728.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pascal Schlachter, Bin Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.17728">COMET: Contrastive Mean Teacher for Online Source-Free Universal Domain Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In real-world applications, there is often a domain shift from training to test data. This observation resulted in the development of test-time adaptation (TTA). It aims to adapt a pre-trained source model to the test data without requiring access to the source data. Thereby, most existing works are limited to the closed-set assumption, i.e. there is no category shift between source and target domain. We argue that in a realistic open-world setting a category shift can appear in addition to a domain shift. This means, individual source classes may not appear in the target domain anymore, samples of new classes may be part of the target domain or even both at the same time. Moreover, in many real-world scenarios the test data is not accessible all at once but arrives sequentially as a stream of batches demanding an immediate prediction. Hence, TTA must be applied in an online manner. To the best of our knowledge, the combination of these aspects, i.e. online source-free universal domain adaptation (online SF-UniDA), has not been studied yet. In this paper, we introduce a Contrastive Mean Teacher (COMET) tailored to this novel scenario. It applies a contrastive loss to rebuild a feature space where the samples of known classes build distinct clusters and the samples of new classes separate well from them. It is complemented by an entropy loss which ensures that the classifier output has a small entropy for samples of known classes and a large entropy for samples of new classes to be easily detected and rejected as unknown. To provide the losses with reliable pseudo labels, they are embedded into a mean teacher (MT) framework. We evaluate our method across two datasets and all category shifts to set an initial benchmark for online SF-UniDA. Thereby, COMET yields state-of-the-art performance and proves to be consistent and robust across a variety of different scenarios.
<div id='section'>Paperid: <span id='pid'>460, <a href='https://arxiv.org/pdf/2311.09737.pdf' target='_blank'>https://arxiv.org/pdf/2311.09737.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bingnan Li, Zhitong Gao, Xuming He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.09737">Gradient-Map-Guided Adaptive Domain Generalization for Cross Modality MRI Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cross-modal MRI segmentation is of great value for computer-aided medical diagnosis, enabling flexible data acquisition and model generalization. However, most existing methods have difficulty in handling local variations in domain shift and typically require a significant amount of data for training, which hinders their usage in practice. To address these problems, we propose a novel adaptive domain generalization framework, which integrates a learning-free cross-domain representation based on image gradient maps and a class prior-informed test-time adaptation strategy for mitigating local domain shift. We validate our approach on two multi-modal MRI datasets with six cross-modal segmentation tasks. Across all the task settings, our method consistently outperforms competing approaches and shows a stable performance even with limited training data.
<div id='section'>Paperid: <span id='pid'>461, <a href='https://arxiv.org/pdf/2310.02416.pdf' target='_blank'>https://arxiv.org/pdf/2310.02416.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Saypraseuth Mounsaveng, Florent Chiaroni, Malik Boudiaf, Marco Pedersoli, Ismail Ben Ayed
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.02416">Bag of Tricks for Fully Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fully Test-Time Adaptation (TTA), which aims at adapting models to data drifts, has recently attracted wide interest. Numerous tricks and techniques have been proposed to ensure robust learning on arbitrary streams of unlabeled data. However, assessing the true impact of each individual technique and obtaining a fair comparison still constitutes a significant challenge. To help consolidate the community's knowledge, we present a categorization of selected orthogonal TTA techniques, including small batch normalization, stream rebalancing, reliable sample selection, and network confidence calibration. We meticulously dissect the effect of each approach on different scenarios of interest. Through our analysis, we shed light on trade-offs induced by those techniques between accuracy, the computational power required, and model complexity. We also uncover the synergy that arises when combining techniques and are able to establish new state-of-the-art results.
<div id='section'>Paperid: <span id='pid'>462, <a href='https://arxiv.org/pdf/2309.15251.pdf' target='_blank'>https://arxiv.org/pdf/2309.15251.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiachen Sun, Mark Ibrahim, Melissa Hall, Ivan Evtimov, Z. Morley Mao, Cristian Canton Ferrer, Caner Hazirbas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.15251">VPA: Fully Test-Time Visual Prompt Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Textual prompt tuning has demonstrated significant performance improvements in adapting natural language processing models to a variety of downstream tasks by treating hand-engineered prompts as trainable parameters. Inspired by the success of textual prompting, several studies have investigated the efficacy of visual prompt tuning. In this work, we present Visual Prompt Adaptation (VPA), the first framework that generalizes visual prompting with test-time adaptation. VPA introduces a small number of learnable tokens, enabling fully test-time and storage-efficient adaptation without necessitating source-domain information. We examine our VPA design under diverse adaptation settings, encompassing single-image, batched-image, and pseudo-label adaptation. We evaluate VPA on multiple tasks, including out-of-distribution (OOD) generalization, corruption robustness, and domain adaptation. Experimental results reveal that VPA effectively enhances OOD generalization by 3.3% across various models, surpassing previous test-time approaches. Furthermore, we show that VPA improves corruption robustness by 6.5% compared to strong baselines. Finally, we demonstrate that VPA also boosts domain adaptation performance by relatively 5.2%. Our VPA also exhibits marked effectiveness in improving the robustness of zero-shot recognition for vision-language models.
<div id='section'>Paperid: <span id='pid'>463, <a href='https://arxiv.org/pdf/2308.15939.pdf' target='_blank'>https://arxiv.org/pdf/2308.15939.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hanqiu Deng, Zhaoxiang Zhang, Jinan Bao, Xingyu Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.15939">Bootstrap Fine-Grained Vision-Language Alignment for Unified Zero-Shot Anomaly Localization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Contrastive Language-Image Pre-training (CLIP) models have shown promising performance on zero-shot visual recognition tasks by learning visual representations under natural language supervision. Recent studies attempt the use of CLIP to tackle zero-shot anomaly detection by matching images with normal and abnormal state prompts. However, since CLIP focuses on building correspondence between paired text prompts and global image-level representations, the lack of fine-grained patch-level vision to text alignment limits its capability on precise visual anomaly localization. In this work, we propose AnoCLIP for zero-shot anomaly localization. In the visual encoder, we introduce a training-free value-wise attention mechanism to extract intrinsic local tokens of CLIP for patch-level local description. From the perspective of text supervision, we particularly design a unified domain-aware contrastive state prompting template for fine-grained vision-language matching. On top of the proposed AnoCLIP, we further introduce a test-time adaptation (TTA) mechanism to refine visual anomaly localization results, where we optimize a lightweight adapter in the visual encoder using AnoCLIP's pseudo-labels and noise-corrupted tokens. With both AnoCLIP and TTA, we significantly exploit the potential of CLIP for zero-shot anomaly localization and demonstrate the effectiveness of AnoCLIP on various datasets.
<div id='section'>Paperid: <span id='pid'>464, <a href='https://arxiv.org/pdf/2306.05401.pdf' target='_blank'>https://arxiv.org/pdf/2306.05401.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ori Press, Steffen Schneider, Matthias KÃ¼mmerer, Matthias Bethge
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.05401">RDumb: A simple approach that questions our progress in continual test-time adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-Time Adaptation (TTA) allows to update pre-trained models to changing data distributions at deployment time. While early work tested these algorithms for individual fixed distribution shifts, recent work proposed and applied methods for continual adaptation over long timescales. To examine the reported progress in the field, we propose the Continually Changing Corruptions (CCC) benchmark to measure asymptotic performance of TTA techniques. We find that eventually all but one state-of-the-art methods collapse and perform worse than a non-adapting model, including models specifically proposed to be robust to performance collapse. In addition, we introduce a simple baseline, "RDumb", that periodically resets the model to its pretrained state. RDumb performs better or on par with the previously proposed state-of-the-art in all considered benchmarks. Our results show that previous TTA approaches are neither effective at regularizing adaptation to avoid collapse nor able to outperform a simplistic resetting strategy.
<div id='section'>Paperid: <span id='pid'>465, <a href='https://arxiv.org/pdf/2303.01630.pdf' target='_blank'>https://arxiv.org/pdf/2303.01630.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenyan Wu, Yimu Pan, Yandong Li, James Z. Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.01630">Learning to Adapt to Online Streams with Distribution Shifts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) is a technique used to reduce distribution gaps between the training and testing sets by leveraging unlabeled test data during inference. In this work, we expand TTA to a more practical scenario, where the test data comes in the form of online streams that experience distribution shifts over time. Existing approaches face two challenges: reliance on a large test data batch from the same domain and the absence of explicitly modeling the continual distribution evolution process. To address both challenges, we propose a meta-learning approach that teaches the network to adapt to distribution-shifting online streams during meta-training. As a result, the trained model can perform continual adaptation to distribution shifts in testing, regardless of the batch size restriction, as it has learned during training. We conducted extensive experiments on benchmarking datasets for TTA, incorporating a broad range of online distribution-shifting settings. Our results showed consistent improvements over state-of-the-art methods, indicating the effectiveness of our approach. In addition, we achieved superior performance in the video segmentation task, highlighting the potential of our method for real-world applications.
<div id='section'>Paperid: <span id='pid'>466, <a href='https://arxiv.org/pdf/2301.06013.pdf' target='_blank'>https://arxiv.org/pdf/2301.06013.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiayi Han, Longbin Zeng, Liang Du, Weiyang Ding, Jianfeng Feng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.06013">Rethinking Precision of Pseudo Label: Test-Time Adaptation via Complementary Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we propose a novel complementary learning approach to enhance test-time adaptation (TTA), which has been proven to exhibit good performance on testing data with distribution shifts such as corruptions. In test-time adaptation tasks, information from the source domain is typically unavailable and the model has to be optimized without supervision for test-time samples. Hence, usual methods assign labels for unannotated data with the prediction by a well-trained source model in an unsupervised learning framework. Previous studies have employed unsupervised objectives, such as the entropy of model predictions, as optimization targets to effectively learn features for test-time samples. However, the performance of the model is easily compromised by the quality of pseudo-labels, since inaccuracies in pseudo-labels introduce noise to the model. Therefore, we propose to leverage the "less probable categories" to decrease the risk of incorrect pseudo-labeling. The complementary label is introduced to designate these categories. We highlight that the risk function of complementary labels agrees with their Vanilla loss formula under the conventional true label distribution. Experiments show that the proposed learning algorithm achieves state-of-the-art performance on different datasets and experiment settings.
<div id='section'>Paperid: <span id='pid'>467, <a href='https://arxiv.org/pdf/2510.09473.pdf' target='_blank'>https://arxiv.org/pdf/2510.09473.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jisu Han, Wonjun Hwang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.09473">D-TPT: Dimensional Entropy Maximization for Calibrating Test-Time Prompt Tuning in Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation paradigm provides flexibility towards domain shifts by performing immediate adaptation on unlabeled target data from the source model. Vision-Language Models (VLMs) leverage their generalization capabilities for diverse downstream tasks, and test-time prompt tuning has emerged as a prominent solution for adapting VLMs. In this work, we explore contrastive VLMs and identify the modality gap caused by a single dominant feature dimension across modalities. We observe that the dominant dimensions in both text and image modalities exhibit high predictive sensitivity, and that constraining their influence can improve calibration error. Building on this insight, we propose dimensional entropy maximization that regularizes the distribution of textual features toward uniformity to mitigate the dependency of dominant dimensions. Our method alleviates the degradation of calibration performance in test-time prompt tuning, offering a simple yet effective solution to enhance the reliability of VLMs in real-world deployment scenarios.
<div id='section'>Paperid: <span id='pid'>468, <a href='https://arxiv.org/pdf/2508.18790.pdf' target='_blank'>https://arxiv.org/pdf/2508.18790.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuhui Tao, Yizhe Zhang, Qiang Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.18790">A Closer Look at Edema Area Segmentation in SD-OCT Images Using Adversarial Framework</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The development of artificial intelligence models for macular edema (ME) analy-sis always relies on expert-annotated pixel-level image datasets which are expen-sive to collect prospectively. While anomaly-detection-based weakly-supervised methods have shown promise in edema area (EA) segmentation task, their per-formance still lags behind fully-supervised approaches. In this paper, we leverage the strong correlation between EA and retinal layers in spectral-domain optical coherence tomography (SD-OCT) images, along with the update characteristics of weakly-supervised learning, to enhance an off-the-shelf adversarial framework for EA segmentation with a novel layer-structure-guided post-processing step and a test-time-adaptation (TTA) strategy. By incorporating additional retinal lay-er information, our framework reframes the dense EA prediction task as one of confirming intersection points between the EA contour and retinal layers, result-ing in predictions that better align with the shape prior of EA. Besides, the TTA framework further helps address discrepancies in the manifestations and presen-tations of EA between training and test sets. Extensive experiments on two pub-licly available datasets demonstrate that these two proposed ingredients can im-prove the accuracy and robustness of EA segmentation, bridging the gap between weakly-supervised and fully-supervised models.
<div id='section'>Paperid: <span id='pid'>469, <a href='https://arxiv.org/pdf/2508.15568.pdf' target='_blank'>https://arxiv.org/pdf/2508.15568.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Youjia Zhang, Youngeun Kim, Young-Geun Choi, Hongyeob Kim, Huiling Liu, Sungeun Hong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.15568">Backpropagation-Free Test-Time Adaptation via Probabilistic Gaussian Alignment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) enhances the zero-shot robustness under distribution shifts by leveraging unlabeled test data during inference. Despite notable advances, several challenges still limit its broader applicability. First, most methods rely on backpropagation or iterative optimization, which limits scalability and hinders real-time deployment. Second, they lack explicit modeling of class-conditional feature distributions. This modeling is crucial for producing reliable decision boundaries and calibrated predictions, but it remains underexplored due to the lack of both source data and supervision at test time. In this paper, we propose ADAPT, an Advanced Distribution-Aware and backPropagation-free Test-time adaptation method. We reframe TTA as a Gaussian probabilistic inference task by modeling class-conditional likelihoods using gradually updated class means and a shared covariance matrix. This enables closed-form, training-free inference. To correct potential likelihood bias, we introduce lightweight regularization guided by CLIP priors and a historical knowledge bank. ADAPT requires no source data, no gradient updates, and no full access to target data, supporting both online and transductive settings. Extensive experiments across diverse benchmarks demonstrate that our method achieves state-of-the-art performance under a wide range of distribution shifts with superior scalability and robustness.
<div id='section'>Paperid: <span id='pid'>470, <a href='https://arxiv.org/pdf/2508.07570.pdf' target='_blank'>https://arxiv.org/pdf/2508.07570.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Khanh-Binh Nguyen, Phuoc-Nguyen Bui, Hyunseung Choo, Duc Thanh Nguyen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.07570">Adaptive Cache Enhancement for Test-Time Adaptation of Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-language models (VLMs) exhibit remarkable zero-shot generalization but suffer performance degradation under distribution shifts in downstream tasks, particularly in the absence of labeled data. Test-Time Adaptation (TTA) addresses this challenge by enabling online optimization of VLMs during inference, eliminating the need for annotated data. Cache-based TTA methods exploit historical knowledge by maintaining a dynamic memory cache of low-entropy or high-confidence samples, promoting efficient adaptation to out-of-distribution data. Nevertheless, these methods face two critical challenges: (1) unreliable confidence metrics under significant distribution shifts, resulting in error accumulation within the cache and degraded adaptation performance; and (2) rigid decision boundaries that fail to accommodate substantial distributional variations, leading to suboptimal predictions. To overcome these limitations, we introduce the Adaptive Cache Enhancement (ACE) framework, which constructs a robust cache by selectively storing high-confidence or low-entropy image embeddings per class, guided by dynamic, class-specific thresholds initialized from zero-shot statistics and iteratively refined using an exponential moving average and exploration-augmented updates. This approach enables adaptive, class-wise decision boundaries, ensuring robust and accurate predictions across diverse visual distributions. Extensive experiments on 15 diverse benchmark datasets demonstrate that ACE achieves state-of-the-art performance, delivering superior robustness and generalization compared to existing TTA methods in challenging out-of-distribution scenarios.
<div id='section'>Paperid: <span id='pid'>471, <a href='https://arxiv.org/pdf/2506.23529.pdf' target='_blank'>https://arxiv.org/pdf/2506.23529.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jisu Han, Jihee Park, Dongyoon Han, Wonjun Hwang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.23529">When Test-Time Adaptation Meets Self-Supervised Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Training on test-time data enables deep learning models to adapt to dynamic environmental changes, enhancing their practical applicability. Online adaptation from source to target domains is promising but it remains highly reliant on the performance of source pretrained model. In this paper, we investigate whether test-time adaptation (TTA) methods can continuously improve models trained via self-supervised learning (SSL) without relying on source pretraining. We introduce a self-supervised TTA protocol after observing that existing TTA approaches struggle when directly applied to self-supervised models with low accuracy on the source domain. Furthermore, we propose a collaborative learning framework that integrates SSL and TTA models, leveraging contrastive learning and knowledge distillation for stepwise representation refinement. We validate our method on diverse self-supervised models, including DINO, MoCo, and iBOT, across TTA benchmarks. Extensive experiments validate the effectiveness of our approach in SSL, showing that it achieves competitive performance even without source pretraining.
<div id='section'>Paperid: <span id='pid'>472, <a href='https://arxiv.org/pdf/2505.11902.pdf' target='_blank'>https://arxiv.org/pdf/2505.11902.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiang You, Xiaozhen Wang, Arben Cela
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11902">Dynamic Perturbed Adaptive Method for Infinite Task-Conflicting Time Series</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We formulate time series tasks as input-output mappings under varying objectives, where the same input may yield different outputs. This challenges a model's generalization and adaptability. To study this, we construct a synthetic dataset with numerous conflicting subtasks to evaluate adaptation under frequent task shifts. Existing static models consistently fail in such settings. We propose a dynamic perturbed adaptive method based on a trunk-branch architecture, where the trunk evolves slowly to capture long-term structure, and branch modules are re-initialized and updated for each task. This enables continual test-time adaptation and cross-task transfer without relying on explicit task labels. Theoretically, we show that this architecture has strictly higher functional expressivity than static models and LoRA. We also establish exponential convergence of branch adaptation under the Polyak-Lojasiewicz condition. Experiments demonstrate that our method significantly outperforms competitive baselines in complex and conflicting task environments, exhibiting fast adaptation and progressive learning capabilities.
<div id='section'>Paperid: <span id='pid'>473, <a href='https://arxiv.org/pdf/2503.23257.pdf' target='_blank'>https://arxiv.org/pdf/2503.23257.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammadmahdi Honarmand, Onur Cezmi Mutlu, Parnian Azizian, Saimourya Surabhi, Dennis P. Wall
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.23257">FIESTA: Fisher Information-based Efficient Selective Test-time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Robust facial expression recognition in unconstrained, "in-the-wild" environments remains challenging due to significant domain shifts between training and testing distributions. Test-time adaptation (TTA) offers a promising solution by adapting pre-trained models during inference without requiring labeled test data. However, existing TTA approaches typically rely on manually selecting which parameters to update, potentially leading to suboptimal adaptation and high computational costs. This paper introduces a novel Fisher-driven selective adaptation framework that dynamically identifies and updates only the most critical model parameters based on their importance as quantified by Fisher information. By integrating this principled parameter selection approach with temporal consistency constraints, our method enables efficient and effective adaptation specifically tailored for video-based facial expression recognition. Experiments on the challenging AffWild2 benchmark demonstrate that our approach significantly outperforms existing TTA methods, achieving a 7.7% improvement in F1 score over the base model while adapting only 22,000 parameters-more than 20 times fewer than comparable methods. Our ablation studies further reveal that parameter importance can be effectively estimated from minimal data, with sampling just 1-3 frames sufficient for substantial performance gains. The proposed approach not only enhances recognition accuracy but also dramatically reduces computational overhead, making test-time adaptation more practical for real-world affective computing applications.
<div id='section'>Paperid: <span id='pid'>474, <a href='https://arxiv.org/pdf/2503.15889.pdf' target='_blank'>https://arxiv.org/pdf/2503.15889.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Cynthia Dong, Hong Jia, Young D. Kwon, Georgios Rizos, Cecilia Mascolo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.15889">LeanTTA: A Backpropagation-Free and Stateless Approach to Quantized Test-Time Adaptation on Edge Devices</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While there are many advantages to deploying machine learning models on edge devices, the resource constraints of mobile platforms, the dynamic nature of the environment, and differences between the distribution of training versus in-the-wild data make such deployments challenging. Current test-time adaptation methods are often memory-intensive and not designed to be quantization-compatible or deployed on low-resource devices. To address these challenges, we present LeanTTA, a novel backpropagation-free and stateless framework for quantized test-time adaptation tailored to edge devices. Our approach minimizes computational costs by dynamically updating normalization statistics without backpropagation, which frees LeanTTA from the common pitfall of relying on large batches and historical data, making our method robust to realistic deployment scenarios. Our approach is the first to enable further computational gains by combining partial adaptation with quantized module fusion. We validate our framework across sensor modalities, demonstrating significant improvements over state-of-the-art TTA methods, including a 15.7% error reduction, peak memory usage of only 11.2MB for ResNet18, and fast adaptation within an order-of-magnitude of normal inference speeds on-device. LeanTTA provides a robust solution for achieving the right trade offs between accuracy and system efficiency in edge deployments, addressing the unique challenges posed by limited data and varied operational conditions.
<div id='section'>Paperid: <span id='pid'>475, <a href='https://arxiv.org/pdf/2412.01154.pdf' target='_blank'>https://arxiv.org/pdf/2412.01154.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Trung-Hieu Hoang, Duc Minh Vo, Minh N. Do
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.01154">R.I.P.: A Simple Black-box Attack on Continual Test-time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) has emerged as a promising solution to tackle the continual domain shift in machine learning by allowing model parameters to change at test time, via self-supervised learning on unlabeled testing data. At the same time, it unfortunately opens the door to unforeseen vulnerabilities for degradation over time. Through a simple theoretical continual TTA model, we successfully identify a risk in the sampling process of testing data that could easily degrade the performance of a continual TTA model. We name this risk as Reusing of Incorrect Prediction (RIP) that TTA attackers can employ or as a result of the unintended query from general TTA users. The risk posed by RIP is also highly realistic, as it does not require prior knowledge of model parameters or modification of testing samples. This simple requirement makes RIP as the first black-box TTA attack algorithm that stands out from existing white-box attempts. We extensively benchmark the performance of the most recent continual TTA approaches when facing the RIP attack, providing insights on its success, and laying out potential roadmaps that could enhance the resilience of future continual TTA systems.
<div id='section'>Paperid: <span id='pid'>476, <a href='https://arxiv.org/pdf/2409.00641.pdf' target='_blank'>https://arxiv.org/pdf/2409.00641.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Masafumi Endo, Tatsunori Taniai, Genya Ishigami
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.00641">Deep Probabilistic Traversability with Test-time Adaptation for Uncertainty-aware Planetary Rover Navigation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traversability assessment of deformable terrain is vital for safe rover navigation on planetary surfaces. Machine learning (ML) is a powerful tool for traversability prediction but faces predictive uncertainty. This uncertainty leads to prediction errors, increasing the risk of wheel slips and immobilization for planetary rovers. To address this issue, we integrate principal approaches to uncertainty handling -- quantification, exploitation, and adaptation -- into a single learning and planning framework for rover navigation. The key concept is \emph{deep probabilistic traversability}, forming the basis of an end-to-end probabilistic ML model that predicts slip distributions directly from rover traverse observations. This probabilistic model quantifies uncertainties in slip prediction and exploits them as traversability costs in path planning. Its end-to-end nature also allows adaptation of pre-trained models with in-situ traverse experience to reduce uncertainties. We perform extensive simulations in synthetic environments that pose representative uncertainties in planetary analog terrains. Experimental results show that our method achieves more robust path planning under novel environmental conditions than existing approaches.
<div id='section'>Paperid: <span id='pid'>477, <a href='https://arxiv.org/pdf/2407.12240.pdf' target='_blank'>https://arxiv.org/pdf/2407.12240.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kien X. Nguyen, Fengchun Qiao, Xi Peng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.12240">Adaptive Cascading Network for Continual Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We study the problem of continual test-time adaption where the goal is to adapt a source pre-trained model to a sequence of unlabelled target domains at test time. Existing methods on test-time training suffer from several limitations: (1) Mismatch between the feature extractor and classifier; (2) Interference between the main and self-supervised tasks; (3) Lack of the ability to quickly adapt to the current distribution. In light of these challenges, we propose a cascading paradigm that simultaneously updates the feature extractor and classifier at test time, mitigating the mismatch between them and enabling long-term model adaptation. The pre-training of our model is structured within a meta-learning framework, thereby minimizing the interference between the main and self-supervised tasks and encouraging fast adaptation in the presence of limited unlabelled data. Additionally, we introduce innovative evaluation metrics, average accuracy and forward transfer, to effectively measure the model's adaptation capabilities in dynamic, real-world scenarios. Extensive experiments and ablation studies demonstrate the superiority of our approach in a range of tasks including image classification, text classification, and speech recognition.
<div id='section'>Paperid: <span id='pid'>478, <a href='https://arxiv.org/pdf/2407.06043.pdf' target='_blank'>https://arxiv.org/pdf/2407.06043.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Puzuo Wang, Wei Yao, Jie Shao, Zhiyi He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.06043">Test-time adaptation for geospatial point cloud semantic segmentation with distinct domain shifts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Domain adaptation (DA) techniques help deep learning models generalize across data shifts for point cloud semantic segmentation (PCSS). Test-time adaptation (TTA) allows direct adaptation of a pre-trained model to unlabeled data during inference stage without access to source data or additional training, avoiding privacy issues and large computational resources. We address TTA for geospatial PCSS by introducing three domain shift paradigms: photogrammetric to airborne LiDAR, airborne to mobile LiDAR, and synthetic to mobile laser scanning. We propose a TTA method that progressively updates batch normalization (BN) statistics with each testing batch. Additionally, a self-supervised learning module optimizes learnable BN affine parameters. Information maximization and reliability-constrained pseudo-labeling improve prediction confidence and supply supervisory signals. Experimental results show our method improves classification accuracy by up to 20\% mIoU, outperforming other methods. For photogrammetric (SensatUrban) to airborne (Hessigheim 3D) adaptation at the inference stage, our method achieves 59.46\% mIoU and 85.97\% OA without retraining or fine-turning.
<div id='section'>Paperid: <span id='pid'>479, <a href='https://arxiv.org/pdf/2403.01344.pdf' target='_blank'>https://arxiv.org/pdf/2403.01344.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Inseop Chung, Kyomin Hwang, Jayeon Yoo, Nojun Kwak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.01344">Mitigating the Bias in the Model for Continual Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual Test-Time Adaptation (CTA) is a challenging task that aims to adapt a source pre-trained model to continually changing target domains. In the CTA setting, a model does not know when the target domain changes, thus facing a drastic change in the distribution of streaming inputs during the test-time. The key challenge is to keep adapting the model to the continually changing target domains in an online manner. We find that a model shows highly biased predictions as it constantly adapts to the chaining distribution of the target data. It predicts certain classes more often than other classes, making inaccurate over-confident predictions. This paper mitigates this issue to improve performance in the CTA scenario. To alleviate the bias issue, we make class-wise exponential moving average target prototypes with reliable target samples and exploit them to cluster the target features class-wisely. Moreover, we aim to align the target distributions to the source distribution by anchoring the target feature to its corresponding source prototype. With extensive experiments, our proposed method achieves noteworthy performance gain when applied on top of existing CTA methods without substantial adaptation time overhead.
<div id='section'>Paperid: <span id='pid'>480, <a href='https://arxiv.org/pdf/2401.00989.pdf' target='_blank'>https://arxiv.org/pdf/2401.00989.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mario DÃ¶bler, Florian Marencke, Robert A. Marsden, Bin Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.00989">Diversity-aware Buffer for Coping with Temporally Correlated Data Streams in Online Test-time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Since distribution shifts are likely to occur after a model's deployment and can drastically decrease the model's performance, online test-time adaptation (TTA) continues to update the model during test-time, leveraging the current test data. In real-world scenarios, test data streams are not always independent and identically distributed (i.i.d.). Instead, they are frequently temporally correlated, making them non-i.i.d. Many existing methods struggle to cope with this scenario. In response, we propose a diversity-aware and category-balanced buffer that can simulate an i.i.d. data stream, even in non-i.i.d. scenarios. Combined with a diversity and entropy-weighted entropy loss, we show that a stable adaptation is possible on a wide range of corruptions and natural domain shifts, based on ImageNet. We achieve state-of-the-art results on most considered benchmarks.
<div id='section'>Paperid: <span id='pid'>481, <a href='https://arxiv.org/pdf/2312.08875.pdf' target='_blank'>https://arxiv.org/pdf/2312.08875.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jayeon Yoo, Dongkwan Lee, Inseop Chung, Donghyun Kim, Nojun Kwak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.08875">What, How, and When Should Object Detectors Update in Continually Changing Test Domains?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>It is a well-known fact that the performance of deep learning models deteriorates when they encounter a distribution shift at test time. Test-time adaptation (TTA) algorithms have been proposed to adapt the model online while inferring test data. However, existing research predominantly focuses on classification tasks through the optimization of batch normalization layers or classification heads, but this approach limits its applicability to various model architectures like Transformers and makes it challenging to apply to other tasks, such as object detection. In this paper, we propose a novel online adaption approach for object detection in continually changing test domains, considering which part of the model to update, how to update it, and when to perform the update. By introducing architecture-agnostic and lightweight adaptor modules and only updating these while leaving the pre-trained backbone unchanged, we can rapidly adapt to new test domains in an efficient way and prevent catastrophic forgetting. Furthermore, we present a practical and straightforward class-wise feature aligning method for object detection to resolve domain shifts. Additionally, we enhance efficiency by determining when the model is sufficiently adapted or when additional adaptation is needed due to changes in the test distribution. Our approach surpasses baselines on widely used benchmarks, achieving improvements of up to 4.9\%p and 7.9\%p in mAP for COCO $\rightarrow$ COCO-corrupted and SHIFT, respectively, while maintaining about 20 FPS or higher.
<div id='section'>Paperid: <span id='pid'>482, <a href='https://arxiv.org/pdf/2311.18520.pdf' target='_blank'>https://arxiv.org/pdf/2311.18520.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Martin Wimpff, Mario DÃ¶bler, Bin Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.18520">Calibration-free online test-time adaptation for electroencephalography motor imagery decoding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Providing a promising pathway to link the human brain with external devices, Brain-Computer Interfaces (BCIs) have seen notable advancements in decoding capabilities, primarily driven by increasingly sophisticated techniques, especially deep learning. However, achieving high accuracy in real-world scenarios remains a challenge due to the distribution shift between sessions and subjects. In this paper we will explore the concept of online test-time adaptation (OTTA) to continuously adapt the model in an unsupervised fashion during inference time. Our approach guarantees the preservation of privacy by eliminating the requirement to access the source data during the adaptation process. Additionally, OTTA achieves calibration-free operation by not requiring any session- or subject-specific data. We will investigate the task of electroencephalography (EEG) motor imagery decoding using a lightweight architecture together with different OTTA techniques like alignment, adaptive batch normalization, and entropy minimization. We examine two datasets and three distinct data settings for a comprehensive analysis. Our adaptation methods produce state-of-the-art results, potentially instigating a shift in transfer learning for BCI decoding towards online adaptation.
<div id='section'>Paperid: <span id='pid'>483, <a href='https://arxiv.org/pdf/2310.20327.pdf' target='_blank'>https://arxiv.org/pdf/2310.20327.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guoliang Lin, Hanjiang Lai, Yan Pan, Jian Yin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.20327">Improving Entropy-Based Test-Time Adaptation from a Clustering View</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Domain shift is a common problem in the realistic world, where training data and test data follow different data distributions. To deal with this problem, fully test-time adaptation (TTA) leverages the unlabeled data encountered during test time to adapt the model. In particular, entropy-based TTA (EBTTA) methods, which minimize the prediction's entropy on test samples, have shown great success. In this paper, we introduce a new clustering perspective on the EBTTA. It is an iterative algorithm: 1) in the assignment step, the forward process of the EBTTA models is the assignment of labels for these test samples, and 2) in the updating step, the backward process is the update of the model via the assigned samples. This new perspective allows us to explore how entropy minimization influences test-time adaptation. Accordingly, this observation can guide us to put forward the improvement of EBTTA. We propose to improve EBTTA from the assignment step and the updating step, where robust label assignment, similarity-preserving constraint, sample selection, and gradient accumulation are proposed to explicitly utilize more information. Experimental results demonstrate that our method can achieve consistent improvements on various datasets. Code is provided in the supplementary material.
<div id='section'>Paperid: <span id='pid'>484, <a href='https://arxiv.org/pdf/2310.11766.pdf' target='_blank'>https://arxiv.org/pdf/2310.11766.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yanyu Ye, Zhenxi Zhang, Wei Wei, Chunna Tian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.11766">Multi Task Consistency Guided Source-Free Test-Time Domain Adaptation Medical Image Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Source-free test-time adaptation for medical image segmentation aims to enhance the adaptability of segmentation models to diverse and previously unseen test sets of the target domain, which contributes to the generalizability and robustness of medical image segmentation models without access to the source domain. Ensuring consistency between target edges and paired inputs is crucial for test-time adaptation. To improve the performance of test-time domain adaptation, we propose a multi task consistency guided source-free test-time domain adaptation medical image segmentation method which ensures the consistency of the local boundary predictions and the global prototype representation. Specifically, we introduce a local boundary consistency constraint method that explores the relationship between tissue region segmentation and tissue boundary localization tasks. Additionally, we propose a global feature consistency constraint toto enhance the intra-class compactness. We conduct extensive experiments on the segmentation of benchmark fundus images. Compared to prediction directly by the source domain model, the segmentation Dice score is improved by 6.27\% and 0.96\% in RIM-ONE-r3 and Drishti GS datasets, respectively. Additionally, the results of experiments demonstrate that our proposed method outperforms existing competitive domain adaptation segmentation algorithms.
<div id='section'>Paperid: <span id='pid'>485, <a href='https://arxiv.org/pdf/2305.18831.pdf' target='_blank'>https://arxiv.org/pdf/2305.18831.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>ThÃ©o Gnassounou, RÃ©mi Flamary, Alexandre Gramfort
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.18831">Convolutional Monge Mapping Normalization for learning on sleep data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In many machine learning applications on signals and biomedical data, especially electroencephalogram (EEG), one major challenge is the variability of the data across subjects, sessions, and hardware devices. In this work, we propose a new method called Convolutional Monge Mapping Normalization (CMMN), which consists in filtering the signals in order to adapt their power spectrum density (PSD) to a Wasserstein barycenter estimated on training data. CMMN relies on novel closed-form solutions for optimal transport mappings and barycenters and provides individual test time adaptation to new data without needing to retrain a prediction model. Numerical experiments on sleep EEG data show that CMMN leads to significant and consistent performance gains independent from the neural network architecture when adapting between subjects, sessions, and even datasets collected with different hardware. Notably our performance gain is on par with much more numerically intensive Domain Adaptation (DA) methods and can be used in conjunction with those for even better performances.
<div id='section'>Paperid: <span id='pid'>486, <a href='https://arxiv.org/pdf/2303.10536.pdf' target='_blank'>https://arxiv.org/pdf/2303.10536.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Onur Cezmi Mutlu, Mohammadmahdi Honarmand, Saimourya Surabhi, Dennis P. Wall
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.10536">TempT: Temporal consistency for Test-time adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We introduce Temporal consistency for Test-time adaptation (TempT) a novel method for test-time adaptation on videos through the use of temporal coherence of predictions across sequential frames as a self-supervision signal. TempT is an approach with broad potential applications in computer vision tasks including facial expression recognition (FER) in videos. We evaluate TempT performance on the AffWild2 dataset. Our approach focuses solely on the unimodal visual aspect of the data and utilizes a popular 2D CNN backbone in contrast to larger sequential or attention-based models used in other approaches. Our preliminary experimental results demonstrate that TempT has competitive performance compared to the previous years reported performances and its efficacy provides a compelling proof-of-concept for its use in various real-world applications.
<div id='section'>Paperid: <span id='pid'>487, <a href='https://arxiv.org/pdf/2302.06378.pdf' target='_blank'>https://arxiv.org/pdf/2302.06378.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gabriela Csurka, Riccardo Volpi, Boris Chidlovskii
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.06378">Semantic Image Segmentation: Two Decades of Research</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Semantic image segmentation (SiS) plays a fundamental role in a broad variety of computer vision applications, providing key information for the global understanding of an image. This survey is an effort to summarize two decades of research in the field of SiS, where we propose a literature review of solutions starting from early historical methods followed by an overview of more recent deep learning methods including the latest trend of using transformers. We complement the review by discussing particular cases of the weak supervision and side machine learning techniques that can be used to improve the semantic segmentation such as curriculum, incremental or self-supervised learning.
  State-of-the-art SiS models rely on a large amount of annotated samples, which are more expensive to obtain than labels for tasks such as image classification. Since unlabeled data is instead significantly cheaper to obtain, it is not surprising that Unsupervised Domain Adaptation (UDA) reached a broad success within the semantic segmentation community. Therefore, a second core contribution of this book is to summarize five years of a rapidly growing field, Domain Adaptation for Semantic Image Segmentation (DASiS) which embraces the importance of semantic segmentation itself and a critical need of adapting segmentation models to new environments. In addition to providing a comprehensive survey on DASiS techniques, we unveil also newer trends such as multi-domain learning, domain generalization, domain incremental learning, test-time adaptation and source-free domain adaptation. Finally, we conclude this survey by describing datasets and benchmarks most widely used in SiS and DASiS and briefly discuss related tasks such as instance and panoptic image segmentation, as well as applications such as medical image segmentation.
<div id='section'>Paperid: <span id='pid'>488, <a href='https://arxiv.org/pdf/2302.05155.pdf' target='_blank'>https://arxiv.org/pdf/2302.05155.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyesu Lim, Byeonggeun Kim, Jaegul Choo, Sungha Choi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.05155">TTN: A Domain-Shift Aware Batch Normalization in Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes a novel batch normalization strategy for test-time adaptation. Recent test-time adaptation methods heavily rely on the modified batch normalization, i.e., transductive batch normalization (TBN), which calculates the mean and the variance from the current test batch rather than using the running mean and variance obtained from the source data, i.e., conventional batch normalization (CBN). Adopting TBN that employs test batch statistics mitigates the performance degradation caused by the domain shift. However, re-estimating normalization statistics using test data depends on impractical assumptions that a test batch should be large enough and be drawn from i.i.d. stream, and we observed that the previous methods with TBN show critical performance drop without the assumptions. In this paper, we identify that CBN and TBN are in a trade-off relationship and present a new test-time normalization (TTN) method that interpolates the statistics by adjusting the importance between CBN and TBN according to the domain-shift sensitivity of each BN layer. Our proposed TTN improves model robustness to shifted domains across a wide range of batch sizes and in various realistic evaluation scenarios. TTN is widely applicable to other test-time adaptation methods that rely on updating model parameters via backpropagation. We demonstrate that adopting TTN further improves their performance and achieves state-of-the-art performance in various standard benchmarks.
<div id='section'>Paperid: <span id='pid'>489, <a href='https://arxiv.org/pdf/2211.13081.pdf' target='_blank'>https://arxiv.org/pdf/2211.13081.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mario DÃ¶bler, Robert A. Marsden, Bin Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.13081">Robust Mean Teacher for Continual and Gradual Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Since experiencing domain shifts during test-time is inevitable in practice, test-time adaption (TTA) continues to adapt the model after deployment. Recently, the area of continual and gradual test-time adaptation (TTA) emerged. In contrast to standard TTA, continual TTA considers not only a single domain shift, but a sequence of shifts. Gradual TTA further exploits the property that some shifts evolve gradually over time. Since in both settings long test sequences are present, error accumulation needs to be addressed for methods relying on self-training. In this work, we propose and show that in the setting of TTA, the symmetric cross-entropy is better suited as a consistency loss for mean teachers compared to the commonly used cross-entropy. This is justified by our analysis with respect to the (symmetric) cross-entropy's gradient properties. To pull the test feature space closer to the source domain, where the pre-trained model is well posed, contrastive learning is leveraged. Since applications differ in their requirements, we address several settings, including having source data available and the more challenging source-free setting. We demonstrate the effectiveness of our proposed method 'robust mean teacher' (RMT) on the continual and gradual corruption benchmarks CIFAR10C, CIFAR100C, and Imagenet-C. We further consider ImageNet-R and propose a new continual DomainNet-126 benchmark. State-of-the-art results are achieved on all benchmarks.
<div id='section'>Paperid: <span id='pid'>490, <a href='https://arxiv.org/pdf/2204.09847.pdf' target='_blank'>https://arxiv.org/pdf/2204.09847.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lu Zhang, Siqi Zhang, Xu Yang, Hong Qiao, Zhiyong Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2204.09847">Unseen Object Instance Segmentation with Fully Test-time RGB-D Embeddings Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Segmenting unseen objects is a crucial ability for the robot since it may encounter new environments during the operation. Recently, a popular solution is leveraging RGB-D features of large-scale synthetic data and directly applying the model to unseen real-world scenarios. However, the domain shift caused by the sim2real gap is inevitable, posing a crucial challenge to the segmentation model. In this paper, we emphasize the adaptation process across sim2real domains and model it as a learning problem on the BatchNorm parameters of a simulation-trained model. Specifically, we propose a novel non-parametric entropy objective, which formulates the learning objective for the test-time adaptation in an open-world manner. Then, a cross-modality knowledge distillation objective is further designed to encourage the test-time knowledge transfer for feature enhancement. Our approach can be efficiently implemented with only test images, without requiring annotations or revisiting the large-scale synthetic training data. Besides significant time savings, the proposed method consistently improves segmentation results on the overlap and boundary metrics, achieving state-of-the-art performance on unseen object instance segmentation.
<div id='section'>Paperid: <span id='pid'>491, <a href='https://arxiv.org/pdf/2510.05635.pdf' target='_blank'>https://arxiv.org/pdf/2510.05635.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexander Murphy, Michal Danilowski, Soumyajit Chatterjee, Abhirup Ghosh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.05635">NEO: No-Optimization Test-Time Adaptation through Latent Re-Centering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-Time Adaptation (TTA) methods are often computationally expensive, require a large amount of data for effective adaptation, or are brittle to hyperparameters. Based on a theoretical foundation of the geometry of the latent space, we are able to significantly improve the alignment between source and distribution-shifted samples by re-centering target data embeddings at the origin. This insight motivates NEO -- a hyperparameter-free fully TTA method, that adds no significant compute compared to vanilla inference. NEO is able to improve the classification accuracy of ViT-Base on ImageNet-C from 55.6% to 59.2% after adapting on just one batch of 64 samples. When adapting on 512 samples NEO beats all 7 TTA methods we compare against on ImageNet-C, ImageNet-R and ImageNet-S and beats 6/7 on CIFAR-10-C, while using the least amount of compute. NEO performs well on model calibration metrics and additionally is able to adapt from 1 class to improve accuracy on 999 other classes in ImageNet-C. On Raspberry Pi and Jetson Orin Nano devices, NEO reduces inference time by 63% and memory usage by 9% compared to baselines. Our results based on 3 ViT architectures and 4 datasets show that NEO can be used efficiently and effectively for TTA.
<div id='section'>Paperid: <span id='pid'>492, <a href='https://arxiv.org/pdf/2510.05635.pdf' target='_blank'>https://arxiv.org/pdf/2510.05635.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alexander Murphy, Michal Danilowski, Soumyajit Chatterjee, Abhirup Ghosh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.05635">NEO: No-Optimization Test-Time Adaptation through Latent Re-Centering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-Time Adaptation (TTA) methods are often computationally expensive, require a large amount of data for effective adaptation, or are brittle to hyperparameters. Based on a theoretical foundation of the geometry of the latent space, we are able to significantly improve the alignment between source and distribution-shifted samples by re-centering target data embeddings at the origin. This insight motivates NEO -- a hyperparameter-free fully TTA method, that adds no significant compute compared to vanilla inference. NEO is able to improve the classification accuracy of ViT-Base on ImageNet-C from 55.6% to 59.2% after adapting on just one batch of 64 samples. When adapting on 512 samples NEO beats all 7 TTA methods we compare against on ImageNet-C, ImageNet-R and ImageNet-S and beats 6/7 on CIFAR-10-C, while using the least amount of compute. NEO performs well on model calibration metrics and additionally is able to adapt from 1 class to improve accuracy on 999 other classes in ImageNet-C. On Raspberry Pi and Jetson Orin Nano devices, NEO reduces inference time by 63% and memory usage by 9% compared to baselines. Our results based on 3 ViT architectures and 4 datasets show that NEO can be used efficiently and effectively for TTA.
<div id='section'>Paperid: <span id='pid'>493, <a href='https://arxiv.org/pdf/2510.04234.pdf' target='_blank'>https://arxiv.org/pdf/2510.04234.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Runhan Huang, Haldun Balim, Heng Yang, Yilun Du
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.04234">Flexible Locomotion Learning with Diffusion Model Predictive Control</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Legged locomotion demands controllers that are both robust and adaptable, while remaining compatible with task and safety considerations. However, model-free reinforcement learning (RL) methods often yield a fixed policy that can be difficult to adapt to new behaviors at test time. In contrast, Model Predictive Control (MPC) provides a natural approach to flexible behavior synthesis by incorporating different objectives and constraints directly into its optimization process. However, classical MPC relies on accurate dynamics models, which are often difficult to obtain in complex environments and typically require simplifying assumptions. We present Diffusion-MPC, which leverages a learned generative diffusion model as an approximate dynamics prior for planning, enabling flexible test-time adaptation through reward and constraint based optimization. Diffusion-MPC jointly predicts future states and actions; at each reverse step, we incorporate reward planning and impose constraint projection, yielding trajectories that satisfy task objectives while remaining within physical limits. To obtain a planning model that adapts beyond imitation pretraining, we introduce an interactive training algorithm for diffusion based planner: we execute our reward-and-constraint planner in environment, then filter and reweight the collected trajectories by their realized returns before updating the denoiser. Our design enables strong test-time adaptability, allowing the planner to adjust to new reward specifications without retraining. We validate Diffusion-MPC on real world, demonstrating strong locomotion and flexible adaptation.
<div id='section'>Paperid: <span id='pid'>494, <a href='https://arxiv.org/pdf/2510.04234.pdf' target='_blank'>https://arxiv.org/pdf/2510.04234.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Runhan Huang, Haldun Balim, Heng Yang, Yilun Du
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.04234">Flexible Locomotion Learning with Diffusion Model Predictive Control</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Legged locomotion demands controllers that are both robust and adaptable, while remaining compatible with task and safety considerations. However, model-free reinforcement learning (RL) methods often yield a fixed policy that can be difficult to adapt to new behaviors at test time. In contrast, Model Predictive Control (MPC) provides a natural approach to flexible behavior synthesis by incorporating different objectives and constraints directly into its optimization process. However, classical MPC relies on accurate dynamics models, which are often difficult to obtain in complex environments and typically require simplifying assumptions. We present Diffusion-MPC, which leverages a learned generative diffusion model as an approximate dynamics prior for planning, enabling flexible test-time adaptation through reward and constraint based optimization. Diffusion-MPC jointly predicts future states and actions; at each reverse step, we incorporate reward planning and impose constraint projection, yielding trajectories that satisfy task objectives while remaining within physical limits. To obtain a planning model that adapts beyond imitation pretraining, we introduce an interactive training algorithm for diffusion based planner: we execute our reward-and-constraint planner in environment, then filter and reweight the collected trajectories by their realized returns before updating the denoiser. Our design enables strong test-time adaptability, allowing the planner to adjust to new reward specifications without retraining. We validate Diffusion-MPC on real world, demonstrating strong locomotion and flexible adaptation.
<div id='section'>Paperid: <span id='pid'>495, <a href='https://arxiv.org/pdf/2510.03574.pdf' target='_blank'>https://arxiv.org/pdf/2510.03574.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mehmet Onurcan Kaya, Desmond Elliott, Dim P. Papadopoulos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.03574">Efficient Test-Time Scaling for Small Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Small Vision-Language Models (VLMs) provide a computationally efficient alternative to larger models, at the cost of weaker generalization abilities and downstream task performance. These shortcomings could be addressed by test-time scaling techniques, but existing methods are typically computationally demanding, contradicting the resource-efficient design goals of small models. To address these limitations, we propose two novel and efficient test-time scaling strategies that leverage the model-internal features rather than external supervision: (i) Test-Time Augmentation (TTAug), which generates multiple augmented inputs and aggregates outputs at the token level without parameter updates, and (ii) Test-Time Adaptation (TTAdapt), which adapts model parameters during inference using consensus-based pseudolabels from TTAug. Through extensive experiments across nine benchmarks, we demonstrate consistent performance improvements while maintaining computational efficiency suitable for resource-constrained environments. The generality of our approach is demonstrated both within models at different scales and across different VLMs without additional tuning.
<div id='section'>Paperid: <span id='pid'>496, <a href='https://arxiv.org/pdf/2510.03574.pdf' target='_blank'>https://arxiv.org/pdf/2510.03574.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mehmet Onurcan Kaya, Desmond Elliott, Dim P. Papadopoulos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.03574">Efficient Test-Time Scaling for Small Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Small Vision-Language Models (VLMs) provide a computationally efficient alternative to larger models, at the cost of weaker generalization abilities and downstream task performance. These shortcomings could be addressed by test-time scaling techniques, but existing methods are typically computationally demanding, contradicting the resource-efficient design goals of small models. To address these limitations, we propose two novel and efficient test-time scaling strategies that leverage the model-internal features rather than external supervision: (i) Test-Time Augmentation (TTAug), which generates multiple augmented inputs and aggregates outputs at the token level without parameter updates, and (ii) Test-Time Adaptation (TTAdapt), which adapts model parameters during inference using consensus-based pseudolabels from TTAug. Through extensive experiments across nine benchmarks, we demonstrate consistent performance improvements while maintaining computational efficiency suitable for resource-constrained environments. The generality of our approach is demonstrated both within models at different scales and across different VLMs without additional tuning.
<div id='section'>Paperid: <span id='pid'>497, <a href='https://arxiv.org/pdf/2509.06974.pdf' target='_blank'>https://arxiv.org/pdf/2509.06974.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xueyi Wang, Elisabeth Wilhelm
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.06974">Individualized and Interpretable Sleep Forecasting via a Two-Stage Adaptive Spatial-Temporal Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Sleep quality significantly impacts well-being. Therefore, healthcare providers and individuals need accessible and reliable forecasting tools for preventive interventions. This paper introduces an interpretable, individualized two-stage adaptive spatial-temporal model for predicting sleep quality scores. Our proposed framework combines multi-scale convolutional layers to model spatial interactions across multiple input variables, recurrent layers and attention mechanisms to capture long-term temporal dependencies, and a two-stage domain adaptation strategy to enhance generalization. The first adaptation stage is applied during training to mitigate overfitting on the training set. In the second stage, a source-free test-time adaptation mechanism is employed to adapt the model to new users without requiring labels. We conducted various experiments with five input window sizes (3, 5, 7, 9, and 11 days) and five prediction window sizes (1, 3, 5, 7, and 9 days). Our model consistently outperformed time series forecasting baseline approaches, including Long Short-Term Memory (LSTM), Informer, PatchTST, and TimesNet. The best performance was achieved with a three-day input window and a one-day prediction window, yielding a root mean square error (RMSE) of 0.216. Furthermore, the model demonstrated good predictive performance even for longer forecasting horizons (e.g, with a 0.257 RMSE for a three-day prediction window), highlighting its practical utility for real-world applications. We also conducted an explainability analysis to examine how different features influence sleep quality. These findings proved that the proposed framework offers a robust, adaptive, and explainable solution for personalized sleep forecasting using sparse data from commercial wearable devices.
<div id='section'>Paperid: <span id='pid'>498, <a href='https://arxiv.org/pdf/2509.06974.pdf' target='_blank'>https://arxiv.org/pdf/2509.06974.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xueyi Wang, Elisabeth Wilhelm
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.06974">Individualized and Interpretable Sleep Forecasting via a Two-Stage Adaptive Spatial-Temporal Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Sleep quality significantly impacts well-being. Therefore, healthcare providers and individuals need accessible and reliable forecasting tools for preventive interventions. This paper introduces an interpretable, individualized two-stage adaptive spatial-temporal model for predicting sleep quality scores. Our proposed framework combines multi-scale convolutional layers to model spatial interactions across multiple input variables, recurrent layers and attention mechanisms to capture long-term temporal dependencies, and a two-stage domain adaptation strategy to enhance generalization. The first adaptation stage is applied during training to mitigate overfitting on the training set. In the second stage, a source-free test-time adaptation mechanism is employed to adapt the model to new users without requiring labels. We conducted various experiments with five input window sizes (3, 5, 7, 9, and 11 days) and five prediction window sizes (1, 3, 5, 7, and 9 days). Our model consistently outperformed time series forecasting baseline approaches, including Long Short-Term Memory (LSTM), Informer, PatchTST, and TimesNet. The best performance was achieved with a three-day input window and a one-day prediction window, yielding a root mean square error (RMSE) of 0.216. Furthermore, the model demonstrated good predictive performance even for longer forecasting horizons (e.g, with a 0.257 RMSE for a three-day prediction window), highlighting its practical utility for real-world applications. We also conducted an explainability analysis to examine how different features influence sleep quality. These findings proved that the proposed framework offers a robust, adaptive, and explainable solution for personalized sleep forecasting using sparse data from commercial wearable devices.
<div id='section'>Paperid: <span id='pid'>499, <a href='https://arxiv.org/pdf/2509.02982.pdf' target='_blank'>https://arxiv.org/pdf/2509.02982.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hritik Arasu, Faisal R Jahangiri
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.02982">StableSleep: Source-Free Test-Time Adaptation for Sleep Staging with Lightweight Safety Rails</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Sleep staging models often degrade when deployed on patients with unseen physiology or recording conditions. We propose a streaming, source-free test-time adaptation (TTA) recipe that combines entropy minimization (Tent) with Batch-Norm statistic refresh and two safety rails: an entropy gate to pause adaptation on uncertain windows and an EMA-based reset to reel back drift. On Sleep-EDF Expanded, using single-lead EEG (Fpz-Cz, 100 Hz, 30s epochs; R&K to AASM mapping), we show consistent gains over a frozen baseline at seconds-level latency and minimal memory, reporting per-stage metrics and Cohen's k. The method is model-agnostic, requires no source data or patient calibration, and is practical for on-device or bedside use.
<div id='section'>Paperid: <span id='pid'>500, <a href='https://arxiv.org/pdf/2509.02982.pdf' target='_blank'>https://arxiv.org/pdf/2509.02982.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hritik Arasu, Faisal R Jahangiri
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.02982">StableSleep: Source-Free Test-Time Adaptation for Sleep Staging with Lightweight Safety Rails</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Sleep staging models often degrade when deployed on patients with unseen physiology or recording conditions. We propose a streaming, source-free test-time adaptation (TTA) recipe that combines entropy minimization (Tent) with Batch-Norm statistic refresh and two safety rails: an entropy gate to pause adaptation on uncertain windows and an EMA-based reset to reel back drift. On Sleep-EDF Expanded, using single-lead EEG (Fpz-Cz, 100 Hz, 30s epochs; R&K to AASM mapping), we show consistent gains over a frozen baseline at seconds-level latency and minimal memory, reporting per-stage metrics and Cohen's k. The method is model-agnostic, requires no source data or patient calibration, and is practical for on-device or bedside use.
<div id='section'>Paperid: <span id='pid'>501, <a href='https://arxiv.org/pdf/2508.00442.pdf' target='_blank'>https://arxiv.org/pdf/2508.00442.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiale Zhou, Wenhan Wang, Shikun Li, Xiaolei Qu, Xin Guo, Yizhong Liu, Wenzhong Tang, Xun Lin, Yefeng Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.00442">TopoTTA: Topology-Enhanced Test-Time Adaptation for Tubular Structure Segmentation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Tubular structure segmentation (TSS) is important for various applications, such as hemodynamic analysis and route navigation. Despite significant progress in TSS, domain shifts remain a major challenge, leading to performance degradation in unseen target domains. Unlike other segmentation tasks, TSS is more sensitive to domain shifts, as changes in topological structures can compromise segmentation integrity, and variations in local features distinguishing foreground from background (e.g., texture and contrast) may further disrupt topological continuity. To address these challenges, we propose Topology-enhanced Test-Time Adaptation (TopoTTA), the first test-time adaptation framework designed specifically for TSS. TopoTTA consists of two stages: Stage 1 adapts models to cross-domain topological discrepancies using the proposed Topological Meta Difference Convolutions (TopoMDCs), which enhance topological representation without altering pre-trained parameters; Stage 2 improves topological continuity by a novel Topology Hard sample Generation (TopoHG) strategy and prediction alignment on hard samples with pseudo-labels in the generated pseudo-break regions. Extensive experiments across four scenarios and ten datasets demonstrate TopoTTA's effectiveness in handling topological distribution shifts, achieving an average improvement of 31.81% in clDice. TopoTTA also serves as a plug-and-play TTA solution for CNN-based TSS models.
<div id='section'>Paperid: <span id='pid'>502, <a href='https://arxiv.org/pdf/2507.06973.pdf' target='_blank'>https://arxiv.org/pdf/2507.06973.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiyuan Dai, Sibei Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.06973">Free on the Fly: Enhancing Flexibility in Test-Time Adaptation with Online EM</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Vision-Language Models (VLMs) have become prominent in open-world image recognition for their strong generalization abilities. Yet, their effectiveness in practical applications is compromised by domain shifts and distributional changes, especially when test data distributions diverge from training data. Therefore, the paradigm of test-time adaptation (TTA) has emerged, enabling the use of online off-the-shelf data at test time, supporting independent sample predictions, and eliminating reliance on test annotations. Traditional TTA methods, however, often rely on costly training or optimization processes, or make unrealistic assumptions about accessing or storing historical training and test data. Instead, this study proposes FreeTTA, a training-free and universally available method that makes no assumptions, to enhance the flexibility of TTA. More importantly, FreeTTA is the first to explicitly model the test data distribution, enabling the use of intrinsic relationships among test samples to enhance predictions of individual samples without simultaneous access--a direction not previously explored. FreeTTA achieves these advantages by introducing an online EM algorithm that utilizes zero-shot predictions from VLMs as priors to iteratively compute the posterior probabilities of each online test sample and update parameters. Experiments demonstrate that FreeTTA achieves stable and significant improvements compared to state-of-the-art methods across 15 datasets in both cross-domain and out-of-distribution settings.
<div id='section'>Paperid: <span id='pid'>503, <a href='https://arxiv.org/pdf/2505.11654.pdf' target='_blank'>https://arxiv.org/pdf/2505.11654.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuhang Liu, Yingxue Zhang, Xin Zhang, Ling Tian, Yanhua Li, Jun Luo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.11654">UrbanMind: Urban Dynamics Prediction with Multifaceted Spatial-Temporal Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Understanding and predicting urban dynamics is crucial for managing transportation systems, optimizing urban planning, and enhancing public services. While neural network-based approaches have achieved success, they often rely on task-specific architectures and large volumes of data, limiting their ability to generalize across diverse urban scenarios. Meanwhile, Large Language Models (LLMs) offer strong reasoning and generalization capabilities, yet their application to spatial-temporal urban dynamics remains underexplored. Existing LLM-based methods struggle to effectively integrate multifaceted spatial-temporal data and fail to address distributional shifts between training and testing data, limiting their predictive reliability in real-world applications. To bridge this gap, we propose UrbanMind, a novel spatial-temporal LLM framework for multifaceted urban dynamics prediction that ensures both accurate forecasting and robust generalization. At its core, UrbanMind introduces Muffin-MAE, a multifaceted fusion masked autoencoder with specialized masking strategies that capture intricate spatial-temporal dependencies and intercorrelations among multifaceted urban dynamics. Additionally, we design a semantic-aware prompting and fine-tuning strategy that encodes spatial-temporal contextual details into prompts, enhancing LLMs' ability to reason over spatial-temporal patterns. To further improve generalization, we introduce a test time adaptation mechanism with a test data reconstructor, enabling UrbanMind to dynamically adjust to unseen test data by reconstructing LLM-generated embeddings. Extensive experiments on real-world urban datasets across multiple cities demonstrate that UrbanMind consistently outperforms state-of-the-art baselines, achieving high accuracy and robust generalization, even in zero-shot settings.
<div id='section'>Paperid: <span id='pid'>504, <a href='https://arxiv.org/pdf/2504.10149.pdf' target='_blank'>https://arxiv.org/pdf/2504.10149.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michal Danilowski, Soumyajit Chatterjee, Abhirup Ghosh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.10149">BoTTA: Benchmarking on-device Test Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The performance of deep learning models depends heavily on test samples at runtime, and shifts from the training data distribution can significantly reduce accuracy. Test-time adaptation (TTA) addresses this by adapting models during inference without requiring labeled test data or access to the original training set. While research has explored TTA from various perspectives like algorithmic complexity, data and class distribution shifts, model architectures, and offline versus continuous learning, constraints specific to mobile and edge devices remain underexplored. We propose BoTTA, a benchmark designed to evaluate TTA methods under practical constraints on mobile and edge devices. Our evaluation targets four key challenges caused by limited resources and usage conditions: (i) limited test samples, (ii) limited exposure to categories, (iii) diverse distribution shifts, and (iv) overlapping shifts within a sample. We assess state-of-the-art TTA methods under these scenarios using benchmark datasets and report system-level metrics on a real testbed. Furthermore, unlike prior work, we align with on-device requirements by advocating periodic adaptation instead of continuous inference-time adaptation. Experiments reveal key insights: many recent TTA algorithms struggle with small datasets, fail to generalize to unseen categories, and depend on the diversity and complexity of distribution shifts. BoTTA also reports device-specific resource use. For example, while SHOT improves accuracy by $2.25\times$ with $512$ adaptation samples, it uses $1.08\times$ peak memory on Raspberry Pi versus the base model. BoTTA offers actionable guidance for TTA in real-world, resource-constrained deployments.
<div id='section'>Paperid: <span id='pid'>505, <a href='https://arxiv.org/pdf/2502.20677.pdf' target='_blank'>https://arxiv.org/pdf/2502.20677.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Youbing Hu, Yun Cheng, Zimu Zhou, Anqi Lu, Zhiqiang Cao, Zhijun Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.20677">FoCTTA: Low-Memory Continual Test-Time Adaptation with Focus</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual adaptation to domain shifts at test time (CTTA) is crucial for enhancing the intelligence of deep learning enabled IoT applications. However, prevailing TTA methods, which typically update all batch normalization (BN) layers, exhibit two memory inefficiencies. First, the reliance on BN layers for adaptation necessitates large batch sizes, leading to high memory usage. Second, updating all BN layers requires storing the activations of all BN layers for backpropagation, exacerbating the memory demand. Both factors lead to substantial memory costs, making existing solutions impractical for IoT devices. In this paper, we present FoCTTA, a low-memory CTTA strategy. The key is to automatically identify and adapt a few drift-sensitive representation layers, rather than blindly update all BN layers. The shift from BN to representation layers eliminates the need for large batch sizes. Also, by updating adaptation-critical layers only, FoCTTA avoids storing excessive activations. This focused adaptation approach ensures that FoCTTA is not only memory-efficient but also maintains effective adaptation. Evaluations show that FoCTTA improves the adaptation accuracy over the state-of-the-arts by 4.5%, 4.9%, and 14.8% on CIFAR10-C, CIFAR100-C, and ImageNet-C under the same memory constraints. Across various batch sizes, FoCTTA reduces the memory usage by 3-fold on average, while improving the accuracy by 8.1%, 3.6%, and 0.2%, respectively, on the three datasets.
<div id='section'>Paperid: <span id='pid'>506, <a href='https://arxiv.org/pdf/2501.18864.pdf' target='_blank'>https://arxiv.org/pdf/2501.18864.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aodi Li, Liansheng Zhuang, Xiao Long, Minghong Yao, Shafei Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.18864">Test-time Loss Landscape Adaptation for Zero-Shot Generalization in Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation of pre-trained vision-language models has emerged as a technique for tackling distribution shifts during the test time. Although existing methods, especially those based on Test-time Prompt Tuning (TPT), have shown promising results, their high computational cost associated with parameter optimization presents challenges for scalability and practical application. This paper unveils the unnecessary nature of backpropagation in existing methods from a loss landscape perspective. Building on this insight, this paper proposes a simple yet effective framework called Test-time Loss Landscape Adaptation (TLLA). TLLA leverages the relative position between the training minimum and test loss landscapes to guide the adaptation process, avoiding the update of model parameters at test time. Specifically, it mainly consists of two main stages: In the prompt tuning stage, a Sharpness-Aware Prompt Tuning (SAPT) method is introduced to identify the training flat minimum, setting the foundation for the subsequent test-time adaptation; In the test stage, a Sharpness-based Test Sample Selection (STSS) approach is utilized to ensure the alignment of flat minima within the training loss landscape and each augmented test sample's loss landscape. Extensive experiments on both domain generalization and cross-dataset benchmarks demonstrate that TLLA achieves state-of-the-art performances while significantly reducing computational overhead. Notably, TLLA surpasses TPT by an average of 5.32\% and 6.98\% on four ImageNet variant datasets when employing ResNet50 and ViT-B/16 image encoders, respectively. The code will be available soon.
<div id='section'>Paperid: <span id='pid'>507, <a href='https://arxiv.org/pdf/2411.17785.pdf' target='_blank'>https://arxiv.org/pdf/2411.17785.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yong-Yeon Jo, Byeong Tak Lee, Beom Joon Kim, Jeong-Ho Hong, Hak Seung Lee, Joon-myoung Kwon
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.17785">New Test-Time Scenario for Biosignal: Concept and Its Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Online Test-Time Adaptation (OTTA) enhances model robustness by updating pre-trained models with unlabeled data during testing. In healthcare, OTTA is vital for real-time tasks like predicting blood pressure from biosignals, which demand continuous adaptation. We introduce a new test-time scenario with streams of unlabeled samples and occasional labeled samples. Our framework combines supervised and self-supervised learning, employing a dual-queue buffer and weighted batch sampling to balance data types. Experiments show improved accuracy and adaptability under real-world conditions.
<div id='section'>Paperid: <span id='pid'>508, <a href='https://arxiv.org/pdf/2409.08566.pdf' target='_blank'>https://arxiv.org/pdf/2409.08566.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyewon Park, Hyejin Park, Jueun Ko, Dongbo Min
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.08566">Hybrid-TTA: Continual Test-time Adaptation via Dynamic Domain Shift Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual Test Time Adaptation (CTTA) has emerged as a critical approach for bridging the domain gap between the controlled training environments and the real-world scenarios, enhancing model adaptability and robustness. Existing CTTA methods, typically categorized into Full-Tuning (FT) and Efficient-Tuning (ET), struggle with effectively addressing domain shifts. To overcome these challenges, we propose Hybrid-TTA, a holistic approach that dynamically selects instance-wise tuning method for optimal adaptation. Our approach introduces the Dynamic Domain Shift Detection (DDSD) strategy, which identifies domain shifts by leveraging temporal correlations in input sequences and dynamically switches between FT and ET to adapt to varying domain shifts effectively. Additionally, the Masked Image Modeling based Adaptation (MIMA) framework is integrated to ensure domain-agnostic robustness with minimal computational overhead. Our Hybrid-TTA achieves a notable 1.6%p improvement in mIoU on the Cityscapes-to-ACDC benchmark dataset, surpassing previous state-of-the-art methods and offering a robust solution for real-world continual adaptation challenges.
<div id='section'>Paperid: <span id='pid'>509, <a href='https://arxiv.org/pdf/2404.00875.pdf' target='_blank'>https://arxiv.org/pdf/2404.00875.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fenggen Yu, Yiming Qian, Xu Zhang, Francisca Gil-Ureta, Brian Jackson, Eric Bennett, Hao Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.00875">DPA-Net: Structured 3D Abstraction from Sparse Views via Differentiable Primitive Assembly</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a differentiable rendering framework to learn structured 3D abstractions in the form of primitive assemblies from sparse RGB images capturing a 3D object. By leveraging differentiable volume rendering, our method does not require 3D supervision. Architecturally, our network follows the general pipeline of an image-conditioned neural radiance field (NeRF) exemplified by pixelNeRF for color prediction. As our core contribution, we introduce differential primitive assembly (DPA) into NeRF to output a 3D occupancy field in place of density prediction, where the predicted occupancies serve as opacity values for volume rendering. Our network, coined DPA-Net, produces a union of convexes, each as an intersection of convex quadric primitives, to approximate the target 3D object, subject to an abstraction loss and a masking loss, both defined in the image space upon volume rendering. With test-time adaptation and additional sampling and loss designs aimed at improving the accuracy and compactness of the obtained assemblies, our method demonstrates superior performance over state-of-the-art alternatives for 3D primitive abstraction from sparse views.
<div id='section'>Paperid: <span id='pid'>510, <a href='https://arxiv.org/pdf/2401.02113.pdf' target='_blank'>https://arxiv.org/pdf/2401.02113.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fahim Faisal Niloy, Kishor Kumar Bhaumik, Simon S. Woo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.02113">Source-Free Online Domain Adaptive Semantic Segmentation of Satellite Images under Image Degradation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Online adaptation to distribution shifts in satellite image segmentation stands as a crucial yet underexplored problem. In this paper, we address source-free and online domain adaptation, i.e., test-time adaptation (TTA), for satellite images, with the focus on mitigating distribution shifts caused by various forms of image degradation. Towards achieving this goal, we propose a novel TTA approach involving two effective strategies. First, we progressively estimate the global Batch Normalization (BN) statistics of the target distribution with incoming data stream. Leveraging these statistics during inference has the ability to effectively reduce domain gap. Furthermore, we enhance prediction quality by refining the predicted masks using global class centers. Both strategies employ dynamic momentum for fast and stable convergence. Notably, our method is backpropagation-free and hence fast and lightweight, making it highly suitable for on-the-fly adaptation to new domain. Through comprehensive experiments across various domain adaptation scenarios, we demonstrate the robust performance of our method.
<div id='section'>Paperid: <span id='pid'>511, <a href='https://arxiv.org/pdf/2308.15037.pdf' target='_blank'>https://arxiv.org/pdf/2308.15037.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Debapriya Tula, Sujoy Paul, Gagan Madan, Peter Garst, Reeve Ingle, Gaurav Aggarwal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.15037">Is it an i or an l: Test-time Adaptation of Text Line Recognition Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recognizing text lines from images is a challenging problem, especially for handwritten documents due to large variations in writing styles. While text line recognition models are generally trained on large corpora of real and synthetic data, such models can still make frequent mistakes if the handwriting is inscrutable or the image acquisition process adds corruptions, such as noise, blur, compression, etc. Writing style is generally quite consistent for an individual, which can be leveraged to correct mistakes made by such models. Motivated by this, we introduce the problem of adapting text line recognition models during test time. We focus on a challenging and realistic setting where, given only a single test image consisting of multiple text lines, the task is to adapt the model such that it performs better on the image, without any labels. We propose an iterative self-training approach that uses feedback from the language model to update the optical model, with confident self-labels in each iteration. The confidence measure is based on an augmentation mechanism that evaluates the divergence of the prediction of the model in a local region. We perform rigorous evaluation of our method on several benchmark datasets as well as their corrupted versions. Experimental results on multiple datasets spanning multiple scripts show that the proposed adaptation method offers an absolute improvement of up to 8% in character error rate with just a few iterations of self-training at test time.
<div id='section'>Paperid: <span id='pid'>512, <a href='https://arxiv.org/pdf/2307.14735.pdf' target='_blank'>https://arxiv.org/pdf/2307.14735.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Subhadeep Roy, Shankhanil Mitra, Soma Biswas, Rajiv Soundararajan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.14735">Test Time Adaptation for Blind Image Quality Assessment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While the design of blind image quality assessment (IQA) algorithms has improved significantly, the distribution shift between the training and testing scenarios often leads to a poor performance of these methods at inference time. This motivates the study of test time adaptation (TTA) techniques to improve their performance at inference time. Existing auxiliary tasks and loss functions used for TTA may not be relevant for quality-aware adaptation of the pre-trained model. In this work, we introduce two novel quality-relevant auxiliary tasks at the batch and sample levels to enable TTA for blind IQA. In particular, we introduce a group contrastive loss at the batch level and a relative rank loss at the sample level to make the model quality aware and adapt to the target data. Our experiments reveal that even using a small batch of images from the test distribution helps achieve significant improvement in performance by updating the batch normalization statistics of the source model.
<div id='section'>Paperid: <span id='pid'>513, <a href='https://arxiv.org/pdf/2304.10113.pdf' target='_blank'>https://arxiv.org/pdf/2304.10113.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Goirik Chakrabarty, Manogna Sreenivas, Soma Biswas
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.10113">SATA: Source Anchoring and Target Alignment Network for Continual Test Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Adapting a trained model to perform satisfactorily on continually changing testing domains/environments is an important and challenging task. In this work, we propose a novel framework, SATA, which aims to satisfy the following characteristics required for online adaptation: 1) can work seamlessly with different (preferably small) batch sizes to reduce latency; 2) should continue to work well for the source domain; 3) should have minimal tunable hyper-parameters and storage requirements. Given a pre-trained network trained on source domain data, the proposed SATA framework modifies the batch-norm affine parameters using source anchoring based self-distillation. This ensures that the model incorporates the knowledge of the newly encountered domains, without catastrophically forgetting about the previously seen ones. We also propose a source-prototype driven contrastive alignment to ensure natural grouping of the target samples, while maintaining the already learnt semantic information. Extensive evaluation on three benchmark datasets under challenging settings justify the effectiveness of SATA for real-world applications.
<div id='section'>Paperid: <span id='pid'>514, <a href='https://arxiv.org/pdf/2301.13018.pdf' target='_blank'>https://arxiv.org/pdf/2301.13018.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bowen Zhao, Chen Chen, Shu-Tao Xia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.13018">DELTA: degradation-free fully test-time adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fully test-time adaptation aims at adapting a pre-trained model to the test stream during real-time inference, which is urgently required when the test distribution differs from the training distribution. Several efforts have been devoted to improving adaptation performance. However, we find that two unfavorable defects are concealed in the prevalent adaptation methodologies like test-time batch normalization (BN) and self-learning. First, we reveal that the normalization statistics in test-time BN are completely affected by the currently received test samples, resulting in inaccurate estimates. Second, we show that during test-time adaptation, the parameter update is biased towards some dominant classes. In addition to the extensively studied test stream with independent and class-balanced samples, we further observe that the defects can be exacerbated in more complicated test environments, such as (time) dependent or class-imbalanced data. We observe that previous approaches work well in certain scenarios while show performance degradation in others due to their faults. In this paper, we provide a plug-in solution called DELTA for Degradation-freE fuLly Test-time Adaptation, which consists of two components: (i) Test-time Batch Renormalization (TBR), introduced to improve the estimated normalization statistics. (ii) Dynamic Online re-weighTing (DOT), designed to address the class bias within optimization. We investigate various test-time adaptation methods on three commonly used datasets with four scenarios, and a newly introduced real-world dataset. DELTA can help them deal with all scenarios simultaneously, leading to SOTA performance.
<div id='section'>Paperid: <span id='pid'>515, <a href='https://arxiv.org/pdf/2212.04145.pdf' target='_blank'>https://arxiv.org/pdf/2212.04145.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yulu Gan, Yan Bai, Yihang Lou, Xianzheng Ma, Renrui Zhang, Nian Shi, Lin Luo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2212.04145">Decorate the Newcomers: Visual Domain Prompt for Continual Test Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual Test-Time Adaptation (CTTA) aims to adapt the source model to continually changing unlabeled target domains without access to the source data. Existing methods mainly focus on model-based adaptation in a self-training manner, such as predicting pseudo labels for new domain datasets. Since pseudo labels are noisy and unreliable, these methods suffer from catastrophic forgetting and error accumulation when dealing with dynamic data distributions. Motivated by the prompt learning in NLP, in this paper, we propose to learn an image-level visual domain prompt for target domains while having the source model parameters frozen. During testing, the changing target datasets can be adapted to the source model by reformulating the input data with the learned visual prompts. Specifically, we devise two types of prompts, i.e., domains-specific prompts and domains-agnostic prompts, to extract current domain knowledge and maintain the domain-shared knowledge in the continual adaptation. Furthermore, we design a homeostasis-based prompt adaptation strategy to suppress domain-sensitive parameters in domain-invariant prompts to learn domain-shared knowledge more effectively. This transition from the model-dependent paradigm to the model-free one enables us to bypass the catastrophic forgetting and error accumulation problems. Experiments show that our proposed method achieves significant performance gains over state-of-the-art methods on four widely-used benchmarks, including CIFAR-10C, CIFAR-100C, ImageNet-C, and VLCS datasets.
<div id='section'>Paperid: <span id='pid'>516, <a href='https://arxiv.org/pdf/2210.10019.pdf' target='_blank'>https://arxiv.org/pdf/2210.10019.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jun-Kun Wang, Andre Wibisono
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.10019">Towards Understanding GD with Hard and Conjugate Pseudo-labels for Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We consider a setting that a model needs to adapt to a new domain under distribution shifts, given that only unlabeled test samples from the new domain are accessible at test time. A common idea in most of the related works is constructing pseudo-labels for the unlabeled test samples and applying gradient descent (GD) to a loss function with the pseudo-labels. Recently, \cite{GSRK22} propose conjugate labels, which is a new kind of pseudo-labels for self-training at test time. They empirically show that the conjugate label outperforms other ways of pseudo-labeling on many domain adaptation benchmarks. However, provably showing that GD with conjugate labels learns a good classifier for test-time adaptation remains open. In this work, we aim at theoretically understanding GD with hard and conjugate labels for a binary classification problem. We show that for square loss, GD with conjugate labels converges to an $Îµ$-optimal predictor under a Gaussian model for any arbitrarily small $Îµ$, while GD with hard pseudo-labels fails in this task. We also analyze them under different loss functions for the update. Our results shed lights on understanding when and why GD with hard labels or conjugate labels works in test-time adaptation.
<div id='section'>Paperid: <span id='pid'>517, <a href='https://arxiv.org/pdf/2509.08436.pdf' target='_blank'>https://arxiv.org/pdf/2509.08436.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xia Yue, Anfeng Liu, Ning Chen, Chenjia Huang, Hui Liu, Zhou Huang, Leyuan Fang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.08436">HyperTTA: Test-Time Adaptation for Hyperspectral Image Classification under Distribution Shifts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Hyperspectral image (HSI) classification models are highly sensitive to distribution shifts caused by real-world degradations such as noise, blur, compression, and atmospheric effects. To address this challenge, we propose HyperTTA (Test-Time Adaptable Transformer for Hyperspectral Degradation), a unified framework that enhances model robustness under diverse degradation conditions. First, we construct a multi-degradation hyperspectral benchmark that systematically simulates nine representative degradations, enabling comprehensive evaluation of robust classification. Based on this benchmark, we develop a Spectral--Spatial Transformer Classifier (SSTC) with a multi-level receptive field mechanism and label smoothing regularization to capture multi-scale spatial context and improve generalization. Furthermore, we introduce a lightweight test-time adaptation strategy, the Confidence-aware Entropy-minimized LayerNorm Adapter (CELA), which dynamically updates only the affine parameters of LayerNorm layers by minimizing prediction entropy on high-confidence unlabeled target samples. This strategy ensures reliable adaptation without access to source data or target labels. Experiments on two benchmark datasets demonstrate that HyperTTA outperforms state-of-the-art baselines across a wide range of degradation scenarios. Code will be made available publicly.
<div id='section'>Paperid: <span id='pid'>518, <a href='https://arxiv.org/pdf/2509.08436.pdf' target='_blank'>https://arxiv.org/pdf/2509.08436.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xia Yue, Anfeng Liu, Ning Chen, Chenjia Huang, Hui Liu, Zhou Huang, Leyuan Fang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.08436">HyperTTA: Test-Time Adaptation for Hyperspectral Image Classification under Distribution Shifts</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Hyperspectral image (HSI) classification models are highly sensitive to distribution shifts caused by real-world degradations such as noise, blur, compression, and atmospheric effects. To address this challenge, we propose HyperTTA (Test-Time Adaptable Transformer for Hyperspectral Degradation), a unified framework that enhances model robustness under diverse degradation conditions. First, we construct a multi-degradation hyperspectral benchmark that systematically simulates nine representative degradations, enabling comprehensive evaluation of robust classification. Based on this benchmark, we develop a Spectral--Spatial Transformer Classifier (SSTC) with a multi-level receptive field mechanism and label smoothing regularization to capture multi-scale spatial context and improve generalization. Furthermore, we introduce a lightweight test-time adaptation strategy, the Confidence-aware Entropy-minimized LayerNorm Adapter (CELA), which dynamically updates only the affine parameters of LayerNorm layers by minimizing prediction entropy on high-confidence unlabeled target samples. This strategy ensures reliable adaptation without access to source data or target labels. Experiments on two benchmark datasets demonstrate that HyperTTA outperforms state-of-the-art baselines across a wide range of degradation scenarios. Code will be made available publicly.
<div id='section'>Paperid: <span id='pid'>519, <a href='https://arxiv.org/pdf/2507.02800.pdf' target='_blank'>https://arxiv.org/pdf/2507.02800.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ebrahim Feghhi, Shreyas Kaasyap, Nima Hadidi, Jonathan C. Kao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.02800">Time-Masked Transformers with Lightweight Test-Time Adaptation for Neural Speech Decoding</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Speech neuroprostheses aim to restore communication for people with severe paralysis by decoding speech directly from neural activity. To accelerate algorithmic progress, a recent benchmark released intracranial recordings from a paralyzed participant attempting to speak, along with a baseline decoding algorithm. Prior work on the benchmark showed impressive accuracy gains. However, these gains increased computational costs and were not demonstrated in a real-time decoding setting. Here, we make three contributions that pave the way towards accurate, efficient, and real-time neural speech decoding. First, we incorporate large amounts of time masking during training. On average, over $50\%$ of each trial is masked. Second, we replace the gated recurrent unit (GRU) architecture used in the baseline algorithm with a compact Transformer. The Transformer architecture uses $77\%$ fewer parameters, cuts peak GPU memory usage by $36\%$ relative, and is significantly faster to calibrate relative to the GRU. Third, we design a lightweight variant of an existing test-time adaptation method developed for decoding handwriting from neural activity. Our variant adapts the model using multiple time masked augmentations of a single trial and requires only one gradient step per trial. Together, these contributions reduce word error rate by $19.5\%$ and effectively mitigate performance degradations across held-out days in a real-time decoding setting while substantially lowering computational costs.
<div id='section'>Paperid: <span id='pid'>520, <a href='https://arxiv.org/pdf/2506.24063.pdf' target='_blank'>https://arxiv.org/pdf/2506.24063.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Deng Li, Aming Wu, Yang Li, Yaowei Wang, Yahong Han
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.24063">Continual Adaptation: Environment-Conditional Parameter Generation for Object Detection in Dynamic Scenarios</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In practice, environments constantly change over time and space, posing significant challenges for object detectors trained based on a closed-set assumption, i.e., training and test data share the same distribution. To this end, continual test-time adaptation has attracted much attention, aiming to improve detectors' generalization by fine-tuning a few specific parameters, e.g., BatchNorm layers. However, based on a small number of test images, fine-tuning certain parameters may affect the representation ability of other fixed parameters, leading to performance degradation. Instead, we explore a new mechanism, i.e., converting the fine-tuning process to a specific-parameter generation. Particularly, we first design a dual-path LoRA-based domain-aware adapter that disentangles features into domain-invariant and domain-specific components, enabling efficient adaptation. Additionally, a conditional diffusion-based parameter generation mechanism is presented to synthesize the adapter's parameters based on the current environment, preventing the optimization from getting stuck in local optima. Finally, we propose a class-centered optimal transport alignment method to mitigate catastrophic forgetting. Extensive experiments conducted on various continuous domain adaptive object detection tasks demonstrate the effectiveness. Meanwhile, visualization results show that the representation extracted by the generated parameters can capture more object-related information and strengthen the generalization ability.
<div id='section'>Paperid: <span id='pid'>521, <a href='https://arxiv.org/pdf/2505.20890.pdf' target='_blank'>https://arxiv.org/pdf/2505.20890.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yoojin Kwon, Hongjun Suh, Wooseok Lee, Taesik Gong, Songyi Han, Hyung-Sin Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.20890">Frequency Composition for Compressed and Domain-Adaptive Neural Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern on-device neural network applications must operate under resource constraints while adapting to unpredictable domain shifts. However, this combined challenge-model compression and domain adaptation-remains largely unaddressed, as prior work has tackled each issue in isolation: compressed networks prioritize efficiency within a fixed domain, whereas large, capable models focus on handling domain shifts. In this work, we propose CoDA, a frequency composition-based framework that unifies compression and domain adaptation. During training, CoDA employs quantization-aware training (QAT) with low-frequency components, enabling a compressed model to selectively learn robust, generalizable features. At test time, it refines the compact model in a source-free manner (i.e., test-time adaptation, TTA), leveraging the full-frequency information from incoming data to adapt to target domains while treating high-frequency components as domain-specific cues. LFC are aligned with the trained distribution, while HFC unique to the target distribution are solely utilized for batch normalization. CoDA can be integrated synergistically into existing QAT and TTA methods. CoDA is evaluated on widely used domain-shift benchmarks, including CIFAR10-C and ImageNet-C, across various model architectures. With significant compression, it achieves accuracy improvements of 7.96%p on CIFAR10-C and 5.37%p on ImageNet-C over the full-precision TTA baseline.
<div id='section'>Paperid: <span id='pid'>522, <a href='https://arxiv.org/pdf/2504.20498.pdf' target='_blank'>https://arxiv.org/pdf/2504.20498.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jianhong Han, Yupei Wang, Liang Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.20498">Style-Adaptive Detection Transformer for Single-Source Domain Generalized Object Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Single-source domain generalization (SDG) in object detection aims to develop a detector using only source domain data that generalizes well to unseen target domains. Existing methods are primarily CNN-based and improve robustness through data augmentation combined with feature alignment. However, these methods are limited, as augmentation is only effective when the synthetic distribution approximates that of unseen domains, thus failing to ensure generalization across diverse scenarios.
  While DEtection TRansformer (DETR) has shown strong generalization in domain adaptation due to global context modeling, its potential for SDG remains underexplored. To this end, we propose Style-Adaptive DEtection TRansformer (SA-DETR), a DETR-based detector tailored for SDG. SA-DETR introduces an online domain style adapter that projects the style representation of unseen domains into the source domain via a dynamic memory bank. This bank self-organizes into diverse style prototypes and is continuously updated under a test-time adaptation framework, enabling effective style rectification.
  Additionally, we design an object-aware contrastive learning module to promote extraction of domain-invariant features. By applying gating masks that constrain contrastive learning in both spatial and semantic dimensions, this module facilitates instance-level cross-domain contrast and enhances generalization.
  Extensive experiments across five distinct weather scenarios demonstrate that SA-DETR consistently outperforms existing methods in both detection accuracy and domain generalization capability.
<div id='section'>Paperid: <span id='pid'>523, <a href='https://arxiv.org/pdf/2504.08348.pdf' target='_blank'>https://arxiv.org/pdf/2504.08348.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Josef Bengtson, David Nilsson, Fredrik Kahl
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.08348">Geometric Consistency Refinement for Single Image Novel View Synthesis via Test-Time Adaptation of Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffusion models for single image novel view synthesis (NVS) can generate highly realistic and plausible images, but they are limited in the geometric consistency to the given relative poses. The generated images often show significant errors with respect to the epipolar constraints that should be fulfilled, as given by the target pose. In this paper we address this issue by proposing a methodology to improve the geometric correctness of images generated by a diffusion model for single image NVS. We formulate a loss function based on image matching and epipolar constraints, and optimize the starting noise in a diffusion sampling process such that the generated image should both be a realistic image and fulfill geometric constraints derived from the given target pose. Our method does not require training data or fine-tuning of the diffusion models, and we show that we can apply it to multiple state-of-the-art models for single image NVS. The method is evaluated on the MegaScenes dataset and we show that geometric consistency is improved compared to the baseline models while retaining the quality of the generated images.
<div id='section'>Paperid: <span id='pid'>524, <a href='https://arxiv.org/pdf/2410.14178.pdf' target='_blank'>https://arxiv.org/pdf/2410.14178.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Younggeol Cho, Youngrae Kim, Junho Yoon, Seunghoon Hong, Dongman Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.14178">Feature Augmentation based Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) allows a model to be adapted to an unseen domain without accessing the source data. Due to the nature of practical environments, TTA has a limited amount of data for adaptation. Recent TTA methods further restrict this by filtering input data for reliability, making the effective data size even smaller and limiting adaptation potential. To address this issue, We propose Feature Augmentation based Test-time Adaptation (FATA), a simple method that fully utilizes the limited amount of input data through feature augmentation. FATA employs Normalization Perturbation to augment features and adapts the model using the FATA loss, which makes the outputs of the augmented and original features similar. FATA is model-agnostic and can be seamlessly integrated into existing models without altering the model architecture. We demonstrate the effectiveness of FATA on various models and scenarios on ImageNet-C and Office-Home, validating its superiority in diverse real-world conditions.
<div id='section'>Paperid: <span id='pid'>525, <a href='https://arxiv.org/pdf/2409.10429.pdf' target='_blank'>https://arxiv.org/pdf/2409.10429.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ming-Hao Hsu, Hung-yi Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.10429">SMILE: Speech Meta In-Context Learning for Low-Resource Language Automatic Speech Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automatic Speech Recognition (ASR) models demonstrate outstanding performance on high-resource languages but face significant challenges when applied to low-resource languages due to limited training data and insufficient cross-lingual generalization. Existing adaptation strategies, such as shallow fusion, data augmentation, and direct fine-tuning, either rely on external resources, suffer computational inefficiencies, or fail in test-time adaptation scenarios. To address these limitations, we introduce Speech Meta In-Context LEarning (SMILE), an innovative framework that combines meta-learning with speech in-context learning (SICL). SMILE leverages meta-training from high-resource languages to enable robust, few-shot generalization to low-resource languages without explicit fine-tuning on the target domain. Extensive experiments on the ML-SUPERB benchmark show that SMILE consistently outperforms baseline methods, significantly reducing character and word error rates in training-free few-shot multilingual ASR tasks.
<div id='section'>Paperid: <span id='pid'>526, <a href='https://arxiv.org/pdf/2407.14605.pdf' target='_blank'>https://arxiv.org/pdf/2407.14605.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luke Bidulka, Mohsen Gholami, Jiannan Zheng, Martin J. McKeown, Z. Jane Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.14605">ESCAPE: Energy-based Selective Adaptive Correction for Out-of-distribution 3D Human Pose Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Despite recent advances in human pose estimation (HPE), poor generalization to out-of-distribution (OOD) data remains a difficult problem. While previous works have proposed Test-Time Adaptation (TTA) to bridge the train-test domain gap by refining network parameters at inference, the absence of ground-truth annotations makes it highly challenging and existing methods typically increase inference times by one or more orders of magnitude. We observe that 1) not every test time sample is OOD, and 2) HPE errors are significantly larger on distal keypoints (wrist, ankle). To this end, we propose ESCAPE: a lightweight correction and selective adaptation framework which applies a fast, forward-pass correction on most data while reserving costly TTA for OOD data. The free energy function is introduced to separate OOD samples from incoming data and a correction network is trained to estimate the errors of pretrained backbone HPE predictions on the distal keypoints. For OOD samples, we propose a novel self-consistency adaptation loss to update the correction network by leveraging the constraining relationship between distal keypoints and proximal keypoints (shoulders, hips), via a second ``reverse" network. ESCAPE improves the distal MPJPE of five popular HPE models by up to 7% on unseen data, achieves state-of-the-art results on two popular HPE benchmarks, and is significantly faster than existing adaptation methods.
<div id='section'>Paperid: <span id='pid'>527, <a href='https://arxiv.org/pdf/2406.12937.pdf' target='_blank'>https://arxiv.org/pdf/2406.12937.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Robert Flynn, Anton Ragni
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.12937">Self-Train Before You Transcribe</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>When there is a mismatch between the training and test domains, current speech recognition systems show significant performance degradation. Self-training methods, such as noisy student teacher training, can help address this and enable the adaptation of models under such domain shifts. However, self-training typically requires a collection of unlabelled target domain data. For settings where this is not practical, we investigate the benefit of performing noisy student teacher training on recordings in the test set as a test-time adaptation approach. Similarly to the dynamic evaluation approach in language modelling, this enables the transfer of information across utterance boundaries and functions as a method of domain adaptation. A range of in-domain and out-of-domain datasets are used for experiments demonstrating large relative gains of up to 32.2%. Interestingly, our method showed larger gains than the typical self-training setup that utilises separate adaptation data.
<div id='section'>Paperid: <span id='pid'>528, <a href='https://arxiv.org/pdf/2311.18270.pdf' target='_blank'>https://arxiv.org/pdf/2311.18270.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Younggeol Cho, Youngrae Kim, Dongman Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.18270">Beyond Entropy: Style Transfer Guided Single Image Continual Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual test-time adaptation (cTTA) methods are designed to facilitate the continual adaptation of models to dynamically changing real-world environments where computational resources are limited. Due to this inherent limitation, existing approaches fail to simultaneously achieve accuracy and efficiency. In detail, when using a single image, the instability caused by batch normalization layers and entropy loss significantly destabilizes many existing methods in real-world cTTA scenarios. To overcome these challenges, we present BESTTA, a novel single image continual test-time adaptation method guided by style transfer, which enables stable and efficient adaptation to the target environment by transferring the style of the input image to the source style. To implement the proposed method, we devise BeIN, a simple yet powerful normalization method, along with the style-guided losses. We demonstrate that BESTTA effectively adapts to the continually changing target environment, leveraging only a single image on both semantic segmentation and image classification tasks. Remarkably, despite training only two parameters in a BeIN layer consuming the least memory, BESTTA outperforms existing state-of-the-art methods in terms of performance.
<div id='section'>Paperid: <span id='pid'>529, <a href='https://arxiv.org/pdf/2311.10845.pdf' target='_blank'>https://arxiv.org/pdf/2311.10845.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuangzhi Li, Lei Ma, Xingyu Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.10845">Domain Generalization of 3D Object Detection by Density-Resampling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Point-cloud-based 3D object detection suffers from performance degradation when encountering data with novel domain gaps. To tackle it, the single-domain generalization (SDG) aims to generalize the detection model trained in a limited single source domain to perform robustly on unexplored domains. In this paper, we propose an SDG method to improve the generalizability of 3D object detection to unseen target domains. Unlike prior SDG works for 3D object detection solely focusing on data augmentation, our work introduces a novel data augmentation method and contributes a new multi-task learning strategy in the methodology. Specifically, from the perspective of data augmentation, we design a universal physical-aware density-based data augmentation (PDDA) method to mitigate the performance loss stemming from diverse point densities. From the learning methodology viewpoint, we develop a multi-task learning for 3D object detection: during source training, besides the main standard detection task, we leverage an auxiliary self-supervised 3D scene restoration task to enhance the comprehension of the encoder on background and foreground details for better recognition and detection of objects. Furthermore, based on the auxiliary self-supervised task, we propose the first test-time adaptation method for domain generalization of 3D object detection, which efficiently adjusts the encoder's parameters to adapt to unseen target domains during testing time, to further bridge domain gaps. Extensive cross-dataset experiments covering "Car", "Pedestrian", and "Cyclist" detections, demonstrate our method outperforms state-of-the-art SDG methods and even overpass unsupervised domain adaptation methods under some circumstances.
<div id='section'>Paperid: <span id='pid'>530, <a href='https://arxiv.org/pdf/2308.16484.pdf' target='_blank'>https://arxiv.org/pdf/2308.16484.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ahmed Hatem, Yiming Qian, Yang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.16484">Test-Time Adaptation for Point Cloud Upsampling Using Meta-Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Affordable 3D scanners often produce sparse and non-uniform point clouds that negatively impact downstream applications in robotic systems. While existing point cloud upsampling architectures have demonstrated promising results on standard benchmarks, they tend to experience significant performance drops when the test data have different distributions from the training data. To address this issue, this paper proposes a test-time adaption approach to enhance model generality of point cloud upsampling. The proposed approach leverages meta-learning to explicitly learn network parameters for test-time adaption. Our method does not require any prior information about the test data. During meta-training, the model parameters are learned from a collection of instance-level tasks, each of which consists of a sparse-dense pair of point clouds from the training data. During meta-testing, the trained model is fine-tuned with a few gradient updates to produce a unique set of network parameters for each test instance. The updated model is then used for the final prediction. Our framework is generic and can be applied in a plug-and-play manner with existing backbone networks in point cloud upsampling. Extensive experiments demonstrate that our approach improves the performance of state-of-the-art models.
<div id='section'>Paperid: <span id='pid'>531, <a href='https://arxiv.org/pdf/2308.16481.pdf' target='_blank'>https://arxiv.org/pdf/2308.16481.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ahmed Hatem, Yiming Qian, Yang Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.16481">Point-TTA: Test-Time Adaptation for Point Cloud Registration Using Multitask Meta-Auxiliary Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present Point-TTA, a novel test-time adaptation framework for point cloud registration (PCR) that improves the generalization and the performance of registration models. While learning-based approaches have achieved impressive progress, generalization to unknown testing environments remains a major challenge due to the variations in 3D scans. Existing methods typically train a generic model and the same trained model is applied on each instance during testing. This could be sub-optimal since it is difficult for the same model to handle all the variations during testing. In this paper, we propose a test-time adaptation approach for PCR. Our model can adapt to unseen distributions at test-time without requiring any prior knowledge of the test data. Concretely, we design three self-supervised auxiliary tasks that are optimized jointly with the primary PCR task. Given a test instance, we adapt our model using these auxiliary tasks and the updated model is used to perform the inference. During training, our model is trained using a meta-auxiliary learning approach, such that the adapted model via auxiliary tasks improves the accuracy of the primary task. Experimental results demonstrate the effectiveness of our approach in improving generalization of point cloud registration and outperforming other state-of-the-art approaches.
<div id='section'>Paperid: <span id='pid'>532, <a href='https://arxiv.org/pdf/2308.00924.pdf' target='_blank'>https://arxiv.org/pdf/2308.00924.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chowdhury Sadman Jahan, Andreas Savakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.00924">Continual Domain Adaptation on Aerial Images under Gradually Degrading Weather</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Domain adaptation (DA) strives to mitigate the domain gap between the source domain where a model is trained, and the target domain where the model is deployed. When a deep learning model is deployed on an aerial platform, it may face gradually degrading weather conditions during operation, leading to widening domain gaps between the training data and the encountered evaluation data. We synthesize two such gradually worsening weather conditions on real images from two existing aerial imagery datasets, generating a total of four benchmark datasets. Under the continual, or test-time adaptation setting, we evaluate three DA models on our datasets: a baseline standard DA model and two continual DA models. In such setting, the models can access only one small portion, or one batch of the target data at a time, and adaptation takes place continually, and over only one epoch of the data. The combination of the constraints of continual adaptation, and gradually deteriorating weather conditions provide the practical DA scenario for aerial deployment. Among the evaluated models, we consider both convolutional and transformer architectures for comparison. We discover stability issues during adaptation for existing buffer-fed continual DA methods, and offer gradient normalization as a simple solution to curb training instability.
<div id='section'>Paperid: <span id='pid'>533, <a href='https://arxiv.org/pdf/2304.06411.pdf' target='_blank'>https://arxiv.org/pdf/2304.06411.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiongjie Cui, Huaijiang Sun, Jianfeng Lu, Bin Li, Weiqing Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.06411">Meta-Auxiliary Learning for Adaptive Human Pose Prediction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Predicting high-fidelity future human poses, from a historically observed sequence, is decisive for intelligent robots to interact with humans. Deep end-to-end learning approaches, which typically train a generic pre-trained model on external datasets and then directly apply it to all test samples, emerge as the dominant solution to solve this issue. Despite encouraging progress, they remain non-optimal, as the unique properties (e.g., motion style, rhythm) of a specific sequence cannot be adapted. More generally, at test-time, once encountering unseen motion categories (out-of-distribution), the predicted poses tend to be unreliable. Motivated by this observation, we propose a novel test-time adaptation framework that leverages two self-supervised auxiliary tasks to help the primary forecasting network adapt to the test sequence. In the testing phase, our model can adjust the model parameters by several gradient updates to improve the generation quality. However, due to catastrophic forgetting, both auxiliary tasks typically tend to the low ability to automatically present the desired positive incentives for the final prediction performance. For this reason, we also propose a meta-auxiliary learning scheme for better adaptation. In terms of general setup, our approach obtains higher accuracy, and under two new experimental designs for out-of-distribution data (unseen subjects and categories), achieves significant improvements.
<div id='section'>Paperid: <span id='pid'>534, <a href='https://arxiv.org/pdf/2509.01033.pdf' target='_blank'>https://arxiv.org/pdf/2509.01033.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiang Li, Yuanming Cao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.01033">Seeing through Unclear Glass: Occlusion Removal with One Shot</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Images taken through window glass are often degraded by contaminants adhered to the glass surfaces. Such contaminants cause occlusions that attenuate the incoming light and scatter stray light towards the camera. Most of existing deep learning methods for neutralizing the effects of contaminated glasses relied on synthetic training data. Few researchers used real degraded and clean image pairs, but they only considered removing or alleviating the effects of rain drops on glasses. This paper is concerned with the more challenging task of learning the restoration of images taken through glasses contaminated by a wide range of occluders, including muddy water, dirt and other small foreign particles found in reality. To facilitate the learning task we have gone to a great length to acquire real paired images with and without glass contaminants. More importantly, we propose an all-in-one model to neutralize contaminants of different types by utilizing the one-shot test-time adaptation mechanism. It involves a self-supervised auxiliary learning task to update the trained model for the unique occlusion type of each test image. Experimental results show that the proposed method outperforms the state-of-the-art methods quantitatively and qualitatively in cleaning realistic contaminated images, especially the unseen ones.
<div id='section'>Paperid: <span id='pid'>535, <a href='https://arxiv.org/pdf/2509.01033.pdf' target='_blank'>https://arxiv.org/pdf/2509.01033.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiang Li, Yuanming Cao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.01033">Seeing through Unclear Glass: Occlusion Removal with One Shot</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Images taken through window glass are often degraded by contaminants adhered to the glass surfaces. Such contaminants cause occlusions that attenuate the incoming light and scatter stray light towards the camera. Most of existing deep learning methods for neutralizing the effects of contaminated glasses relied on synthetic training data. Few researchers used real degraded and clean image pairs, but they only considered removing or alleviating the effects of rain drops on glasses. This paper is concerned with the more challenging task of learning the restoration of images taken through glasses contaminated by a wide range of occluders, including muddy water, dirt and other small foreign particles found in reality. To facilitate the learning task we have gone to a great length to acquire real paired images with and without glass contaminants. More importantly, we propose an all-in-one model to neutralize contaminants of different types by utilizing the one-shot test-time adaptation mechanism. It involves a self-supervised auxiliary learning task to update the trained model for the unique occlusion type of each test image. Experimental results show that the proposed method outperforms the state-of-the-art methods quantitatively and qualitatively in cleaning realistic contaminated images, especially the unseen ones.
<div id='section'>Paperid: <span id='pid'>536, <a href='https://arxiv.org/pdf/2508.04924.pdf' target='_blank'>https://arxiv.org/pdf/2508.04924.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zahidul Islam, Sujoy Paul, Mrigank Rochan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.04924">Test-Time Adaptation for Video Highlight Detection Using Meta-Auxiliary Learning and Cross-Modality Hallucinations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing video highlight detection methods, although advanced, struggle to generalize well to all test videos. These methods typically employ a generic highlight detection model for each test video, which is suboptimal as it fails to account for the unique characteristics and variations of individual test videos. Such fixed models do not adapt to the diverse content, styles, or audio and visual qualities present in new, unseen test videos, leading to reduced highlight detection performance. In this paper, we propose Highlight-TTA, a test-time adaptation framework for video highlight detection that addresses this limitation by dynamically adapting the model during testing to better align with the specific characteristics of each test video, thereby improving generalization and highlight detection performance. Highlight-TTA is jointly optimized with an auxiliary task, cross-modality hallucinations, alongside the primary highlight detection task. We utilize a meta-auxiliary training scheme to enable effective adaptation through the auxiliary task while enhancing the primary task. During testing, we adapt the trained model using the auxiliary task on the test video to further enhance its highlight detection performance. Extensive experiments with three state-of-the-art highlight detection models and three benchmark datasets show that the introduction of Highlight-TTA to these models improves their performance, yielding superior results.
<div id='section'>Paperid: <span id='pid'>537, <a href='https://arxiv.org/pdf/2508.00777.pdf' target='_blank'>https://arxiv.org/pdf/2508.00777.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zihan Wang, Samira Ebrahimi Kahou, Narges Armanfard
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.00777">Zero-Shot Anomaly Detection with Dual-Branch Prompt Selection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Zero-shot anomaly detection (ZSAD) enables identifying and localizing defects in unseen categories by relying solely on generalizable features rather than requiring any labeled examples of anomalies. However, existing ZSAD methods, whether using fixed or learned prompts, struggle under domain shifts because their training data are derived from limited training domains and fail to generalize to new distributions. In this paper, we introduce PILOT, a framework designed to overcome these challenges through two key innovations: (1) a novel dual-branch prompt learning mechanism that dynamically integrates a pool of learnable prompts with structured semantic attributes, enabling the model to adaptively weight the most relevant anomaly cues for each input image; and (2) a label-free test-time adaptation strategy that updates the learnable prompt parameters using high-confidence pseudo-labels from unlabeled test data. Extensive experiments on 13 industrial and medical benchmarks demonstrate that PILOT achieves state-of-the-art performance in both anomaly detection and localization under domain shift.
<div id='section'>Paperid: <span id='pid'>538, <a href='https://arxiv.org/pdf/2507.14057.pdf' target='_blank'>https://arxiv.org/pdf/2507.14057.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marcel Hedman, Desi R. Ivanova, Cong Guan, Tom Rainforth
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.14057">Step-DAD: Semi-Amortized Policy-Based Bayesian Experimental Design</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We develop a semi-amortized, policy-based, approach to Bayesian experimental design (BED) called Stepwise Deep Adaptive Design (Step-DAD). Like existing, fully amortized, policy-based BED approaches, Step-DAD trains a design policy upfront before the experiment. However, rather than keeping this policy fixed, Step-DAD periodically updates it as data is gathered, refining it to the particular experimental instance. This test-time adaptation improves both the flexibility and the robustness of the design strategy compared with existing approaches. Empirically, Step-DAD consistently demonstrates superior decision-making and robustness compared with current state-of-the-art BED methods.
<div id='section'>Paperid: <span id='pid'>539, <a href='https://arxiv.org/pdf/2505.22284.pdf' target='_blank'>https://arxiv.org/pdf/2505.22284.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junyu Fan, Chuanlin Liao, Yi Lin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.22284">From Controlled Scenarios to Real-World: Cross-Domain Degradation Pattern Matching for All-in-One Image Restoration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As a fundamental imaging task, All-in-One Image Restoration (AiOIR) aims to achieve image restoration caused by multiple degradation patterns via a single model with unified parameters. Although existing AiOIR approaches obtain promising performance in closed and controlled scenarios, they still suffered from considerable performance reduction in real-world scenarios since the gap of data distributions between the training samples (source domain) and real-world test samples (target domain) can lead inferior degradation awareness ability. To address this issue, a Unified Domain-Adaptive Image Restoration (UDAIR) framework is proposed to effectively achieve AiOIR by leveraging the learned knowledge from source domain to target domain. To improve the degradation identification, a codebook is designed to learn a group of discrete embeddings to denote the degradation patterns, and the cross-sample contrastive learning mechanism is further proposed to capture shared features from different samples of certain degradation. To bridge the data gap, a domain adaptation strategy is proposed to build the feature projection between the source and target domains by dynamically aligning their codebook embeddings, and a correlation alignment-based test-time adaptation mechanism is designed to fine-tune the alignment discrepancies by tightening the degradation embeddings to the corresponding cluster center in the source domain. Experimental results on 10 open-source datasets demonstrate that UDAIR achieves new state-of-the-art performance for the AiOIR task. Most importantly, the feature cluster validate the degradation identification under unknown conditions, and qualitative comparisons showcase robust generalization to real-world scenarios.
<div id='section'>Paperid: <span id='pid'>540, <a href='https://arxiv.org/pdf/2505.10641.pdf' target='_blank'>https://arxiv.org/pdf/2505.10641.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Linjing You, Jiabao Lu, Xiayuan Huang, Xiangli Nie
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.10641">FRET: Feature Redundancy Elimination for Test Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-Time Adaptation (TTA) aims to enhance the generalization of deep learning models when faced with test data that exhibits distribution shifts from the training data. In this context, only a pre-trained model and unlabeled test data are available, making it particularly relevant for privacy-sensitive applications. In practice, we observe that feature redundancy in embeddings tends to increase as domain shifts intensify in TTA. However, existing TTA methods often overlook this redundancy, which can hinder the model's adaptability to new data. To address this issue, we introduce Feature Redundancy Elimination for Test-time Adaptation (FRET), a novel perspective for TTA. A straightforward approach (S-FRET) is to directly minimize the feature redundancy score as an optimization objective to improve adaptation. Despite its simplicity and effectiveness, S-FRET struggles with label shifts, limiting its robustness in real-world scenarios. To mitigate this limitation, we further propose Graph-based FRET (G-FRET), which integrates a Graph Convolutional Network (GCN) with contrastive learning. This design not only reduces feature redundancy but also enhances feature discriminability in both the representation and prediction layers. Extensive experiments across multiple model architectures, tasks, and datasets demonstrate the effectiveness of S-FRET and show that G-FRET achieves state-of-the-art performance. Further analysis reveals that G-FRET enables the model to extract non-redundant and highly discriminative features during inference, thereby facilitating more robust test-time adaptation.
<div id='section'>Paperid: <span id='pid'>541, <a href='https://arxiv.org/pdf/2505.03420.pdf' target='_blank'>https://arxiv.org/pdf/2505.03420.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fei Zhao, Chengcui Zhang, Runlin Zhang, Tianyang Wang, Xi Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.03420">Mitigating Image Captioning Hallucinations in Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Hallucinations in vision-language models (VLMs) hinder reliability and real-world applicability, usually stemming from distribution shifts between pretraining data and test samples. Existing solutions, such as retraining or fine-tuning on additional data, demand significant computational resources and labor-intensive data collection, while ensemble-based methods incur additional costs by introducing auxiliary VLMs. To address these challenges, we propose a novel test-time adaptation framework using reinforcement learning to mitigate hallucinations during inference without retraining or any auxiliary VLMs. By updating only the learnable parameters in the layer normalization of the language model (approximately 0.003% of the model parameters), our method reduces distribution shifts between test samples and pretraining samples. A CLIP-based hallucination evaluation model is proposed to provide dual rewards to VLMs. Experimental results demonstrate a 15.4% and 17.3% reduction in hallucination rates on LLaVA and InstructBLIP, respectively. Our approach outperforms state-of-the-art baselines with a 68.3% improvement in hallucination mitigation, demonstrating its effectiveness.
<div id='section'>Paperid: <span id='pid'>542, <a href='https://arxiv.org/pdf/2505.00986.pdf' target='_blank'>https://arxiv.org/pdf/2505.00986.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiao Ma, Young D. Kwon, Dong Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.00986">On-demand Test-time Adaptation for Edge Devices</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Continual Test-time adaptation (CTTA) continuously adapts the deployed model on every incoming batch of data. While achieving optimal accuracy, existing CTTA approaches present poor real-world applicability on resource-constrained edge devices, due to the substantial memory overhead and energy consumption. In this work, we first introduce a novel paradigm -- on-demand TTA -- which triggers adaptation only when a significant domain shift is detected. Then, we present OD-TTA, an on-demand TTA framework for accurate and efficient adaptation on edge devices. OD-TTA comprises three innovative techniques: 1) a lightweight domain shift detection mechanism to activate TTA only when it is needed, drastically reducing the overall computation overhead, 2) a source domain selection module that chooses an appropriate source model for adaptation, ensuring high and robust accuracy, 3) a decoupled Batch Normalization (BN) update scheme to enable memory-efficient adaptation with small batch sizes. Extensive experiments show that OD-TTA achieves comparable and even better performance while reducing the energy and computation overhead remarkably, making TTA a practical reality.
<div id='section'>Paperid: <span id='pid'>543, <a href='https://arxiv.org/pdf/2505.00533.pdf' target='_blank'>https://arxiv.org/pdf/2505.00533.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Linjing You, Jiabao Lu, Xiayuan Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.00533">Test-time Correlation Alignment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks often degrade under distribution shifts. Although domain adaptation offers a solution, privacy constraints often prevent access to source data, making Test-Time Adaptation (TTA, which adapts using only unlabeled test data) increasingly attractive. However, current TTA methods still face practical challenges: (1) a primary focus on instance-wise alignment, overlooking CORrelation ALignment (CORAL) due to missing source correlations; (2) complex backpropagation operations for model updating, resulting in overhead computation and (3) domain forgetting. To address these challenges, we provide a theoretical analysis to investigate the feasibility of Test-time Correlation Alignment (TCA), demonstrating that correlation alignment between high-certainty instances and test instances can enhance test performances with a theoretical guarantee. Based on this, we propose two simple yet effective algorithms: LinearTCA and LinearTCA+. LinearTCA applies a simple linear transformation to achieve both instance and correlation alignment without additional model updates, while LinearTCA+ serves as a plug-and-play module that can easily boost existing TTA methods. Extensive experiments validate our theoretical insights and show that TCA methods significantly outperforms baselines across various tasks, benchmarks and backbones. Notably, LinearTCA achieves higher accuracy with only 4% GPU memory and 0.6% computation time compared to the best TTA baseline. It also outperforms existing methods on CLIP over 1.86%.
<div id='section'>Paperid: <span id='pid'>544, <a href='https://arxiv.org/pdf/2504.04795.pdf' target='_blank'>https://arxiv.org/pdf/2504.04795.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jin Liu, Jialong Xie, Leibing Xiao, Chaoqun Wang, Fengyu Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.04795">Embodied Perception for Test-time Grasping Detection Adaptation with Knowledge Infusion</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>It has always been expected that a robot can be easily deployed to unknown scenarios, accomplishing robotic grasping tasks without human intervention. Nevertheless, existing grasp detection approaches are typically off-body techniques and are realized by training various deep neural networks with extensive annotated data support. {In this paper, we propose an embodied test-time adaptation framework for grasp detection that exploits the robot's exploratory capabilities.} The framework aims to improve the generalization performance of grasping skills for robots in an unforeseen environment. Specifically, we introduce embodied assessment criteria based on the robot's manipulation capability to evaluate the quality of the grasp detection and maintain suitable samples. This process empowers the robots to actively explore the environment and continuously learn grasping skills, eliminating human intervention. Besides, to improve the efficiency of robot exploration, we construct a flexible knowledge base to provide context of initial optimal viewpoints. Conditioned on the maintained samples, the grasp detection networks can be adapted in the test-time scene. When the robot confronts new objects, it will undergo the same adaptation procedure mentioned above to realize continuous learning. Extensive experiments conducted on a real-world robot demonstrate the effectiveness and generalization of our proposed framework.
<div id='section'>Paperid: <span id='pid'>545, <a href='https://arxiv.org/pdf/2503.18334.pdf' target='_blank'>https://arxiv.org/pdf/2503.18334.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haotian Zhai, Xinyu Chen, Can Zhang, Tianming Sha, Ruirui Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.18334">Mitigating Cache Noise in Test-Time Adaptation for Large Vision-Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) of visual language models has recently attracted significant attention as a solution to the performance degradation caused by distribution shifts in downstream tasks. However, existing cache-based TTA methods have certain limitations. They mainly rely on the accuracy of cached feature labels, and the presence of noisy pseudo-labels can cause these features to deviate from their true distribution. This makes cache retrieval methods based on similarity matching highly sensitive to outliers or extreme samples. Moreover, current methods lack effective mechanisms to model class distributions, which limits their ability to fully exploit the potential of cached information. To address these challenges, we introduce a comprehensive and reliable caching mechanism and propose a novel zero-shot TTA method called "Cache, Residual, Gaussian" (CRG). This method not only employs learnable residual parameters to better align positive and negative visual prototypes with text prototypes, thereby optimizing the quality of cached features, but also incorporates Gaussian Discriminant Analysis (GDA) to dynamically model intra-class feature distributions, further mitigating the impact of noisy features. Experimental results on 13 benchmarks demonstrate that CRG outperforms state-of-the-art TTA methods, showcasing exceptional robustness and adaptability.
<div id='section'>Paperid: <span id='pid'>546, <a href='https://arxiv.org/pdf/2411.15204.pdf' target='_blank'>https://arxiv.org/pdf/2411.15204.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Minguk Jang, Hye Won Chung
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.15204">Label Distribution Shift-Aware Prediction Refinement for Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) is an effective approach to mitigate performance degradation of trained models when encountering input distribution shifts at test time. However, existing TTA methods often suffer significant performance drops when facing additional class distribution shifts. We first analyze TTA methods under label distribution shifts and identify the presence of class-wise confusion patterns commonly observed across different covariate shifts. Based on this observation, we introduce label Distribution shift-Aware prediction Refinement for Test-time adaptation (DART), a novel TTA method that refines the predictions by focusing on class-wise confusion patterns. DART trains a prediction refinement module during an intermediate time by exposing it to several batches with diverse class distributions using the training dataset. This module is then used during test time to detect and correct class distribution shifts, significantly improving pseudo-label accuracy for test data. Our method exhibits 5-18% gains in accuracy under label distribution shifts on CIFAR-10C, without any performance degradation when there is no label distribution shift. Extensive experiments on CIFAR, PACS, OfficeHome, and ImageNet benchmarks demonstrate DART's ability to correct inaccurate predictions caused by test-time distribution shifts. This improvement leads to enhanced performance in existing TTA methods, making DART a valuable plug-in tool.
<div id='section'>Paperid: <span id='pid'>547, <a href='https://arxiv.org/pdf/2410.07263.pdf' target='_blank'>https://arxiv.org/pdf/2410.07263.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sanchayan Dutta, Suvrit Sra
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.07263">Toward generalizable learning of all (linear) first-order methods via memory augmented Transformers</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We show that memory-augmented Transformers can implement the entire class of linear first-order methods (LFOMs), a class that contains gradient descent (GD) and more advanced methods such as conjugate gradient descent (CGD), momentum methods and all other variants that linearly combine past gradients. Building on prior work that studies how Transformers simulate GD, we provide theoretical and empirical evidence that memory-augmented Transformers can learn more advanced algorithms. We then take a first step toward turning the learned algorithms into actually usable methods by developing a mixture-of-experts (MoE) approach for test-time adaptation to out-of-distribution (OOD) samples. Lastly, we show that LFOMs can themselves be treated as learnable algorithms, whose parameters can be learned from data to attain strong performance.
<div id='section'>Paperid: <span id='pid'>548, <a href='https://arxiv.org/pdf/2408.07511.pdf' target='_blank'>https://arxiv.org/pdf/2408.07511.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yarin Bar, Shalev Shaer, Yaniv Romano
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.07511">Protected Test-Time Adaptation via Online Entropy Matching: A Betting Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a novel approach for test-time adaptation via online self-training, consisting of two components. First, we introduce a statistical framework that detects distribution shifts in the classifier's entropy values obtained on a stream of unlabeled samples. Second, we devise an online adaptation mechanism that utilizes the evidence of distribution shifts captured by the detection tool to dynamically update the classifier's parameters. The resulting adaptation process drives the distribution of test entropy values obtained from the self-trained classifier to match those of the source domain, building invariance to distribution shifts. This approach departs from the conventional self-training method, which focuses on minimizing the classifier's entropy. Our approach combines concepts in betting martingales and online learning to form a detection tool capable of quickly reacting to distribution shifts. We then reveal a tight relation between our adaptation scheme and optimal transport, which forms the basis of our novel self-supervised loss. Experimental results demonstrate that our approach improves test-time accuracy under distribution shifts while maintaining accuracy and calibration in their absence, outperforming leading entropy minimization methods across various scenarios.
<div id='section'>Paperid: <span id='pid'>549, <a href='https://arxiv.org/pdf/2404.16168.pdf' target='_blank'>https://arxiv.org/pdf/2404.16168.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fin Amin, Jung-Eun Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.16168">The Over-Certainty Phenomenon in Modern Test-Time Adaptation Algorithms</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>When neural networks are confronted with unfamiliar data that deviate from their training set, this signifies a domain shift. While these networks output predictions on their inputs, they typically fail to account for their level of familiarity with these novel observations. Prevailing works navigate test-time adaptation with the goal of curtailing model entropy, yet they unintentionally produce models that struggle with sub-optimal calibration-a dilemma we term the over-certainty phenomenon. This over-certainty in predictions can be particularly dangerous in the setting of domain shifts, as it may lead to misplaced trust. In this paper, we propose a solution that not only maintains accuracy but also addresses calibration by mitigating the over-certainty phenomenon. To do this, we introduce a certainty regularizer that dynamically adjusts pseudo-label confidence by accounting for both backbone entropy and logit norm. Our method achieves state-of-the-art performance in terms of Expected Calibration Error and Negative Log Likelihood, all while maintaining parity in accuracy.
<div id='section'>Paperid: <span id='pid'>550, <a href='https://arxiv.org/pdf/2404.16168.pdf' target='_blank'>https://arxiv.org/pdf/2404.16168.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fin Amin, Jung-Eun Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.16168">The Over-Certainty Phenomenon in Modern Test-Time Adaptation Algorithms</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>When neural networks are confronted with unfamiliar data that deviate from their training set, this signifies a domain shift. While these networks output predictions on their inputs, they typically fail to account for their level of familiarity with these novel observations. Prevailing works navigate test-time adaptation with the goal of curtailing model entropy, yet they unintentionally produce models that struggle with sub-optimal calibration-a dilemma we term the over-certainty phenomenon. This over-certainty in predictions can be particularly dangerous in the setting of domain shifts, as it may lead to misplaced trust. In this paper, we propose a solution that not only maintains accuracy but also addresses calibration by mitigating the over-certainty phenomenon. To do this, we introduce a certainty regularizer that dynamically adjusts pseudo-label confidence by accounting for both backbone entropy and logit norm. Our method achieves state-of-the-art performance in terms of Expected Calibration Error and Negative Log Likelihood, all while maintaining parity in accuracy.
<div id='section'>Paperid: <span id='pid'>551, <a href='https://arxiv.org/pdf/2311.18071.pdf' target='_blank'>https://arxiv.org/pdf/2311.18071.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mrigank Raman, Rohan Shah, Akash Kannan, Pranit Chawla
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.18071">Turn Down the Noise: Leveraging Diffusion Models for Test-time Adaptation via Pseudo-label Ensembling</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The goal of test-time adaptation is to adapt a source-pretrained model to a continuously changing target domain without relying on any source data. Typically, this is either done by updating the parameters of the model (model adaptation) using inputs from the target domain or by modifying the inputs themselves (input adaptation). However, methods that modify the model suffer from the issue of compounding noisy updates whereas methods that modify the input need to adapt to every new data point from scratch while also struggling with certain domain shifts. We introduce an approach that leverages a pre-trained diffusion model to project the target domain images closer to the source domain and iteratively updates the model via pseudo-label ensembling. Our method combines the advantages of model and input adaptations while mitigating their shortcomings. Our experiments on CIFAR-10C demonstrate the superiority of our approach, outperforming the strongest baseline by an average of 1.7% across 15 diverse corruptions and surpassing the strongest input adaptation baseline by an average of 18%.
<div id='section'>Paperid: <span id='pid'>552, <a href='https://arxiv.org/pdf/2309.04755.pdf' target='_blank'>https://arxiv.org/pdf/2309.04755.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haotian Guan, Jinping Dong, Wei-Ning Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.04755">A Novel Training Framework for Physics-informed Neural Networks: Towards Real-time Applications in Ultrafast Ultrasound Blood Flow Imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ultrafast ultrasound blood flow imaging is a state-of-the-art technique for depiction of complex blood flow dynamics in vivo through thousands of full-view image data (or, timestamps) acquired per second. Physics-informed Neural Network (PINN) is one of the most preeminent solvers of the Navier-Stokes equations, widely used as the governing equation of blood flow. However, that current approaches rely on full Navier-Stokes equations is impractical for ultrafast ultrasound. We hereby propose a novel PINN training framework for solving the Navier-Stokes equations. It involves discretizing Navier-Stokes equations into steady state and sequentially solving them with test-time adaptation. The novel training framework is coined as SeqPINN. Upon its success, we propose a parallel training scheme for all timestamps based on averaged constant stochastic gradient descent as initialization. Uncertainty estimation through Stochastic Weight Averaging Gaussian is then used as an indicator of generalizability of the initialization. This algorithm, named SP-PINN, further expedites training of PINN while achieving comparable accuracy with SeqPINN. The performance of SeqPINN and SP-PINN was evaluated through finite-element simulations and in vitro phantoms of single-branch and trifurcate blood vessels. Results show that both algorithms were manyfold faster than the original design of PINN, while respectively achieving Root Mean Square Errors of 0.63 cm/s and 0.81 cm/s on the straight vessel and 1.35 cm/s and 1.63 cm/s on the trifurcate vessel when recovering blood flow velocities. The successful implementation of SeqPINN and SP-PINN open the gate for real-time training of PINN for Navier-Stokes equations and subsequently reliable imaging-based blood flow assessment in clinical practice.
<div id='section'>Paperid: <span id='pid'>553, <a href='https://arxiv.org/pdf/2207.10792.pdf' target='_blank'>https://arxiv.org/pdf/2207.10792.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Minguk Jang, Sae-Young Chung, Hye Won Chung
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2207.10792">Test-Time Adaptation via Self-Training with Nearest Neighbor Information</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) aims to adapt a trained classifier using online unlabeled test data only, without any information related to the training procedure. Most existing TTA methods adapt the trained classifier using the classifier's prediction on the test data as pseudo-label. However, under test-time domain shift, accuracy of the pseudo labels cannot be guaranteed, and thus the TTA methods often encounter performance degradation at the adapted classifier. To overcome this limitation, we propose a novel test-time adaptation method, called Test-time Adaptation via Self-Training with nearest neighbor information (TAST), which is composed of the following procedures: (1) adds trainable adaptation modules on top of the trained feature extractor; (2) newly defines a pseudo-label distribution for the test data by using the nearest neighbor information; (3) trains these modules only a few times during test time to match the nearest neighbor-based pseudo label distribution and a prototype-based class distribution for the test data; and (4) predicts the label of test data using the average predicted class distribution from these modules. The pseudo-label generation is based on the basic intuition that a test data and its nearest neighbor in the embedding space are likely to share the same label under the domain shift. By utilizing multiple randomly initialized adaptation modules, TAST extracts useful information for the classification of the test data under the domain shift, using the nearest neighbor information. TAST showed better performance than the state-of-the-art TTA methods on two standard benchmark tasks, domain generalization, namely VLCS, PACS, OfficeHome, and TerraIncognita, and image corruption, particularly CIFAR-10/100C.
<div id='section'>Paperid: <span id='pid'>554, <a href='https://arxiv.org/pdf/2507.15523.pdf' target='_blank'>https://arxiv.org/pdf/2507.15523.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Weichuang Shao, Iman Yi Liao, Tomas Henrique Bode Maul, Tissa Chandesa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.15523">An Investigation of Test-time Adaptation for Audio Classification under Background Noise</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Domain shift is a prominent problem in Deep Learning, causing a model pre-trained on a source dataset to suffer significant performance degradation on test datasets. This research aims to address the issue of audio classification under domain shift caused by background noise using Test-Time Adaptation (TTA), a technique that adapts a pre-trained model during testing using only unlabelled test data before making predictions. We adopt two common TTA methods, TTT and TENT, and a state-of-the-art method CoNMix, and investigate their respective performance on two popular audio classification datasets, AudioMNIST (AM) and SpeechCommands V1 (SC), against different types of background noise and noise severity levels. The experimental results reveal that our proposed modified version of CoNMix produced the highest classification accuracy under domain shift (5.31% error rate under 10 dB exercise bike background noise and 12.75% error rate under 3 dB running tap background noise for AM) compared to TTT and TENT. The literature search provided no evidence of similar works, thereby motivating the work reported here as the first study to leverage TTA techniques for audio classification under domain shift.
<div id='section'>Paperid: <span id='pid'>555, <a href='https://arxiv.org/pdf/2506.17442.pdf' target='_blank'>https://arxiv.org/pdf/2506.17442.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Guan, David Bates, Li Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.17442">Keeping Medical AI Healthy: A Review of Detection and Correction Methods for System Degradation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Artificial intelligence (AI) is increasingly integrated into modern healthcare, offering powerful support for clinical decision-making. However, in real-world settings, AI systems may experience performance degradation over time, due to factors such as shifting data distributions, changes in patient characteristics, evolving clinical protocols, and variations in data quality. These factors can compromise model reliability, posing safety concerns and increasing the likelihood of inaccurate predictions or adverse outcomes. This review presents a forward-looking perspective on monitoring and maintaining the "health" of AI systems in healthcare. We highlight the urgent need for continuous performance monitoring, early degradation detection, and effective self-correction mechanisms. The paper begins by reviewing common causes of performance degradation at both data and model levels. We then summarize key techniques for detecting data and model drift, followed by an in-depth look at root cause analysis. Correction strategies are further reviewed, ranging from model retraining to test-time adaptation. Our survey spans both traditional machine learning models and state-of-the-art large language models (LLMs), offering insights into their strengths and limitations. Finally, we discuss ongoing technical challenges and propose future research directions. This work aims to guide the development of reliable, robust medical AI systems capable of sustaining safe, long-term deployment in dynamic clinical settings.
<div id='section'>Paperid: <span id='pid'>556, <a href='https://arxiv.org/pdf/2506.02081.pdf' target='_blank'>https://arxiv.org/pdf/2506.02081.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chihiro Maru, Shoetsu Sato
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.02081">RATFM: Retrieval-augmented Time Series Foundation Model for Anomaly Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Inspired by the success of large language models (LLMs) in natural language processing, recent research has explored the building of time series foundation models and applied them to tasks such as forecasting, classification, and anomaly detection. However, their performances vary between different domains and tasks. In LLM-based approaches, test-time adaptation using example-based prompting has become common, owing to the high cost of retraining. In the context of anomaly detection, which is the focus of this study, providing normal examples from the target domain can also be effective. However, time series foundation models do not naturally acquire the ability to interpret or utilize examples or instructions, because the nature of time series data used during training does not encourage such capabilities. To address this limitation, we propose a retrieval augmented time series foundation model (RATFM), which enables pretrained time series foundation models to incorporate examples of test-time adaptation. We show that RATFM achieves a performance comparable to that of in-domain fine-tuning while avoiding domain-dependent fine-tuning. Experiments on the UCR Anomaly Archive, a multi-domain dataset including nine domains, confirms the effectiveness of the proposed approach.
<div id='section'>Paperid: <span id='pid'>557, <a href='https://arxiv.org/pdf/2505.19607.pdf' target='_blank'>https://arxiv.org/pdf/2505.19607.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yewon Han, Seoyun Yang, Taesup Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.19607">Energy-based Preference Optimization for Test-time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-Time Adaptation (TTA) enhances model robustness by enabling adaptation to target distributions that differ from training distributions, improving real-world generalizability. Existing TTA approaches focus on adjusting the conditional distribution; however these methods often depend on uncertain predictions in the absence of label information, leading to unreliable performance. Energy-based frameworks suggest a promising alternative to address distribution shifts without relying on uncertain predictions, instead computing the marginal distribution of target data. However, they involve the critical challenge of requiring extensive SGLD sampling, which is impractical for test-time scenarios requiring immediate adaptation. In this work, we propose Energy-based Preference Optimization for Test-time Adaptation (EPOTTA), which is based on a sampling free strategy. We first parameterize the target model using a pretrained model and residual energy function, enabling marginal likelihood maximization of target data without sampling. Building on the observation that the parameterization is mathematically equivalent to DPO objective, we then directly adapt the model to a target distribution without explicitly training the residual. Our experiments verify that EPOTTA is well-calibrated and performant while achieving computational efficiency.
<div id='section'>Paperid: <span id='pid'>558, <a href='https://arxiv.org/pdf/2502.09026.pdf' target='_blank'>https://arxiv.org/pdf/2502.09026.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuan Wei, Xiuzhuang Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.09026">Billet Number Recognition Based on Test-Time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>During the steel billet production process, it is essential to recognize machine-printed or manually written billet numbers on moving billets in real-time. To address the issue of low recognition accuracy for existing scene text recognition methods, caused by factors such as image distortions and distribution differences between training and test data, we propose a billet number recognition method that integrates test-time adaptation with prior knowledge. First, we introduce a test-time adaptation method into a model that uses the DB network for text detection and the SVTR network for text recognition. By minimizing the model's entropy during the testing phase, the model can adapt to the distribution of test data without the need for supervised fine-tuning. Second, we leverage the billet number encoding rules as prior knowledge to assess the validity of each recognition result. Invalid results, which do not comply with the encoding rules, are replaced. Finally, we introduce a validation mechanism into the CTC algorithm using prior knowledge to address its limitations in recognizing damaged characters. Experimental results on real datasets, including both machine-printed billet numbers and handwritten billet numbers, show significant improvements in evaluation metrics, validating the effectiveness of the proposed method.
<div id='section'>Paperid: <span id='pid'>559, <a href='https://arxiv.org/pdf/2412.14103.pdf' target='_blank'>https://arxiv.org/pdf/2412.14103.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>RÃ©mi Marsal, Alexandre Chapoutot, Philippe Xu, David Filliat
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.14103">A Simple yet Effective Test-Time Adaptation for Zero-Shot Monocular Metric Depth Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The recent development of foundation models for monocular depth estimation such as Depth Anything paved the way to zero-shot monocular depth estimation. Since it returns an affine-invariant disparity map, the favored technique to recover the metric depth consists in fine-tuning the model. However, this stage is not straightforward, it can be costly and time-consuming because of the training and the creation of the dataset. The latter must contain images captured by the camera that will be used at test time and the corresponding ground truth. Moreover, the fine-tuning may also degrade the generalizing capacity of the original model. Instead, we propose in this paper a new method to rescale Depth Anything predictions using 3D points provided by sensors or techniques such as low-resolution LiDAR or structure-from-motion with poses given by an IMU. This approach avoids fine-tuning and preserves the generalizing power of the original depth estimation model while being robust to the noise of the sparse depth or of the depth model. Our experiments highlight enhancements relative to zero-shot monocular metric depth estimation methods, competitive results compared to fine-tuned approaches and a better robustness than depth completion approaches. Code available at https://gitlab.ensta.fr/ssh/monocular-depth-rescaling.
<div id='section'>Paperid: <span id='pid'>560, <a href='https://arxiv.org/pdf/2411.07567.pdf' target='_blank'>https://arxiv.org/pdf/2411.07567.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Muhammad F. A. Chaudhary, Stephanie M. Aguilera, Arie Nakhmani, Joseph M. Reinhardt, Surya P. Bhatt, Sandeep Bodduluri
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.07567">Uncertainty-Aware Test-Time Adaptation for Inverse Consistent Diffeomorphic Lung Image Registration</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Diffeomorphic deformable image registration ensures smooth invertible transformations across inspiratory and expiratory chest CT scans. Yet, in practice, deep learning-based diffeomorphic methods struggle to capture large deformations between inspiratory and expiratory volumes, and therefore lack inverse consistency. Existing methods also fail to account for model uncertainty, which can be useful for improving performance. We propose an uncertainty-aware test-time adaptation framework for inverse consistent diffeomorphic lung registration. Our method uses Monte Carlo (MC) dropout to estimate spatial uncertainty that is used to improve model performance. We train and evaluate our method for inspiratory-to-expiratory CT registration on a large cohort of 675 subjects from the COPDGene study, achieving a higher Dice similarity coefficient (DSC) between the lung boundaries (0.966) compared to both VoxelMorph (0.953) and TransMorph (0.953). Our method demonstrates consistent improvements in the inverse registration direction as well with an overall DSC of 0.966, higher than VoxelMorph (0.958) and TransMorph (0.956). Paired t-tests indicate statistically significant improvements.
<div id='section'>Paperid: <span id='pid'>561, <a href='https://arxiv.org/pdf/2409.13106.pdf' target='_blank'>https://arxiv.org/pdf/2409.13106.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jinho Park, Se Young Chun, Mingoo Seok
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.13106">UL-VIO: Ultra-lightweight Visual-Inertial Odometry with Noise Robust Test-time Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Data-driven visual-inertial odometry (VIO) has received highlights for its performance since VIOs are a crucial compartment in autonomous robots. However, their deployment on resource-constrained devices is non-trivial since large network parameters should be accommodated in the device memory. Furthermore, these networks may risk failure post-deployment due to environmental distribution shifts at test time. In light of this, we propose UL-VIO -- an ultra-lightweight (<1M) VIO network capable of test-time adaptation (TTA) based on visual-inertial consistency. Specifically, we perform model compression to the network while preserving the low-level encoder part, including all BatchNorm parameters for resource-efficient test-time adaptation. It achieves 36X smaller network size than state-of-the-art with a minute increase in error -- 1% on the KITTI dataset. For test-time adaptation, we propose to use the inertia-referred network outputs as pseudo labels and update the BatchNorm parameter for lightweight yet effective adaptation. To the best of our knowledge, this is the first work to perform noise-robust TTA on VIO. Experimental results on the KITTI, EuRoC, and Marulan datasets demonstrate the effectiveness of our resource-efficient adaptation method under diverse TTA scenarios with dynamic domain shifts.
<div id='section'>Paperid: <span id='pid'>562, <a href='https://arxiv.org/pdf/2310.01291.pdf' target='_blank'>https://arxiv.org/pdf/2310.01291.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jonathan Samuel Lumentut, Kyoung Mu Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.01291">3DHR-Co: A Collaborative Test-time Refinement Framework for In-the-Wild 3D Human-Body Reconstruction Task</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The field of 3D human-body reconstruction (abbreviated as 3DHR) that utilizes parametric pose and shape representations has witnessed significant advancements in recent years. However, the application of 3DHR techniques to handle real-world, diverse scenes, known as in-the-wild data, still faces limitations. The primary challenge arises as curating accurate 3D human pose ground truth (GT) for in-the-wild scenes is still difficult to obtain due to various factors. Recent test-time refinement approaches on 3DHR leverage initial 2D off-the-shelf human keypoints information to support the lack of 3D supervision on in-the-wild data. However, we observed that additional 2D supervision alone could cause the overfitting issue on common 3DHR backbones, making the 3DHR test-time refinement task seem intractable. We answer this challenge by proposing a strategy that complements 3DHR test-time refinement work under a collaborative approach. Specifically, we initially apply a pre-adaptation approach that works by collaborating various 3DHR models in a single framework to directly improve their initial outputs. This approach is then further combined with the test-time adaptation work under specific settings that minimize the overfitting issue to further boost the 3DHR performance. The whole framework is termed as 3DHR-Co, and on the experiment sides, we showed that the proposed work can significantly enhance the scores of common classic 3DHR backbones up to -34 mm pose error suppression, putting them among the top list on the in-the-wild benchmark data. Such achievement shows that our approach helps unveil the true potential of the common classic 3DHR backbones. Based on these findings, we further investigate various settings on the proposed framework to better elaborate the capability of our collaborative approach in the 3DHR task.
<div id='section'>Paperid: <span id='pid'>563, <a href='https://arxiv.org/pdf/2309.03879.pdf' target='_blank'>https://arxiv.org/pdf/2309.03879.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Linus Ericsson, Da Li, Timothy M. Hospedales
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.03879">Better Practices for Domain Adaptation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Distribution shifts are all too common in real-world applications of machine learning. Domain adaptation (DA) aims to address this by providing various frameworks for adapting models to the deployment data without using labels. However, the domain shift scenario raises a second more subtle challenge: the difficulty of performing hyperparameter optimisation (HPO) for these adaptation algorithms without access to a labelled validation set. The unclear validation protocol for DA has led to bad practices in the literature, such as performing HPO using the target test labels when, in real-world scenarios, they are not available. This has resulted in over-optimism about DA research progress compared to reality. In this paper, we analyse the state of DA when using good evaluation practice, by benchmarking a suite of candidate validation criteria and using them to assess popular adaptation algorithms. We show that there are challenges across all three branches of domain adaptation methodology including Unsupervised Domain Adaptation (UDA), Source-Free Domain Adaptation (SFDA), and Test Time Adaptation (TTA). While the results show that realistically achievable performance is often worse than expected, they also show that using proper validation splits is beneficial, as well as showing that some previously unexplored validation metrics provide the best options to date. Altogether, our improved practices covering data, training, validation and hyperparameter optimisation form a new rigorous pipeline to improve benchmarking, and hence research progress, within this important field going forward.
<div id='section'>Paperid: <span id='pid'>564, <a href='https://arxiv.org/pdf/2510.05530.pdf' target='_blank'>https://arxiv.org/pdf/2510.05530.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Harshil Vejendla
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.05530">LATTA: Langevin-Anchored Test-Time Adaptation for Enhanced Robustness and Stability</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) aims to adapt a pretrained model to distribution shifts using only unlabeled test data. While promising, existing methods like Tent suffer from instability and can catastrophically forget the source knowledge, especially with small batch sizes or challenging corruptions. We argue that this arises from overly deterministic updates on a complex loss surface. In this paper, we introduce Langevin-Anchored Test-Time Adaptation (LATTA), a novel approach that regularizes adaptation through two key mechanisms: (1) a noisy weight perturbation inspired by Stochastic Gradient Langevin Dynamics (SGLD) to explore the local parameter space and escape poor local minima, and (2) a stable weight anchor that prevents the model from diverging from its robust source pre-training. This combination allows LATTA to adapt effectively without sacrificing stability. Unlike prior Bayesian TTA methods, LATTA requires no architectural changes or expensive Monte Carlo passes. We conduct extensive experiments on standard benchmarks, including Rotated-MNIST and the more challenging CIFAR-10-C. Our results demonstrate that LATTA significantly outperforms existing methods, including Tent, CoTTA, and EATA, setting a new state of the art for self-supervised TTA by improving average accuracy on CIFAR-10-C by over 2% while simultaneously reducing performance variance.
<div id='section'>Paperid: <span id='pid'>565, <a href='https://arxiv.org/pdf/2510.05530.pdf' target='_blank'>https://arxiv.org/pdf/2510.05530.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Harshil Vejendla
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.05530">LATTA: Langevin-Anchored Test-Time Adaptation for Enhanced Robustness and Stability</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Test-time adaptation (TTA) aims to adapt a pretrained model to distribution shifts using only unlabeled test data. While promising, existing methods like Tent suffer from instability and can catastrophically forget the source knowledge, especially with small batch sizes or challenging corruptions. We argue that this arises from overly deterministic updates on a complex loss surface. In this paper, we introduce Langevin-Anchored Test-Time Adaptation (LATTA), a novel approach that regularizes adaptation through two key mechanisms: (1) a noisy weight perturbation inspired by Stochastic Gradient Langevin Dynamics (SGLD) to explore the local parameter space and escape poor local minima, and (2) a stable weight anchor that prevents the model from diverging from its robust source pre-training. This combination allows LATTA to adapt effectively without sacrificing stability. Unlike prior Bayesian TTA methods, LATTA requires no architectural changes or expensive Monte Carlo passes. We conduct extensive experiments on standard benchmarks, including Rotated-MNIST and the more challenging CIFAR-10-C. Our results demonstrate that LATTA significantly outperforms existing methods, including Tent, CoTTA, and EATA, setting a new state of the art for self-supervised TTA by improving average accuracy on CIFAR-10-C by over 2% while simultaneously reducing performance variance.
<div id='section'>Paperid: <span id='pid'>566, <a href='https://arxiv.org/pdf/2505.16257.pdf' target='_blank'>https://arxiv.org/pdf/2505.16257.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Masanari Kimura
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.16257">Higher-Order Asymptotics of Test-Time Adaptation for Batch Normalization Statistics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study develops a higher-order asymptotic framework for test-time adaptation (TTA) of Batch Normalization (BN) statistics under distribution shift by integrating classical Edgeworth expansion and saddlepoint approximation techniques with a novel one-step M-estimation perspective. By analyzing the statistical discrepancy between training and test distributions, we derive an Edgeworth expansion for the normalized difference in BN means and obtain an optimal weighting parameter that minimizes the mean-squared error of the adapted statistic. Reinterpreting BN TTA as a one-step M-estimator allows us to derive higher-order local asymptotic normality results, which incorporate skewness and other higher moments into the estimator's behavior. Moreover, we quantify the trade-offs among bias, variance, and skewness in the adaptation process and establish a corresponding generalization bound on the model risk. The refined saddlepoint approximations further deliver uniformly accurate density and tail probability estimates for the BN TTA statistic. These theoretical insights provide a comprehensive understanding of how higher-order corrections and robust one-step updating can enhance the reliability and performance of BN layers in adapting to changing data distributions.
